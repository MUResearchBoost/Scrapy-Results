abstract,authors,id,title,url
"BACKGROUND:Medical simulation has become an essential educational tool in the curricula of healthcare professionals. A literature review revealed a knowledge gap in healthcare simulation education with respect to the technological expertise required to operate highly sophisticated simulation equipment. With this motivation, a case study was designed to determine if implementing on-site technological expertise allows for the facile navigation of high fidelity manikins. Next, a research study was conducted to evaluate engineering students understanding of simulation, and their interest to attend a program in medical simulation. OBJECTIVES:To determine if on-site technological expertise lifts barriers associated with manikin use and to assess levels of understanding and interest among engineering students following exposure to the technology used in healthcare simulation. DESIGN:A prospective, descriptive study with pre-post surveys. SETTINGS:The Nursing Skills and Simulation Center at a New England University campus. PARTICIPANTS:Engineering students attending 6 different engineering programs (Computer Science, Computer Engineering, Mechanical Engineering, Biomedical Engineering, Electrical Engineering and Technology Management) and having different educational levels (undergraduate and graduate). METHODS:Two assessments were applied to engineering students attending a class on technology used in healthcare simulation. A pre-test measured the understanding and interest of students in the engineering/computer science courses before attending a simulation class. A post-test assessment measured their improvement in understanding and interest to learn more about simulation technologies. RESULTS:Statistical analysis and comparisons of pre-and post-test assessments show a 23% gain in understanding of this field following exposure to the healthcare simulation class. Furthermore, post test results show greater than 67% of those surveyed have an interest in attending a program in healthcare simulation. CONCLUSIONS:The results indicate the collaboration of nursing and engineering has lifted known barriers to simulation education, and reveal engineering students have an interest in the field of medical simulation.","Papp C
Deeb RS
Booth C
El-Sayed A
Freilicher T
","(PMID:30205258
)",Bridging medical simulation with computer science and engineering: A growing field of study.,https://europepmc.org/abstract/MED/30205258%0A
"This paper addresses two questions related to reproducibility within the context of research related to computer science. First, requirements on reproducibility are analyzed based on a survey addressed to researchers in the academic and private sector. The survey indicates a strong need for open but also easily accessible results, thus reproducing an experiment should not require too much effort. The results from the survey are then used to formulate general guidelines for making research results reproducible. In addition, this paper explores a number of existing software tools that could bring forward reproducibility in research results. After a general analysis of tools a further investigation is done via three case studies based on actual research projects which are used to evaluate the previously introduced tools. Results indicate that due to conflicting requirements, none of the presented solutions fulfills all intended goals perfectly. However, we present requirements and guidelines for making research reproducible. While the main focus of this paper is on reproducibility in computer science, the results of this paper are still valid for other fields using computation as a tool.","Elmenreich W
Moll P
Theuermann S
Lux M
","(PPR:PPR46281
)",Making computer science results reproducible - A case study using Gradle and Docker,https://europepmc.org/abstract/PPR/PPR46281%0A
"The aim of the present study is to investigate both the performance and preferences of males and females Computer Science (CS) graduates. In order to attain the above goal, a quantitative case study was conducted regarding 89 degrees, acquired from 2006 to 2012, from the Department of Computer Science and Technology, University of Peloponnese, Greece. The analysis of the data revealed that in terms of performance, no significant differences between the mean grades of males and females exist, in almost most of the courses included in the curriculum of the aforementioned CS department. Any statistically significant differences in performances were present in almost equal number of courses in favor of males and females. It seems also, that females performed better in the courses they selected more than males. Regarding preferences, in CS courses, it seems that gender differences are existent. Males preferred more than females did core programming courses and advanced topics of Software Systems, computer networks, computer engineering, robotics and mathematics, whereas females preferred more the study of algorithms and security issues, computer fractals, data management, computer architecture, and mobile communication. In addition, females preferred courses in reference with humanities and social sciences, CS terminology, and career opportunities. Yet, females did not select any of programming lab-based courses, computer engineering, computer network issues and robotics.","Berdousis I
Kordaki M
","(PPR:PPR50534
)",Gender Gap in Computer Science: Preferences and Performance,https://europepmc.org/abstract/PPR/PPR50534%0A
"As computer scientists working in bioinformatics/computational biology, we often face the challenge of coming up with an algorithm to answer a biological question. This occurs in many areas, such as variant calling, alignment and assembly. In this tutorial, we use the example of the genome assembly problem to demonstrate how to go from a question in the biological realm to a solution in the computer science realm. We show the modeling process step-by-step, including all the intermediate failed attempts. Please note this is not an introduction to how genome assembly algorithms work and, if treated as such, would be incomplete and unnecessarily long-winded.","Medvedev P
","(PMID:29394324
)",Modeling biological problems in computer science: a case study in genome assembly.,https://europepmc.org/abstract/MED/29394324%0A
No abstract provided.,"Schramm S
","(PMID:29052633
)",Computer science: Data analysis meets quantum physics.,https://europepmc.org/abstract/MED/29052633%0A
"Connecting the dots among the amino acid sequence of a protein, its structure, and its function remains a central theme in molecular biology, as it would have many applications in the treatment of illnesses related to misfolding or protein instability. As a result of high-throughput sequencing methods, biologists currently live in a protein sequence-rich world. However, our knowledge of protein structure based on experimental data remains comparatively limited. As a consequence, protein structure prediction has established itself as a very active field of research to fill in this gap. This field, once thought to be reserved for theoretical biophysicists, is constantly reinventing itself, borrowing ideas informed by an ever-increasing assembly of scientific domains, from biology, chemistry, (statistical) physics, mathematics, computer science, statistics, bioinformatics, and more recently data sciences. We review the recent progress arising from this integration of knowledge, from the development of specific computer architecture to allow for longer timescales in physics-based simulations of protein folding to the recent advances in predicting contacts in proteins based on detection of coevolution using very large data sets of aligned protein sequences.","Delarue M
Koehl P
","(PMID:30079234
 PMCID:PMC6058471)","Combined approaches from physics, statistics, and computer science for ab initio protein structure prediction: ex unitate vires (unity is strength)?",https://europepmc.org/abstract/MED/30079234%0A
"Connecting the dots among the amino acid sequence of a protein, its structure, and its function remains a central theme in molecular biology, as it would have many applications in the treatment of illnesses related to misfolding or protein instability. As a result of high-throughput sequencing methods, biologists currently live in a protein sequence-rich world. However, our knowledge of protein structure based on experimental data remains comparatively limited. As a consequence, protein structure prediction has established itself as a very active field of research to fill in this gap. This field, once thought to be reserved for theoretical biophysicists, is constantly reinventing itself, borrowing ideas informed by an ever-increasing assembly of scientific domains, from biology, chemistry, (statistical) physics, mathematics, computer science, statistics, bioinformatics, and more recently data sciences. We review the recent progress arising from this integration of knowledge, from the development of specific computer architecture to allow for longer timescales in physics-based simulations of protein folding to the recent advances in predicting contacts in proteins based on detection of coevolution using very large data sets of aligned protein sequences.","Delarue M
Koehl P
","(PPR:PPR45704
)","Combined approaches from physics, statistics, and computer science for ab initio protein structure prediction: ex unitate vires (unity is strength)?",https://europepmc.org/abstract/PPR/PPR45704%0A
"The recent ""incentive auction"" of the US Federal Communications Commission was the first auction to reallocate radio frequencies between two different kinds of uses: from broadcast television to wireless Internet access. The design challenge was not just to choose market rules to govern a fixed set of potential trades but also, to determine the broadcasters' property rights, the goods to be exchanged, the quantities to be traded, the computational procedures, and even some of the performance objectives. An essential and unusual challenge was to make the auction simple enough for human participants while still ensuring that the computations would be tractable and capable of delivering nearly efficient outcomes.","Leyton-Brown K
Milgrom P
Segal I
","(PMID:28652335
 PMCID:PMC5514724)",Economics and computer science of a radio spectrum reallocation.,https://europepmc.org/abstract/MED/28652335%0A
No abstract provided.,"Cardelli L
Hernansaiz-Ballesteros RD
Dalchau N
Csikász-Nagy A
","(PMID:28056093
 PMCID:PMC5215766)",Efficient Switches in Biology and Computer Science.,https://europepmc.org/abstract/MED/28056093%0A
"This special issue on advancing interdisciplinary collaboration between computer scientists and social scientists documents the joint results of the international Lorentz workshop, ""Interdisciplinary Insights into Group and Team Dynamics,"" which took place in Leiden, The Netherlands, July 2016. An equal number of scholars from social and computer science participated in the workshop and contributed to the papers included in this special issue. In this introduction, we first identify interaction dynamics as the core of group and team models and review how scholars in social and computer science have typically approached behavioral interactions in groups and teams. Next, we identify key challenges for interdisciplinary collaboration between social and computer scientists, and we provide an overview of the different articles in this special issue aimed at addressing these challenges.","Lehmann-Willenbrock N
Hung H
Keyton J
","(PMID:29249891
 PMCID:PMC5700772)",New Frontiers in Analyzing Dynamic Group Interactions: Bridging Social and Computer Science.,https://europepmc.org/abstract/MED/29249891%0A
"Computing is highly segregated and stratified by gender. While there is abundant scholarship investigating this problem, emerging evidence suggests that a hierarchy of value exists between the social and technical dimensions of Computer Science and Engineering (CSE) and this plays a role in the underrepresentation of women in the field. This ethnographic study of women's experiences in computing offers evidence of a systemic preference for the technical dimensions of computing over the social and a correlation between gender and social aspirations. Additionally, it suggests there is a gap between the exaltation of computing's social contributions and the realities of them. My participants expressed a yearning to contribute to the collective well-being of society using their computing skills. I trace moments of rupture in my participants' stories, moments when they felt these aspirations were in conflict with the cultural values in their organizations. I interpret these ruptures within a consideration of yearning, a need my participants had to contribute meaningfully to society that remained unfulfilled. The yearning to align one's altruistic values with one's careers aspirations in CSE illuminates an area for greater exploration on the path to realizing gender equity in computing. I argue that before a case can be made that careers in computing do indeed contribute to social and civil engagements, we must first address the meaning of the social within the values, ideologies and practices of CSE institutions and next, develop ways to measure and evaluate the field's contributions to society.","Carrigan CM
","(PMID:28790936
 PMCID:PMC5513966)",Yearning to Give Back: Searching for Social Purpose in Computer Science and Engineering.,https://europepmc.org/abstract/MED/28790936%0A
"The absence of accessibility in many ICT systems and products indicates insufficient accessibility competence among designers, developers and project managers. Higher education institutions play an important role in raising awareness and competence and in preparing universal design and digital accessibility specialists. Although many universities are teaching accessibility as part of the biomedical, special education and disability studies programmes, few provide accessibility education in technical specialisations such as computer science. By combining literature review and manual search and inspection we aim at investigating the state of the art in integrating universal design and digital accessibility into the curricula of computer sciences-related programmes.","Nishchyk A
Chen W
","(PMID:30371460
)",Integrating Universal Design and Accessibility into Computer Science Curricula - A Review of Literature and Practices in Europe.,https://europepmc.org/abstract/MED/30371460%0A
"While the underrepresentation of women in the fast-growing STEM field of computer science (CS) has been much studied, no consensus exists on the key factors influencing this widening gender gap. Possible suspects include gender differences in aptitude, interest, and academic environment. Our study contributes to this literature by applying student engagement research to study the experiences of college students studying CS, to assess the degree to which differences in men and women's engagement may help account for gender inequity in the field. Specifically, we use the Experience Sampling Method (ESM) to evaluate in real-time the engagement of college students during varied activities and environments. Over the course of a full week in fall semester and a full week in spring semester, 165 students majoring in CS at two Research I universities were ""beeped"" several times a day via a smartphone app prompting them to fill out a short questionnaire including open-ended and scaled items. These responses were paired with administrative and over 2 years of transcript data provided by their institutions. We used mean comparisons and logistic regression analysis to compare enrollment and persistence patterns among CS men and women. Results suggest that despite the obstacles associated with women's underrepresentation in computer science, women are more likely to continue taking computer science courses when they felt challenged and skilled in their initial computer science classes. We discuss implications for further research.","Milesi C
Perez-Felkner L
Brown K
Schneider B
","(PMID:28487664
 PMCID:PMC5403895)","Engagement, Persistence, and Gender in Computer Science: Results of a Smartphone ESM Study.",https://europepmc.org/abstract/MED/28487664%0A
"We suggest that in the framework of the Category Theory it is possible to demonstrate the mathematical and logical dual equivalence between the category of the q-deformed Hopf Coalgebras and the category of the q-deformed Hopf Algebras in quantum field theory (QFT), interpreted as a thermal field theory. Each pair algebra-coalgebra characterizes a QFT system and its mirroring thermal bath, respectively, so to model dissipative quantum systems in far-from-equilibrium conditions, with an evident significance also for biological sciences. Our study is in fact inspired by applications to neuroscience where the brain memory capacity, for instance, has been modeled by using the QFT unitarily inequivalent representations. The q-deformed Hopf Coalgebras and the q-deformed Hopf Algebras constitute two dual categories because characterized by the same functor T, related with the Bogoliubov transform, and by its contravariant application Top, respectively. The q-deformation parameter is related to the Bogoliubov angle, and it is effectively a thermal parameter. Therefore, the different values of q identify univocally, and label the vacua appearing in the foliation process of the quantum vacuum. This means that, in the framework of Universal Coalgebra, as general theory of dynamic and computing systems (""labelled state-transition systems""), the so labelled infinitely many quantum vacua can be interpreted as the Final Coalgebra of an ""Infinite State Black-Box Machine"". All this opens the way to the possibility of designing a new class of universal quantum computing architectures based on this coalgebraic QFT formulation, as its ability of naturally generating a Fibonacci progression demonstrates.","Basti G
Capolupo A
Vitiello G
","(PMID:28479315
)",Quantum field theory and coalgebraic logic in theoretical computer science.,https://europepmc.org/abstract/MED/28479315%0A
"The requirement of employability in the job market prompted universities to conduct internship training as part of their study plans. There is a need to train students on important academic and professional skills related to the workplace with an IT component. This article describes a statistical study that measures satisfaction levels among students in the faculty of Information Technology and Computer Science in Jordan. The objective of this study is to explore factors that influence student satisfaction with regards to enrolling in an internship training program. The study was conducted to gather student perceptions, opinions, preferences and satisfaction levels related to the program. Data were collected via a mixed method survey (surveys and interviews) from student-respondents. The survey collects demographic and background information from students, including their perception of faculty performance in the training poised to prepare them for the job market. Findings from this study show that students expect internship training to improve their professional and personal skills as well as to increase their workplace-related satisfaction. It is concluded that improving the internship training is crucial among the students as it is expected to enrich their experiences, knowledge and skills in the personal and professional life. It is also expected to increase their level of confidence when it comes to exploring their future job opportunities in the Jordanian market.","Jaradat GM
","(PMID:28456017
)",Internship training in computer science: Exploring student satisfaction levels.,https://europepmc.org/abstract/MED/28456017%0A
"While women are generally underrepresented in STEM fields, there are noticeable differences between fields. For instance, the gender ratio in biology is more balanced than in computer science. We were interested in how this difference is reflected in the interdisciplinary field of computational/quantitative biology. To this end, we examined the proportion of female authors in publications from the PubMed and arXiv databases. There are fewer female authors on research papers in computational biology, as compared to biology in general. This is true across authorship position, year, and journal impact factor. A comparison with arXiv shows that quantitative biology papers have a higher ratio of female authors than computer science papers, placing computational biology in between its two parent fields in terms of gender representation. Both in biology and in computational biology, a female last author increases the probability of other authors on the paper being female, pointing to a potential role of female PIs in influencing the gender balance.","Bonham KS
Stefan MI
","(PMID:29023441
 PMCID:PMC5638210)","Women are underrepresented in computational biology: An analysis of the scholarly literature in biology, computer science and computational biology.",https://europepmc.org/abstract/MED/29023441%0A
No abstract provided.,authors field is NULL.,"(PMID:27680910
)",Computer science: Ancient scroll virtually unrolled.,https://europepmc.org/abstract/MED/27680910%0A
"Women are vastly underrepresented in the fields of computer science and engineering (CS&E). We examined whether women might view the intellectual characteristics of prototypical individuals in CS&E in more stereotype-consistent ways than men might and, consequently, show less interest in CS&E. We asked 269 U.S. college students (187, 69.5% women) to describe the prototypical computer scientist (Study 1) or engineer (Study 2) through open-ended descriptions as well as through a set of trait ratings. Participants also rated themselves on the same set of traits and rated their similarity to the prototype. Finally, participants in both studies were asked to describe their likelihood of pursuing future college courses and careers in computer science (Study 1) or engineering (Study 2). Across both studies, we found that women offered more stereotype-consistent ratings than did men of the intellectual characteristics of prototypes in CS (Study 1) and engineering (Study 2). Women also perceived themselves as less similar to the prototype than men did. Further, the observed gender differences in prototype perceptions mediated the tendency for women to report lower interest in CS&E fields relative to men. Our work highlights the importance of prototype perceptions for understanding the gender gap in CS&E and suggests avenues for interventions that may increase women's representation in these vital fields.","Ehrlinger J
Plant EA
Hartwig MK
Vossen JJ
Columb CJ
Brewer LE
","(PMID:29367799
 PMCID:PMC5756563)",Do Gender Differences in Perceived Prototypical Computer Scientists and Engineers Contribute to Gender Gaps in Computer Science and Engineering?,https://europepmc.org/abstract/MED/29367799%0A
"The present paper provides insight into an emerging research discipline called Psychoinformatics. In the context of Psychoinformatics, we emphasize the cooperation between the disciplines of psychology and computer science in handling large data sets derived from heavily used devices, such as smartphones or online social network sites, in order to shed light on a large number of psychological traits, including personality and mood. New challenges await psychologists in light of the resulting ""Big Data"" sets, because classic psychological methods will only in part be able to analyze this data derived from ubiquitous mobile devices, as well as other everyday technologies. As a consequence, psychologists must enrich their scientific methods through the inclusion of methods from informatics. The paper provides a brief review of one area of this research field, dealing mainly with social networks and smartphones. Moreover, we highlight how data derived from Psychoinformatics can be combined in a meaningful way with data from human neuroscience. We close the paper with some observations of areas for future research and problems that require consideration within this new discipline.","Montag C
Duke É
Markowetz A
","(PMID:27403204
 PMCID:PMC4923556)",Toward Psychoinformatics: Computer Science Meets Psychology.,https://europepmc.org/abstract/MED/27403204%0A
No abstract provided.,"Lisman JE
","(PMID:28690580
 PMCID:PMC5481348)",Locke's View of the Hard Problem of Consciousness and Its Implications for Neuroscience and Computer Science.,https://europepmc.org/abstract/MED/28690580%0A
"The University of Pittsburgh's Department of Biomedical Informatics and Division of Pathology Informatics created a Science, Technology, Engineering, and Mathematics (STEM) pipeline in 2011 dedicated to providing cutting-edge informatics research and career preparatory experiences to a diverse group of highly motivated high-school students. In this third editorial installment describing the program, we provide a brief overview of the pipeline, report on achievements of the past scholars, and present results from self-reported assessments by the 2015 cohort of scholars. The pipeline continues to expand with the 2015 addition of the innovation internship, and the introduction of a program in 2016 aimed at offering first-time research experiences to undergraduates who are underrepresented in pathology and biomedical informatics. Achievements of program scholars include authorship of journal articles, symposium and summit presentations, and attendance at top 25 universities. All of our alumni matriculated into higher education and 90% remain in STEM majors. The 2015 high-school program had ten participating scholars who self-reported gains in confidence in their research abilities and understanding of what it means to be a scientist.","King AJ
Fisher AM
Becich MJ
Boone DN
","(PMID:28400991
 PMCID:PMC5359992)","Computer Science, Biology and Biomedical Informatics academy: Outcomes from 5 years of Immersing High-school Students into Informatics Research.",https://europepmc.org/abstract/MED/28400991%0A
"In this age of data-driven science and high-throughput biology, computational thinking is becoming an increasingly important skill for tackling both new and long-standing biological questions. However, despite its obvious importance and conspicuous integration into many areas of biology, computer science is still viewed as an obscure field that has, thus far, permeated into only a few of the biology curricula across the nation. A national survey has shown that lack of computational literacy in environmental sciences is the norm rather than the exception [Valle & Berdanier (2012) Bulletin of the Ecological Society of America, 93, 373-389]. In this article, we seek to introduce a few important concepts in computer science with the aim of providing a context-specific introduction aimed at research biologists. Our goal was to help biologists understand some of the most important mainstream computational concepts to better appreciate bioinformatics methods and trade-offs that are not obvious to the uninitiated.","Belcaid M
Toonen RJ
","(PMID:25824671
)",Demystifying computer science for molecular ecologists.,https://europepmc.org/abstract/MED/25824671%0A
No abstract provided.,"You J
","(PMID:25574001
)",Computer science. Beyond the Turing Test.,https://europepmc.org/abstract/MED/25574001%0A
"A century ago, the Welch-Rose Report established a public health education system in the United States. Since then, the system has evolved to address emerging health needs and integrate new technologies. Today, personalized health technologies generate large amounts of data. Emerging computer science techniques, such as machine learning, present an opportunity to extract insights from these data that could help identify high-risk individuals and tailor health interventions and recommendations. As these technologies play a larger role in health promotion, collaboration between the public health and technology communities will become the norm. Offering public health trainees coursework in computer science alongside traditional public health disciplines will facilitate this evolution, improving public health's capacity to harness these technologies to improve population health.","Kunkle S
Christie G
Yach D
El-Sayed AM
","(PMID:27227145
 PMCID:PMC4869246)",The Importance of Computer Science for Public Health Training: An Opportunity and Call to Action.,https://europepmc.org/abstract/MED/27227145%0A
No abstract provided.,"Legenstein R
","(PMID:25951279
)",Computer science: Nanoscale connections for brain-like circuits.,https://europepmc.org/abstract/MED/25951279%0A
"Chromosome conformation capture techniques are producing a huge amount of data about the architecture of our genome. These data can provide us with a better understanding of the events that induce critical regulations of the cellular function from small changes in the three-dimensional genome architecture. Generating a unified view of spatial, temporal, genetic and epigenetic properties poses various challenges of data analysis, visualization, integration and mining, as well as of high performance computing and big data management. Here, we describe the critical issues of this new branch of bioinformatics, oriented at the comprehension of the three-dimensional genome architecture, which we call 'Nucleome Bioinformatics', looking beyond the currently available tools and methods, and highlight yet unaddressed challenges and the potential approaches that could be applied for tackling them. Our review provides a map for researchers interested in using computer science for studying 'Nucleome Bioinformatics', to achieve a better understanding of the biological processes that occur inside the nucleus.","Shavit Y
Merelli I
Milanesi L
Lio' P
","(PMID:26433013
)",How computer science can help in understanding the 3D genome architecture.,https://europepmc.org/abstract/MED/26433013%0A
No abstract provided.,"Sandholm T
","(PMID:25574004
)",Computer science. Solving imperfect-information games.,https://europepmc.org/abstract/MED/25574004%0A
No abstract provided.,"Nelson B
","(PMID:24579095
)",Computer science: Hacking into the cyberworld.,https://europepmc.org/abstract/MED/24579095%0A
"Several studies have estimated the potential economic and social impact of the mHealth development. Considering the latest study by Institute for Healthcare Informatics, more than 165.000 apps of health and medicine are offered including all the stores from different platforms. Thus, the global mHealth market was an estimated $10.5 billion in 2014 and is expected to grow 33.5 percent annually between 2015 and 2020s. In fact, apps of Health have become the third-fastest growing category, only after games and utilities.This study aims to identify, study and evaluate the role of interdisciplinary research teams in the development of articles and applications in the field of mHealth. It also aims to evaluate the impact that the development of mHealth has had on the health and computer science field, through the study of publications in specific databases for each area which have been published until nowadays.Interdisciplinary nature is strongly connected to the scientific quality of the journal in which the work is published. This way, there are significant differences in those works that are made up by an interdisciplinary research team because of they achieve to publish in journals with higher quartiles. There are already studies that warn of methodological deficits in some studies in mHealth, low accuracy and no reproducibility. Studies of low precision and poor reproducibility, coupled with the low evidence, provide low degrees of recommendation of the interventions targeted and therefore low applicability.From the evidence of this study, working in interdisciplinary groups from different areas greatly enhances the quality of research work as well as the quality of the publications derived from its results.","Molina Recio G
García-Hernández L
Molina Luque R
Salas-Morera L
","(PMID:27454164
 PMCID:PMC4959385)",The role of interdisciplinary research team in the impact of health apps in health and computer science publications: a systematic review.,https://europepmc.org/abstract/MED/27454164%0A
No abstract provided.,"Jones N
","(PMID:24402264
)",Computer science: The learning machines.,https://europepmc.org/abstract/MED/24402264%0A
No abstract provided.,"Evans JA
","(PMID:24092715
)",Computer science. Future science.,https://europepmc.org/abstract/MED/24092715%0A
"In recent years, several publications in computer science journals have proposed new heuristic methods for parsimony analysis. This contribution discusses those papers, including methods highly praised by their authors, such as Hydra, Sampars and GA + PR + LS. Trees of comparable or better scores can be obtained using the program TNT, but from one to three orders of magnitude faster. In some cases, the search methods are very similar to others long in use in phylogenetics, but the enormous speed differences seem to correspond more to poor implementations than to actual differences in the methods themselves.","Goloboff PA
","(AGR:IND601329307
)","Computer science and parsimony: a reappraisal, with discussion of methods for poorly structured datasets",https://europepmc.org/abstract/AGR/IND601329307%0A
No abstract provided.,"Barton NH
Novak S
Paixão T
","(PMID:25009183
 PMCID:PMC4115508)",Diverse forms of selection in evolution and computer science.,https://europepmc.org/abstract/MED/25009183%0A
No abstract provided.,"Cho A
","(PMID:24948715
)","Computer science. Quantum or not, controversial computer yields no speedup.",https://europepmc.org/abstract/MED/24948715%0A
"Poker is a family of games that exhibit imperfect information, where players do not have full knowledge of past events. Whereas many perfect-information games have been solved (e.g., Connect Four and checkers), no nontrivial imperfect-information game played competitively by humans has previously been solved. Here, we announce that heads-up limit Texas hold'em is now essentially weakly solved. Furthermore, this computation formally proves the common wisdom that the dealer in the game holds a substantial advantage. This result was enabled by a new algorithm, CFR(+), which is capable of solving extensive-form games orders of magnitude larger than previously possible.","Bowling M
Burch N
Johanson M
Tammelin O
","(PMID:25574016
)",Computer science. Heads-up limit hold'em poker is solved.,https://europepmc.org/abstract/MED/25574016%0A
"Despite having made significant inroads into many traditionally male-dominated fields (e.g., biology, chemistry), women continue to be underrepresented in computer science and engineering. We propose that students' stereotypes about the culture of these fields-including the kind of people, the work involved, and the values of the field-steer girls away from choosing to enter them. Computer science and engineering are stereotyped in modern American culture as male-oriented fields that involve social isolation, an intense focus on machinery, and inborn brilliance. These stereotypes are compatible with qualities that are typically more valued in men than women in American culture. As a result, when computer science and engineering stereotypes are salient, girls report less interest in these fields than their male peers. However, altering these stereotypes-by broadening the representation of the people who do this work, the work itself, and the environments in which it occurs-significantly increases girls' sense of belonging and interest in the field. Academic stereotypes thus serve as gatekeepers, driving girls away from certain fields and constraining their learning opportunities and career aspirations.","Cheryan S
Master A
Meltzoff AN
","(PMID:25717308
 PMCID:PMC4323745)",Cultural stereotypes as gatekeepers: increasing girls' interest in computer science and engineering by diversifying stereotypes.,https://europepmc.org/abstract/MED/25717308%0A
"This paper presents an applied concept of a brain-computer interface (BCI) student research laboratory (BCI-LAB) at the Life Science Center of TARA, University of Tsukuba, Japan. Several successful case studies of the student projects are reviewed together with the BCI Research Award 2014 winner case. The BCI-LAB design and project-based teaching philosophy is also explained. Future teaching and research directions summarize the review.","Rutkowski TM
","(PMID:26737088
)",Student teaching and research laboratory focusing on brain-computer interface paradigms--A creative environment for computer science students.,https://europepmc.org/abstract/MED/26737088%0A
No abstract provided.,"Recupero DR
","(PMID:23539588
)",Computer science. Toward a green Internet.,https://europepmc.org/abstract/MED/23539588%0A
"Over the past century, medical imaging has brought a new revolution: internal anatomy of a patient could be seen without any invasive technique. This revolution has highlighted the two main limits of current anatomy: the anatomical description is physician dependent, and the average anatomy is more and more frequently insufficient to describe anatomical variations. These drawbacks can sometimes be so important that they create mistakes but they can be overcome through the use of 3D patient-specific surgical anatomy.In this article, we propose to illustrate such improvement of standard anatomy on liver. We first propose a general scheme allowing to easily compare the four main liver anatomical descriptions by Takasaki, Goldsmith and Woodburne, Bismuth and Couinaud. From this general scheme we propose four rules to apply in order to correct these initial anatomical definitions. Application of these rules allows to correct usual vascular topological mistakes of standard anatomy. We finally validate such correction on a database of 20 clinical cases compared to the 111 clinical cases of a Couinaud article.Out of the 20 images of the database, we note a revealing difference in 14 cases (70%) on at least one important branch of the portal network. Only six cases (30%) do not present a revealing difference between both labellings. We also show that the right portal fissure location on our 20 cases defined between segment V and VI of our anatomical definition is well correlated with the real position described by Couinaud on 111 cases, knowing that the theoretical position was only found in 46 cases out of 111, i.e., 41.44% of cases with the non-corrected Couinaud definition.We have proposed a new anatomical segmentation of the liver based on four main rules to apply in order to correct topological errors of the four main standard segmentations. Our validation clearly illustrates that this new definition corrects the large amount of mistakes created by the current standard definitions, increased by physician interpretation that can vary from one case to another.","Soler L
Mutter D
Pessaux P
Marescaux J
","(PMID:29075611
 PMCID:PMC5638021)",Patient specific anatomy: the new area of anatomy based on computer science illustrated on liver.,https://europepmc.org/abstract/MED/29075611%0A
"Research productivity assessment is increasingly relevant for allocation of research funds. On one hand, this assessment is challenging because it involves both qualitative and quantitative analysis of several characteristics, most of them subjective in nature. On the other hand, current tools and academic social networks make bibliometric data web-available to everyone for free. Those tools, especially when combined with other data, are able to create a rich environment from which information on research productivity can be extracted. In this context, our work aims at characterizing the Brazilian Computer Science graduate programs and the relationship among themselves. We (i) present views of the programs from different perspectives, (ii) rank the programs according to each perspective and a combination of them, (iii) show correlation between assessment metrics, (iv) discuss how programs relate to another, and (v) infer aspects that boost programs' research productivity. The results indicate that programs with a higher insertion in the coauthorship network topology also possess a higher research productivity between 2004 and 2009.","Digiampietri LA
Mena-Chalco JP
Vaz de Melo PO
Malheiro AP
Meira DN
Franco LF
Oliveira LB
","(PMID:24728179
 PMCID:PMC3984164)",BraX-Ray: an X-ray of the Brazilian computer science graduate programs.,https://europepmc.org/abstract/MED/24728179%0A
No abstract provided.,"Cho A
","(PMID:23766303
)",Computer science. Network science at center of surveillance dispute.,https://europepmc.org/abstract/MED/23766303%0A
"Linnaeus University offers two master's courses in information visualization for computer science students with programming experience. This article briefly describes the syllabi, exercises, and practices developed for these courses.","Kerren A
","(PMID:24807935
)",Information visualization courses for students with a computer science background.,https://europepmc.org/abstract/MED/24807935%0A
"To determine appropriate computer science curricula, educators sought to better understand the different affordances of teaching with a visual programming language (Alice) or a text-based language (Jython). Although students often preferred one language, that language wasn't necessarily the one from which they learned the most.","DiSalvo B
","(PMID:25388231
)",Graphical qualities of educational technology: Using drag-and-drop and text-based programs for introductory computer science.,https://europepmc.org/abstract/MED/25388231%0A
"Food quality, safety and authenticity are important issues for consumers, governments, as well as the food industry. In the last decade, several researchers have attempted to go beyond traditional microbiological, DNA-based and other methods using rapid techniques. This broad term involves a variety of sensors such as hyperspectral and multispectral imaging, vibrational spectroscopy, as well as biomimetic receptors.The resulting data acquired from the above-mentioned sensors require the application of various case-specific data analysis methods for the purpose of simple understanding and visualization of the acquired high-dimensional dataset, but also for classification and prediction purposes.It is evident that rapid techniques coupled with data analysis methods have given promising results in several food products with various sensors. Additionally there are several applications, new sensors and new algorithms that remain to be explored and validated in the future.","Ropodi AI
E.Z. Panagou
G.-J.E. Nychas
","(AGR:IND605264253
)","Data mining derived from food analyses using non-invasive/non-destructive analytical techniques; determination of food authenticity, quality & safety in tandem with computer science disciplines",https://europepmc.org/abstract/AGR/IND605264253%0A
No abstract provided.,"Hodges A
","(PMID:22499929
)",Computer science. Beyond Turing's machines.,https://europepmc.org/abstract/MED/22499929%0A
No abstract provided.,"French RM
","(PMID:22499930
)",Computer science. Dusting off the Turing test.,https://europepmc.org/abstract/MED/22499930%0A
No abstract provided.,"Janson S
","(PMID:21764738
)",Computer science. Networking--smoothly does it.,https://europepmc.org/abstract/MED/21764738%0A
No abstract provided.,"O'Grady M
O'Hare G
","(PMID:22461597
)",Computer science. How smart is your city?,https://europepmc.org/abstract/MED/22461597%0A
No abstract provided.,"Service RF
","(PMID:22282784
)",Computer science. What it'll take to go exascale.,https://europepmc.org/abstract/MED/22282784%0A
No abstract provided.,"Kephart JO
","(PMID:21310989
)",Computer science. Learning from nature.,https://europepmc.org/abstract/MED/21310989%0A
"The Human Genome Project and the explosion of high-throughput data have transformed the areas of molecular and personalized medicine, which are producing a wide range of studies and experimental results and providing new insights for developing medical applications. Research in many interdisciplinary fields is resulting in data repositories and computational tools that support a wide diversity of tasks: genome sequencing, genome-wide association studies, analysis of genotype-phenotype interactions, drug toxicity and side effects assessment, prediction of protein interactions and diseases, development of computational models, biomarker discovery, and many others. The authors of the present paper have developed several inventories covering tools, initiatives and studies in different computational fields related to molecular medicine: medical informatics, bioinformatics, clinical informatics and nanoinformatics. With these inventories, created by mining the scientific literature, we have carried out several reviews of these fields, providing researchers with a useful framework to locate, discover, search and integrate resources. In this paper we present an analysis of the state-of-the-art as it relates to computational resources for molecular medicine, based on results compiled in our inventories, as well as results extracted from a systematic review of the literature and other scientific media. The present review is based on the impact of their related publications and the available data and software resources for molecular medicine. It aims to provide information that can be useful to support ongoing research and work to improve diagnostics and therapeutics based on molecular-level insights.","de la Iglesia D
García-Remesal M
de la Calle G
Kulikowski C
Sanz F
Maojo V
","(PMID:23548020
)",The impact of computer science in molecular medicine: enabling high-throughput research.,https://europepmc.org/abstract/MED/23548020%0A
"This editorial provides insights into how informatics can attract highly trained students by involving them in science, technology, engineering, and math (STEM) training at the high school level and continuing to provide mentorship and research opportunities through the formative years of their education. Our central premise is that the trajectory necessary to be expert in the emergent fields in front of them requires acceleration at an early time point. Both pathology (and biomedical) informatics are new disciplines which would benefit from involvement by students at an early stage of their education. In 2009, Michael T Lotze MD, Kirsten Livesey (then a medical student, now a medical resident at University of Pittsburgh Medical Center (UPMC)), Richard Hersheberger, PhD (Currently, Dean at Roswell Park), and Megan Seippel, MS (the administrator) launched the University of Pittsburgh Cancer Institute (UPCI) Summer Academy to bring high school students for an 8 week summer academy focused on Cancer Biology. Initially, pathology and biomedical informatics were involved only in the classroom component of the UPCI Summer Academy. In 2011, due to popular interest, an informatics track called Computer Science, Biology and Biomedical Informatics (CoSBBI) was launched. CoSBBI currently acts as a feeder program for the undergraduate degree program in bioinformatics at the University of Pittsburgh, which is a joint degree offered by the Departments of Biology and Computer Science. We believe training in bioinformatics is the best foundation for students interested in future careers in pathology informatics or biomedical informatics. We describe our approach to the recruitment, training and research mentoring of high school students to create a pipeline of exceptionally well-trained applicants for both the disciplines of pathology informatics and biomedical informatics. We emphasize here how mentoring of high school students in pathology informatics and biomedical informatics will be critical to assuring their success as leaders in the era of big data and personalized medicine.","Dutta-Moscato J
Gopalakrishnan V
Lotze MT
Becich MJ
","(PMID:24860688
 PMCID:PMC4030307)","Creating a pipeline of talent for informatics: STEM initiative for high school students in computer science, biology, and biomedical informatics.",https://europepmc.org/abstract/MED/24860688%0A
"Systems biology is centrally engaged with computational modelling across multiple scales and at many levels of abstraction. Formal modelling, precise and formalised abstraction relationships, and computation also lie at the heart of computer science--and over the past decade a growing number of computer scientists have been bringing their discipline's core intellectual and computational tools to bear on biology in fascinating new ways. This paper explores some of the apparent points of contact between the two fields, in the context of a multi-disciplinary discussion on conceptual foundations of systems biology.","Melham T
","(PMID:22975313
)","Modelling, abstraction, and computation in systems biology: A view from computer science.",https://europepmc.org/abstract/MED/22975313%0A
No abstract provided.,"Bridson R
Batty C
","(PMID:21205658
)",Computer science. Computational physics in film.,https://europepmc.org/abstract/MED/21205658%0A
No abstract provided.,"Mesirov JP
","(PMID:20093459
 PMCID:PMC3878063)",Computer science. Accessible reproducible research.,https://europepmc.org/abstract/MED/20093459%0A
No abstract provided.,"Wulf WA
Jones AK
","(PMID:19965500
)",Computer science. Reflections on cybersecurity.,https://europepmc.org/abstract/MED/19965500%0A
No abstract provided.,"Cook DJ
","(PMID:22461596
 PMCID:PMC3731753)",Computer science. How smart is your home?,https://europepmc.org/abstract/MED/22461596%0A
"Synthetic biology is a nascent field that emerged in earnest only around the turn of the millennium. It aims to engineer new biological systems and impart new biological functionality, often through genetic modifications. The design and construction of new biological systems is a complex, multistep process, requiring multidisciplinary collaborative efforts from ""fusion"" scientists who have formal training in computer science or engineering, as well as hands-on biological expertise. The public has high expectations for synthetic biology and eagerly anticipates the development of solutions to the major challenges facing humanity. This article discusses laboratory practices and the conduct of research in synthetic biology. It argues that the fusion science approach, which integrates biology with computer science and engineering best practices, including standardization, process optimization, computer-aided design and laboratory automation, miniaturization, and systematic management, will increase the predictability and reproducibility of experiments and lead to breakthroughs in the construction of new biological systems. The article also discusses several successful fusion projects, including the development of software tools for DNA construction design automation, recursive DNA construction, and the development of integrated microfluidics systems.","Linshiz G
Goldberg A
Konry T
Hillson NJ
","(PMID:23502561
)","The fusion of biology, computer science, and engineering: towards efficient and successful synthetic biology.",https://europepmc.org/abstract/MED/23502561%0A
No abstract provided.,"Mitchell TM
","(PMID:20019279
)",Computer science. Mining our reality.,https://europepmc.org/abstract/MED/20019279%0A
No abstract provided.,"Waltz D
Buchanan BG
","(PMID:19342574
)",Computer science. Automating science.,https://europepmc.org/abstract/MED/19342574%0A
No abstract provided.,"Chang FR
","(PMID:19644101
)",Computer science. Is your computer secure?,https://europepmc.org/abstract/MED/19644101%0A
No abstract provided.,"Hornby GS
Kurtoglu T
","(PMID:19608905
)",Computer science. Toward a smarter Web.,https://europepmc.org/abstract/MED/19608905%0A
No abstract provided.,"Nelson MR
","(PMID:19556494
)",Computer science. Building an open Cloud.,https://europepmc.org/abstract/MED/19556494%0A
No abstract provided.,"Bell G
Hey T
Szalay A
","(PMID:19265007
)",Computer science. Beyond the data deluge.,https://europepmc.org/abstract/MED/19265007%0A
No abstract provided.,"Fox A
","(PMID:21273473
)",Computer science. Cloud computing--what's in it for me as a scientist?,https://europepmc.org/abstract/MED/21273473%0A
No abstract provided.,"Sharkey N
","(PMID:19095930
)",Computer science. The ethical frontiers of robotics.,https://europepmc.org/abstract/MED/19095930%0A
No abstract provided.,"Mackenzie D
","(PMID:18339918
)",Computer science. Hash of the future?,https://europepmc.org/abstract/MED/18339918%0A
No abstract provided.,"Golbeck J
","(PMID:18801986
)",Computer science. Weaving a Web of trust.,https://europepmc.org/abstract/MED/18801986%0A
"Attachment-related avoidance and anxiety have repeatedly been associated with poorer adjustment in various social, emotional, and behavioral domains. We examined 2 domains in which avoidant individuals might be better equipped than their less avoidant peers to succeed and be satisfied--professional singles tennis and computer science. These fields may reward self-reliance, independence, and the ability to work without proximal social support from loved ones. In study 1, we followed 58 professional singles tennis players for 16 months and found that scores on attachment-related avoidance predicted a higher ranking, above and beyond the contributions of training and coping resources. In study 2, we sampled 100 students and found that those who scored higher on avoidance were happier with their choice of computer science as a career than those who scored lower on avoidance. Results are discussed in relation to the possible adaptive functions of certain personality characteristics often viewed as undesirable.","Ein-Dor T
Reizer A
Shaver PR
Dotan E
","(PMID:22091787
)","Standoffish perhaps, but successful as well: evidence that avoidant attachment can be beneficial in professional tennis and computer science.",https://europepmc.org/abstract/MED/22091787%0A
No abstract provided.,"Shneiderman B
","(PMID:18323442
)",Computer science. Science 2.0.,https://europepmc.org/abstract/MED/18323442%0A
No abstract provided.,"Donath J
","(PMID:17615329
)",Computer science. Virtually trustworthy.,https://europepmc.org/abstract/MED/17615329%0A
No abstract provided.,"Mézard M
","(PMID:17303742
)",Computer science. Where are the exemplars?,https://europepmc.org/abstract/MED/17303742%0A
"People can make decisions to join a group based solely on exposure to that group's physical environment. Four studies demonstrate that the gender difference in interest in computer science is influenced by exposure to environments associated with computer scientists. In Study 1, simply changing the objects in a computer science classroom from those considered stereotypical of computer science (e.g., Star Trek poster, video games) to objects not considered stereotypical of computer science (e.g., nature poster, phone books) was sufficient to boost female undergraduates' interest in computer science to the level of their male peers. Further investigation revealed that the stereotypical broadcast a masculine stereotype that discouraged women's sense of ambient belonging and subsequent interest in the environment (Studies 2, 3, and 4) but had no similar effect on men (Studies 3, 4). This masculine stereotype prevented women's interest from developing even in environments entirely populated by other women (Study 2). Objects can thus come to broadcast stereotypes of a group, which in turn can deter people who do not identify with these stereotypes from joining that group.","Cheryan S
Plaut VC
Davies PG
Steele CM
","(PMID:19968418
)",Ambient belonging: how stereotypical cues impact gender participation in computer science.,https://europepmc.org/abstract/MED/19968418%0A
No abstract provided.,"Subrahmanian VS
Dickerson J
","(PMID:19965459
)",Computer science. What can virtual worlds and games do for national security?,https://europepmc.org/abstract/MED/19965459%0A
"This editorial introduces BioData Mining, a new journal which publishes research articles related to advances in computational methods and techniques for the extraction of useful knowledge from heterogeneous biological data. We outline the aims and scope of the journal, introduce the publishing model and describe the open peer review policy, which fosters interaction within the research community.","Aguilar-Ruiz JS
Moore JH
Ritchie MD
","(PMID:18822148
 PMCID:PMC2547862)",Filling the gap between biology and computer science.,https://europepmc.org/abstract/MED/18822148%0A
No abstract provided.,"Ploeger LS
","(PMID:16823175
 PMCID:PMC4617496)",Computer science meets medical science.,https://europepmc.org/abstract/MED/16823175%0A
"This paper explores the growing concerns with computer science research, and in particular, computer security research and its relationship with the committees that review human subjects research. It offers cases that review boards are likely to confront, and provides a context for appropriate consideration of such research, as issues of bots, clouds, and worms enter the discourse of human subjects review.","Buchanan E
Aycock J
Dexter S
Dittrich D
Hvizdak E
","(PMID:21680978
)",Computer science security research and human subjects: emerging considerations for research ethics boards.,https://europepmc.org/abstract/MED/21680978%0A
"Until ca. 2000, information security was seen as a technological discipline, based on computer science but with mathematics helping in the design of ciphers and protocols. That perspective started to change as researchers and practitioners realized the importance of economics. As distributed systems are increasingly composed of machines that belong to principals with divergent interests, incentives are becoming as important to dependability as technical design. A thriving new field of information security economics provides valuable insights not just into 'security' topics such as privacy, bugs, spam and phishing, but into more general areas of system dependability and policy. This research programme has recently started to interact with psychology. One thread is in response to phishing, the most rapidly growing form of online crime, in which fraudsters trick people into giving their credentials to bogus websites; a second is through the increasing importance of security usability; and a third comes through the psychology-and-economics tradition. The promise of this multidisciplinary research programme is a novel framework for analysing information security problems-one that is both principled and effective.","Anderson R
Moore T
","(PMID:19487207
)","Information security: where computer science, economics and psychology meet.",https://europepmc.org/abstract/MED/19487207%0A
No abstract provided.,"Wilks Y
","(PMID:17991851
)",Computer science. Is there progress on talking sensibly to machines?,https://europepmc.org/abstract/MED/17991851%0A
"This article presents an in-depth analysis of past and present publishing practices in academic computer science to suggest the establishment of a more consistent publishing standard. Historical precedent for academic publishing in computer science is established through the study of anecdotes as well as statistics collected from databases of published computer science papers. After examining these facts alongside information about analogous publishing situations and standards in other scientific fields, the article concludes with a list of basic principles that should be adopted in any computer science publishing standard. These principles would contribute to the reliability and scientific nature of academic publications in computer science and would allow for more straightforward discourse in future publications.","Solomon J
","(PMID:19247811
)","Programmers, professors, and parasites: credit and co-authorship in computer science.",https://europepmc.org/abstract/MED/19247811%0A
No abstract provided.,"Subrahmanian VS
","(PMID:17872433
)",Computer science. Cultural modeling in real time.,https://europepmc.org/abstract/MED/17872433%0A
No abstract provided.,"Chazelle B
","(PMID:17885118
)",Computer science. Coding and computing join forces.,https://europepmc.org/abstract/MED/17885118%0A
No abstract provided.,"Berners-Lee T
Hall W
Hendler J
Shadbolt N
Weitzner DJ
","(PMID:16902115
)",Computer science. Creating a science of the Web.,https://europepmc.org/abstract/MED/16902115%0A
No abstract provided.,"Ford R
Spafford EH
","(PMID:17626875
)","Computer science. Happy birthday, dear viruses.",https://europepmc.org/abstract/MED/17626875%0A
"Reduction of frustration was the driving force in an approach to social balance as it was recently considered by Antal [T. Antal, P. L. Krapivsky, and S. Redner, Phys. Rev. E 72, 036121 (2005)]. We generalize their triad dynamics to k-cycle dynamics for arbitrary integer k. We derive the phase structure, determine the stationary solutions, and calculate the time it takes to reach a frozen state. The main difference in the phase structure as a function of k is related to k being even or odd. As a second generalization we dilute the all-to-all coupling as considered by Antal to a random network with connection probability w<1. Interestingly, this model can be mapped to a satisfiability problem of computer science. The phase of social balance in our original interpretation then becomes the phase of satisfaction of all logical clauses in the satisfiability problem. In common to the cases we study, the ideal solution without any frustration always exists, but the question actually is as to whether this solution can be found by means of a local stochastic algorithm within a finite time. The answer depends on the choice of parameters. After establishing the mapping between the two classes of models, we generalize the social-balance problem to a diluted network topology for which the satisfiability problem is usually studied. On the other hand, in connection with the satisfiability problem we generalize the random local algorithm to a p-random local algorithm, including a parameter p that corresponds to the propensity parameter in the social balance problem. The qualitative effect of the inclusion of this parameter is a bias towards the optimal solution and a reduction of the needed simulation time.","Radicchi F
Vilone D
Yoon S
Meyer-Ortmanns H
","(PMID:17358393
)",Social balance as a satisfiability problem of computer science.,https://europepmc.org/abstract/MED/17358393%0A
No abstract provided.,"Adami C
","(PMID:17110560
)",Computer science. What do robots dream of?,https://europepmc.org/abstract/MED/17110560%0A
No abstract provided.,"Mackenzie D
","(PMID:18339917
)",Computer science. Cryptologists cook up some hash for new 'bake-off'.,https://europepmc.org/abstract/MED/18339917%0A
No abstract provided.,"Cottrell GW
","(PMID:16873635
)",Computer science. New life for neural networks.,https://europepmc.org/abstract/MED/16873635%0A
"The author has surveyed a quarter of the accredited undergraduate computer science programs in the United States. More than half of these programs offer a 'social and ethical implications of computing' course taught by a computer science faculty member, and there appears to be a trend toward teaching ethics classes within computer science departments. Although the decision to create an 'in house' computer ethics course may sometimes be a pragmatic response to pressure from the accreditation agency, this paper argues that teaching ethics within a computer science department can provide students and faculty members with numerous benefits. The paper lists topics that can be covered in a computer ethics course and offers some practical suggestions for making the course successful.","Quinn MJ
","(PMID:16609720
)",On teaching computer ethics within a computer science department.,https://europepmc.org/abstract/MED/16609720%0A
No abstract provided.,"Lester B
","(PMID:18006735
)",Robots' allure: can it remedy what ails computer science?,https://europepmc.org/abstract/MED/18006735%0A
"Nursing and computer science students and faculty worked with the American Red Cross to investigate the potential for information technology to provide Red Cross disaster services nurses with improved access to accurate community resources in times of disaster. Funded by a national 3-year grant, this interdisciplinary partnership led to field testing of an information system to support local community disaster preparedness at seven Red Cross chapters across the United States. The field test results demonstrate the benefits of the technology and the value of interdisciplinary research. The work also created a sustainable learning and research model for the future. This article describes the collaborative model used in this interdisciplinary research and exemplifies the benefits to faculty and students of well-timed interdisciplinary and community collaboration.","Vanderbeek J
Carson A
Troy D
","(PMID:18600129
 PMCID:PMC2497443)",Evolution of a collaborative model between nursing and computer science faculty and a community service organization to develop an information system.,https://europepmc.org/abstract/MED/18600129%0A
No abstract provided.,"Cho A
","(PMID:17641173
)","Computer science. Program proves that checkers, perfectly played, is a no-win situation.",https://europepmc.org/abstract/MED/17641173%0A
No abstract provided.,"Rabiner L
","(PMID:12970555
)",Computer science. The power of speech.,https://europepmc.org/abstract/MED/12970555%0A
No abstract provided.,"Martin U
","(PMID:16188614
)",Panelist position statement: logic and models in computer science.,https://europepmc.org/abstract/MED/16188614%0A
"The core curriculum in the education of medical informaticians remains a topic of concern and discussion. This paper reports on a survey of medical informaticians with Master's level credentials that asked about computer science (CS) topics or skills that they need in their employment. All subjects were graduates or ""near-graduates"" of a single medical informatics Master's program that they entered with widely varying educational backgrounds. The survey instrument was validated for face and content validity prior to use. All survey items were rated as having some degree of importance in the work of these professionals, with retrieval and analysis of data from databases, database design and web technologies deemed most important. Least important were networking skills and object-oriented design and concepts. These results are consistent with other work done in the field and suggest that strong emphasis on technical skills, particularly databases, data analysis, web technologies, computer programming and general computer science are part of the core curriculum for medical informatics.","Logan JR
Price SL
","(PMID:15063372
)",Computer science education for medical informaticians.,https://europepmc.org/abstract/MED/15063372%0A
"Membrane protein is a pivotal constituent of a cell that exerts a crucial influence on diverse biological processes. The accurate identification of membrane protein types is deeply essential for revealing molecular mechanisms and drug development. Primarily, several traditional methods were exploited to classify these types. However, experimental methods are laborious, time-consuming, and costly due to rapid exploration of uncharacterized protein sequences generated in the postgenomic era. Hence, machine learning-based methods are more indispensable for reliable and fast identification of membrane protein types. A variety of state-of-the-art investigations have been elucidated to improve prediction performance, but predictive validity is still insufficient. Motivated by this, we designed a promising sequential support vector machine based predictor called TargetHMP to predict types of membrane proteins. We captured the local informative features by exploring evolutionary profiles through a novel method called the segmentation-based pseudo position-specific scoring matrix (Seg-PsePSSM). TargetHMP attained high accuracy of 94.99%, 93.48%, and 90.36% on the S1, S2, and S3 datasets, respectively, using a vigorous leave-one-out-cross-validation test. The results indicate that the performance of the proposed method outperformed prior predictors. We expect that the proposed approach will help research academia in general and pharmaceutical drug discovery in particular.","Kabir M
Arif M
Ali F
Ahmad S
Swati ZNK
Yu DJ
","(PMID:30393088
)",Prediction of membrane protein types by exploring local discriminative information from evolutionary profiles.,https://europepmc.org/abstract/MED/30393088%0A
"A significant portion of genes in vertebrate genomes belongs to multigene families, with each family containing several gene copies whose presence/absence, as well as isoform structure, can be highly variable across individuals. Existing de novo techniques for assaying the sequences of such highly-similar gene families fall short of reconstructing end-to-end transcripts with nucleotide-level precision or assigning alternatively spliced transcripts to their respective gene copies. We present IsoCon, a high-precision method using long PacBio Iso-Seq reads to tackle this challenge. We apply IsoCon to nine Y chromosome ampliconic gene families and show that it outperforms existing methods on both experimental and simulated data. IsoCon has allowed us to detect an unprecedented number of novel isoforms and has opened the door for unraveling the structure of many multigene families and gaining a deeper understanding of genome evolution and human diseases.","Sahlin K
Tomaszkiewicz M
Makova KD
Medvedev P
","(PMID:30389934
 PMCID:PMC6214943)",Deciphering highly similar multigene family transcripts from Iso-Seq data with IsoCon.,https://europepmc.org/abstract/MED/30389934%0A
No abstract provided.,"Paz JP
","(PMID:14684809
)",Computer science. Randomness in quantum computation.,https://europepmc.org/abstract/MED/14684809%0A
"When the nodes in the network are deployed in the target area with an appropriate density, the effective aggregation and transmission of the data gathered in the monitoring area remain to be solved. The existing Compressed Sensing (CS) based on data aggregation schemes are accomplished in a centralized manner and the Sink node achieves the task of data aggregation. However, these existing schemes may suffer from load imbalance and coverage void issues. In order to address these problems, we propose a Compressed Sensing based on Fault-tolerant Correcting Data Aggregation (CS-FCDA) scheme to accurately reconstruct the compressed data. Therefore, the network communication overhead can be greatly reduced while maintaining the quality of the reconstructed data. Meanwhile, we adopt the node clustering mechanism to optimize and balance the network load. It is shown via simulation results, compared with other data aggregation schemes, that the proposed scheme shows obvious improvement in terms of the Fault-tolerant correcting capability and the network energy efficiency of the data reconstruction.","Sun Z
Wang H
Liu B
Li C
Pan X
Nie Y
","(PMID:30400248
)",CS-FCDA: A Compressed Sensing-Based on Fault-Tolerant Data Aggregation in Sensor Networks.,https://europepmc.org/abstract/MED/30400248%0A
"Currently, there is a growing demand for the use of communication network bandwidth for the Internet of Things (IoT) within the cyber-physical-social system (CPSS), while needing progressively more powerful technologies for using scarce spectrum resources. Then, cognitive radio networks (CRNs) as one of those important solutions mentioned above, are used to achieve IoT effectively. Generally, dynamic resource allocation plays a crucial role in the design of CRN-aided IoT systems. Aiming at this issue, orthogonal frequency division multiplexing (OFDM) has been identified as one of the successful technologies, which works with a multi-carrier parallel radio transmission strategy. In this article, through the use of swarm intelligence paradigm, a solution approach is accordingly proposed by employing an efficient Jaya algorithm, called PA-Jaya, to deal with the power allocation problem in cognitive OFDM radio networks for IoT. Because of the algorithm-specific parameter-free feature in the proposed PA-Jaya algorithm, a satisfactory computational performance could be achieved in the handling of this problem. For this optimization problem with some constraints, the simulation results show that compared with some popular algorithms, the efficiency of spectrum utilization could be further improved by using PA-Jaya algorithm with faster convergence speed, while maximizing the total transmission rate.","Luo X
He Z
Zhao Z
Wang L
Wang W
Ning H
Wang JH
Zhao W
Zhang J
","(PMID:30373268
)",Resource Allocation in the Cognitive Radio Network-Aided Internet of Things for the Cyber-Physical-Social System: An Efficient Jaya Algorithm.,https://europepmc.org/abstract/MED/30373268%0A
"This paper details a new methodology, instance-based reinforcement learning, for constructing adaptive treatment strategies from randomized trials. Adaptive treatment strategies are operationalized clinical guidelines which recommend the next best treatment for an individual based on his/her personal characteristics and response to earlier treatments. The instance-based reinforcement learning methodology comes from the computer science literature, where it was developed to optimize sequences of actions in an evolving, time varying system. When applied in the context of treatment design, this method provides the means to evaluate both the therapeutic and diagnostic effects of treatments in constructing an adaptive treatment strategy. The methodology is illustrated with data from the STAR*D trial, a multi-step randomized study of treatment alternatives for individuals with treatment-resistant major depressive disorder.","Pineau J
Bellemare MG
Rush AJ
Ghizaru A
Murphy SA
","(PMID:17320311
 PMCID:PMC1934348)",Constructing evidence-based treatment strategies using methods from computer science.,https://europepmc.org/abstract/MED/17320311%0A
"Computer-aided diagnosis (CAD) is a field that is essentially based on pattern recognition that improves the accuracy of a diagnosis made by a physician who takes into account the computer's ""opinion"" derived from the quantitative analysis of radiological images. Radiomics is a field based on data science that massively and comprehensively analyzes a large number of medical images to extract a large number of phenotypic features reflecting disease traits, and explores the associations between the features and patients' prognoses for precision medicine. According to the definitions for both, you may think that radiomics is not a paraphrase of CAD, but you may also think that these definitions are ""image manipulation"". However, there are common and different features between the two fields. This review paper elaborates on these common and different features and introduces the potential of radiomics for cancer diagnosis and treatment by comparing it with CAD.","Arimura H
Soufi M
Ninomiya K
Kamezawa H
Yamada M
","(PMID:30374837
)",Potentials of radiomics for cancer diagnosis and treatment in comparison with computer-aided diagnosis.,https://europepmc.org/abstract/MED/30374837%0A
"The existing public key-based en-route filtering schemes are vulnerable to report disruption attacks or selective forwarding attacks, and they fail to consider any measure to detect and punish the malicious nodes. The authors propose a series of public key-based security mechanisms for wireless sensor networks (WSNs) in this paper, including a mechanism for verifying the partial signatures, a substitution mechanism, an effective report forwarding protocol, and a trust value-based mechanism to identify and punish the malicious nodes. Finally, the authors develop a public key-based authentication and en-route filtering scheme (PKAEF), which can resist false data injection attacks, report disruption attacks and selective forwarding attacks, and can mitigate the impact of malicious nodes. Detailed performance analysis and evaluation show that, in most cases, PKAEF outperforms previous works in terms of safety, filtering efficiency, and data availability.","Yi C
Yang G
Dai H
Liu L
Li N
","(PMID:30413068
)",Public Key-Based Authentication and En-Route Filtering Scheme in Wireless Sensor Networks.,https://europepmc.org/abstract/MED/30413068%0A
"Personalized emotion recognition provides an individual training model for each target user in order to mitigate the accuracy problem when using general training models collected from multiple users. Existing personalized speech emotion recognition research has a cold-start problem that requires a large amount of emotionally-balanced data samples from the target user when creating the personalized training model. Such research is difficult to apply in real environments due to the difficulty of collecting numerous target user speech data with emotionally-balanced label samples. Therefore, we propose the Robust Personalized Emotion Recognition Framework with the Adaptive Data Boosting Algorithm to solve the cold-start problem. The proposed framework incrementally provides a customized training model for the target user by reinforcing the dataset by combining the acquired target user speech with speech from other users, followed by applying SMOTE (Synthetic Minority Over-sampling Technique)-based data augmentation. The proposed method proved to be adaptive across a small number of target user datasets and emotionally-imbalanced data environments through iterative experiments using the IEMOCAP (Interactive Emotional Dyadic Motion Capture) database.","Bang J
Hur T
Kim D
Huynh-The T
Lee J
Han Y
Banos O
Kim JI
Lee S
","(PMID:30400224
)",Adaptive Data Boosting Technique for Robust Personalized Speech Emotion in Emotionally-Imbalanced Small-Sample Environments.,https://europepmc.org/abstract/MED/30400224%0A
No abstract provided.,"Gomes CP
Selman B
","(PMID:12161641
)",Computer science. Satisfied with physics.,https://europepmc.org/abstract/MED/12161641%0A
"Computer simulations of the spread of malignant tumor cells in an entire organism provide important insights into the mechanisms of metastatic progression. Key elements for the usefulness of these models are the adequate selection of appropriate mathematical models describing the tumor growth and its parametrization as well as a proper choice of the fractal dimension of the blood vessels in the primary tumor. In addition, survival in the bloodstream and evasion into the connective spaces of the target organ of the future metastasis have to be modeled. Determination of these from experimental models is complicated by systematic and unsystematic experimental errors which are difficult to assess. In this chapter, we demonstrate how to select the best-suited mathematical function to describe tumor growth for experimental xenograft mouse tumor models and how to parametrize them. Common pitfalls and problems are described as well as methods to avoid them.","Hoffmann B
Frenzel T
Schmitz R
Schumacher U
Wedemann G
","(PMID:30378082
)",Modeling Growth of Tumors and Their Spreading Behavior Using Mathematical Functions.,https://europepmc.org/abstract/MED/30378082%0A
"Anomaly detection aims to separate anomalous pixels from the background, and has become an important application of remotely sensed hyperspectral image processing. Anomaly detection methods based on low-rank and sparse representation (LRASR) can accurately detect anomalous pixels. However, with the significant volume increase of hyperspectral image repositories, such techniques consume a significant amount of time (mainly due to the massive amount of matrix computations involved). In this paper, we propose a novel distributed parallel algorithm (DPA) by redesigning key operators of LRASR in terms of MapReduce model to accelerate LRASR on cloud computing architectures. Independent computation operators are explored and executed in parallel on Spark. Specifically, we reconstitute the hyperspectral images in an appropriate format for efficient DPA processing, design the optimized storage strategy, and develop a pre-merge mechanism to reduce data transmission. Besides, a repartitioning policy is also proposed to improve DPA's efficiency. Our experimental results demonstrate that the newly developed DPA achieves very high speedups when accelerating LRASR, in addition to maintaining similar accuracies. Moreover, our proposed DPA is shown to be scalable with the number of computing nodes and capable of processing big hyperspectral images involving massive amounts of data.","Zhang Y
Wu Z
Sun J
Zhang Y
Zhu Y
Liu J
Zang Q
Plaza A
","(PMID:30366454
)",A Distributed Parallel Algorithm Based on Low-Rank and Sparse Representation for Anomaly Detection in Hyperspectral Images.,https://europepmc.org/abstract/MED/30366454%0A
This paper presents a portable magnetic induction tomography (MIT) transceiver integrated circuit to miniaturize conventional equipment-based MIT systems. The miniaturized MIT function is enabled through single-chip transceiver implementation. The proposed MIT transceiver utilizes a phase-locked loop (PLL) for frequency sweeping and a phase-domain sigma⁻delta modulator with phase-band auto-tracking for a full-range fine-phase resolution. The designed transceiver is fabricated and verified to achieve the measured signal to noise and distortion ratio (SNDR) of 101.7 dB. Its system-level prototype including in-house magnetic sensor coils is manufactured and functionally verified for four different material types.,"Park CS
Jeon J
Oh B
Chae HY
Park K
Son H
Kim JJ
","(PMID:30405069
)",A Portable Phase-Domain Magnetic Induction Tomography Transceiver with Phase-Band Auto-Tracking and Frequency-Sweep Capabilities.,https://europepmc.org/abstract/MED/30405069%0A
"Many dietary assessment methods attempt to estimate total food and nutrient intake. If the intention is simply to determine whether participants achieve dietary recommendations, this leads to much redundant data. We used data mining techniques to explore the number of foods that intake information was required on to accurately predict achievement, or not, of key dietary recommendations.We built decision trees for achievement of recommendations for fruit and vegetables, sodium, fat, saturated fat and free sugars using data from a national dietary surveillance data set. Decision trees describe complex relationships between potential predictor variables (age, sex and all foods listed in the database) and outcome variables (achievement of each of the recommendations).UK National Diet and Nutrition Survey (NDNS, 2008-12).The analysis included 4156 individuals.Information on consumption of 113 out of 3911 (3 %) foods, plus age and sex was required to accurately categorize individuals according to all five recommendations. The best trade-off between decision tree accuracy and number of foods included occurred at between eleven (for fruit and vegetables) and thirty-two (for fat, plus age) foods, achieving an accuracy of 72 % (for fat) to 83 % (for fruit and vegetables), with similar values for sensitivity and specificity.Using information on intake of 113 foods, it is possible to predict with 72-83 % accuracy whether individuals achieve key dietary recommendations. Substantial further research is required to make use of these findings for dietary assessment.","Giabbanelli PJ
Adams J
","(PMID:26879185
 PMCID:PMC4873899)","Identifying small groups of foods that can predict achievement of key dietary recommendations: data mining of the UK National Diet and Nutrition Survey, 2008-12.",https://europepmc.org/abstract/MED/26879185%0A
"The inherent complexity of human physical activities makes it difficult to accurately recognize activities with wearable sensors. To this end, this paper proposes a hierarchical activity recognition framework and two different feature selection methods to improve the recognition performance. Specifically, according to the characteristics of human activities, predefined activities of interest are organized into a hierarchical tree structure, where each internal node represents different groups of activities and each leaf node represents a specific activity label. Then, the proposed feature selection methods are appropriately integrated to optimize the feature space of each node. Finally, we train corresponding classifiers to distinguish different activity groups and to classify a new unseen sample into one of the leaf-nodes in a top-down fashion to predict its activity label. To evaluate the performance of the proposed framework and feature selection methods, we conduct extensive comparative experiments on publicly available datasets and analyze the model complexity. Experimental results show that the proposed method reduces the dimensionality of original feature space and contributes to enhancement of the overall recognition accuracy. In addition, for feature selection, returning multiple activity-specific feature subsets generally outperforms the case of returning a common subset of features for all activities.","Wang A
Chen G
Wu X
Liu L
An N
Chang CY
","(PMID:30366461
)",Towards Human Activity Recognition: A Hierarchical Feature Selection Framework.,https://europepmc.org/abstract/MED/30366461%0A
"(1) Background: Gene-expression data usually contain missing values (MVs). Numerous methods focused on how to estimate MVs have been proposed in the past few years. Recent studies show that those imputation algorithms made little difference in classification. Thus, some scholars believe that how to select the informative genes for downstream classification is more important than how to impute MVs. However, most feature-selection (FS) algorithms need beforehand imputation, and the impact of beforehand MV imputation on downstream FS performance is seldom considered. (2) Method: A modified chi-square test-based FS is introduced for gene-expression data. To deal with the challenge of a small sample size of gene-expression data, a heuristic method called recursive element aggregation is proposed in this study. Our approach can directly handle incomplete data without any imputation methods or missing-data assumptions. The most informative genes can be selected through a threshold. After that, the best-first search strategy is utilized to find optimal feature subsets for classification. (3) Results: We compare our method with several FS algorithms. Evaluation is performed on twelve original incomplete cancer gene-expression datasets. We demonstrate that MV imputation on an incomplete dataset impacts subsequent FS in terms of classification tasks. Through directly conducting FS on incomplete data, our method can avoid potential disturbances on subsequent FS procedures caused by MV imputation. An experiment on small, round blue cell tumor (SRBCT) dataset showed that our method found additional genes besides many common genes with the two compared existing methods.","Yan Y
Dai T
Yang M
Du X
Zhang Y
Zhang Y
","(PMID:30380746
)",Classifying Incomplete Gene-Expression Data: Ensemble Learning with Non-Pre-Imputation Feature Filtering and Best-First Search Technique.,https://europepmc.org/abstract/MED/30380746%0A
No abstract provided.,"Krieger K
","(PMID:16614189
)",Computer science. Life in silico: a different kind of intelligent design.,https://europepmc.org/abstract/MED/16614189%0A
"Laser-induced breakdown spectroscopy (LIBS) is an important analysis technique with applications in many industrial branches and fields of scientific research. Nowadays, the advantages of LIBS are impaired by the main drawback in the interpretation of obtained spectra and identification of observed spectral lines. This procedure is highly time-consuming since it is essentially based on the comparison of lines present in the spectrum with the literature database. This paper proposes the use of various computational intelligence methods to develop a reliable and fast classification of quasi-destructively acquired LIBS spectra into a set of predefined classes. We focus on a specific problem of classification of paper-ink samples into 30 separate, predefined classes. For each of 30 classes (10 pens of each of 5 ink types combined with 10 sheets of 5 paper types plus empty pages), 100 LIBS spectra are collected. Four variants of preprocessing, seven classifiers (decision trees, random forest, k-nearest neighbor, support vector machine, probabilistic neural network, multi-layer perceptron, and generalized regression neural network), 5-fold stratified cross-validation, and a test on an independent set (for methods evaluation) scenarios are employed. Our developed system yielded an accuracy of 99.08%, obtained using the random forest classifier. Our results clearly demonstrates that machine learning methods can be used to identify the paper-ink samples based on LIBS reliably at a faster rate.","Rzecki K
Sośnicki T
Baran M
Niedźwiecki M
Król M
Łojewski T
Acharya UR
Yildirim Ö
Pławiak P
","(PMID:30380626
)",Application of Computational Intelligence Methods for the Automated Identification of Paper-Ink Samples Based on LIBS.,https://europepmc.org/abstract/MED/30380626%0A
"Recently, modern smartphones equipped with a variety of embedded-sensors, such as accelerometers and gyroscopes, have been used as an alternative platform for human activity recognition (HAR), since they are cost-effective, unobtrusive and they facilitate real-time applications. However, the majority of the related works have proposed a position-dependent HAR, i.e., the target subject has to fix the smartphone in a pre-defined position. Few studies have tackled the problem of position-independent HAR. They have tackled the problem either using handcrafted features that are less influenced by the position of the smartphone or by building a position-aware HAR. The performance of these studies still needs more improvement to produce a reliable smartphone-based HAR. Thus, in this paper, we propose a deep convolution neural network model that provides a robust position-independent HAR system. We build and evaluate the performance of the proposed model using the RealWorld HAR public dataset. We find that our deep learning proposed model increases the overall performance compared to the state-of-the-art traditional machine learning method from 84% to 88% for position-independent HAR. In addition, the position detection performance of our model improves superiorly from 89% to 98%. Finally, the recognition time of the proposed model is evaluated in order to validate the applicability of the model for real-time applications.","Almaslukh B
Artoli AM
Al-Muhtadi J
","(PMID:30388855
)",A Robust Deep Learning Approach for Position-Independent Smartphone-Based Human Activity Recognition.,https://europepmc.org/abstract/MED/30388855%0A
"Video-based person re-identification is an important task with the challenges of lighting variation, low-resolution images, background clutter, occlusion, and human appearance similarity in the multi-camera visual sensor networks. In this paper, we propose a video-based person re-identification method called the end-to-end learning architecture with hybrid deep appearance-temporal feature. It can learn the appearance features of pivotal frames, the temporal features, and the independent distance metric of different features. This architecture consists of two-stream deep feature structure and two Siamese networks. For the first-stream structure, we propose the Two-branch Appearance Feature (TAF) sub-structure to obtain the appearance information of persons, and used one of the two Siamese networks to learn the similarity of appearance features of a pairwise person. To utilize the temporal information, we designed the second-stream structure that consisting of the Optical flow Temporal Feature (OTF) sub-structure and another Siamese network, to learn the person's temporal features and the distances of pairwise features. In addition, we select the pivotal frames of video as inputs to the Inception-V3 network on the Two-branch Appearance Feature sub-structure, and employ the salience-learning fusion layer to fuse the learned global and local appearance features. Extensive experimental results on the PRID2011, iLIDS-VID, and Motion Analysis and Re-identification Set (MARS) datasets showed that the respective proposed architectures reached 79%, 59% and 72% at Rank-1 and had advantages over state-of-the-art algorithms. Meanwhile, it also improved the feature representation ability of persons.","Sun R
Huang Q
Xia M
Zhang J
","(PMID:30380623
)",Video-Based Person Re-Identification by an End-To-End Learning Architecture with Hybrid Deep Appearance-Temporal Feature.,https://europepmc.org/abstract/MED/30380623%0A
"The working⁻sleeping cycle strategy used for sensor nodes with limited power supply in wireless sensor networks can effectively save their energy, but also causes opportunistic node connections due to the intermittent communication mode, which can affect the reliability of data transmission. To address this problem, a data collection scheme based on opportunistic node connections is proposed to achieve efficient data collection in a network with a mobile sink. In this scheme, the mobile sink first broadcasts a tag message to start a data collection period, and all nodes that receive this message will use the probe message to forward their own source information to the mobile sink. On receiving these probe messages, the mobile sink then constructs an opportunistic connection random graph by analyzing the source information included in them, and calculates the optimal path from itself to each node in this random graph, therefore a spanning tree could be generated with the mobile sink play as the root node, finally, it broadcasts this spanning tree so that each node could obtain an optimal path from itself to the mobile sink to forward the sensing data. In addition, a routing protocol that adapts to different nodes operating statuses is proposed to improve the reliability of data transmission. Simulation results show that the proposed scheme works better concerning the packet delivery rate, energy consumption and network lifetime.","Yang G
Peng Z
He X
","(PMID:30380799
)",Data Collection Based on Opportunistic Node Connections in Wireless Sensor Networks.,https://europepmc.org/abstract/MED/30380799%0A
"The most recent history of parallel Magnetic Resonance Imaging (pMRI) has in large part been devoted to finding ways to reduce acquisition time. While joint total variation (JTV) regularized model has been demonstrated as a powerful tool in increasing sampling speed for pMRI, however, the major bottleneck is the inefficiency of the optimization method. While all present state-of-the-art optimizations for the JTV model could only reach a sublinear convergence rate, in this paper, we squeeze the performance by proposing a linear-convergent optimization method for the JTV model. The proposed method is based on the Iterative Reweighted Least Squares algorithm. Due to the complexity of the tangled JTV objective, we design a novel preconditioner to further accelerate the proposed method. Extensive experiments demonstrate the superior performance of the proposed algorithm for pMRI regarding both accuracy and efficiency compared with state-of-the-art methods.","Xu Z
Wang S
Li Y
Zhu F
Huang J
","(PMID:29423650
)",PRIM: An Efficient Preconditioning Iterative Reweighted Least Squares Method for Parallel Brain MRI Reconstruction.,https://europepmc.org/abstract/MED/29423650%0A
No abstract provided.,"Balthrop J
Forrest S
Newman ME
Williamson MM
","(PMID:15105484
)",Computer science. Technological networks and the spread of computer viruses.,https://europepmc.org/abstract/MED/15105484%0A
"Independent component analysis (ICA) is a potential spatial filtering method for the implementation of motor imagery brain-computer interface (MIBCI). However, ICA-based MIBCI (ICA-MIBCI) is sensitive to electroencephalogram (EEG) channels and the quality of the training data, which are two crucial factors affecting the stability and classification performance of ICA-MIBCI. To address these problems, this paper is mainly focused on the investigation of EEG channel optimization. As a reference, we constructed a single-trial-based ICA-MIBCI system with commonly used channels and common spatial pattern-based MIBCI (CSP-MIBCI). To minimize the impact of artifacts on EEG channel optimization, a data-quality evaluation method, named ""self-testing"" in this paper, was used in a single-trial-based ICA-MIBCI system to evaluate the quality of single trials in each dataset; the resulting self-testing accuracies were used for the selection of high-quality trials. Given several candidate channel configurations, ICA filters were calculated using selected high-quality trials and applied to the corresponding ICA-MIBCI implementation. Optimal channels for each dataset were assessed and selected according to the self-testing results related to various candidate configurations. Forty-eight MI datasets of six subjects were employed in this study to validate the proposed methods. Experimental results revealed that the average classification accuracy of the optimal channels yielded a relative increment of 2.8% and 8.5% during self-testing, 14.4% and 9.5% during session-to-session transfer, and 36.2% and 26.7% during subject-to-subject transfer compared to CSP-MIBCI and ICA-MIBCI with fixed the channel configuration. This work indicates that the proposed methods can efficiently improve the practical feasibility of ICA-MIBCI.","Ruan J
Wu X
Zhou B
Guo X
Lv Z
","(PMID:30402801
)",An Automatic Channel Selection Approach for ICA-Based Motor Imagery Brain Computer Interface.,https://europepmc.org/abstract/MED/30402801%0A
No abstract provided.,"Kirkpatrick S
","(PMID:12560537
)",Computer science. Rough times ahead.,https://europepmc.org/abstract/MED/12560537%0A
"A heterogeneous method of coupled multiscale strength model is presented in this paper for calculating the strength of medical polyesters such as polylactide (PLA), polyglycolide (PGA) and their copolymers during degradation by bulk erosion. The macroscopic device is discretized into an array of mesoscopic cells. A polymer chain is assumed to stay in one cell. With the polymer chain scission, it is found that the molecular weight, chain recrystallization induced by polymer chain scissions, and the cavities formation due to polymer cell collapse play different roles in the composition of mechanical strength of the polymer. Therefore, three types of strength phases were proposed to display the heterogeneous strength structures and to represent different strength contribution to polymers, which are amorphous phase, crystallinity phase and strength vacancy phase, respectively. The strength of the amorphous phase is related to the molecular weight; strength of the crystallinity phase is related to molecular weight and degree of crystallization; and the strength vacancy phase has negligible strength. The vacancy strength phase includes not only the cells with cavity status but also those with an amorphous status, but a molecular weight value below a threshold molecular weight. This heterogeneous strength model is coupled with micro chain scission, chain recrystallization and a macro oligomer diffusion equation to form a multiscale strength model which can simulate the strength phase evolution, cells status evolution, molecular weight, degree of crystallinity, weight loss and device strength during degradation. Different example cases are used to verify this model. The results demonstrate a good fit to experimental data.","Zhang T
Jin G
Han X
Gao Y
Zeng Q
Hou B
Zhang D
","(PMID:30399563
)",Multiscale modelling for the heterogeneous strength of biodegradable polyesters.,https://europepmc.org/abstract/MED/30399563%0A
"Changes in ocean temperature over time have important implications for marine ecosystems and global climate change. Marine temperature changes with time and has the features of closeness, period, and trend. This paper analyzes the temporal dependence of marine temperature variation at multiple depths and proposes a new ocean-temperature time-series prediction method based on the temporal dependence parameter matrix fusion of historical observation data. The Temporal Dependence-Based Long Short-Term Memory (LSTM) Networks for Marine Temperature Prediction (TD-LSTM) proves better than other methods while predicting sea-surface temperature (SST) by using Argo data. The performances were good at various depths and different regions.","Liu J
Zhang T
Han G
Gou Y
","(PMID:30404217
)",TD-LSTM: Temporal Dependence-Based LSTM Networks for Marine Temperature Prediction.,https://europepmc.org/abstract/MED/30404217%0A
"The publication presents a comparative study of two fibre-optic sensors in the application of heart rate (HR) and respiratory rate (RR) monitoring of the human body. After consultation with clinical practitioners, two types of non-invasive measuring and analysis systems based on fibre Bragg grating (FBG) and fibre-optic interferometer (FOI) have been designed and assembled. These systems use probes (both patent pending) that have been encapsulated in the bio-compatible polydimethylsiloxane (PMDS). The main advantage of PDMS is that it is electrically non-conductive and, as well as optical fibres, has low permeability. The initial verification measurement of the system designed was performed on four subjects in a harsh magnetic resonance (MR) environment under the supervision of a senior radiology assistant. A follow-up comparative study was conducted, upon a consent of twenty volunteers, in a laboratory environment with a minimum motion load and discussed with a head doctor of the Radiodiagnostic Institute. The goal of the laboratory study was to perform measurements that would simulate as closely as possible the environment of harsh MR or the environment of long-term health care facilities, hospitals and clinics. Conventional HR and RR measurement systems based on ECG measurements and changes in the thoracic circumference were used as references. The data acquired was compared by the objective Bland⁻Altman (B⁻A) method and discussed with practitioners. The results obtained confirmed the functionality of the designed probes, both in the case of RR and HR measurements (for both types of B⁻A, more than 95% of the values lie within the ±1.96 SD range), while demonstrating higher accuracy of the interferometric probe (in case of the RR determination, 95.66% for the FOI probe and 95.53% for the FBG probe, in case of the HR determination, 96.22% for the FOI probe and 95.23% for the FBG probe).","Nedoma J
Kepak S
Fajkus M
Cubik J
Siska P
Martinek R
Krupa P
","(PMID:30384506
)",Magnetic Resonance Imaging Compatible Non-Invasive Fibre-Optic Sensors Based on the Bragg Gratings and Interferometers in the Application of Monitoring Heart and Respiration Rate of the Human Body: A Comparative Study.,https://europepmc.org/abstract/MED/30384506%0A
"OBJECTIVES:To develop and test a new multifeature-based computer-aided diagnosis (CADx) scheme of lung cancer by fusing quantitative imaging (QI) features and serum biomarkers to improve CADx performance in classifying between malignant and benign pulmonary nodules. METHODS:First, a dataset involving 173 patients was retrospectively assembled, which includes computed tomography (CT) images and five serum biomarkers extracted from blood samples. Second, a CADx scheme using a four-step-based semiautomatic segmentation method was applied to segment the targeted lung nodules, and compute 78 QI features from each segmented nodule from CT images. Third, two support vector machine (SVM) classifiers were built using QI features and serum biomarkers, respectively. SVM classifiers were trained and tested using the overall dataset with a Relief feature selection method, a synthetic minority oversampling technique and a leave-one-case-out validation method. Finally, to further improve CADx performance, an information-fusion method was used to combine the prediction scores generated by two SVM classifiers. RESULTS:Areas under receiver operating characteristic curves (AUC) generated by QI feature and serum biomarker-based SVMs were 0.81 ± 0.03 and 0.69 ± 0.05, respectively. Using an optimal weighted fusion method to combine prediction scores generated by two SVMs, AUC value significantly increased to 0.85 ± 0.03 (P < 0.05). CONCLUSIONS:This study demonstrates (a) higher CADx performance by using QI features than using the serum biomarkers and (b) feasibility of further improving CADx performance by fusion of QI features and serum biomarkers, which indicates that QI features and serum biomarkers contain the complementary classification information.","Gong J
Liu JY
Jiang YJ
Sun XW
Zheng B
Nie SD
","(PMID:30317652
)",Fusion of quantitative imaging features and serum biomarkers to improve performance of computer-aided diagnosis scheme for lung cancer: A preliminary study.,https://europepmc.org/abstract/MED/30317652%0A
"Mutation frequencies vary along the genome, but the factors determining this variability are only partially understood. Pich et al. unravel a ∼10 bp periodicity in mutation rates at nucleosome-proximal regions that follows minor groove orientation. Opposing differential DNA damage and repair processes could shape genetic divergence irrespective of selection.","Kotler E
Segal E
","(PMID:30388449
)",The Helix Twist: Damage and Repair Follows the DNA Minor Groove.,https://europepmc.org/abstract/MED/30388449%0A
"Both experimental and computational methods are available to gather information about a protein's conformational space and interpret changes in protein structure. However, experimentally observing and computationally modeling large proteins remain critical challenges for structural biology. Our work aims at addressing these challenges by combining computational and experimental techniques relying on each other to overcome their respective limitations. Indeed, despite its advantages, an experimental technique such as hydrogen-exchange monitoring cannot produce structural models because of its low resolution. Additionally, the computational methods that can generate such models suffer from the curse of dimensionality when applied to large proteins. Adopting a common solution to this issue, we have recently proposed a framework in which our computational method for protein conformational sampling is biased by experimental hydrogen-exchange data. In this paper, we present our latest application of this computational framework: generating an atomic-resolution structural model for an unknown protein state. For that, starting from an available protein structure, we explore the conformational space of this protein, using hydrogen-exchange data on this unknown state as a guide. We have successfully used our computational framework to generate models for three proteins of increasing size, the biggest one undergoing large-scale conformational changes.","Devaurs D
Antunes DA
Kavraki LE
","(PMID:30384411
)",Revealing Unknown Protein Structures Using Computational Conformational Sampling Guided by Experimental Hydrogen-Exchange Data.,https://europepmc.org/abstract/MED/30384411%0A
"For many decades, ultrasonic imaging inspection has been adopted as a principal method to detect multiple defects, e.g., void and corrosion. However, the data interpretation relies on an inspector's subjective judgment, thus making the results vulnerable to human error. Nowadays, advanced computer vision techniques reveal new perspectives on the high-level visual understanding of universal tasks. This research aims to develop an efficient automatic ultrasonic image analysis system for nondestructive testing (NDT) using the latest visual information processing technique. To this end, we first established an ultrasonic inspection image dataset containing 6849 ultrasonic scan images with full defect/no-defect annotations. Using the dataset, we performed a comprehensive experimental comparison of various computer vision techniques, including both conventional methods using hand-crafted visual features and the most recent convolutional neural networks (CNN) which generate multiple-layer stacking for representation learning. In the computer vision community, the two groups are referred to as shallow and deep learning, respectively. Experimental results make it clear that the deep learning-enabled system outperformed conventional (shallow) learning schemes by a large margin. We believe this benchmarking could be used as a reference for similar research dealing with automatic defect detection in ultrasonic imaging inspection.","Ye J
Ito S
Toyama N
","(PMID:30405086
)",Computerized Ultrasonic Imaging Inspection: From Shallow to Deep Learning.,https://europepmc.org/abstract/MED/30405086%0A
"Underground personnel localization is highly important in the operations of coal mines. Considering the special underground environment, this paper introduces a novel localization scheme based on step detection and image recognition technologies, which makes use of unique characteristics of the underground environment like the dark environment and the miner's lamp. Since the underground topology is relatively simple, the miner can be located only by step information. However, the localization with step information always causes the problem of cumulative error. To solve this problem, we rebuild a special base station with a camera in a dark underground environment. A miner's lamp, which every miner carries, can simply transform to irradiate unique shapes (such as triangles, rectangles, and circles) and every coal miner at the base station can identify these shapes based on image recognition technologies. Thus, we can obtain the miner's precise position when he/she is passing by a base station. In that way, we can correct the localization results to solve cumulative error. We implemented our algorithm in indoor and underground environments. The experimental results show that 96% of spatial errors were 2.5 m or less.","Niu Q
Yang X
Yin Y
","(PMID:30380683
)",IPL: Image-Assisted Person Localization for Underground Coal Mines.,https://europepmc.org/abstract/MED/30380683%0A
No abstract provided.,"Hanson B
Coontz R
","(PMID:11557872
)",A computer science odyssey.,https://europepmc.org/abstract/MED/11557872%0A
"Overlapping structures of protein⁻protein interaction networks are very prevalent in different biological processes, which reflect the sharing mechanism to common functional components. The overlapping community detection (OCD) algorithm based on central node selection (CNS) is a traditional and acceptable algorithm for OCD in networks. The main content of CNS is the central node selection and the clustering procedure. However, the original CNS does not consider the influence among the nodes and the importance of the division of the edges in networks. In this paper, an OCD algorithm based on a central edge selection (CES) algorithm for detection of overlapping communities of protein⁻protein interaction (PPI) networks is proposed. Different from the traditional CNS algorithms for OCD, the proposed algorithm uses community magnetic interference (CMI) to obtain more reasonable central edges in the process of CES, and employs a new distance between the non-central edge and the set of the central edges to divide the non-central edge into the correct cluster during the clustering procedure. In addition, the proposed CES improves the strategy of overlapping nodes pruning (ONP) to make the division more precisely. The experimental results on three benchmark networks and three biological PPI networks of Mus. musculus, Escherichia coli, and Cerevisiae show that the CES algorithm performs well.","Zhang F
Ma A
Wang Z
Ma Q
Liu B
Huang L
Wang Y
","(PMID:30322177
 PMCID:PMC6222769)",A Central Edge Selection Based Overlapping Community Detection Algorithm for the Detection of Overlapping Structures in Protein⁻Protein Interaction Networks.,https://europepmc.org/abstract/MED/30322177%0A
"The probabilistic nature of synaptic transmission has remained enigmatic. However, recent developments have started to shed light on why the brain may rely on probabilistic synapses. Here, we start out by reviewing experimental evidence on the specificity and plasticity of synaptic response statistics. Next, we overview different computational perspectives on the function of plastic probabilistic synapses for constrained, statistical and deep learning. We highlight that all of these views require some form of optimisation of probabilistic synapses, which has recently gained support from theoretical analysis of long-term synaptic plasticity experiments. Finally, we contrast these different computational views and propose avenues for future research. Overall, we argue that the time is ripe for a better understanding of the computational functions of probabilistic synapses.","Llera-Montero M
Sacramento J
Costa RP
","(PMID:30308457
)",Computational roles of plastic probabilistic synapses.,https://europepmc.org/abstract/MED/30308457%0A
No abstract provided.,"Panch T
Szolovits P
Atun R
","(PMID:30405904
 PMCID:PMC6199467)","Artificial intelligence, machine learning and health systems.",https://europepmc.org/abstract/MED/30405904%0A
"This paper describes the author's experience of infusing an introductory database course with privacy content, and the on-going project entitled Integrating Ethics Into the Database Curriculum, that evolved from that experience. The project, which has received funding from the National Science Foundation, involves the creation of a set of privacy modules that can be implemented systematically by database educators throughout the database design thread of an undergraduate course.","Appel F
","(PMID:16279760
)",Ethics across the computer science curriculum: privacy modules in an introductory database course.,https://europepmc.org/abstract/MED/16279760%0A
"The soil is composed of several nutrients which are important for the effective growth of plants. Nitrogen, phosphorus, and potassium are micronutrients which are very important for plant growth. There have been several methods and soil tests developed to test the compositions of these nutrients in the soil. Interpreting the results gotten from such tests has been a herculean task for farmers. Employing the use of a soft computing method to interpret such result would be a noble idea. In this paper, we describe the use of fuzzy logic to interpret the values of nitrogen, phosphorus, and potassium (NPK) gotten from conventional soil test to know their levels in the soil and predict possible NPK inputs.","Ogunleye GO
Fashoto SG
Mashwama P
Arekete SA
Olaniyan OM
Omodunbi BA
","(PMID:30410427
 PMCID:PMC6205101)",Fuzzy Logic Tool to Forecast Soil Fertility in Nigeria.,https://europepmc.org/abstract/MED/30410427%0A
"ACL-injuries are one of the most common knee injuries in noncontact sports. Kinematic data of injury prone situations provide important information to study the underlying ACL-injury mechanisms. However, these data are rare. In this work an approach is presented to generate injury prone situations for noncontact ACL-injuries on a computer. The injury prone situations are generated by a musculoskeletal simulation model using kinematic data of a non-injury situation and the method of Monte Carlo simulation. The approach is successfully applied to generate injury prone landings in downhill ski racing. The characteristics of the obtained injury prone landings are consistent with video recordings of injury cases.","Eberle R
Heinrich D
van den Bogert AJ
Oberguggenberger M
Nachbauer W
","(PMID:30398089
)",An approach to generate noncontact ACL-injury prone situations on a computer using kinematic data of non-injury situations and Monte Carlo simulation.,https://europepmc.org/abstract/MED/30398089%0A
"For Diels⁻Alder (DA) reactions in solution, an accurate and converged free energy (FE) surface at ab initio (ai) quantum mechanical/molecular mechanical (QM/MM) level is imperative for the understanding of reaction mechanism. However, this computation is still far too expensive. In a previous work, we proposed a new method termed MBAR+wTP, with which the computation of the ai FE profile can be accelerated by several orders of magnitude via a three-step procedure: (I) an umbrella sampling (US) using a semi-empirical (SE) QM/MM Hamiltonian is performed; (II) the FE profile is generated using the Multistate Bennett Acceptance Ratio (MBAR) analysis; and (III) a weighted Thermodynamic Perturbation (wTP) from the SE Hamiltonian to the ai Hamiltonian is performed to obtain the ai QM/MM FE profile using weight factors from the MBAR analysis. In this work, this method is extended to the calculations of two-dimensional FE surfaces of two Diels⁻Alder reactions of cyclopentadiene with either acrylonitrile or 1-4-naphthoquinone at ai QM/MM level. The accurate activation free energies at the ai QM/MM level, which are much closer to the experimental measurements than those calculated by other methods, indicate that this MBAR+wTP method can be applied in the studies of complex reactions in condensed phase with much-enhanced efficiency.","Li P
Liu F
Jia X
Shao Y
Hu W
Zheng J
Mei Y
","(PMID:30274188
 PMCID:PMC6222833)",Efficient Computation of Free Energy Surfaces of Diels⁻Alder Reactions in Explicit Solvent at Ab Initio QM/MM Level.,https://europepmc.org/abstract/MED/30274188%0A
"Progress in the life sciences, including genome sequencing and high-throughput experimentation, offers an opportunity for understanding biology and medicine from a systems perspective. This 'new view', which complements the more traditional component-based approach, involves the integration of biological research with approaches from engineering disciplines and computer science. The result is more than a new set of technologies. Rather, it promises a fundamental reconceptualization of the life sciences based on the development of quantitative and predictive models to describe crucial processes. To achieve this change, learning communities are being formed at the interface of the life sciences, engineering and computer science. Through these communities, research and education will be integrated across disciplines and the challenges associated with multidisciplinary team-based science will be addressed.","Tadmor B
Tidor B
","(PMID:16182211
)",Interdisciplinary research and education at the biology-engineering-computer science interface: a perspective.,https://europepmc.org/abstract/MED/16182211%0A
"In the experiment of inertial confinement fusion, soft X-ray spectrum unfolding can provide important information to optimize the design of the laser and target. As the laser beams increase, there are limited locations for installing detection channels to obtain measurements, and the soft X-ray spectrum can be difficult to recover. In this paper, a novel recovery method of soft X-ray spectrum unfolding based on compressive sensing is proposed, in which (1) the spectrum recovery is formulated as a problem of accurate signal recovery from very few measurements (i.e., compressive sensing), and (2) the proper basis atoms are selected adaptively over a Legendre orthogonal basis dictionary with a large size and Lasso regression in the sense of ℓ1 norm, which enables the spectrum to be accurately recovered with little measured data from the limited detection channels. Finally, the presented approach is validated with experimental data. The results show that it can still achieve comparable accuracy from only 8 spectrometer detection channels as it has previously done from 14 detection channels. This means that the presented approach is capable of recovering spectrum from the data of limited detection channels, and it can be used to save more space for other detectors.","Xia N
Huang Y
Li H
Li P
Wang K
Wang F
","(PMID:30388853
)",A Novel Recovery Method of Soft X-ray Spectrum Unfolding Based on Compressive Sensing.,https://europepmc.org/abstract/MED/30388853%0A
"We demonstrate a unique microfluidic device for continuous-flow cell sorting by railing target cells along physical tracks (electrode sidewalls) based on the combined effect of dielectrophoresis and hydrodynamic drag. The tracks are the raised digits of comb-like structures made of conducting bulk silicon as the electrodes. Unlike other volumetric electrodes, the structures feature a segmented sidewall profile with linear and concave segments forming the tracks and supporting columns, respectively. The interdigitated bulk electrodes lead to a built-in flow chamber in which the digits (tracks) extend downstream at a characteristic angle with respect to the flow, which runs through the passages between the columns. Target cells leaving the passages are levitated and docked against the tracks under positive dielectrophoresis and railed under hydrodynamic drag. Railing efficiency, as high as >95%, is reported against the activation voltage and flow rate for the designs 7°, 16°, and 26° as the track angles. A collection efficiency of about 86% is noted for both target (HCT116) and non-target cells (K562) in the 16° design at a sample flow rate of 8.3 μL min-1 and an activation voltage of 12.5 Vp at 200 kHz. This performance is comparable if not better than those obtained with thin-film surface microelectrodes and yet achieved here at an order of magnitude higher sample flow rate. This enhancement mainly arises from a considerably low drag along the tracks in relation to the chamber top or bottom surface where the thin-film electrodes would be typically placed.","Xing X
Ng CN
Chau ML
Yobas L
","(PMID:30403217
)",Railing cells along 3D microelectrode tracks for continuous-flow dielectrophoretic sorting.,https://europepmc.org/abstract/MED/30403217%0A
"In genetic evolution, meiotic recombination plays an important role. Recombination introduces genetic variations and is a vital source of biodiversity and appears as a driving force in evolutionary development. Local regions of chromosomes where recombination events tend to be concentrated are known as hotspots and regions with relatively low frequencies of recombination are called coldspots. Predicting hotspots and coldspots can enlighten structure of recombination and genome evolution. In this paper, we proposed a predictor, called iRecSpot-EF to predict recombination hot and cold spots. iRecSpot-EF uses a novel set of features extracted from the genome sequences. We introduce the frequency of (l,k,p)-mers in the sequence as features. Our proposed feature extraction method hinges solely upon the nucleotide sequences, thus being cost-effective and robust. After feature extraction, the most informative features are selected using AdaBoost algorithm. We have selected logistic regression as the classification algorithm. iRecSpot-EF was tested on a standard benchmark dataset using cross-fold validation. It achieved an accuracy of 95.14% and area under Receiver Operating Characteristic curve (auROC) of 0.985. The performance of iRecSpot-EF is significantly better than the state-of-the-art methods. iRecSpot-EF is readily available for use from http://iRecSpot.pythonanywhere.com/server. All relevant codes are available via open repository at: https://github.com/mrzResearchArena/iRecSpot.","Jani MR
Khan Mozlish MT
Ahmed S
Tahniat NS
Farid DM
Shatabda S
","(PMID:30336361
)",iRecSpot-EF: Effective sequence based features for recombination hotspot prediction.,https://europepmc.org/abstract/MED/30336361%0A
"Objective: To evaluate the effect of computer-assisted design based on three-dimensional reconstruction technique on the reduction accuracy of tibial and fibular fractures with Taylor external fixation. Methods: A retrospective review was conducted on the clinical data of 69 patients who had tibia and fibula fractures treated with Taylor external fixation in department of orthopedic trauma of Tianjin Hospital from January 2016 to January 2018 to compare the residual deformity after fracture reduction between computer-assisted design method (experimental group) and the standard measurement method (control group). The frontal and lateral tibia and fibula X-ray of all the affected limbs were taken. In experimental group, all the patients took bilateral tibial CT tomography, and then DICOM format documents were input into the Mimics 17.1 software and got three-dimensional models of targeted bone and external fixation ring. After that the visual image matching was performed between external fixation ring three-dimensional reconstruction model and the standard model and also between the affected limb and the contralateral limb. Then the reduction trajectory plan of bone broken end and the position of external fixation ring were obtained. The STL files were input to Solid Works software and got the length of six rods to adjust the Taylor external fixation. In control group, the films were measured by Coreldraw X7 X-ray measurement software and the parameters were input in Taylor Spatial Frame system software. And then six calibrated threaded rods were adjusted according to the prescription of the software. Finally, all the patients took the X-ray films again to evaluate the degree of residual displacement. Skew distributional data are indicated with M(QR), and method of non-parameter was used to analyze variances between groups. Results: All patients had better fracture reduction and achieved functional reset criteria. In the control group, the amount of displacement and angle residual aberration (improvement) in the frontal and lateral radiographs were 0.50(2.30)mm(90%), 0.00(0.85)mm(100%)and 0.00°(1.50°)(100%), 0.00°(0.00°)(100%), respectively. In the control group, the amount of displacement and angle residual aberration (improvement) in the frontal and lateral radiographs were 1.40(3.28)mm(69%), 2.15(4.27)mm(46%)and 1.15°(1.85°)(73%), 0.80°(2.10°)(67%). The positive and lateral angles and lateral displacements in the two groups were significantly different(P<0.05), but there was no statistically significant difference in positive displacement (P=0.099). Conclusion: Both computer-assisted design method and the standard measurement method have satisfactory reduction effect, but computer-assisted design can accurately correct fracture deformity, which is good for fracture healing and functional recovery of affected limb.","Zhang XP
Liu YS
Ma XL
Sun ZH
Wang S
Li H
Zhang T
","(PMID:30369163
)",[The application of computer-assisted design in the reduction of long bone fractures with Taylor spatial frame].,https://europepmc.org/abstract/MED/30369163%0A
"Relation extraction between medical concepts from electronic medical records has pervasive applications as well as significance. However, previous researches utilizing machine learning algorithms judge the semantic types of medical concept pair mentions independently. In fact, different concept pair mentions in the same context are of dependencies which can provide beneficial evidences for identifying their relation types. To the best of our knowledge, only one study has considered such dependencies in discharge summaries. However, its hard constraints are not applied effectively to the History of Present Illness (HPI) in electronic Medical Records. According to the writing characteristics of HPI records, we generalize two regularities of dependencies among concept pairs mentioned in an HPI record to enhance the performance of relation extraction. We incorporate the two soft constraints corresponding to the regularities and the posterior probabilities returned by a local classifier into a joint inference process which applies Integer Quadratic Programming method to carry out collective classification for all concept pair mentions in an HPI record. We implement four local classification models including support vector machine, logistics regression, random forest and piecewise convolutional neural networks to examine the performance of our approach. A series of experimental results demonstrate that our collective classification method has made a principal improvement and outperforms the other state-of-the-art methods.","Chen L
Li Y
Chen W
Liu X
Yu Z
Zhang S
","(PMID:30292854
)",Utilizing soft constraints to enhance medical relation extraction from the history of present illness in electronic medical records.,https://europepmc.org/abstract/MED/30292854%0A
"Problems in computer science, such as error correction in information transfer and ""satisfiability"" in optimization, show phase transitions familiar from solid-state physics. In his Perspective, Mézard explains how recent advances in these three fields originate in similar ""message passing"" procedures. The exchange of elaborate messages between different variables and constraints, used in the study of phase transitions in physical systems, helps to make error correction and satisfiability codes more efficient.","Mézard M
","(PMID:14500972
)",Physics/computer science. Passing messages between disciplines.,https://europepmc.org/abstract/MED/14500972%0A
"The aim of the study was the evaluation of a dietary habits profile and physical activity of Physiotherapy and Technical & Computer Science students. The research involved a group of 174 non-full-time students of higher education institutions in Krakow aged between 22 and 27. 81 students of the surveyed studied Physiotherapy at the University of Physical Education, whereas 93 followed a course in Technical & Computer Science at the Pedagogical University. In this project a diagnostic survey method was used. The study revealed that the lifestyle of university youth left much to be desired. Dietary errors were exemplified by irregular meals intake, low consumption of fish, milk and dairy, snacking between meals on high calorie products with a poor nutrient content. With regard to physical activity, Physiotherapy students were characterised by more positive attitudes than those from Technical & Computer Science. Such physical activity forms as swimming, team sports, cycling and strolling were declared by the surveyed the most frequently. Health-oriented education should be introduced in such a way as to improve the knowledge pertaining to a health-promoting lifestyle as a means of prevention of numerous diseases.","Medrela-Kuder E
","(PMID:22171523
)",[Evaluation of the lifestyle of students of physiotherapy and technical & computer science basing on their diet and physical activity].,https://europepmc.org/abstract/MED/22171523%0A
"AIM:To examine the practices used by New Zealand's 20 district health boards (DHBs) to protect patient privacy when patient information is used for research, and particularly practices for de-identifying information. METHOD:An e-mailed questionnaire survey, using New Zealand's Official Information Act to request information on the policies and practices of each DHB. RESULTS:19/20 DHBs (95%) responded to the survey, one of which reported that it did not provide patient information for research. 18/18 (100%) of the DHBs that reported providing patient information for research required the project to have ethics approval. 18/18 (100%) of the DHBs that offered patient data for research also required individual patient consent and/or de-identification of the information before it was used for research. 14/18 DHBs (78%) deidentified data before releasing it for research, 8/18 DHBs (48%) sought individual patient consent before releasing data for research, and 5/18 (28%) used both methods. Other measures to protect privacy included confidentiality agreements, encryption and cybersecurity procedures. CONCLUSION:Our findings show DHBs self-report that they have sufficient measures in place to protect privacy when patient information is used for research. However, these measures need to be continuously evaluated against rapidly evolving international practices and technological developments.","Yogarajan V
Mayo M
Pfahringer B
","(PMID:30408815
)",Privacy protection for health information research in New Zealand district health boards.,https://europepmc.org/abstract/MED/30408815%0A
"Identifying drug-target interactions will greatly narrow down the scope of search of candidate medications, and thus can serve as the vital first step in drug discovery. Considering that in vitro experiments are extremely costly and time-consuming, high efficiency computational prediction methods could serve as promising strategies for drug-target interaction (DTI) prediction. In this review, our goal is to focus on machine learning approaches and provide a comprehensive overview. First, we summarize a brief list of databases frequently used in drug discovery. Next, we adopt a hierarchical classification scheme and introduce several representative methods of each category, especially the recent state-of-the-art methods. In addition, we compare the advantages and limitations of methods in each category. Lastly, we discuss the remaining challenges and future outlook of machine learning in DTI prediction. This article may provide a reference and tutorial insights on machine learning-based DTI prediction for future researchers.","Chen R
Liu X
Jin S
Lin J
Liu J
","(PMID:30200333
 PMCID:PMC6225477)",Machine Learning for Drug-Target Interaction Prediction.,https://europepmc.org/abstract/MED/30200333%0A
"In its simplest form, multicast communication is the process of sending data packets from a source to multiple destinations in the same logical multicast group. IP multicast allows the efficient transport of data through wide-area networks, and its potentially great value for the Grid has been highlighted recently by a number of research groups. In this paper, we focus on the use of IP multicast in Grid applications, which require high-throughput reliable multicast. These include Grid-enabled computational steering and collaborative visualization applications, and wide-area distributed computing. We describe the results of our extensive evaluation studies of state-of-the-art reliable-multicast protocols, which were performed on the UK's high-speed academic networks. Based on these studies, we examine the ability of current reliable multicast technology to meet the Grid's requirements and discuss future directions.","Nekovee M
Barcellos MP
Daw M
","(PMID:16099747
)",Reliable multicast for the Grid: a case study in experimental computer science.,https://europepmc.org/abstract/MED/16099747%0A
"Motivation:Cellular function is closely related to the localizations of its substructures. It is, however, challenging to experimentally label all subcellular structures simultaneously in the same cell. This raises the need of building a computational model to learn the relationships among these subcellular structures and use reference structures to infer the localizations of other structures. Results:We formulate such a task as a conditional image generation problem and propose to use conditional generative adversarial networks for tackling it. We employ an encoder-decoder network as the generator and propose to use skip connections between the encoder and decoder to provide spatial information to the decoder. To incorporate the conditional information in a variety of different ways, we develop three different types of skip connections, known as the self-gated connection, encoder-gated connection, and label-gated connection. The proposed skip connections are built based on the conditional information using gating mechanisms. By learning a gating function, the network is able to control what information should be passed through the skip connections from the encoder to the decoder. Since the gate parameters are also learned automatically, we expect that only useful spatial information is transmitted to the decoder to help image generation. We perform both qualitative and quantitative evaluations to assess the effectiveness of our proposed approaches. Experimental results show that our cGAN-based approaches have the ability to generate the desired subcellular structures correctly. Our results also demonstrate that the proposed approaches outperform the existing approach based on adversarial autoencoders, and the new skip connections lead to improved performance. In addition, the localizations of generated subcellular structures by our approaches are consistent with observations in biological experiments. Availability:The source code and more results are available at https://github.com/divelab/cgan/.","Yuan H
Cai L
Wang Z
Hu X
Zhang S
Ji S
","(PMID:30398548
)",Computational Modeling of Cellular Structures Using Conditional Deep Generative Networks.,https://europepmc.org/abstract/MED/30398548%0A
"This study uses the machine vision method to develop an on-machine turning tool insert condition monitoring system for tool condition monitoring in the cutting processes of computer numerical control (CNC) machines. The system can identify four external turning tool insert conditions, namely fracture, built-up edge (BUE), chipping, and flank wear. This study also designs a visual inspection system for the tip of an insert using the surrounding light source and fill-light, which can be mounted on the turning machine tool, to overcome the environmental effect on the captured insert image for subsequent image processing. During image capture, the intensity of the light source changes to ensure that the test insert has appropriate surface and tip features. This study implements outer profile construction, insert status region capture, insert wear region judgment, and calculation to monitor and classify insert conditions. The insert image is then trimmed according to the vertical flank, horizontal blade, and vertical blade lines. The image of the insert-wear region is captured to monitor flank or chipping wear using grayscale value histogram. The amount of wear is calculated using the wear region image as the evaluation index to judge normal wear or over-wear conditions. On-machine insert condition monitoring is tested to confirm that the proposed system can judge insert fracture, BUE, chipping, and wear. The results demonstrate that the standard deviation of the chipping and amount of wear accounts for 0.67% and 0.62%, of the average value, respectively, thus confirming the stability of system operation.","Sun WH
Yeh SS
","(PMID:30322197
 PMCID:PMC6213146)",Using the Machine Vision Method to Develop an On-machine Insert Condition Monitoring System for Computer Numerical Control Turning Machine Tools.,https://europepmc.org/abstract/MED/30322197%0A
"In this study we provide the analysis of eye movement behavior elicited by low-level feature distinctiveness with a dataset of synthetically-generated image patterns. Design of visual stimuli was inspired by the ones used in previous psychophysical experiments, namely in free-viewing and visual searching tasks, to provide a total of 15 types of stimuli, divided according to the task and feature to be analyzed. Our interest is to analyze the influences of low-level feature contrast between a salient region and the rest of distractors, providing fixation localization characteristics and reaction time of landing inside the salient region. Eye-tracking data was collected from 34 participants during the viewing of a 230 images dataset. Results show that saliency is predominantly and distinctively influenced by: 1. feature type, 2. feature contrast, 3. temporality of fixations, 4. task difficulty and 5. center bias. This experimentation proposes a new psychophysical basis for saliency model evaluation using synthetic images.","Berga D
Fdez-Vidal XR
Otazu X
Leborán V
Pardo XM
","(PMID:30408434
)",Psychophysical evaluation of individual low-level feature influences on visual attention.,https://europepmc.org/abstract/MED/30408434%0A
"Intrinsically disordered proteins and regions are involved in a wide range of cellular functions, and they often facilitate protein-protein interactions. Molecular recognition features (MoRFs) are segments of intrinsically disordered regions that bind to partner proteins, where binding is concomitant with a transition to a structured conformation. MoRFs facilitate translation, transport, signaling, and regulatory processes and are found across all domains of life. A popular computational tool, MoRFpred, accurately predicts MoRFs in protein sequences. MoRFpred is implemented as a user-friendly web server that is freely available at http://biomine.cs.vcu.edu/servers/MoRFpred/ . We describe this predictor, explain how to run the web server, and show how to interpret the results it generates. We also demonstrate the utility of this web server based on two case studies, focusing on the relevance of evolutionary conservation of MoRF regions.","Oldfield CJ
Uversky VN
Kurgan L
","(PMID:30298407
)",Predicting Functions of Disordered Proteins with MoRFpred.,https://europepmc.org/abstract/MED/30298407%0A
"The cyber-physical system (CPS) is a next-generation smart system that combines computing with physical space. It has been applied in various fields because the uncertainty of the physical world can be ideally controlled using cyber technology. In terms of environmental control, studies have been conducted to enhance the effectiveness of the service by inducing ideal emotions in the service space. This paper proposes a CPS control system for inducing emotion based on multiple sensors. The CPS can expand the constrained environmental sensors of the physical space variously by combining the virtual space with the physical space. The cyber space is constructed in a Unity 3D space that can be experienced through virtual reality devices. We collect the temperature, humidity, dust concentration, and current emotion in the physical space as an environmental control elements, and the control illumination, color temperature, video, sound and volume in the cyber space. The proposed system consists of an emotion prediction module using modular Bayesian networks and an optimal stimulus decision module for deriving the predicted emotion to the target emotion based on utility theory and reinforcement learning. To verify the system, the performance is evaluated using the data collected from real situations.","Choi SG
Cho SB
","(PMID:30400364
)",Sensor Information Fusion by Integrated AI to Control Public Emotion in a Cyber-Physical Environment.,https://europepmc.org/abstract/MED/30400364%0A
"The function of a protein is largely determined by its three-dimensional structure and its interactions with other proteins. Changes to a protein's amino acid sequence can alter its function by perturbing the energy landscapes of protein folding and binding. Many tools have been developed to predict the energetic effect of amino acid changes, utilizing features describing the sequence of a protein, the structure of a protein, or both. Those tools can have many applications, such as distinguishing between deleterious and benign mutations and designing proteins and peptides with attractive properties. In this chapter, we describe how to use one of such tools, ELASPIC, to predict the effect of mutations on the stability of proteins and the affinity between proteins, in the context of a human protein-protein interaction network. ELASPIC uses a wide range of sequential and structural features to predict the change in the Gibbs free energy for protein folding and protein-protein interactions. It can be used both through a web server and as a stand-alone application. Since ELASPIC was trained using homology models and not crystal structures, it can be applied to a much broader range of proteins than traditional methods. It can leverage precalculated sequence alignments, homology models, and other features, in order to drastically lower the amount of time required to evaluate individual mutations and make tractable the analysis of millions of mutations affecting the majority of proteins in a genome.","Strokach A
Corbi-Verge C
Teyra J
Kim PM
","(PMID:30298389
)",Predicting the Effect of Mutations on Protein Folding and Protein-Protein Interactions.,https://europepmc.org/abstract/MED/30298389%0A
"The variational auto-encoder (VAE) is a powerful and scalable deep generative model. Under the architecture of VAE, the choice of the approximate posterior distribution is one of the crucial issues, and it has a significant impact on tractability and flexibility of the VAE. Generally, latent variables are assumed to be normally distributed with a diagonal covariance matrix, however, it is not flexible enough to match the true complex posterior distribution. We introduce a novel approach to design a flexible and arbitrarily complex approximate posterior distribution. Unlike VAE, firstly, an initial density is constructed by a Gaussian mixture model, and each component has a diagonal covariance matrix. Then this relatively simple distribution is transformed into a more flexible one by applying a sequence of invertible Householder transformations until the desired complexity has been achieved. Additionally, we also give a detailed theoretical and geometric interpretation of Householder transformations. Lastly, due to this change of approximate posterior distribution, the Kullback-Leibler distance between two mixture densities is required to be calculated, but it has no closed form solution. Therefore, we redefine a new variational lower bound by virtue of its upper bound. Compared with other generative models based on similar VAE architecture, our method achieves new state-of-the-art results on benchmark datasets including MNIST, Fashion-MNIST, Omniglot and Histopathology data a more challenging medical images dataset, the experimental results show that our method can improve the flexibility of posterior distribution more effectively.","Liu G
Liu Y
Guo M
Li P
Li M
","(PMID:30408693
)",Variational inference with Gaussian mixture model and householder flow.,https://europepmc.org/abstract/MED/30408693%0A
"Mobile Crowdsensing (MCS) is a paradigm for collecting large-scale sensor data by leveraging mobile devices equipped with small and low-powered sensors. MCS has recently received considerable attention from diverse fields, because it can reduce the cost incurred in the process of collecting a large amount of sensor data. However, in the task assignment process in MCS, to allocate the requested tasks efficiently, the workers need to send their specific location to the requester, which can raise serious location privacy issues. In this paper, we focus on the methods for publishing differentially a private spatial histogram to guarantee the location privacy of the workers. The private spatial histogram is a sanitized spatial index where each node represents the sub-regions and contains the noisy counts of the objects in each sub-region. With the sanitized spatial histograms, it is possible to estimate approximately the number of workers in the arbitrary area, while preserving their location privacy. However, the existing methods have given little concern to the domain size of the input dataset, leading to the low estimation accuracy. This paper proposes a partitioning technique SAGA (Skew-Aware Grid pArtitioning) based on the hotspots, which is more appropriate to adjust the domain size of the dataset. Further, to optimize the overall errors, we lay a uniform grid in each hotspot. Experimental results on four real-world datasets show that our method provides an enhanced query accuracy compared to the existing methods.","Kim JS
Chung YD
Kim JW
","(PMID:30380798
)",Differentially Private and Skew-Aware Spatial Decompositions for Mobile Crowdsensing.,https://europepmc.org/abstract/MED/30380798%0A
No abstract provided.,"Geller J
Perl Y
Cui L
Zhang GQ
","(PMID:30205171
)",Quality assurance of biomedical terminologies and ontologies.,https://europepmc.org/abstract/MED/30205171%0A
"The accuracy and diversity of recommendation algorithms have always been the research hotspot of recommender systems. A good recommender system should not only have high accuracy and diversity, but also have adequate robustness against spammer attacks. However, the issue of recommendation robustness has received relatively little attention in the literature. In this paper, we systematically study the influences of different spammer behaviors on the recommendation results in various recommendation algorithms. We further propose an improved algorithm by incorporating the inner-similarity of user's purchased items in the classic KNN approach. The new algorithm effectively enhances the robustness against spammer attacks and thus outperforms traditional algorithms in recommendation accuracy and diversity when spammers exist in the online commercial systems.","Zhang C
Liu J
Qu Y
Han T
Ge X
Zeng A
","(PMID:30383766
 PMCID:PMC6211683)",Enhancing the robustness of recommender systems against spammers.,https://europepmc.org/abstract/MED/30383766%0A
"Malaria parasitemia diagnosis and grading is hard and still far from perfection. Inaccurate diagnosis and grading has caused tremendous deaths rate particularly in young children worldwide. The current research deeply reviews automated malaria parasitemia diagnosis and grading in thin blood smear digital images through image analysis and computer vision based techniques. Actually, state-of-the-art reveals that current proposed practices present partially or morphology dependent solutions to the problem of computer vision based microscopy diagnosis of malaria parasitemia. Accordingly, a deep appraisal of the current practices is investigated, compared and analyzed on benchmark datasets. The open gaps are highlighted and the future directions are laid down for a complete automated microscopy diagnosis for malaria parasitemia based on those factors that have not been affected by other diseases. Moreover, a general computer vision framework to perform malaria parasitemia estimation/grading is constructed in universal directions. Finally, remaining problems are highlighted and possible directions are suggested. RESEARCH HIGHLIGHTS: The current research presents a microscopic malaria parasitemia diagnosis and grading of malaria in thin blood smear digital images through image analysis and computer vision based techniques. The open gaps are highlighted and future directions for a complete automated microscopy diagnosis of malaria parasitemia mentioned.","Rehman A
Abbas N
Saba T
Mehmood Z
Mahmood T
Ahmed KT
","(PMID:30207623
)",Microscopic malaria parasitemia diagnosis and grading on benchmark datasets.,https://europepmc.org/abstract/MED/30207623%0A
"Recently released large-scale neuron morphological data has greatly facilitated the research in neuroinformatics. However, the sheer volume and complexity of these data pose significant challenges for efficient and accurate neuron exploration. In this paper, we propose an effective retrieval framework to address these problems, based on frontier techniques of deep learning and binary coding. For the first time, we develop a deep learning based feature representation method for the neuron morphological data, where the 3D neurons are first projected into binary images and then learned features using an unsupervised deep neural network, i.e., stacked convolutional autoencoders (SCAEs). The deep features are subsequently fused with the hand-crafted features for more accurate representation. Considering the exhaustive search is usually very time-consuming in large-scale databases, we employ a novel binary coding method to compress feature vectors into short binary codes. Our framework is validated on a public data set including 58,000 neurons, showing promising retrieval precision and efficiency compared with state-of-the-art methods. In addition, we develop a novel neuron visualization program based on the techniques of augmented reality (AR), which can help users take a deep exploration of neuron morphologies in an interactive and immersive manner.","Li Z
Butler E
Li K
Lu A
Ji S
Zhang S
","(PMID:29435954
)",Large-scale Exploration of Neuronal Morphologies Using Deep Learning and Augmented Reality.,https://europepmc.org/abstract/MED/29435954%0A
"Clusters retrieved by generic Adaptive Resonance Theory (ART) networks are limited to their internal categorical representation. This study extends the capabilities of ART by incorporating multiple vigilance thresholds in a single network: stricter (data compression) and looser (cluster similarity) vigilance values are used to obtain a many-to-one mapping of categories-to-clusters. It demonstrates this idea in the context of Fuzzy ART, presented as Dual Vigilance Fuzzy ART (DVFA), to improve the ability to capture clusters with arbitrary geometry. DVFA outperformed Fuzzy ART for the datasets in our experiments while yielding a statistically-comparable performance to another more complex, multi-prototype Fuzzy ART-based architecture.","Brito da Silva LE
Elnabarawy I
Wunsch DC 2nd
","(PMID:30388429
)",Dual vigilance fuzzy adaptive resonance theory.,https://europepmc.org/abstract/MED/30388429%0A
"Theoretical biology is a field that attempts to understand the complex phenomena of life in terms of mathematical and physical principles. Likewise, theoretical medicine employs mathematical arguments and models as a methodology in approaching the complexities of human disease. Naturally, these concepts can be applied to dermatology. There are many possible methods available in the theoretical investigation of skin disease. A number of examples are presented briefly. These include the mathematical modelling of pattern formation in congenital naevi and erythema gyratum repens, an information-theoretic approach to the analysis of genetic networks in autoimmunity, and computer simulations of early melanoma growth. To conclude, an analogy is drawn between the behaviour of well-known physical processes, such as earthquakes, and the spatio-temporal evolution of skin disease. Creating models in skin disease can lead to predictions that can be investigated experimentally or by observation and offer the prospect of unexpected or important insights into pathogenesis.","Gilmore S
","(PMID:15842395
)","Modelling skin disease: lessons from the worlds of mathematics, physics and computer science.",https://europepmc.org/abstract/MED/15842395%0A
"Many motion sensor-based applications have been developed in recent years because they provide useful information about daily activities and current health status of users. However, most of these applications require knowledge of sensor positions. Therefore, this research focused on the problem of detecting sensor positions. We collected standing-still and walking sensor data at various body positions from ten subjects. The offset values were removed by subtracting the sensor data of standing-still phase from the walking data for each axis of each sensor unit. Our hierarchical classification technique is based on optimizing local classifiers. Many common features are computed, and informative features are selected for specific classifications. In this approach, local classifiers such as arm-side and hand-side discriminations yielded F1-scores of 0.99 and 1.00, correspondingly. Overall, the proposed method achieved an F1-score of 0.81 and 0.84 using accelerometers and gyroscopes, respectively. Furthermore, we also discuss contributive features and parameter tuning in this analysis.","Sang VNT
Yano S
Kondo T
","(PMID:30356012
)",On-Body Sensor Positions Hierarchical Classification.,https://europepmc.org/abstract/MED/30356012%0A
"Neurons communicate nonlinearly through spike activities. Generalized linear models (GLMs) describe spike activities with a cascade of a linear combination across inputs, a static nonlinear function, and an inhomogeneous Bernoulli or Poisson process, or Cox process if a self-history term is considered. This structure considers the output nonlinearity in spike generation but excludes the nonlinear interaction among input neurons. Recent studies extend GLMs by modeling the interaction among input neurons with a quadratic function, which considers the interaction between every pair of input spikes. However, quadratic effects may not fully capture the nonlinear nature of input interaction. We therefore propose a staged point-process model to describe the nonlinear interaction among inputs using a few hidden units, which follows the idea of artificial neural networks. The output firing probability conditioned on inputs is formed as a cascade of two linear-nonlinear (a linear combination plus a static nonlinear function) stages and an inhomogeneous Bernoulli process. Parameters of this model are estimated by maximizing the log likelihood on output spike trains. Unlike the iterative reweighted least squares algorithm used in GLMs, where the performance is guaranteed by the concave condition, we propose a modified Levenberg-Marquardt (L-M) algorithm, which directly calculates the Hessian matrix of the log likelihood, for the nonlinear optimization in our model. The proposed model is tested on both synthetic data and real spike train data recorded from the dorsal premotor cortex and primary motor cortex of a monkey performing a center-out task. Performances are evaluated by discrete-time rescaled Kolmogorov-Smirnov tests, where our model statistically outperforms a GLM and its quadratic extension, with a higher goodness-of-fit in the prediction results. In addition, the staged point-process model describes nonlinear interaction among input neurons with fewer parameters than quadratic models, and the modified L-M algorithm also demonstrates fast convergence.","Qian C
Sun X
Zhang S
Xing D
Li H
Zheng X
Pan G
Wang Y
","(PMID:30314427
)",Nonlinear Modeling of Neural Interaction for Spike Prediction Using the Staged Point-Process Model.,https://europepmc.org/abstract/MED/30314427%0A
"Investigation into the network of protein-protein interactions (PPIs) will provide valuable insights into the inner workings of cells. Accordingly, it is crucially important to develop an automated method or high-throughput tool that can efficiently predict the PPIs. In this study, a new predictor, called ""iPPI-PseAAC(CGR)"", was developed by incorporating the information of ""chaos game representation"" into the PseAAC (Pseudo Amino Acid Composition). The advantage by doing so is that some key sequence-order or sequence-pattern information can be more effectively incorporated during the treatment of the protein pair samples. The operation engine used in this predictor is the random forests algorithm. It has been observed via the cross-validations on the widely used benchmark datasets that the success rates achieved by the proposed predictor are remarkably higher than those by its existing counterparts. For the convenience of the most experimental scientists, a user-friendly web-server for the new predictor has been established at http://www.jci-bioinfo.cn/iPPI-PseAAC(CGR), by which users can easily get their desired results without the need to go through the detailed mathematics.","Jia J
Li X
Qiu W
Xiao X
Chou KC
","(PMID:30312687
)",iPPI-PseAAC(CGR): Identify protein-protein interactions by incorporating chaos game representation into PseAAC.,https://europepmc.org/abstract/MED/30312687%0A
"Living organisms must maintain proper regulation including defense and healing. Life-threatening problems may be caused by pathogens or an organism's own cells' deficiency or hyperactivity, in cancer or auto-immunity. Life evolved solutions to these problems that can be conceptualized through the lens of information security, which is a well-developed field in computer science. Here I argue that taking an information security view of cell biology is not merely semantics, but useful to explain features of cell signaling and regulation. It also offers a conduit for cross-fertilization of advanced ideas from computer science, and the potential for biology to inform computer science. First, I consider whether cells use passwords, i.e., precise initiation sequences that are required for subsequent signals to have any effect, by analyzing chromatin regulation and cellular reprogramming. Second, I consider whether cells use the more advanced security feature of encryption. Encryption could benefit cells by making it more difficult for pathogens to hijack cell networks. Because the 'language' of cell signaling is unknown, i.e., similar to an alien language detected by SETI, I use information theory to consider the general case of how non-randomness filters can be used to recognize (1) that a data stream encodes a language, rather than noise, and (2) quantitative criteria for whether an unknown language is encrypted. This leads to the result that an unknown language is encrypted if efforts at decryption produce sharp decreases in entropy and increases in mutual information. A fully decrypted language should have minimum entropy and maximum mutual information. The magnitude of which should scale with language complexity. I demonstrate this with a simple numerical experiment on English language text encrypted with a basic polyalphabetic cipher. I conclude with unanswered questions for future research.","Root A
","(PPR:PPR57559
)",Do Cells use Passwords? Do they Encrypt Information?,https://europepmc.org/abstract/PPR/PPR57559%0A
"SIGNIFICANCE:Computer-specific progressive addition lenses (PC-PALs) are shown to reduce computer vision syndrome (CVS) symptoms, increase visual comfort and tolerance, and improve body posture at the personal computer. They are highly preferred by computer workers. Increasing their use may aid prevention measures within the workplace health management. PURPOSE:This study investigates whether technical differences between general-purpose progressive addition lenses (GP-PALs) and PC-PALs are subjectively manifest in CVS. MATERIALS AND METHODS:One hundred ninety presbyopic visual display unit (VDU) workers aged 53 ± 6 years (mean ± SD) were fitted with GP-PALs and PC-PALs in a subject-masked, randomized, crossover study. Subjects tested both corrections at their personal workplace for 2 weeks each, for VDU work only. Comfort and lens type preferences were assessed using a 24-item questionnaire developed for this study. RESULTS:Computer vision syndrome was perceived approximately seven times more often with GP-PALs compared with PC-PALs. Eighty-four percent of subjects preferred PC-PALs for their VDU work. Computer-specific progressive addition lenses ratings were statistically and clinically significantly better than GP-PALs (5.95 vs. 4.42 of 7 points; 1.53; 95% confidence interval, 1.20 to 1.85). An existing ametropia or prior experience with PALs did not influence the score. Only 14.2% of subjects had received information about specific VDU eyewear from their optician or optometrist, whereas 79% expressed the wish to be informed about these products. CONCLUSIONS:Computer-specific progressive addition lenses reduce the perception of the CVS and are highly preferred by VDU workers.","Kolbe O
Degle S
","(PMID:30339644
)",Presbyopic Personal Computer Work: A Comparison of Progressive Addition Lenses for General Purpose and Personal Computer Work.,https://europepmc.org/abstract/MED/30339644%0A
"BACKGROUND:Smoking cessation is the most common preventative for an array of diseases, including lung cancer and chronic obstructive pulmonary disease. Although there are many efforts advocating for smoking cessation, smoking is still highly prevalent. For instance, in the USA in 2015, 50% of all smokers attempted to quit smoking, and only 5-7% of them succeeded - with slight deviation depending on external assistance. Previous studies show that computer-tailored messages which support smoking abstinence are effective. The combination of health recommender systems and behavioral-change theories is becoming increasingly popular in computer-tailoring. The objective of this study is to evaluate patients's smoking cessation rates by means of two randomized controlled trials using computer-tailored motivational messages. A group of 100 patients will be recruited in medical centers in Taiwan (50 patients in the intervention group, and 50 patients in the control group), and a group of 1000 patients will be recruited on-line (500 patients in the intervention group, and 500 patients in the control group). The collected data will be made available to the public in an open-source data portal. METHODS:Our study will gather data from two sources. The first source is a clinical pilot in which a group of patients from two Taiwanese medical centers will be randomly assigned to either an intervention or a control group. The intervention group will be provided with a mobile app that sends motivational messages selected by a recommender system that takes the user profile (including gender, age, motivations, and social context) and similar users' opinions. For 6 months, the patients' smoking activity will be followed up, and confirmed as ""smoke-free"" by using a test that measures expired carbon monoxide and urinary cotinine levels. The second source will be a public pilot in which Internet users wanting to quit smoking will be able to download the same mobile app as used in the clinical pilot. They will be randomly assigned to a control group that receives basic motivational messages or to an intervention group, that receives personalized messages by the recommender system. For 6 months, patients in the public pilot will be assessed periodically with self-reported questionnaires. DISCUSSION:This study will be the first to use the I-Change behavioral-change model in combination with a health recommender system and will, therefore, provide relevant insights into computer-tailoring for smoking cessation. If our hypothesis is validated, clinical practice for smoking cessation would benefit from the use of our mobile solution. TRIAL REGISTRATION:ClinicalTrials.gov, ID: NCT03108651 . Registered on 11 April 2017.","Hors-Fraile S
Malwade S
Spachos D
Fernandez-Luque L
Su CT
Jeng WL
Syed-Abdul S
Bamidis P
Li YJ
","(PMID:30413176
 PMCID:PMC6230227)",A recommender system to quit smoking with mobile motivational messages: study protocol for a randomized controlled trial.,https://europepmc.org/abstract/MED/30413176%0A
"Although tracking research has achieved excellent performance in mathematical angles, it is still meaningful to analyze tracking problems from multiple perspectives. This motivation not only promotes the independence of tracking research but also increases the flexibility of practical applications. This paper presents a significant tracking framework based on the multi-dimensional state⁻action space reinforcement learning, termed as multi-angle analysis collaboration tracking (MACT). MACT is comprised of a basic tracking framework and a strategic framework which assists the former. Especially, the strategic framework is extensible and currently includes feature selection strategy (FSS) and movement trend strategy (MTS). These strategies are abstracted from the multi-angle analysis of tracking problems (observer's attention and object's motion). The content of the analysis corresponds to the specific actions in the multidimensional action space. Concretely, the tracker, regarded as an agent, is trained with Q-learning algorithm and ϵ -greedy exploration strategy, where we adopt a customized rewarding function to encourage robust object tracking. Numerous contrast experimental evaluations on the OTB50 benchmark demonstrate the effectiveness of the strategies and improvement in speed and accuracy of MACT tracker.","Xue W
Feng Z
Xu C
Meng Z
Zhang C
","(PMID:30355977
)",Adaptive Object Tracking via Multi-Angle Analysis Collaboration.,https://europepmc.org/abstract/MED/30355977%0A
"Recently, remote points-of-care as a novel medical model has emerged and received considerable attention due to its convenient medical services such as efficient real-time monitoring and prompt information feedback. Although the points-of-care has more attractive advantages compared with traditional health care systems, some important issues still require a serious consideration such as privacy protection and the security of the transmitted biomedical signals. In this study, we propose a novel authentication and key agreement mechanism that ensures privacy preservation and provides biomedical signals protection during the communication process by negotiating a shared key to encrypt/decrypt sensitive information. Chaotic maps are employed in our design to achieve mutual authentication and key agreement for resource-constrained points-of-care, which also increases the efficiency in comparison with those schemes designed by Elliptic Curve Cryptography or RSA. Furthermore, dynamic identities are adopted in the proposed scheme to achieve user anonymity and user untraceability for the high-privacy-required points-of-care. The security of the proposed scheme is proven via Real-or-Random model. The performance analysis shows that the proposed scheme reduces computational overhead in comparison with the state-of-the-art schemes.","Zhang L
Luo H
Zhao L
Zhang Y
","(PMID:30390144
)",Privacy Protection for Point-of-Care Using Chaotic Maps-Based Authentication and Key Agreement.,https://europepmc.org/abstract/MED/30390144%0A
"Problem Solving (PS) skills allow students to handle problems within an educational context. PS is a core competence of Computer Science education and affects programming success. In this vein, this paper aims to investigate PS ability performance in primary school pupils of a computer course, implemented according to the Neo-Piagetian theory of cognitive development. The study included 945 Slovenian pupils, ranging from fourth to sixth grade. The effects of gender, age and consecutive years of attending the course were examined on pupils' PS ability at the pre-operational and concrete operational stages. Pupils completed a survey questionnaire with four types of tasks (a series of statements, if-statements, loops and variables) at both stages. The analysis revealed three findings: the performance of PS ability in all tasks was, at the pre-operational stage, associated positively with performance at the concrete operational stage; there were no gender differences in PS performance at both stages, and both the grade and consecutive year of taking the computer course had an effect on PS ability performance at both stages. Those in the lowest grade and those taking the course for the first year reported lower performances than their older counterparts. These findings may help curriculum designers across the world develop efficient approaches to teaching computer courses.","Kožuh I
Krajnc R
Hadjileontiadis LJ
Debevc M
","(PMID:30208039
 PMCID:PMC6135368)",Assessment of problem solving ability in novice programmers.,https://europepmc.org/abstract/MED/30208039%0A
"Although combining data from multiple entities could power life-saving breakthroughs, open sharing of pharmacological data is generally not viable because of data privacy and intellectual property concerns. To this end, we leverage modern cryptographic tools to introduce a computational protocol for securely training a predictive model of drug-target interactions (DTIs) on a pooled dataset that overcomes barriers to data sharing by provably ensuring the confidentiality of all underlying drugs, targets, and observed interactions. Our protocol runs within days on a real dataset of more than 1 million interactions and is more accurate than state-of-the-art DTI prediction methods. Using our protocol, we discover previously unidentified DTIs that we experimentally validated via targeted assays. Our work lays a foundation for more effective and cooperative biomedical research.","Hie B
Cho H
Berger B
","(PMID:30337410
)",Realizing private and practical pharmacological collaboration.,https://europepmc.org/abstract/MED/30337410%0A
"There are several kinds of Chinese herbal medicines originating from diverse sources. However, the rapid taxonomic identification of large quantities of Chinese herbal medicines is difficult using traditional methods, and the process of identification itself is prone to error. Therefore, the traditional methods of Chinese herbal medicine identification must meet higher standards of accuracy. With the rapid development of bioinformatics, methods relying on bioinformatics strategies offer advantages with respect to the speed and accuracy of the identification of Chinese herbal medicine ingredients. This article reviews the applicability and limitations of biochip and DNA barcoding technology in the identification of Chinese herbal medicines. Furthermore, the future development of the two technologies of interest is discussed.","Han K
Wang M
Zhang L
Wang C
","(PMID:30360419
 PMCID:PMC6222746)",Application of Molecular Methods in the Identification of Ingredients in Chinese Herbal Medicines.,https://europepmc.org/abstract/MED/30360419%0A
"Security is the most critical issue amid transmission of medical images because it contains sensitive information of patients. Medical image security is an essential method for secure the sensitive data when computerized images and their relevant patient data are transmitted across public networks. In this paper, the dual encryption procedure is utilized to encrypt the medical images. Initially Blowfish Encryption is considered and then signcryption algorithm is utilized to confirm the encryption model. After that, the Opposition based Flower Pollination (OFP) is utilized to upgrade the private and public keys. The performance of the proposed strategy is evaluated using performance measures such as Peak Signal to Noise Ratio (PSNR), entropy, Mean Square Error (MSE), and Correlation Coefficient (CC).","Avudaiappan T
Balasubramanian R
Pandiyan SS
Saravanan M
Lakshmanaprabu SK
Shankar K
","(PMID:30244385
)",Medical Image Security Using Dual Encryption with Oppositional Based Optimization Algorithm.,https://europepmc.org/abstract/MED/30244385%0A
"The detection of a silent interval or gap provides important insight into temporal processing by the auditory system. Previous research has uncovered a multitude of empirical findings leaving the mechanism of gap detection poorly understood and key issues unresolved. Here, we expand the findings by measuring psychometric functions for a number of conditions including both across-frequency and across-intensity gap detection as a first study of its kind. A model is presented which not only accounts for our findings in a quantitative manner, but also helps frame the body of work on auditory gap research. The model is based on the peripheral response and postulates that the identification of gap requires the detection of activity associated with silence.","Mori S
Kikuchi Y
Hirose N
Lepage H
Wong W
","(PMID:30343329
)",Auditory gap detection: psychometric functions and insights into the underlying neural activity.,https://europepmc.org/abstract/MED/30343329%0A
"In the version of this article originally published, there was an error in the URL linked to by an accession code in the data availability section of the methods. The erroneous URL was: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE100351 . The correct URL is: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE115821 . The error has been corrected in the HTML and PDF versions of this article.","Auslander N
Zhang G
Lee JS
Frederick DT
Miao B
Moll T
Tian T
Wei Z
Madan S
Sullivan RJ
Boland G
Flaherty K
Herlyn M
Ruppin E
","(PMID:30333558
)",Publisher Correction: Robust prediction of response to immune checkpoint blockade therapy in metastatic melanoma.,https://europepmc.org/abstract/MED/30333558%0A
"One of the most important issues in predictive modeling is to determine major cause factors of a phenomenon and causal relationships between them. Extracting causal relationships between parameters in a natural phenomenon can be accomplished through checking the parameters' changes in consecutive events. In addition, using information and probabilistic theory help better conception of causal relationships of a phenomenon. Therefore, probabilistic causal discovery from sequential data of a natural phenomenon can be useful for dimension reduction and predicting the future trend of a process. In this paper, we introduce a novel method for causal discovery from a sequential data based on a probabilistic causal graph. In this method, first, Causal Feature Dependency matrix (CFD matrix) is generated based on the features' changes in consecutive events. Then, a probabilistic causal graph is created from CFD matrix. In this graph, some valueless features will be eliminated on the basis of entropy value of each conditional density function. Finally, prediction operation is performed based on the output of causal graph. Experimental results on the Pooled Resource Open-Access ALS Clinical Trials (PRO-ACT) sequential data set from Amyotrophic Lateral Sclerosis (ALS) disease show that our proposed algorithm can predict the progression rate of ALS disease properly with high precision.","Ahangaran M
Jahed-Motlagh MR
Minaei-Bidgoli B
","(PMID:30339928
)",Causal Discovery from Sequential Data in ALS Disease based on Entropy Criteria.,https://europepmc.org/abstract/MED/30339928%0A
"The key of a surgical treatment for the lung cancer is to remove the infected part with the least excision and to retain most of the healthy lung tissue. The traditional computer surgery assisted system show that the patient's CT images or three-dimensional structure in the PC screen. This assisted system is not a real three-dimensional system and can't display well the position of pulmonary vessels and trachea of the patients to surgeon. To solve the problem, a computer assisted system for precise lung surgery for precise surgery based on medical image and VR is developed in this paper. Firstly, the regional growth and filling algorithm is designed to segment lung trachea and lung vessels. Then, the reference edge grid algorithm is used to construct the model of the segmentation trachea and lung vessels. And the models are saved as an identifiable STL type file. Finally, according to the system analysis for the specific system function, the computer assisted system is implemented to display the three-dimensional pulmonary vessels and trachea on the mixed reality device. The surgeons can observe and interface precisely the real three-dimensional lung structure of the patient to help them operate accurately the lung surgery.","Tan W
Ge W
Hang Y
Wu S
Liu S
Liu M
","(PMID:30279980
)",Computer assisted system for precise lung surgery based on medical image computing and mixed reality.,https://europepmc.org/abstract/MED/30279980%0A
"BACKGROUND:In the past, manufacture of prosthetic socket by using traditional handmade method not only consumed research time but also required a special assembly approach. Recently, reverse engineering and rapid prototype technology have grown up explosively, and thus, provide a choice to fabricate prosthetic socket. METHODS:Application 3D computer aided design and manufacturing (computer-aided design/computer-aided engineering) tools approach the surface shape stump data is digitized and can be easily modified and reused. Collocation investigates gait parameters of prosthetic socket, and interface stress between stump and socket with different processing conditions. Meanwhile, questionnaire was utilized to survey satisfaction rating scale, comfort level, of subjects using this kind of artificial device. RESULTS:The main outcome of current research including gait parameters, stress interface and satisfaction rating scale those would be an informative reference for further studies in design and manufacture as well as clinical applications of prosthetic sockets. CONCLUSIONS:This study found that, regardless of the method used for socket fabrication, most stress was concentrated in tibia end pressure-relief area. This caused discomfort in the area of tibia end to the participant wearing prosthesis. This discomfort was most evident in case when the prosthetic socket was fabricated using RE and RP.","Hsu CH
Ou CH
Hong WL
Gao YH
","(PMID:30396348
 PMCID:PMC6219010)",Comfort level discussion for prosthetic sockets with different fabricating processing conditions.,https://europepmc.org/abstract/MED/30396348%0A
"Accumulated studies have shown that environmental factors (EFs) can regulate the expression of microRNA (miRNA) which is closely associated with several diseases. Therefore, identifying miRNA-EF associations can facilitate the study of diseases. Recently, several computational methods have been proposed to explore miRNA-EF interactions. In this paper, a novel computational method, MEI-BRWMLL, is proposed to uncover the relationship between miRNA and EF. The similarities of miRNA-miRNA are calculated by using miRNA sequence, miRNA-EF interaction, and the similarities of EF-EF are calculated based on the anatomical therapeutic chemical information, chemical structure and miRNA-EF interaction. The similarity network fusion is used to fuse the similarity between miRNA and the similarity between EF, respectively. Further, the multiple-label learning and bi-random walk are employed to identify the association between miRNA and EF. The experimental results show that our method outperforms the state-of-the-art algorithms.","Luo H
Lan W
Chen Q
Wang Z
Liu Z
Yue X
Zhu L
","(PMID:30249984
 PMCID:PMC6222788)",Inferring microRNA-Environmental Factor Interactions Based on Multiple Biological Information Fusion.,https://europepmc.org/abstract/MED/30249984%0A
"CircRNAs have particular biological structure and have proven to play important roles in diseases. It is time-consuming and costly to identify circRNA-disease associations by biological experiments. Therefore, it is appealing to develop computational methods for predicting circRNA-disease associations. In this study, we propose a new computational path weighted method for predicting circRNA-disease associations. Firstly, we calculate the functional similarity scores of diseases based on disease-related gene annotations and the semantic similarity scores of circRNAs based on circRNA-related gene ontology, respectively. To address missing similarity scores of diseases and circRNAs, we calculate the Gaussian Interaction Profile (GIP) kernel similarity scores for diseases and circRNAs, respectively, based on the circRNA-disease associations downloaded from circR2Disease database (http://bioinfo.snnu.edu.cn/CircR2Disease/). Then, we integrate disease functional similarity scores and circRNA semantic similarity scores with their related GIP kernel similarity scores to construct a heterogeneous network made up of three sub-networks: disease similarity network, circRNA similarity network and circRNA-disease association network. Finally, we compute an association score for each circRNA-disease pair based on paths connecting them in the heterogeneous network to determine whether this circRNA-disease pair is associated. We adopt leave one out cross validation (LOOCV) and five-fold cross validations to evaluate the performance of our proposed method. In addition, three common diseases, Breast Cancer, Gastric Cancer and Colorectal Cancer, are used for case studies. Experimental results illustrate the reliability and usefulness of our computational method in terms of different validation measures, which indicates PWCDA can effectively predict potential circRNA-disease associations.","Lei X
Fang Z
Chen L
Wu FX
","(PMID:30384427
)",PWCDA: Path Weighted Method for Predicting circRNA-Disease Associations.,https://europepmc.org/abstract/MED/30384427%0A
"In this paper, we report a compact wavelength-flattened directional coupler (WFDC) based chemical sensor featuring an incorporated subwavelength grating (SWG) structure for the mid-infrared (MIR). By incorporating a SWG structure into directional coupler (DC), the dispersion in DC can be engineered to allow broadband operation which is advantageous to extract spectroscopic information for MIR sensing analysis. Meanwhile, the Bragg reflection introduced by the SWG structure produces a sharp trough at the Bragg wavelength. This sharp trough is sensitive to the surrounding refractive index (RI) change caused by the existence of analytes. Therefore, high sensitivity can be achieved in a small footprint. Around fivefold enhancement in the operation bandwidth compared to conventional DC is achieved for 100% coupling efficiency in a 40 µm long WFDC experimentally. Detection of dichloromethane (CH₂Cl₂) in ethanol (C₂H₅OH) is investigated in a SWG-based WFDC sensor 136.8 µm long. Sensing performance is studied by 3D finite-difference time domain (FDTD) simulation while sensitivity is derived by computation. Both RI sensing and absorption sensing are examined. RI sensing reveals a sensitivity of -0.47% self-normalized transmitted power change per percentage of CH₂Cl₂ concentration while 0.12% change in the normalized total integrated output power is realized in the absorption sensing. As the first demonstration of the DC based sensor in the MIR, our device has the potential for tertiary mixture sensing by utilizing both changes in the real and imaginary part of RI. It can also be used as a broadband building block for MIR application such as spectroscopic sensing system.","Dong B
Hu T
Luo X
Chang Y
Guo X
Wang H
Kwong DL
Lo GQ
Lee C
","(PMID:30388814
)",Wavelength-Flattened Directional Coupler Based Mid-Infrared Chemical Sensor Using Bragg Wavelength in Subwavelength Grating Structure.,https://europepmc.org/abstract/MED/30388814%0A
"Motivation:State-of-the-art biomedical named entity recognition (BioNER) systems often require handcrafted features specific to each entity type, such as genes, chemicals and diseases. Although recent studies explored using neural network models for BioNER to free experts from manual feature engineering, the performance remains limited by the available training data for each entity type. Results:We propose a multi-task learning framework for BioNER to collectively use the training data of different types of entities and improve the performance on each of them. In experiments on 15 benchmark BioNER datasets, our multi-task model achieves substantially better performance compared with state-of-the-art BioNER systems and baseline neural sequence labeling models. Further analysis shows that the large performance gains come from sharing character- and word-level information among relevant biomedical entities across differently labeled corpora. Availability:Our source code is available at https://github.com/yuzhimanhua/lm-lstm-crf. Supplementary information:Supplementary data are available at Bioinformatics online.","Wang X
Zhang Y
Ren X
Zhang Y
Zitnik M
Shang J
Langlotz C
Han J
","(PMID:30307536
)",Cross-type Biomedical Named Entity Recognition with Deep Multi-Task Learning.,https://europepmc.org/abstract/MED/30307536%0A
"Bone cancer originates from bone and rapidly spreads to the rest of the body affecting the patient. A quick and preliminary diagnosis of bone cancer begins with the analysis of bone X-ray or MRI image. Compared to MRI, an X-ray image provides a low-cost diagnostic tool for diagnosis and visualization of bone cancer. In this paper, a novel technique for the assessment of cancer stage and grade in long bones based on X-ray image analysis has been proposed. Cancer-affected bone images usually appear with a variation in bone texture in the affected region. A fusion of different methodologies is used for the purpose of our analysis. In the proposed approach, we extract certain features from bone X-ray images and use support vector machine (SVM) to discriminate healthy and cancerous bones. A technique based on digital geometry is deployed for localizing cancer-affected regions. Characterization of the present stage and grade of the disease and identification of the underlying bone-destruction pattern are performed using a decision tree classifier. Furthermore, the method leads to the development of a computer-aided diagnostic tool that can readily be used by paramedics and doctors. Experimental results on a number of test cases reveal satisfactory diagnostic inferences when compared with ground truth known from clinical findings.","Bandyopadhyay O
Biswas A
Bhattacharya BB
","(PMID:30367308
)",Bone-Cancer Assessment and Destruction Pattern Analysis in Long-Bone X-ray Image.,https://europepmc.org/abstract/MED/30367308%0A
"We discuss the inductive classification problem by proposing a joint framework termed Adaptive Non-negative Projective Semi-Supervised Learning (ANP-SSL). Specifically, ANP-SSL integrates the adaptive inductive label propagation, adaptive reconstruction weights learning and the neighborhood preserving projective nonnegative matrix factorization (PNMF) explicitly. To make the label prediction results more accurate, ANP-SSL incorporates the semi-supervised data representation and classification errors into regular PNMF for minimization, which can enable our ANP-SSL to perform the adaptive weights learning and label propagation over the spatially local and part-based data representations, which differs from most existing work that usually assign weights and predict labels based on the original data that often has noise and corruptions. Moreover, existing methods usually pre-assign weights before the process of label estimation, but such operation cannot ensure the learnt weights by independent step to be optimal for the subsequent classification. The combined representation error can also make the learnt reduced part-based representations of neighborhood preserving PNMF, which can potentially enhance the prediction results. By minimizing the classification error jointly over the neighborhood preserving nonnegative representation can make the embedding based classification efficient. Extensive results on several public image databases verified the effectiveness of our ANP-SSL, compared with other state-of-the-art methods.","Zhang Z
Jia L
Zhao M
Ye Q
Zhang M
Wang M
","(PMID:30195861
)",Adaptive non-negative projective semi-supervised learning for inductive classification.,https://europepmc.org/abstract/MED/30195861%0A
"White matter hyperintensities (WMH) are commonly found in the brains of healthy elderly individuals and have been associated with various neurological and geriatric disorders. In this paper, we present a study using deep fully convolutional network and ensemble models to automatically detect such WMH using fluid attenuation inversion recovery (FLAIR) and T1 magnetic resonance (MR) scans. The algorithm was evaluated and ranked 1st in the WMH Segmentation Challenge at MICCAI 2017. In the evaluation stage, the implementation of the algorithm was submitted to the challenge organizers, who then independently tested it on a hidden set of 110 cases from 5 scanners. Averaged dice score, precision and robust Hausdorff distance obtained on held-out test datasets were 80%, 84% and 6.30 mm respectively. These were the highest achieved in the challenge, suggesting the proposed method is the state-of-the-art. Detailed descriptions and quantitative analysis on key components of the system were provided. Furthermore, a study of cross-scanner evaluation is presented to discuss how the combination of modalities affect the generalization capability of the system. The adaptability of the system to different scanners and protocols is also investigated. A quantitative study is further presented to show the effect of ensemble size and the effectiveness of the ensemble model. Additionally, software and models of our method are made publicly available. The effectiveness and generalization capability of the proposed system show its potential for real-world clinical practice.","Li H
Jiang G
Zhang J
Wang R
Wang Z
Zheng WS
Menze B
","(PMID:30125711
)",Fully convolutional network ensembles for white matter hyperintensities segmentation in MR images.,https://europepmc.org/abstract/MED/30125711%0A
"Due to importantly beneficial effects on physical and mental health and strong association with many rehabilitation programs, Physical Activity Recognition and Monitoring (PARM) have been considered as a key paradigm for smart healthcare. Traditional methods for PARM focus on controlled environments with the aim of increasing the types of identifiable activity subjects complete and improving recognition accuracy and system robustness by means of novel body-worn sensors or advanced learning algorithms. The emergence of the Internet of Things (IoT) enabling technology is transferring PARM studies to open and connected uncontrolled environments by connecting heterogeneous cost-effective wearable devices and mobile apps. Little is currently known about whether traditional PARM technologies can tackle the new challenges of IoT environments and how to effectively harness and improve these technologies. In an effort to understand the use of IoT technologies in PARM studies, this paper will give a systematic review, critically examining PARM studies from a typical IoT layer-based perspective. It will firstly summarize the state-of-the-art in traditional PARM methodologies as used in the healthcare domain, including sensory, feature extraction and recognition techniques. The paper goes on to identify some new research trends and challenges of PARM studies in the IoT environments, and discusses some key enabling techniques for tackling them. Finally, this paper consider some of the successful case studies in the area and look at the possible future industrial applications of PARM in smart healthcare.","Qi J
Yang P
Waraich A
Deng Z
Zhao Y
Yang Y
","(PMID:30267895
)",Examining sensor-based physical activity recognition and monitoring for healthcare using Internet of Things: A systematic review.,https://europepmc.org/abstract/MED/30267895%0A
"The process of discovering novel drugs to treat diseases requires a long time and high cost. It is important to understand side effects of drugs as well as their therapeutic effects, because these can seriously damage the patients due to unexpected actions of the derived candidate drugs. In order to overcome these limitations, computational methods for predicting the therapeutic effects and side effects have been proposed. In particular, text mining is a widely used technique in the field of systems biology, because it can discover hidden relationships between drugs, genes and diseases from a large amount of literature data. Compared with in vivo/in vitro experiments, text mining derives meaningful results with less time and cost. In this study, we propose an algorithm for predicting novel drug-phenotype associations and drug-side effect associations using topic modeling and natural language processing (NLP). We extract sentences in which drugs and genes co-occur from the abstracts of the literature and identify words that describe the relationship between them using NLP. Considering the characteristics of the identified words, we determine if the drug has an up-regulation effect or a down-regulation effect on the gene. Based on genes that affect drugs and their regulatory relationships, we group the frequently occurring genes and regulatory relationships into topics, and build a drug-topic probability matrix by calculating the score that the drug will have a topic using topic modeling. Using the matrix, a classifier is constructed for predicting the novel indications and side effects of drugs considering the characteristics of known drug-phenotype associations or drug-side effect associations. The proposed method predicts both indications and side effects with a single algorithm, and it can exclude drugs with serious side effects or side effects that patients do not want to experience from among the candidate drugs provided for the treatment of the phenotype. Furthermore, lists of novel candidate drugs for phenotypes and side effects can be continuously updated with our algorithm every time a document is added. More than a thousand documents are produced per day, and it is possible for our algorithm to efficiently derive candidate drugs because it requires less cost than the existing drug repositioning methods. The resource of PISTON is available at databio.gachon.ac.kr/tools/PISTON.","Jang G
Lee T
Hwang S
Park C
Ahn J
Seo S
Hwang Y
Yoon Y
","(PMID:30268842
)",PISTON: Predicting drug indications and side effects using topic modeling and natural language processing.,https://europepmc.org/abstract/MED/30268842%0A
"DNA-binding proteins (DBPs) are responsible for several cellular functions, starting from our immunity system to the transport of oxygen. In the recent studies, scientists have used supervised machine learning based methods that use information from the protein sequence only to classify the DBPs. Most of the methods work effectively on the train sets but performance of most of them degrades in the independent test set. It shows a room for improving the prediction method by reducing over-fitting. In this paper, we have extracted several features solely using the protein sequence and carried out two different types of feature selection on them. Our results have proven comparable on training set and significantly improved on the independent test set. On the independent test set our accuracy was 82.26% which is 1.62% improved compared to the previous best state-of-the-art methods. Performance in terms of sensitivity and area under receiver operating characteristic curve for the independent test set was also higher and they were 0.95 and 0.823 respectively.","Adilina S
Farid DM
Shatabda S
","(PMID:30316822
)",Effective DNA binding protein prediction by using key features via Chou's general PseAAC.,https://europepmc.org/abstract/MED/30316822%0A
"Electrocardiography (ECG) sensors play a vital role in the Internet of Medical Things, and these sensors help in monitoring the electrical activity of the heart. ECG signal analysis can improve human life in many ways, from diagnosing diseases among cardiac patients to managing the lifestyles of diabetic patients. Abnormalities in heart activities lead to different cardiac diseases and arrhythmia. However, some cardiac diseases, such as myocardial infarction (MI) and atrial fibrillation (Af), require special attention due to their direct impact on human life. The classification of flattened T wave cases of MI in ECG signals and how much of these cases are similar to ST-T changes in MI remain an open issue for researchers. This article presents a novel contribution to classify MI and Af. To this end, we propose a new approach called deep deterministic learning (DDL), which works by combining predefined heart activities with fused datasets. In this research, we used two datasets. The first dataset, Massachusetts Institute of Technology-Beth Israel Hospital, is publicly available, and we exclusively obtained the second dataset from the University of Malaya Medical Center, Kuala Lumpur Malaysia. We first initiated predefined activities on each individual dataset to recognize patterns between the ST-T change and flattened T wave cases and then used the data fusion approach to merge both datasets in a manner that delivers the most accurate pattern recognition results. The proposed DDL approach is a systematic stage-wise methodology that relies on accurate detection of R peaks in ECG signals, time domain features of ECG signals, and fine tune-up of artificial neural networks. The empirical evaluation shows high accuracy (i.e., ≤99.97%) in pattern matching ST-T changes and flattened T waves using the proposed DDL approach. The proposed pattern recognition approach is a significant contribution to the diagnosis of special cases of MI.","Iqbal U
Wah TY
Habib Ur Rehman M
Mujtaba G
Imran M
Shoaib M
","(PMID:30397730
)",Deep Deterministic Learning for Pattern Recognition of Different Cardiac Diseases through the Internet of Medical Things.,https://europepmc.org/abstract/MED/30397730%0A
"Acute Leukemia is a life-threatening disease common both in children and adults that can lead to death if left untreated. Acute Lymphoblastic Leukemia (ALL) spreads out in children's bodies rapidly and takes the life within a few weeks. To diagnose ALL, the hematologists perform blood and bone marrow examination. Manual blood testing techniques that have been used since long time are often slow and come out with the less accurate diagnosis. This work improves the diagnosis of ALL with a computer-aided system, which yields accurate result by using image processing and deep learning techniques. This research proposed a method for the classification of ALL into its subtypes and reactive bone marrow (normal) in stained bone marrow images. A robust segmentation and deep learning techniques with the convolutional neural network are used to train the model on the bone marrow images to achieve accurate classification results. Experimental results thus obtained and compared with the results of other classifiers Naïve Bayesian, KNN, and SVM. Experimental results reveal that the proposed method achieved 97.78% accuracy. The obtained results exhibit that the proposed approach could be used as a tool to diagnose Acute Lymphoblastic Leukemia and its sub-types that will definitely assist pathologists.","Rehman A
Abbas N
Saba T
Rahman SIU
Mehmood Z
Kolivand H
","(PMID:30351463
)",Classification of acute lymphoblastic leukemia using deep learning.,https://europepmc.org/abstract/MED/30351463%0A
"Skeletal bone age assessment is a widely used standard procedure in both disease detection and growth prediction for children in endocrinology. Conventional manual assessment methods mainly rely on personal experience in observing X-ray images of left hand and wrist to calculate bone age, which show some intrinsic limitations from low efficiency to unstable accuracy. To address these problems, some automated methods based on image processing or machine learning have been proposed, while their performances are not satisfying enough yet in assessment accuracy. Motivated by the remarkable success of deep learning (DL) techniques in the fields of image classification and speech recognition, we develop a deep automated skeletal bone age assessment model based on convolutional neural networks (CNNs) and support vector regression (SVR) using multiple kernel learning (MKL) algorithm to process heterogeneous features in this paper. This deep framework has been constructed, not only exploring the X-ray images of hand and twist but also some other heterogeneous information like race and gender. The experiment results prove its better performance with higher bone age assessment accuracy on two different data sets compared with the state of the art, indicating that the fused heterogeneous features provide a better description of the degree of bones' maturation.","Tong C
Liang B
Li J
Zheng Z
","(PMID:30390162
)",A Deep Automated Skeletal Bone Age Assessment Model with Heterogeneous Features Learning.,https://europepmc.org/abstract/MED/30390162%0A
"How mutation and selection determine the fitness landscape of tumors and hence clinical outcome is an open fundamental question in cancer biology, crucial for the assessment of therapeutic strategies and resistance to treatment. Here we explore the mutation-selection phase diagram of 6,721 tumors representing 23 cancer types by quantifying the overall somatic point mutation load (ML) and selection (dN/dS) in the entire proteome of each tumor. We show that ML strongly correlates with patient survival, revealing two opposing regimes around a critical point. In low-ML cancers, a high number of mutations indicates poor prognosis, whereas high-ML cancers show the opposite trend, presumably due to mutational meltdown. Although the majority of cancers evolve near neutrality, deviations are observed at extreme MLs. Melanoma, with the highest ML, evolves under purifying selection, whereas in low-ML cancers, signatures of positive selection are observed, demonstrating how selection affects tumor fitness. Moreover, different cancers occupy specific positions on the ML-dN/dS plane, revealing a diversity of evolutionary trajectories. These results support and expand the theory of tumor evolution and its nonlinear effects on survival.","Persi E
Wolf YI
Leiserson MDM
Koonin EV
Ruppin E
","(PMID:30404913
)",Criticality in tumor evolution and clinical outcome.,https://europepmc.org/abstract/MED/30404913%0A
"The Luneburg lens is a spherically symmetrical gradient refractive index (GRIN) device with unique imaging properties. Its wide field-of-view (FoV) and minimal aberration have lead it to be successfully applied in microwave antennas. However, only limited realizations have been demonstrated in acoustics. Previously proposed acoustic Luneburg lenses are mostly limited to inherently two-dimensional designs at frequencies from 1 kHz to 7 kHz. In this paper, we apply a new design method for scalable and self-supporting metamaterials to demonstrate Luneburg lenses for airborne sound and ultrasonic waves. Two Luneburg lenses are fabricated: a 2.5D ultrasonic version for 40 kHz and a 3D version for 8 kHz sound. Imaging performance of the ultrasonic version is experimentally demonstrated.","Xie Y
Fu Y
Jia Z
Li J
Shen C
Xu Y
Chen H
Cummer SA
","(PMID:30385792
 PMCID:PMC6212425)",Acoustic Imaging with Metamaterial Luneburg Lenses.,https://europepmc.org/abstract/MED/30385792%0A
"Software defined networks brings greater flexibility to networks and therefore generates new vitality. Thanks to the ability to update soft code to sensor nodes, wireless sensor networks (WSNs) brings profound changes to Internet of Things. However, it is a challenging issue to minimize delay and transmission times and maintain long lifetime when broadcasting data packets in high loss ratio and low duty cycle WSNs. Although there have been some research concerning code dissemination, those schemes can only achieve a tradeoff between different performances, instead of optimizing all these important performances at the same time. Therefore, in this paper we propose a new strategy that can reduce delay and transmission times simultaneously. In traditional method, the broadcasting nature of wireless communication is not sufficiently utilized. By allowing sons of the same parent node to share awake slots, the broadcasting nature is well exploited and delay is thus reduced as well as transmission times with lifetime not affected. And, as we discover there is energy surplus when collecting data in area away from sink, we further improve this strategy so that all the performances can be further bettered. Compared with traditional method, the methods we design (IFAS, BTAS and AAPS) can respectively reduce delay by 20.56%, 31.59%, 55.16% and reduce transmission times by 29.53%, 43.93%, 42.04%, while not reducing lifetime.","Qi W
Liu W
Liu X
Liu A
Wang T
Xiong NN
Cai Z
","(PMID:30340393
 PMCID:PMC6211130)",Minimizing Delay and Transmission Times with Long Lifetime in Code Dissemination Scheme for High Loss Ratio and Low Duty Cycle Wireless Sensor Networks.,https://europepmc.org/abstract/MED/30340393%0A
"Association studies to discover links between genetic markers and phenotypes are central to bioinformatics. Methods of regularized regression, such as variants of the Lasso, are popular for this task. Despite the good predictive performance of these methods in the average case, they suffer from unstable selections of correlated variables and inconsistent selections of linearly dependent variables. Unfortunately, as we demonstrate empirically, such problematic situations of correlated and linearly dependent variables often exist in genomic data sets and lead to under-performance of classical methods of variable selection.To address these challenges, we propose the Precision Lasso. Precision Lasso is a Lasso variant that promotes sparse variable selection by regularization governed by the covariance and inverse covariance matrices of explanatory variables. We illustrate its capacity for stable and consistent variable selection in simulated data with highly correlated and linearly dependent variables. We then demonstrate the effectiveness of the Precision Lasso to select meaningful variables from transcriptomic profiles of breast cancer patients. Our results indicate that in settings with correlated and linearly dependent variables, the Precision Lasso outperforms popular methods of variable selection such as the Lasso, the Elastic Net, and Minimax Concave Penalty (MCP) regression.Software is available at https://github.com/HaohanWang/thePrecisionLasso.Supplementary data are available at Bioinformatics online.","Wang H
Lengerich BJ
Aragam B
Xing EP
","(PMID:30184048
)",Precision Lasso: Accounting for Correlations and Linear Dependencies in High-Dimensional Genomic Data.,https://europepmc.org/abstract/MED/30184048%0A
"Three-dimensional (3D) imaging has attracted more and more interest because of its widespread applications, especially in information and life science. These techniques can be broadly divided into two types: ray-based and wavefront-based 3D imaging. Issues such as imaging quality and system complexity of these techniques limit the applications significantly, and therefore many investigations have focused on 3D imaging from depth measurements. This paper presents an overview of 3D imaging from depth measurements, and provides a summary of the connection between the ray-based and wavefront-based 3D imaging techniques.","Chen N
Zuo C
Lam EY
Lee B
","(PMID:30384501
)",3D Imaging Based on Depth Measurement Technologies.,https://europepmc.org/abstract/MED/30384501%0A
"Protein arginylation mediated by arginyltransferase ATE1 is a key regulatory process essential for mammalian embryogenesis, cell migration, and protein regulation. Despite decades of studies, very little is known about the specificity of ATE1-mediated target site recognition. Here, we used in vitro assays and computational analysis to dissect target site specificity of mouse arginyltransferases and gain insights into the complexity of the mammalian arginylome. We found that the four ATE1 isoforms have different, only partially overlapping target site specificity that includes more variability in the target residues than previously believed. Based on all the available data, we generated an algorithm for identifying potential arginylation consensus motif and used this algorithm for global prediction of proteins arginylated in vivo on the N-terminal D and E. Our analysis reveals multiple proteins with potential ATE1 target sites and expand our understanding of the biological complexity of the intracellular arginylome.","Wang J
Pejaver VR
Dann GP
Wolf MY
Kellis M
Huang Y
Garcia BA
Radivojac P
Kashina A
","(PMID:30385798
 PMCID:PMC6212499)",Target site specificity and in vivo complexity of the mammalian arginylome.,https://europepmc.org/abstract/MED/30385798%0A
"The structural evolution of tantalum (Ta) during rapid cooling was investigated by molecular dynamics simulation, in terms of the system energy, the pair distribution function and the largest standard cluster analysis. It was found that the critical cooling rate for vitrification was about R ≥ 0.25 K ps-1, two orders lower than other metals (such as Au, Ag, Al, Zr and Zn) and that the meta-stable σ phase (β-Ta) not only appears on the pathway from liquid to the stable body-centred cubic crystal, but is also easily obtained at room temperature as a long-lived metastable phase with some probability. The most interesting point is that the liquid, amorphous and β-Ta phases share a nontrivial structural homology; the intrinsic topologically close-packed (TCP) structures in liquids are inherited and developed in different ways, resulting in amorphous or crystalline solids, respectively. With highly local packing fractions and geometrical incompatibility with the global close-packed (such as hcp, fcc and bcc) crystals, TCP structures inevitably result in structural heterogeneity and favour vitrification. As a superset of icosahedrons, TCP structures are ubiquitous in metallic melts, and just before the onset of crystallization reach their maximal number, which is much bigger in Ta than in other poor-GFA metals; so we argue that the strong forming ability of TCP local structures significantly enhances the glass forming ability of pure metals. These findings open up a new perspective that could have a profound impact on the research into metallic glasses.","Wu Z
Mo Y
Lang L
Yu A
Xie Q
Liu R
Tian Z
","(PMID:30383068
)",Topologically close-packed characteristic of amorphous tantalum.,https://europepmc.org/abstract/MED/30383068%0A
"BACKGROUND:Sri Lanka offers a huge diversity of flora with a large proportion of those being endemic to the island. Both the endemic and native plants species serve as a rich bank of phytochemicals. METHOD:In this study, ""Sri Lankan Flora"" an online web-based information system of phytochemical compounds isolated from the flora of Sri Lanka was proposed. RESULTS:The database contained 3D structures of those compounds, calculated quantitative-structure-activity relationship (QSAR) data and the GROMOS 54a7 force field parameters for each and every compound. The manually curated chemical structures, activities and force field parameters provide a possible direct avenue for computer aided drug discovery. The present study is a continuing project with a wider goal of building up a database, not only for assisting the computer aided drug designing process, but also for other chemical applications, as the database includes structural, physical, chemical and dynamic properties of chemical compounds of flora of Sri Lanka. The database is freely accessible at: http://science.cmb.ac.lk/tools/slflora.","Rathnayake S
Weerasinghe S
","(PMID:30306862
)",Development of an Information System of Structures and Force Field Parameters of Chemical Compounds from Sri Lankan Flora.,https://europepmc.org/abstract/MED/30306862%0A
"Traditional fabrication techniques for microfluidic devices utilize a planar chip format that possesses limited control over the geometry of and materials placement around microchannel cross-sections. This imposes restrictions on the design of flow fields and external forces (electric, magnetic, piezoelectric, etc.) that can be imposed onto fluids and particles. Here we report a method of fabricating microfluidic channels with complex cross-sections. A scaled-up version of a microchannel is dimensionally reduced through a thermal drawing process, enabling the fabrication of meters-long microfluidic fibers with nonrectangular cross-sectional shapes, such as crosses, five-pointed stars, and crescents. In addition, by codrawing compatible materials, conductive domains can be integrated at arbitrary locations along channel walls. We validate this technology by studying unexplored regimes in hydrodynamic flow and by designing a high-throughput cell separation device. By enabling these degrees of freedom in microfluidic device design, fiber microfluidics provides a method to create microchannel designs that are inaccessible using planar techniques.","Yuan R
Lee J
Su HW
Levy E
Khudiyev T
Voldman J
Fink Y
","(PMID:30373819
)",Microfluidics in structured multimaterial fibers.,https://europepmc.org/abstract/MED/30373819%0A
"BACKGROUND:The widespread application of data-driven factorization-based methods, such as independent component analysis (ICA), to functional magnetic resonance imaging data facilitates the study of neural function and how it is disrupted by psychiatric disorders such as schizophrenia. While the increasing number of these methods motivates a comparison of their relative performance, such a comparison is difficult to perform on real fMRI data, since the ground truth is, relatively, unknown and the alignment of factors across different methods is impractical and imprecise. NEW METHOD:We present a novel method, global difference maps (GDMs), to compare the results of different fMRI analysis techniques on real fMRI data, quantify their relative performances, and highlight the differences between the decompositions visually. COMPARISON WITH EXISTING METHODS:We apply this method to compare the performances of two different factorization-based methods, ICA and its multiset extension independent vector analysis (IVA), for the analysis of fMRI data from 109 patients with schizophrenia and 138 healthy controls during the performance of three tasks. RESULTS:Through this application of GDMs, we find that IVA can determine regions that are more discriminatory between patients and controls than ICA, though IVA is less effective at emphasizing regions found in only a subset of the tasks. CONCLUSIONS:These results demonstrate that GDMs are an effective way to compare the performances of different factorization-based methods as well as regression-based analyses.","Levin-Schwartz Y
Calhoun VD
Adalı T
","(PMID:30389489
)",A method to compare the discriminatory power of data-driven methods: Application to ICA and IVA.,https://europepmc.org/abstract/MED/30389489%0A
"Research on cytokine recognition is of great significance in the medical field due to the fact cytokines benefit the diagnosis and treatment of diseases, but the current methods for cytokine recognition have many shortcomings, such as low sensitivity and low F-score. Therefore, this paper proposes a new method on the basis of feature combination. The features are extracted from compositions of amino acids, physicochemical properties, secondary structures, and evolutionary information. The classifier used in this paper is SVM. Experiments show that our method is better than other methods in terms of accuracy, sensitivity, specificity, F-score and Matthew's correlation coefficient.","Yang Z
Wang J
Zheng Z
Bai X
","(PMID:30103521
 PMCID:PMC6222536)",A New Method for Recognizing Cytokines Based on Feature Combination and a Support Vector Machine Classifier.,https://europepmc.org/abstract/MED/30103521%0A
"Automatic and accurate segmentation of hippocampal structures in medical images is of great importance in neuroscience studies. In multi-atlas based segmentation methods, to alleviate the misalignment when registering atlases to the target image, patch-based methods have been widely studied to improve the performance of label fusion. However, weights assigned to the fused labels are usually computed based on predefined features (e.g. image intensities), thus being not necessarily optimal. Due to the lack of discriminating features, the original feature space defined by image intensities may limit the description accuracy. To solve this problem, we propose a patch-based label fusion with structured discriminant embedding method to automatically segment the hippocampal structure from the target image in a voxel-wise manner. Specifically, multi-scale intensity features and texture features are first extracted from the image patch for feature representation. Margin fisher analysis (MFA) is then applied to the neighboring samples in the atlases for the target voxel, in order to learn a subspace in which the distance between intra-class samples is minimized and the distance between inter-class samples is simultaneously maximized. Finally, the k-nearest neighbor (kNN) classifier is employed in the learned subspace to determine the final label for the target voxel. In the experiments, we evaluate our proposed method by conducting hippocampus segmentation using the ADNI dataset. Both the qualitative and quantitative results show that our method outperforms the conventional multi-atlas based segmentation methods.","Wang Y
Ma G
Wu X
Zhou J
","(PMID:29512026
)",Patch-Based Label Fusion with Structured Discriminant Embedding for Hippocampus Segmentation.,https://europepmc.org/abstract/MED/29512026%0A
No abstract provided.,"Shah N
Nute MG
Warnow T
Pop M
","(PMID:30247621
)",Misunderstood parameter of NCBI BLAST impacts the correctness of bioinformatics workflows.,https://europepmc.org/abstract/MED/30247621%0A
"In this paper, we propose a robust subspace learning (SL) framework for dimensionality reduction which further extends the existing SL methods to a low-rank and sparse embedding (LRSE) framework from three aspects: overall optimum, robustness and generalization. Owing to the uses of low-rank and sparse constraints, both the global subspaces and local geometric structures of data are captured by the reconstruction coefficient matrix and at the same time the low-dimensional embedding of data are enforced to respect the low-rankness and sparsity. In this way, the reconstruction coefficient matrix learning and SL are jointly performed, which can guarantee an overall optimum. Moreover, we adopt a sparse matrix to model the noise which makes LRSE robust to the different types of noise. The combination of global subspaces and local geometric structures brings better generalization for LRSE than related methods, i.e., LRSE performs better than conventional SL methods in unsupervised and supervised scenarios, particularly in unsupervised scenario the improvement of classification accuracy is considerable. Seven specific SL methods including unsupervised and supervised methods can be derived from the proposed framework and the experiments on different data sets (including corrupted data) demonstrate the superiority of these methods over the existing, well-established SL methods. Further, we exploit experiments to provide some new insights for SL.","Han N
Wu J
Liang Y
Fang X
Wong WK
Teng S
","(PMID:30216870
)",Low-rank and sparse embedding for dimensionality reduction.,https://europepmc.org/abstract/MED/30216870%0A
"Fetal electrocardiography is among the most promising methods of modern electronic fetal monitoring. However, before they can be fully deployed in the clinical practice as a gold standard, the challenges associated with the signal quality must be solved. During the last two decades, a great amount of articles dealing with improving the quality of the fetal electrocardiogram signal acquired from the abdominal recordings have been introduced. This article aims to present an extensive literature survey of different non-adaptive signal processing methods applied for fetal electrocardiogram extraction and enhancement. It is limiting that a different non-adaptive method works well for each type of signal, but independent component analysis, principal component analysis and wavelet transforms are the most commonly published methods of signal processing and have good accuracy and speed of algorithms.","Jaros R
Martinek R
Kahankova R
","(PMID:30373259
)",Non-Adaptive Methods for Fetal ECG Signal Processing: A Review and Appraisal.,https://europepmc.org/abstract/MED/30373259%0A
"In this study, we propose to use a method based on the combination of sample entropy with multiscale and multidimensional approaches, along with a fuzzy function. The model was applied to quantify and classify H&E histological images of colorectal cancer. The multiscale approach was defined by analysing windows of different sizes and variations in tolerance for determining pattern similarity. The multidimensional strategy was performed by considering each pixel in the colour image as an n-dimensional vector, which was analysed from the Minkowski distance. The fuzzy strategy was a Gaussian function used to verify the pertinence of the distances between windows. The result was a method capable of computing similarities between pixels contained in windows of various sizes, as well as the information present in the colour channels. The power of quantification was tested in a public colorectal image dataset, which was composed of both benign and malignant classes. The results were given as inputs for classifiers of different categories and analysed by applying the k-fold cross-validation and holdout methods. The derived performances indicate that the proposed association was capable of distinguishing the benign and malignant groups, with values that surpassed those results obtained with important techniques available in the Literature. The best performance was an AUC value of 0.983, an important result, mainly when we consider the difficulties of clinical practice for the diagnosis of the colorectal cancer.","Segato Dos Santos LF
Neves LA
Rozendo GB
Ribeiro MG
Zanchetta do Nascimento M
Azevedo Tosta TA
","(PMID:30368171
)",Multidimensional and fuzzy sample entropy (SampEnMF) for quantifying H&E histological images of colorectal cancer.,https://europepmc.org/abstract/MED/30368171%0A
"Multistage processing of automated breast ultrasound lesions recognition is dependent on the performance of prior stages. To improve the current state of the art, we propose the use of end-to-end deep learning approaches using fully convolutional networks (FCNs), namely FCN-AlexNet, FCN-32s, FCN-16s, and FCN-8s for semantic segmentation of breast lesions. We use pretrained models based on ImageNet and transfer learning to overcome the issue of data deficiency. We evaluate our results on two datasets, which consist of a total of 113 malignant and 356 benign lesions. To assess the performance, we conduct fivefold cross validation using the following split: 70% for training data, 10% for validation data, and 20% testing data. The results showed that our proposed method performed better on benign lesions, with a top ""mean Dice"" score of 0.7626 with FCN-16s, when compared with the malignant lesions with a top mean Dice score of 0.5484 with FCN-8s. When considering the number of images with Dice score >0.5 , 89.6% of the benign lesions were successfully segmented and correctly recognised, whereas 60.6% of the malignant lesions were successfully segmented and correctly recognized. We conclude the paper by addressing the future challenges of the work.","Yap MH
Goyal M
Osman FM
Martí R
Denton E
Juette A
Zwiggelaar R
","(PMID:30310824
)",Breast ultrasound lesions recognition: end-to-end deep learning approaches.,https://europepmc.org/abstract/MED/30310824%0A
"BACKGROUND:The Human Phenotype Ontology (HPO) is one of the most popular bioinformatics resources. Recently, HPO-based phenotype semantic similarity has been effectively applied to model patient phenotype data. However, the existing tools are revised based on the Gene Ontology (GO)-based term similarity. The design of the models are not optimized for the unique features of HPO. In addition, existing tools only allow HPO terms as input and only provide pure text-based outputs. RESULTS:We present PhenoSimWeb, a web application that allows researchers to measure HPO-based phenotype semantic similarities using four approaches borrowed from GO-based similarity measurements. Besides, we provide a approach considering the unique properties of HPO. And, PhenoSimWeb allows text that describes phenotypes as input, since clinical phenotype data is always in text. PhenoSimWeb also provides a graphic visualization interface to visualize the resulting phenotype network. CONCLUSIONS:PhenoSimWeb is an easy-to-use and functional online application. Researchers can use it to calculate phenotype similarity conveniently, predict phenotype associated genes or diseases, and visualize the network of phenotype interactions. PhenoSimWeb is available at http://120.77.47.2:8080.","Peng J
Xue H
Hui W
Lu J
Chen B
Jiang Q
Shang X
Wang Y
","(PMID:30367579
)",An online tool for measuring and visualizing phenotype similarities using HPO.,https://europepmc.org/abstract/MED/30367579%0A
"Orthognathic surgery belongs to the scope of maxillofacial surgery. It treats dentofacial deformities consisting in discrepancy between the facial bones (upper and lower jaws). Such impairment affects chewing, talking, and breathing and can ultimately result in the loss of teeth. Orthognathic surgery restores facial harmony and dental occlusion through bone cutting, repositioning, and fixation. However, in routine practice, we face the limitations of conventional tools and the lack of intraoperative assistance. These limitations occur at every step of the surgical workflow: preoperative planning, simulation, and intraoperative navigation. The aim of this research was to provide novel tools to improve simulation and navigation. We first developed a semiautomated segmentation pipeline allowing accurate and time-efficient patient-specific 3D modeling from computed tomography scans mandatory to achieve surgical planning. This step allowed an improvement of processing time by a factor of 6 compared with interactive segmentation, with a 1.5-mm distance error. Next, we developed a software to simulate the postoperative outcome on facial soft tissues. Volume meshes were processed from segmented DICOM images, and the Bullet open source mechanical engine was used together with a mass-spring model to reach a postoperative simulation accuracy <1 mm. Our toolset was completed by the development of a real-time navigation system using minimally invasive electromagnetic sensors. This navigation system featured a novel user-friendly interface based on augmented virtuality that improved surgical accuracy and operative time especially for trainee surgeons, therefore demonstrating its educational benefits. The resulting software suite could enhance operative accuracy and surgeon education for improved patient care.","Lutz JC
Hostettler A
Agnus V
Nicolau S
George D
Soler L
Rémond Y
","(PMID:30270757
)","A New Software Suite in Orthognathic Surgery : Patient Specific Modeling, Simulation and Navigation.",https://europepmc.org/abstract/MED/30270757%0A
"Although the number of sequenced insect genomes numbers in the hundreds, little is known about gene regulatory sequences in any species other than the well-studied Drosophila melanogaster. We provide here a detailed protocol for using SCRMshaw, a computational method for predicting cis-regulatory modules (CRMs, also ""enhancers"") in sequenced insect genomes. SCRMshaw is effective for CRM discovery throughout the range of holometabolous insects and potentially in even more diverged species, with true-positive prediction rates of 75% or better. Minimal requirements for using SCRMshaw are a genome sequence and training data in the form of known Drosophila CRMs; a comprehensive set of the latter can be obtained from the SCRMshaw download site. For basic applications, a user with only modest computational know-how can run SCRMshaw on a desktop computer. SCRMshaw can be run with a single, narrow set of training data to predict CRMs regulating a specific pattern of gene expression, or with multiple sets of training data covering a broad range of CRM activities to provide an initial rough regulatory annotation of a complete, newly-sequenced genome.","Kazemian M
Halfon MS
","(PMID:30414115
)",CRM Discovery Beyond Model Insects.,https://europepmc.org/abstract/MED/30414115%0A
No abstract provided.,"Dong D
Su W
Shi W
Zou Q
Peng S
","(PMID:30054215
)",VCSRA: A fast and accurate multiple sequence alignment algorithm with a high degree of parallelism.,https://europepmc.org/abstract/MED/30054215%0A
"One of the hottest topics being researched in the field of IoT relates to making connected devices smarter, by locally computing relevant information and integrating data coming from other sensors through a local network. Such works are still in their early stages either by lack of access to data or, on the other hand, by the lack of simple test cases with a clear added value. This contribution aims at shading some light on how knowledge can be obtained, using a simple use case. It focuses on the feasibility of having a home refrigerator performing temperature forecasts, using information provided by both internal and external sensors. The problem is reviewed for both its potential applications and to compare the use of different algorithms, from simple linear correlations to ARIMA models. We analyse the precision and computational cost using real data from a refrigerator. Results indicate that small average errors, down to ≈0.09 ∘ C, can be obtained. Lastly, it is devised how can the scenario be improved, and, most importantly, how this work can be extended in the future.","Monteiro PL
Zanin M
Ruiz EM
Pimentão J
Sousa PADC
","(PMID:30356003
)",Indoor Temperature Prediction in an IoT Scenario.,https://europepmc.org/abstract/MED/30356003%0A
"OBJECTIVE:A novel computer-aided detection (CAD) scheme for lung nodule detection using a 3D deep convolutional neural network combined with a multi-scale prediction strategy is proposed to assist radiologists by providing a second opinion on accurate lung nodule detection, which is a crucial step in early diagnosis of lung cancer. METHOD:A 3D deep convolutional neural network (CNN) with multi-scale prediction was used to detect lung nodules after the lungs were segmented from chest CT scans, with a comprehensive method utilized. Compared with a 2D CNN, a 3D CNN can utilize richer spatial 3D contextual information and generate more discriminative features after being trained with 3D samples to fully represent lung nodules. Furthermore, a multi-scale lung nodule prediction strategy, including multi-scale cube prediction and cube clustering, is also proposed to detect extremely small nodules. RESULT:The proposed method was evaluated on 888 thin-slice scans with 1186 nodules in the LUNA16 database. All results were obtained via 10-fold cross-validation. Three options of the proposed scheme are provided for selection according to the actual needs. The sensitivity of the proposed scheme with the primary option reached 87.94% and 92.93% at one and four false positives per scan, respectively. Meanwhile, the competition performance metric (CPM) score is very satisfying (0.7967). CONCLUSION:The experimental results demonstrate the outstanding detection performance of the proposed nodule detection scheme. In addition, the proposed scheme can be extended to other medical image recognition fields.","Gu Y
Lu X
Yang L
Zhang B
Yu D
Zhao Y
Gao L
Wu L
Zhou T
","(PMID:30390571
)",Automatic lung nodule detection using a 3D deep convolutional neural network combined with a multi-scale prediction strategy in chest CTs.,https://europepmc.org/abstract/MED/30390571%0A
"Gene fusion structure is a class of common somatic mutational events in cancer genomes, which are often formed by chromosomal mutations. Identifying the driver gene(s) in a fusion structure is important for many downstream analyses and it contributes to clinical practices. Existing computational approaches have prioritized the importance of oncogenes by incorporating prior knowledge from gene networks. However, different methods sometimes suffer different weaknesses when handling gene fusion data due to multiple issues such as fusion gene representation, network integration, and the effectiveness of the evaluation algorithms. In this paper, Synstable Fusion (SYN), an algorithm for computationally evaluating the fusion genes, is proposed. This algorithm uses network-based strategy by incorporating gene networks as prior information, but estimates the driver genes according to the destructiveness hypothesis. This hypothesis balances the two popular evaluation strategies in the existing studies, thereby providing more comprehensive results. A machine learning framework is introduced to integrate multiple networks and further solve the conflicting results from different networks. In addition, a synchronous stability model is established to reduce the computational complexity of the evaluation algorithm. To evaluate the proposed algorithm, we conduct a series of experiments on both artificial and real datasets. The results demonstrate that the proposed algorithm performs well on different configurations and is robust when altering the internal parameter settings.","Xu M
Zhao Z
Zhang X
Gao A
Wu S
Wang J
","(PMID:30115851
 PMCID:PMC6222865)",Synstable Fusion: A Network-Based Algorithm for Estimating Driver Genes in Fusion Structures.,https://europepmc.org/abstract/MED/30115851%0A
"A novel anti-cancer drug sensitivity testing (DST) approach was developed based on in vitro single-cell Raman spectrum intensity (RSI). Generally, the intensity of Raman spectra (RS) for a single living cell treated with drugs positively relates to the sensitivity of the cells to the drugs. In this study, five cancer cell lines (BGC 823, SGC 7901, MGC 803, AGS, and NCI-N87) were exposed to three cytotoxic compounds or to combinations of these compounds, and then they were evaluated for their responses with RSI. The results of RSI were consistent with conventional DST methods. The parametric correlation coefficient for the RSI and Methylthiazolyl tetrazolium assay (MTT) was 0.8558 ± 0.0850, and the coefficient of determination was calculated as R² = 0.9529 ± 0.0355 for fitting the dose⁻response curve. Moreover, RSI data for NCI-N87 cells treated by trastuzumab, everolimus (cytostatic), and these drugs in combination demonstrated that the RSI method was suitable for testing the sensitivity of cytostatic drugs. Furthermore, a heterogeneity coefficient H was introduced for quantitative characterization of the heterogeneity of cancer cells treated by drugs. The largest possible variance between RSs of cancer cells were quantitatively obtained using eigenvalues of principal component analysis (PCA). The ratio of H between resistant cells and sensitive cells was greater than 1.5, which suggested the H-value was effective to describe the heterogeneity of cancer cells. Briefly, the RSI method might be a powerful tool for simple and rapid detection of the sensitivity of tumor cells to anti-cancer drugs and the heterogeneity of their responses to these drugs.","Zhang Y
Xu J
Yu Y
Shang W
Ye A
","(PMID:30405051
)",Anti-Cancer Drug Sensitivity Assay with Quantitative Heterogeneity Testing Using Single-Cell Raman Spectroscopy.,https://europepmc.org/abstract/MED/30405051%0A
"In the original version of this Article, financial support was not fully acknowledged. The PDF and HTML versions of the Article have now been corrected to include funding from the Deutsche Forschungsgemeinschaft Grant SFB958/A04.","Mardt A
Pasquali L
Wu H
Noé F
","(PMID:30349135
 PMCID:PMC6197247)",Author Correction: VAMPnets for deep learning of molecular kinetics.,https://europepmc.org/abstract/MED/30349135%0A
"The emergence of single-cell RNA sequencing (scRNA-seq) technologies has enabled us to measure the expression levels of thousands of genes at single-cell resolution. However, insufficient quantities of starting RNA in the individual cells cause significant dropout events, introducing a large number of zero counts in the expression matrix. To circumvent this, we developed an autoencoder-based sparse gene expression matrix imputation method. AutoImpute, which learns the inherent distribution of the input scRNA-seq data and imputes the missing values accordingly with minimal modification to the biologically silent genes. When tested on real scRNA-seq datasets, AutoImpute performed competitively wrt., the existing single-cell imputation methods, on the grounds of expression recovery from subsampled data, cell-clustering accuracy, variance stabilization and cell-type separability.","Talwar D
Mongia A
Sengupta D
Majumdar A
","(PMID:30397240
 PMCID:PMC6218547)",AutoImpute: Autoencoder based imputation of single-cell RNA-seq data.,https://europepmc.org/abstract/MED/30397240%0A
"Omics, such as genomics, transcriptome and proteomics, has been affected by the era of big data. A huge amount of high dimensional and complex structured data has made it no longer applicable for conventional machine learning algorithms. Fortunately, deep learning technology can contribute toward resolving these challenges. There is evidence that deep learning can handle omics data well and resolve omics problems. This survey aims to provide an entry-level guideline for researchers, to understand and use deep learning in order to solve omics problems. We first introduce several deep learning models and then discuss several research areas which have combined omics and deep learning in recent years. In addition, we summarize the general steps involved in using deep learning which have not yet been systematically discussed in the existent literature on this topic. Finally, we compare the features and performance of current mainstream open source deep learning frameworks and present the opportunities and challenges involved in deep learning. This survey will be a good starting point and guideline for omics researchers to understand deep learning.","Zhang Z
Zhao Y
Liao X
Shi W
Li K
Zou Q
Peng S
","(PMID:30265280
)",Deep learning in omics: a survey and guideline.,https://europepmc.org/abstract/MED/30265280%0A
"Automated selection of signals in protein NMR spectra, known as peak picking, has been studied for over 20 years, nevertheless existing peak picking methods are still largely deficient. Accurate and precise automated peak picking would accelerate the structure calculation, and analysis of dynamics and interactions of macromolecules. Recent advancement in handling big data, together with an outburst of machine learning techniques, offer an opportunity to tackle the peak picking problem substantially faster than manual picking and on par with human accuracy. In particular, deep learning has proven to systematically achieve human-level performance in various recognition tasks, and thus emerges as an ideal tool to address automated identification of NMR signals.We have applied a convolutional neural network for visual analysis of multidimensional NMR spectra. A comprehensive test on 31 manually annotated spectra has demonstrated top-tier average precision (AP) of 0.9596, 0.9058 and 0.8271 for backbone, side-chain and NOESY spectra, respectively. Furthermore, a combination of extracted peak lists with automated assignment routine, FLYA, outperformed other methods, including the manual one, and led to correct resonance assignment at the levels of 90.40%, 89.90% and 90.20% for three benchmark proteins.The proposed model is a part of a Dumpling software (platform for protein NMR data analysis), and is available at https://dumpling.bio/.Supplementary data are available at Bioinformatics online.","Klukowski P
Augoff M
Zieba M
Drwal M
Gonczarek A
Walczak MJ
","(PMID:29547986
)",NMRNet: a deep learning approach to automated peak picking of protein NMR spectra.,https://europepmc.org/abstract/MED/29547986%0A
"The urea cycle (UC) is the main pathway by which mammals dispose of waste nitrogen. We find that specific alterations in the expression of most UC enzymes occur in many tumors, leading to a general metabolic hallmark termed ""UC dysregulation"" (UCD). UCD elicits nitrogen diversion toward carbamoyl-phosphate synthetase2, aspartate transcarbamylase, and dihydrooratase (CAD) activation and enhances pyrimidine synthesis, resulting in detectable changes in nitrogen metabolites in both patient tumors and their bio-fluids. The accompanying excess of pyrimidine versus purine nucleotides results in a genomic signature consisting of transversion mutations at the DNA, RNA, and protein levels. This mutational bias is associated with increased numbers of hydrophobic tumor antigens and a better response to immune checkpoint inhibitors independent of mutational load. Taken together, our findings demonstrate that UCD is a common feature of tumors that profoundly affects carcinogenesis, mutagenesis, and immunotherapy response.","Lee JS
Adler L
Karathia H
Carmel N
Rabinovich S
Auslander N
Keshet R
Stettner N
Silberman A
Agemy L
Helbling D
Eilam R
Sun Q
Brandis A
Malitsky S
Itkin M
Weiss H
Pinto S
Kalaora S
Levy R
Barnea E
Admon A
Dimmock D
Stern-Ginossar N
Scherz A
Nagamani SCS
Unda M
Wilson DM 3rd
Elhasid R
Carracedo A
Samuels Y
Hannenhalli S
Ruppin E
Erez A
","(PMID:30100185
)",Urea Cycle Dysregulation Generates Clinically Relevant Genomic and Biochemical Signatures.,https://europepmc.org/abstract/MED/30100185%0A
"Due to strong ocean waves, broken clouds, and extensive cloud cover interferences, ocean ship detection performs poorly when using optical remote sensing images. In addition, it is a challenge to detect small ships on medium resolution optical remote sensing that cover a large area. In this paper, in order to balance the requirements of real-time processing and high accuracy detection, we proposed a novel ship detection framework based on locally oriented scene complexity analysis. First, the proposed method can separate a full image into two types of local scenes (i.e., simple or complex local scenes). Next, simple local scenes would utilize the fast saliency model (FSM) to rapidly complete candidate extraction, and for complex local scenes, the ship feature clustering model (SFCM) will be applied to achieve refined detection against severe background interferences. The FSM considers a fusion enhancement image as an input of the pulse response analysis in the frequency domain to achieve rapid ship detection in simple local scenes. Next, the SFCM builds the descriptive model of the ship feature clustering algorithm to ensure the detection performance on complex local scenes. Extensive experiments on SPOT-5 and GF-2 ocean optical remote sensing images show that the proposed ship detection framework has better performance than the state-of-the-art methods, and it addresses the tricky problem of real-time ocean ship detection under strong waves, broken clouds, extensive cloud cover, and ship fleet interferences. Finally, the proposed ocean ship detection framework is demonstrated on an onboard processing hardware.","Zhuang Y
Qi B
Chen H
Bi F
Li L
Xie Y
","(PMID:30404224
)",Locally Oriented Scene Complexity Analysis Real-Time Ocean Ship Detection from Optical Remote Sensing Images.,https://europepmc.org/abstract/MED/30404224%0A
"A hybrid biofuel cell (HBFC) is explored as a low-cost alternative to abiotic and enzymatic biofuel cells. Here the HBFC provides an enzymeless approach for the fabrication of the anodic electrode while employing an enzymatic approach for the fabrication of the cathodic electrode to develop energy harvesting platform to power bioelectronic devices. The anode employed 250 μm braided gold wire modified with colloidal platinum (Au-co-Pt) and bilirubin oxidase (BODx) modified gold coated Buckypaper (BP-Au-BODx) cathode. The functionalization of the gold coated multi-walled carbon nanotube (MWCNT) structures of the BP electrodes is achieved by 3-mercaptopropionic acid surface modification to possess negatively charged carboxylic groups and subsequently followed by EDC/Sulfo-NHS (1-Ethyl-3-(3-dimethylaminopropyl) carbodiimide hydrochloride and N-Hydroxysulfosuccinimide) crosslinking with BODx. The integration of the BODx and gold coated MWCNTs is evaluated for bioelectrocatalytic activity. The Au-co-Pt and BP-Au-BODx exhibited excellent electrocatalytic activity towards glucose oxidation with a linear dynamic range up to 20 mM glucose and molecular oxygen reduction, respectively. The HBFC demonstrated excellent performance with the largest open circuit voltages of 0.735 V and power density of 46.31 μW/cm2 in 3 mM glucose. In addition, the HBFC operating on 3 mM glucose exhibited excellent uninterrupted operational stability while continuously powering a small electronic device. These results provide great opportunities for implementing this simple but efficient HBFC to harvest the biochemical energy of target fuel(s) in diverse medical and environmental applications.","Hasan MQ
Kuis R
Narayanan JS
Slaughter G
","(PMID:30397324
 PMCID:PMC6218521)",Fabrication of highly effective hybrid biofuel cell based on integral colloidal platinum and bilirubin oxidase on gold support.,https://europepmc.org/abstract/MED/30397324%0A
"A novel statistical feature extraction method, called the neighborhood preserving neural network (NPNN), is proposed in this paper. NPNN can be viewed as a nonlinear data-driven fault detection technique through preserving the local geometrical structure of normal process data. The ""local geometrical structure "" means that each sample can be constructed as a linear combination of its neighbors. NPNN is characterized by adaptively training a nonlinear neural network which takes the local geometrical structure of the data into consideration. Moreover, in order to extract uncorrelated and faithful features, NPNN adopts orthogonal constraints in the objective function. Through backpropagation and eigen decomposition (ED) technique, NPNN is optimized to extract low-dimensional features from original high-dimensional process data. After nonlinear feature extraction, Hotelling T2 statistic and the squared prediction error (SPE) statistic are utilized for the fault detection tasks. The advantages of the proposed NPNN method are demonstrated by both theoretical analysis and case studies on the Tennessee Eastman (TE) benchmark process. Extensive experimental results show the superiority of NPNN in terms of missed detection rate (MDR) and false alarm rate (FAR). The source code of NPNN can be found in https://github.com/htzhaoecust/npnn.","Zhao H
Lai Z
","(PMID:30388431
)",Neighborhood preserving neural network for fault detection.,https://europepmc.org/abstract/MED/30388431%0A
"The security of electronic medical information is very important for health care organisations, which have to ensure confidentiality, integrity and availability of the information provided. This paper will briefly outline the legal measures adopted by the European Community, Italy and the United States to regulate the use and disclosure of medical records. It will then go on to highlight how information technology can help to address these issues with special reference to the management of organisation policies. To this end, we will present a modelling example for the security policy of a radiological department.","Asirelli P
Braccini G
Caramella D
Coco A
Fabbrini F
","(PMID:12471368
)",A computer science approach to managing security in health care.,https://europepmc.org/abstract/MED/12471368%0A
"Automatic classification and prediction of epileptic electroencephalogram (EEG) signal are of great concern to the research community due to its non-stationary and non-linear properties. Features with minimal computation cost are highly needed for the rapid real-time precise diagnosis and implementation in the EEG scanning devices. Even though energy is a well-known feature for the analysis of signals, it is very rarely used in EEG analysis. An exponential energy feature in the time domain is proposed in this study. The proposed exponential energy feature provides a classification accuracy of 89% in the Bern-Barcelona EEG dataset and 99.5% in the Ralph Andrzejak EEG dataset. The promising results open a wide applicability of exponential energy in biomedical signal analysis.","O K F
R R
","(PMID:30399396
)",Time-domain exponential energy for epileptic EEG signal classification.,https://europepmc.org/abstract/MED/30399396%0A
"Cardiovascular diseases (CVDs) are the leading cause of death throughout the world. The total risk of developing CVD is determined by the combined effect of different cardiovascular risk factors (e.g., diabetes, raised blood pressure, unhealthy diet, tobacco use, stress, etc.) that commonly coexist and act multiplicatively. Most CVDs can be prevented by an early identification of the highest risk factors and an appropriate treatment. The stratification of cardiovascular risk factors involves a wide range of parameters and tests that specialists use in their clinical practice. In addition to cardiovascular (CV) risk stratification, ambulatory blood pressure monitoring (ABPM) also provides relevant information for diagnostic and treatment purposes. This work presents a list of protocols based on the Hydra platform, a web-based system for clinical decision support which incorporates a set of functionalities and services that are required for complete cardiovascular analysis, risk assessment, early diagnosis, treatment and monitoring of patients over time. The program includes tools for inputting and managing comprehensive patient data, organized into different checkups to track the evolution over time. It also has a risk stratification tool to compute a CV risk factor based upon several risk stratification tables of reference. Additionally, the program includes a tool that incorporates ABPM analysis and allows the extraction of valuable information by monitoring blood pressure over a specific period of time. Finally, the reporting service summarizes the most relevant information in a set of reports that aid clinicians in their clinical decision-making process.","Ramos L
Novo J
Barreira N
Rouco J
Penedo MG
Ortega M
","(PMID:30320756
)","Hydra, a Computer-Based Platform for Aiding Clinicians in Cardiovascular Analysis and Diagnosis.",https://europepmc.org/abstract/MED/30320756%0A
"Drug repositioning is an important area of biomedical research. The drug repositioning studies have shifted to computational approaches. Large-scale perturbation databases, such as the Connectivity Map and the Library of Integrated Network-Based Cellular Signatures, contain a number of chemical-induced gene expression profiles and provide great opportunities for computational biology and drug repositioning. One reason is that the profiles provided by the Connectivity Map and the Library of Integrated Network-Based Cellular Signatures databases show an overall view of biological mechanism in drugs, diseases and genes. In this article, we provide a review of the two databases and their recent applications in drug repositioning.","Wang F
Lei X
Wu FX
","(PMID:30381060
)",A review of drug repositioning based chemical-induced cell line expression data.,https://europepmc.org/abstract/MED/30381060%0A
"Transporters involved in the cellular entry and exit of ions or molecules throughout the membrane proteins and thereby play an essential role in recognizing the immune system and energy transducers. According to their relevance in proteomics, numerous studies have been conducted to analyze the transporters; especially the discrimination of their classes and subfamilies. We realized that post translational modification information had a critical role in the process of transport proteins. Therefore, in this study, we aim to incorporate post translational information with radial basis function networks to improve the predictive performance of transport proteins in major classes (channels/pores, electrochemical transporters, and active transporters) and six different families (α-type channels, β-barrel porins, pore-forming toxins, porters, PP bond hydrolysis-driven transporters, and oxidoreduction-driven transporters). The experiment results by using PSSM profiles combined with PTM information could classify the transporters into three classes and six families with five-fold cross-validation accuracy of 87.6% and 92.5%, respectively. For the independent dataset of 444 proteins, the performance with post translational modification attained the accuracy of 82.13% and 89.34% for classifying three classes and six families, respectively. Compared with the other methods and previous works, our result shows that the predictive performance is better with the accuracy improvement by 12%. We suggest that our study could become a robust model for biologists to discriminate transport proteins with high performance and understand better the function of transport proteins. Further, the contributions of this study could be fundamental for further research that can use PTM information to enhance numerous computational biology problems.","Le NQK
Sandag GA
Ou YY
","(PMID:30393099
)",Incorporating post translational modification information for enhancing the predictive performance of membrane transport proteins.,https://europepmc.org/abstract/MED/30393099%0A
"Summary:PASTA is a multiple sequence method that uses divide-and-conquer plus iteration to enable base alignment methods to scale with high accuracy to large sequence datasets. By default, PASTA included MAFFT L-INS-i; our new extension of PASTA enables the use of MAFFT G-INS-i, MAFFT Homologs, CONTRAlign and ProbCons. We analyzed the performance of each base method and PASTA using these base methods on 224 datasets from BAliBASE 4 with at least 50 sequences. We show that PASTA enables the most accurate base methods to scale to larger datasets at reduced computational effort, and generally improves alignment and tree accuracy on the largest BAliBASE datasets. Availability and implementation:PASTA is available at https://github.com/kodicollins/pasta and has also been integrated into the original PASTA repository at https://github.com/smirarab/pasta. Supplementary information:Supplementary data are available at Bioinformatics online.","Collins K
Warnow T
","(PMID:29931282
 PMCID:PMC6223367)",PASTA for proteins.,https://europepmc.org/abstract/MED/29931282%0A
"OBJECTIVES:To determine if in singing there is an effect of lung volume on the electroglottographic waveform, and if so, how it varies over the voice range. STUDY DESIGN:Eight trained female singers sang the tune ""Frère Jacques"" in 18 conditions: three phonetic contexts, three dynamic levels, and high or low lung volume. Conditions were randomized and replicated. METHODS:The audio and EGG signals were recorded in synchrony with signals tracking respiration and vertical larynx position. The first 10 Fourier descriptors of every EGG cycle were computed. These spectral data were clustered statistically, and the clusters were mapped by color into a voice range profile display, thus visualizing the EGG waveform changes under the influence of fo and SPL. The rank correlations and effect sizes of the relationships between relative lung volume and several adduction-related EGG wave shape metrics were similarly rendered on a color scale, in voice range profile-style 'voice maps.' RESULTS:In most subjects, EGG waveforms varied considerably over the voice range. Within subjects, reproducibility was high, not only across the replications, but also across the phonetic contexts. The EGG waveforms were quite individual, as was the nature of the EGG shape variation across the range. EGG metrics were significantly correlated to changes in lung volume, in parts of the range of the song, and in most subjects. However, the effect sizes of the relative lung volume were generally much smaller than the effects of fo and SPL, and the relationships always varied, even changing polarity from one part of the range to another. CONCLUSIONS:Most subjects exhibited small, reproducible effects of the relative lung volume on the EGG waveform. Some hypothesized influences of tracheal pull were seen, mostly at the lowest SPLs. The effects were however highly variable, both across the moderately wide fo-SPL range and across subjects. Different singers may be applying different techniques and compensatory behaviors with changing lung volume. The outcomes emphasize the importance of making observations over a substantial part of the voice range, and not only of phonations sustained at a few fundamental frequencies and sound levels.","Ternström S
D'Amario S
Selamtzis A
","(PMID:30337119
)",Effects of the Lung Volume on the Electroglottographic Waveform in Trained Female Singers.,https://europepmc.org/abstract/MED/30337119%0A
"Mobile data are a feasible way for us to understand and reveal the feature of human mobility. However, it is extremely hard to have a fine-grained picture of large-scale mobility data, in particular at an urban scale. Here, we present a large-scale dataset of 2-million mobile phone users with time-varying locations, denoted as the temporal network of individuals, conducted by an open-data program in Changchun Municipality. To reveal human mobility across locations, we further construct the aggregated mobility network for each day by taking cellular base stations as nodes coupled by edges weighted by the total number of users' movements between pairs of nodes. The resulting temporal network of mobile phone users and the dynamic, weighted and directed mobility network are released in simple formats for easy access to motivating research using this new and extensive data of human mobility.","Du Z
Yang Y
Gao C
Huang L
Huang Q
Bai Y
","(PMID:30375989
 PMCID:PMC6207067)","The temporal network of mobile phone users in Changchun Municipality, Northeast China.",https://europepmc.org/abstract/MED/30375989%0A
"Human-computer interaction (HCI) is an important feature of augmented reality (AR) technology. The naturalness is the inevitable trend of HCI. Gesture is the most natural and frequently used body auxiliary interaction mode in daily interactions except for language. However, there are often meaningless, subconscious gesture intervals between the two adjacent dynamic gestures. So, continuous dynamic gesture spotting is the premise and basis of dynamic gesture recognition, but there is no mature and unified algorithm to solve this problem.In order to realize the natural HCI based on gesture recognition entirely, a general AR application development platform is presented in this paper.According to the position and pose tracking data of the user's hand, the dynamic gesture spotting algorithm based on evidence theory is proposed. Firstly, Through analysis of the speed change of hand motion during the dynamic gestures, three knowledge rules are summed up. Then, accurate dynamic gesture spotting is realized with the application of evidence reasoning. Moreover, this algorithm first detects the starting point of gesture in the rising trend of hand motion speed, eliminates the delay between spotting and recognition, and thus ensures real-time performance. Finally, the algorithm is verified in several AR applications developed on the platform.There are two main experimental results. First, there are six users participating in the dynamic gesture spotting experiment, and the gesture spotting accuracy can meet the demand. Second, The accuracy of recognition after spotting is higher than that of the simultaneous recognition and spotting.So, It can be concluded that the proposed continuous dynamic gesture spotting algorithm based on Dempster-Shafer theory can extract almost all the effective dynamic gestures in the HCI of our AR platform, and on this basis, it can effectively improve the accuracy of the subsequent dynamic gesture recognition.","Li Q
Huang C
Yao Z
Chen Y
Ma L
","(PMID:29956447
)",Continuous dynamic gesture spotting algorithm based on Dempster-Shafer Theory in the augmented reality human computer interaction.,https://europepmc.org/abstract/MED/29956447%0A
"The purpose of this paper is to study that the rowers' technique may be analysed using 3D data. An quantitative analysis of rowing technique, both of the posture and of the handle's positions while rowing are presented. The analysed parameters in ergometer rowing are obtained from three-dimensional data. They include: stroke count, time and speed of each stroke, angles of the handle and the rower's back calculated in two planes. One rower and five first-time rowers were the participants in this study. Their movements were recorded using the Vicon motion capture system. The participants rowed a distance of 500 m. The obtained results indicate that an optical motion capture system may be used for verifying the rower's technique.","Lukasik E
Smolka J
Skublewska-Paszkowska M
","(PMID:30097243
)",P 126 - Quantitative analysis of rowing technique using motion capture system.,https://europepmc.org/abstract/MED/30097243%0A
No abstract provided.,"Descoteaux M
Maier-Hein L
Franz A
Jannin P
Collins LD
Duchesne S
","(PMID:30120692
)",Guest editorial for the IJCARS special issue on MICCAI 2017.,https://europepmc.org/abstract/MED/30120692%0A
"A novel method to determine the Grade Group (GG) in prostate cancer (PCa) using multi-parametric magnetic resonance imaging (mpMRI) biomarkers is investigated in this paper. In this method, high-level features are extracted from hand-crafted texture features using a deep network of stacked sparse autoencoders (SSAE) and classified them using a softmax classifier (SMC). Transaxial T2 Weighted (T2W), Apparent Diffusion Coefficient (ADC) and high B-Value Diffusion-Weighted (BVAL) images obtained from PROSTATEx-2 2017 challenge dataset are used in this technique. The method was evaluated on the challenge dataset composed of a training set of 112 lesions and a test set of 70 lesions. It achieved a quadratic-weighted Kappa score of 0.2772 on evaluation using test dataset of the challenge. It also reached a Positive Predictive Value (PPV) of 80% in predicting PCa with GG > 1. The method achieved first place in the challenge, winning over 43 methods submitted by 21 groups. A 3-fold cross-validation using training data of the challenge was further performed and the method achieved a quadratic-weighted kappa score of 0.2326 and Positive Predictive Value (PPV) of 80.26% in predicting PCa with GG > 1. Even though the training dataset is a highly imbalanced one, the method was able to achieve a fair kappa score. Being one of the pioneer methods which attempted to classify prostate cancer into 5 grade groups from MRI images, it could serve as a base method for further investigations and improvements.","Abraham B
Nair MS
","(PMID:30205334
)",Computer-aided classification of prostate cancer grade groups from MRI images using texture features and stacked sparse autoencoder.,https://europepmc.org/abstract/MED/30205334%0A
"As one of the well-studied RNA methylation modifications, N6-methyladenosine (m6A) plays important roles in various biological progresses, such as RNA splicing and degradation, etc. Identification of m6A sites is fundamentally important for better understanding of their functional mechanisms. Recently, machine learning based prediction methods have emerged as an effective approach for fast and accurate identification of m6A sites. In this paper, we proposed ""M6AMRFS"", a new machine learning based predictor for the identification of m6A sites. In this predictor, we exploited a new feature representation algorithm to encode RNA sequences with two feature descriptors (dinucleotide binary encoding and Local position-specific dinucleotide frequency), and used the F-score algorithm combined with SFS (Sequential Forward Search) to enhance the feature representation ability. To predict m6A sites, we employed the eXtreme Gradient Boosting (XGBoost) algorithm to build a predictive model. Benchmarking results showed that the proposed predictor is competitive with the state-of-the art predictors. Importantly, robust predictions for multiple species by our predictor demonstrate that our predictive models have strong generalization ability. To the best of our knowledge, M6AMRFS is the first tool that can be used for the identification of m6A sites in multiple species. To facilitate the use of our predictor, we have established a user-friendly webserver with the implementation of M6AMRFS, which is currently available in http://server.malab.cn/M6AMRFS/. We anticipate that it will be a useful tool for the relevant research of m6A sites.","Qiang X
Chen H
Ye X
Su R
Wei L
","(PMID:30410501
 PMCID:PMC6209681)",M6AMRFS: Robust Prediction of N6-Methyladenosine Sites With Sequence-Based Features in Multiple Species.,https://europepmc.org/abstract/MED/30410501%0A
"Recently, the construction of models for multicellular systems such as tissues has been attracting great interest. These model systems are expected to reproduce a cell communication network and provide insight into complicated functions in living systems./Such network structures have mainly been modelled using a droplet and a vesicle. However, in the droplet and vesicle network, there are difficulties attributed to structural instabilities due to external stimuli and perturbations. Thus, the fabrication of a network composed of a stable component such as hydrogel is desired. In this article, the construction of a stable network composed of honeycomb-shaped microhydrogels is described. We produced the microhydrogel network using a centrifugal microfluidic technique and a photosensitive polymer. In the network, densely packed honeycomb-shaped microhydrogels were observed. Additionally, we successfully controlled the degree of packing of microhydrogels in the network by changing the centrifugal force. We believe that our stable network will contribute to the study of cell communication in multicellular systems.","Hayakawa M
Umeyama S
Nagai KH
Onoe H
Takinoue M
","(PMID:30241312
)",Controlled Construction of Stable Network Structure Composed of Honeycomb-Shaped Microhydrogels.,https://europepmc.org/abstract/MED/30241312%0A
"Although a standard reinforcement learning model can capture many aspects of reward-seeking behaviors, it may not be practical for modeling human natural behaviors because of the richness of dynamic environments and limitations in cognitive resources. We propose a modular reinforcement learning model that addresses these factors. Based on this model, a modular inverse reinforcement learning algorithm is developed to estimate both the rewards and discount factors from human behavioral data, which allows predictions of human navigation behaviors in virtual reality with high accuracy across different subjects and with different tasks. Complex human navigation trajectories in novel environments can be reproduced by an artificial agent that is based on the modular model. This model provides a strategy for estimating the subjective value of actions and how they influence sensory-motor decisions in natural behavior.","Zhang R
Zhang S
Tong MH
Cui Y
Rothkopf CA
Ballard DH
Hayhoe MM
","(PMID:30359364
 PMCID:PMC6219815)",Modeling sensory-motor decisions in natural behavior.,https://europepmc.org/abstract/MED/30359364%0A
"The past twenty years have ignited a new spark in the research of Electroencephalogram (EEG), which was pursued to develop innovative Brain Computer Interfaces (BCIs) in order to help severely disabled people live a better life with a high degree of independence. Current BCIs are more theoretical than practical and are suffering from numerous challenges. New trends of research propose combining EEG to other simple and efficient bioelectric inputs such as Electro-oculography (EOG) resulting from eye movements, to produce more practical and robust Hybrid Brain Computer Interface systems (hBCI) or Brain/Neuronal Computer Interface (BNCI). Working towards this purpose, existing research in EOG based Human Computer Interaction (HCI) applications, must be organized and surveyed in order to develop a vision on the potential benefits of combining both input modalities and give rise to new designs that maximize these benefits. Our aim is to support and inspire the design of new hBCI systems based on both EEG and EOG signals, in doing so; first the current EOG based HCI systems were surveyed with a particular focus on EOG based systems for communication using virtual keyboard. Then, a survey of the current EEG-EOG virtual keyboard was performed highlighting the design protocols employed. We concluded with a discussion of the potential advantages of combining both systems with recommendations to give deep insight for future design issues for all EEG-EOG hBCI systems. Finally, a general architecture was proposed for a new EEG-EOG hBCI system. The proposed hybrid system completely alters the traditional view of the eye movement features present in EEG signal as artifacts that should be removed; instead EOG traces are extracted from EEG in our proposed hybrid architecture and are considered as an additional input modality sharing control according to the chosen design protocol.","Hosni SM
Shedeed HA
Mabrouk MS
Tolba MF
","(PMID:30368637
)",EEG-EOG based Virtual Keyboard: Toward Hybrid Brain Computer Interface.,https://europepmc.org/abstract/MED/30368637%0A
"PURPOSE:For the development of computer-assisted detection (CAD) software using voxel-based classification, gold standards defined by pixel-by-pixel painting, called painted gold standards, are desirable. However, for radiologists who define gold standards, a simplified method of definition is desirable. One of the simplest methods of defining gold standards is a spherical region, called a spherical gold standard. In this study, we investigated whether spherical gold standards can be used as an alternative to painted gold standards for computerized detection using voxel-based classification. MATERIALS AND METHODS:The spherical gold standards were determined by the center of gravity and the maximum diameter. We compared two types of gold standard, painted gold standards and spherical gold standards, by two types of CAD software using voxel-based classification. RESULTS:The time required to paint the area of one lesion was 4.7-6.5 times longer than the time required to define a spherical gold standard. For the same performance of the CAD software, the number of training cases required for the spherical gold standard was 1.6-7.6 times that for the painted gold standards. CONCLUSION:Spherical gold standards can be used as an alternative to painted gold standards for the computerized detection of lesions with simple shapes.","Nomura Y
Hayashi N
Hanaoka S
Takenaga T
Nemoto M
Miki S
Yoshikawa T
Abe O
","(PMID:30343401
)",Can the spherical gold standards be used as an alternative to painted gold standards for the computerized detection of lesions using voxel-based classification?,https://europepmc.org/abstract/MED/30343401%0A
"Numerical results on conditions for the emergence of propagation failure of diffusive fronts in two-species competition models for populations with either logistic growth or strong Allee effect are presented. Particularly, the stability against environmental perturbations is investigated. Two different density dependencies of the noise intensities are considered. They mimic a differential functional response of the competitors to the variable environment. Assuming classical linearly density-dependent noise intensities, stochastic wave pinning can occur. This is an ecologically important finding regarding biological invasion as it means that the invasion speed can be reduced by environmental perturbations even yielding a reversal of the invasion wave. However, this depends on the form of the functional per-capita noise response.","Köhnke MC
Malchow H
","(PMID:30393108
)",Wave pinning in competition-diffusion models in variable environments.,https://europepmc.org/abstract/MED/30393108%0A
"This paper presents an exploratory landscape analysis of three NP-hard combinatorial optimisation problems: the number partitioning problem, the binary knapsack problem, and the quadratic binary knapsack problem. In the paper, we examine empirically a number of fitness landscape properties of randomly generated instances of these problems. We believe that the studied properties give insight into the structure of the problem landscape and can be representative of the problem difficulty, in particular with respect to local search algorithms. Our work focuses on studying how these properties vary with different values of problem parameters. We also compare these properties across various landscapes that were induced by different penalty functions and different neighbourhood operators. Unlike existing studies of these problems, we study instances generated at random from various distributions. We found a general trend where some of the landscape features in all of the three problems were found to vary between the different distributions. We captured this variation by a single, easy to calculate, parameter and we showed that it has a potentially useful application in guiding the choice of the neighbourhood operator of some local search heuristics.","Alyahya K
Rowe JE
","(PMID:30365387
)",Landscape Analysis of a Class of NP-Hard Binary Packing Problems.,https://europepmc.org/abstract/MED/30365387%0A
"BACKGROUND:Although supervoxel segmentation methods have been employed for brain Magnetic Resonance Image (MRI) processing and analysis, due to the specific features of the brain, including complex-shaped internal structures and partial volume effect, their performance remains unsatisfactory. NEW METHODS:To address these issues, this paper presents a novel iterative spatial fuzzy clustering (ISFC) algorithm to generate 3D supervoxels for brain MRI volume based on prior knowledge. This work makes use of the common topology among the human brains to obtain a set of seed templates from a population-based brain template MRI image. After selecting the number of supervoxels, the corresponding seed template is projected onto the considered individual brain for generating reliable seeds. Then, to deal with the influence of partial volume effect, an efficient iterative spatial fuzzy clustering algorithm is proposed to allocate voxels to the seeds and to generate the supervoxels for the overall brain MRI volume. RESULTS:The performance of the proposed algorithm is evaluated on two widely used public brain MRI datasets and compared with three other up-to-date methods. CONCLUSIONS:The proposed algorithm can be utilized for several brain MRI processing and analysis, including tissue segmentation, tumor detection and segmentation, functional parcellation and registration.","Kong Y
Wu J
Yang G
Zuo Y
Chen Y
Shu H
Coatrieux JL
","(PMID:30315839
)",Iterative spatial fuzzy clustering for 3D brain magnetic resonance image supervoxel segmentation.,https://europepmc.org/abstract/MED/30315839%0A
"Investigating the interactions among multiple participants is a challenge for researchers from various disciplines, including the decision sciences and spatial cognition. With a local area network and dedicated software platform, experimenters can efficiently monitor the behavior of the participants that are simultaneously immersed in a desktop virtual environment and digitalize the collected data. These capabilities allow for experimental designs in spatial cognition and navigation research that would be difficult (if not impossible) to conduct in the real world. Possible experimental variations include stress during an evacuation, cooperative and competitive search tasks, and other contextual factors that may influence emergent crowd behavior. However, such a laboratory requires maintenance and strict protocols for data collection in a controlled setting. While the external validity of laboratory studies with human participants is sometimes questioned, a number of recent papers suggest that the correspondence between real and virtual environments may be sufficient for studying social behavior in terms of trajectories, hesitations, and spatial decisions. In this article, we describe a method for conducting experiments on decision-making and navigation with up to 36 participants in a networked desktop virtual reality setup (i.e., the Decision Science Laboratory or DeSciL). This experiment protocol can be adapted and applied by other researchers in order to set up a networked desktop virtual reality laboratory.","Zhao H
Thrash T
Wehrli S
Hölscher C
Kapadia M
Grübel J
Weibel RP
Schinazi VR
","(PMID:30199016
)",A Networked Desktop Virtual Reality Setup for Decision Science and Navigation Experiments with Multiple Participants.,https://europepmc.org/abstract/MED/30199016%0A
"Exploration of brain dynamics patterns has attracted increasing attention due to its fundamental significance in understanding the working mechanism of the brain. However, due to the lack of effective modeling methods, how the simultaneously recorded LFP can inform us about the brain dynamics remains a general challenge. In this paper, we propose a novel sparse coding based method to investigate brain dynamics of freely-behaving mice from the perspective of functional connectivity, using super-long local field potential (LFP) recordings from 13 distinct regions of the mouse brain. Compared with surrogate datasets, six and four reproducible common functional connectivities were discovered to represent the space of brain dynamics in the frequency bands of alpha and theta respectively. Modeled by a finite state machine, temporal transition framework of functional connectivities was inferred for each frequency band, and evident preference was discovered. Our results offer a novel perspective for analyzing neural recording data at such high temporal resolution and recording length, as common functional connectivities and their transition framework discovered in this work reveal the nature of the brain dynamics in freely behaving mice.","Wang H
Xie K
Xie L
Li X
Li M
Lyu C
Chen H
Chen Y
Liu X
Tsien J
Liu T
","(PMID:30341589
)",Functional Brain Connectivity Revealed by Sparse Coding of Large-Scale Local Field Potential Dynamics.,https://europepmc.org/abstract/MED/30341589%0A
"The composition of the scientific workforce shapes the direction of scientific research, directly through the selection of questions to investigate, and indirectly through its influence on the training of future scientists. In most fields, however, complete census information is difficult to obtain, complicating efforts to study workforce dynamics and the effects of policy. This is particularly true in computer science, which lacks a single, all-encompassing directory or professional organization. A full census of computer science would serve many purposes, not the least of which is a better understanding of the trends and causes of unequal representation in computing. Previous academic census efforts have relied on narrow or biased samples, or on professional society membership rolls. A full census can be constructed directly from online departmental faculty directories, but doing so by hand is expensive and time-consuming. Here, we introduce a topical web crawler for automating the collection of faculty information from web-based department rosters, and demonstrate the resulting system on the 205 PhD-granting computer science departments in the U.S. and Canada. This method can quickly construct a complete census of the field, and achieve over 99% precision and recall. We conclude by comparing the resulting 2017 census to a hand-curated 2011 census to quantify turnover and retention in computer science, in general and for female faculty in particular, demonstrating the types of analysis made possible by automated census construction.","Morgan AC
Way SF
Clauset A
","(PMID:30157278
 PMCID:PMC6114776)",Automatically assembling a full census of an academic field.,https://europepmc.org/abstract/MED/30157278%0A
"Visual evoked potentials (VEPs) can be measured in the EEG as response to a visual stimulus. Commonly, VEPs are displayed by averaging multiple responses to a certain stimulus or a classifier is trained to identify the response to a certain stimulus. While the traditional approach is limited to a set of predefined stimulation patterns, we present a method that models the general process of VEP generation and thereby can be used to predict arbitrary visual stimulation patterns from EEG and predict how the brain responds to arbitrary stimulation patterns. We demonstrate how this method can be used to model single-flash VEPs, steady state VEPs (SSVEPs) or VEPs to complex stimulation patterns. It is further shown that this method can also be used for a high-speed BCI in an online scenario where it achieved an average information transfer rate (ITR) of 108.1 bit/min. Furthermore, in an offline analysis, we show the flexibility of the method allowing to modulate a virtually unlimited amount of targets with any desired trial duration resulting in a theoretically possible ITR of more than 470 bit/min.","Nagel S
Spüler M
","(PMID:30346983
 PMCID:PMC6197660)",Modelling the brain response to arbitrary visual stimulation patterns for a flexible high-speed Brain-Computer Interface.,https://europepmc.org/abstract/MED/30346983%0A
"Playas are the often most noticeable surface water feature in the Southern High Plains. The purpose of our study is to provide local and timely reference data on playa water quality and quantity in drier and wetter weather conditions. Water quality parameters of three playas in Texas, in the summer of 2016, were monitored via weekly environmental sampling. Annual water volume-depth dynamics within the study playas were also estimated by water balance informed by climate and geospatial data. The results showed that both direct rainfall and runoff affect the volume of water within the playa where the volume of runoff entering into a playa is contingent upon the surrounding drainage area. In addition, water quality does vary substantially from playa to playa (conductivity 180-850 μS/cm, TOC 13-81 mg/L) and between playa and non-playa surface water. Differences were related to local soils, drainage area size/slope, and land use. It was also found from the water quality analysis that playas are capable of containing a quality of water that would make them an attractive habitat for wildlife. The greatest economic value of playas may be their ability to contain high quantities of biodiversity though the future of their capacity to do so is uncertain.","Howell NL
Butler EB
Guerrero B
","(PMID:30368187
)",Water quality variation with storm runoff and evaporation in playa wetlands.,https://europepmc.org/abstract/MED/30368187%0A
"BACKGROUND:Exposure to high levels of metals/metalloids may impair semen quality. Computer-aided sperm analysis (CASA) can be used for kinematic analysis of spermatozoa, which provides additional insights into sperm motion characteristics. OBJECTIVE:To explore the associations of urinary and seminal plasma metal/metalloid concentrations with CASA motion parameters and assess the degree of correspondence between the two sample types. METHODS:Eighteen metals/metalloids in seminal plasma and repeated urine samples were determined among 746 men recruited from a reproductive center. We assessed their associations with 6 CASA motion parameters [i.e., straight-line velocity (VSL), curvilinear velocity (VCL), average path velocity (VAP), linearity (LIN), straightness (STR) and amplitude head displacement (ALH)] using multivariable linear regression models. RESULTS:We found significantly inverse dose-dependent relationships between seminal plasma arsenic (As) and VSL, VCL and VAP, between seminal plasma selenium (Se) and VSL and VAP, between seminal plasma zinc (Zn) and STR and LIN, and between seminal plasma manganese (Mn) and LIN in single-metal models [all false discovery rate (FDR) adjusted P for trend < 0.05]. These dose-response relationships remained statistically significant based on multiple-metal models and restricted cubic spline functions. Metal/metalloid concentrations in urine poorly predicted the same-day seminal plasma concentrations [coefficient of determination (R2) < 0.15]. We didn't find any significant associations between urinary metal/metalloid concentrations and the CASA motion parameters. CONCLUSION:Exposure to high levels of As, Se, Mn and Zn may impair sperm motion capacity. Concentrations of metals/metalloids in spot urine samples cannot accurately predict same-day seminal plasma exposure levels.","Wan ZZ
Chen HG
Lu WQ
Wang YX
Pan A
","(PMID:30296767
)",Metal/metalloid levels in urine and seminal plasma in relation to computer-aided sperm analysis motion parameters.,https://europepmc.org/abstract/MED/30296767%0A
"Multiple sclerosis (MS) is a chronic disease. It affects the central nervous system and its clinical manifestation can variate. Magnetic Resonance Imaging (MRI) is often used to detect, characterize and quantify MS lesions in the brain, due to the detailed structural information that it can provide. Manual detection and measurement of MS lesions in MRI data is time-consuming, subjective and prone to errors. Therefore, multiple automated methodologies for MRI-based MS lesion segmentation have been proposed. Here, a review of the state-of-the-art of automatic methods available in the literature is presented. The current survey provides a categorization of the methodologies in existence in terms of their input data handling, their main strategy of segmentation and their type of supervision. The strengths and weaknesses of each category are analyzed and explicitly discussed. The positive and negative aspects of the methods are highlighted, pointing out the future trends and, thus, leading to possible promising directions for future research. In addition, a further clustering of the methods, based on the databases used for their evaluation, is provided. The aforementioned clustering achieves a reliable comparison among methods evaluated on the same databases. Despite the large number of methods that have emerged in the field, there is as yet no commonly accepted methodology that has been established in clinical practice. Future challenges such as the simultaneous exploitation of more sophisticated MRI protocols and the hybridization of the most promising methods are expected to further improve the performance of the segmentation.","Danelakis A
Theoharis T
Verganelakis DA
","(PMID:30326367
)",Survey of automated multiple sclerosis lesion segmentation techniques on magnetic resonance imaging.,https://europepmc.org/abstract/MED/30326367%0A
"Chemical-disease relation (CDR) extraction is significantly important to various areas of biomedical research and health care. Nowadays, many large-scale biomedical knowledge bases (KBs) containing triples about entity pairs and their relations have been built. KBs are important resources for biomedical relation extraction. However, previous research pays little attention to prior knowledge. In addition, the dependency tree contains important syntactic and semantic information, which helps to improve relation extraction. So how to effectively use it is also worth studying. In this paper, we propose a novel convolutional attention network (CAN) for CDR extraction. Firstly, we extract the shortest dependency path (SDP) between chemical and disease pairs in a sentence, which includes a sequence of words, dependency directions, and dependency relation tags. Then the convolution operations are performed on the SDP to produce deep semantic dependency features. After that, an attention mechanism is employed to learn the importance/weight of each semantic dependency vector related to knowledge representations learned from KBs. Finally, in order to combine dependency information and prior knowledge, the concatenation of weighted semantic dependency representations and knowledge representations is fed to the softmax layer for classification. Experiments on the BioCreative V CDR dataset show that our method achieves comparable performance with the state-of-the-art systems, and both dependency information and prior knowledge play important roles in CDR extraction task.","Zhou H
Ning S
Yang Y
Liu Z
Lang C
Lin Y
","(PMID:30017973
)",Chemical-induced disease relation extraction with dependency information and prior knowledge.,https://europepmc.org/abstract/MED/30017973%0A
"PURPOSE:Bronchoscopy is useful in lung cancer detection, but cannot be used to differentiate cancer types. A computer-aided diagnosis (CAD) system was proposed to distinguish malignant cancer types to achieve objective diagnoses. METHODS:Bronchoscopic images of 12 adenocarcinoma and 10 squamous cell carcinoma patients were collected. The images were transformed from a red-blue-green (RGB) to a hue-saturation-value (HSV) color space to obtain more meaningful color textures. By combining significant textural features (P < 0.05) in a machine learning classifier, a prediction model of malignant types was established. RESULTS:The performance of the CAD system achieved an accuracy of 86% (19/22), a sensitivity of 90% (9/10), a specificity of 83% (10/12), a positive predictive value of 82% (9/11), and a negative predictive value of 91% (10/11) in distinguishing lung cancer types. The area under the receiver operating characteristic curve was 0.82. CONCLUSIONS:On the basis of extracted HSV textures of bronchoscopic images, the CAD system can provide recommendations for clinical diagnoses of lung cancer types.","Feng PH
Lin YT
Lo CM
","(PMID:30325517
)",A machine learning texture model for classifying lung cancer subtypes using preliminary bronchoscopic findings.,https://europepmc.org/abstract/MED/30325517%0A
"The aim of the study was to analyze the influence of oxygene partial pressure (p02), base excess (BE) and buffer base (BB) parameters of cord blood obtained perinatally on quantity of obtained cells and focus on the perfect donor criteria. The study included 50 pregnant women aged between 18 and 38 years in which spontaneous labors and elective cesarean sections were performed. Umbilical cord blood was collected immediately after the women were delivered of newborns. The cells were analyzed in the Polish Stem Cells Bank in Warsaw. In the study group of patients different stem cells viability levels did not differ significantly in terms of pO2, BB and BE level, however, there was a trend that the higher the viability the lower BE value. The experiment showed also that the cord blood (CB) oxygenation scope is vitally important for the CB cells viability.","Jendyk C
Drosdzol-Cop A
Nowak-Brzezińska A
Sadłocha M
Stojko R
Jastrzȩbska-Stojko Ż
","(PMID:30341674
)","The influence of p02, BE, BB parameters of perinatally obtained cord blood on quantity of obtained cells and focus on the perfect donor criteria.",https://europepmc.org/abstract/MED/30341674%0A
"This paper presents a lightweight synthesis algorithm, named adaptive region segmentation based piecewise linear (ARSPL) algorithm, for reconstructing standard 12-lead electrocardiogram (ECG) signals from a 3-lead subset (I, II and V2). Such a lightweight algorithm is particularly suitable for healthcare mobile devices with limited resources for computing, communication and data storage. After detection of R-peaks, the ECGs are segmented by cardiac cycles. Each cycle is further divided into four regions according to different cardiac electrical activity stages. A personalized linear regression algorithm is then applied to these regions respectively for improved ECG synthesis. The proposed ARSPL method has been tested on 39 subjects randomly selected from the PTB diagnostic ECG database and achieved accurate synthesis of remaining leads with an average correlation coefficient of 0.947, an average root-mean-square error of 55.4μV, and an average runtime performance of 114ms. Overall, these results are significantly better than those of the common linear regression method, the back propagation (BP) neural network and the BP optimized using the genetic algorithm. We have also used the reconstructed ECG signals to evaluate the denivelation of ST segment, which is a potential symptom of intrinsic myocardial disease. After ARSPL, only 10.71% of the synthesized ECG cycles are with a ST-level synthesis error larger than 0.1mV, which is also better than those of the three above-mentioned methods.","Zhu H
Pan Y
Cheng KT
Huan R
","(PMID:30339673
 PMCID:PMC6195291)",A lightweight piecewise linear synthesis method for standard 12-lead ECG signals based on adaptive region segmentation.,https://europepmc.org/abstract/MED/30339673%0A
"The purpose of this study is to develop a novel breast abnormality detection system by utilizing the potential of infrared breast thermography (IBT) in early breast abnormality detection. Since the temperature distributions are different in normal and abnormal thermograms and hot thermal patches are visible in abnormal thermograms, the abnormal thermograms possess more complex information than the normal thermograms. Here, the proposed method exploits the presence of hot thermal patches and vascular changes by using the power law transformation for pre-processing and singular value decomposition to characterize the thermal patches. The extracted singular values are found to be statistically significant (p < 0.001) in breast abnormality detection. The discriminability of the singular values is evaluated by using seven different classifiers incorporating tenfold cross-validations, where the thermograms of the Department of Biotechnology-Tripura University-Jadavpur University (DBT-TU-JU) and Database of Mastology Research (DMR) databases are used. In DMR database, the highest classification accuracy of 98.00% with the area under the ROC curve (AUC) of 0.9862 is achieved with the support vector machine using polynomial kernel. The same for the DBT-TU-JU database is 92.50% with AUC of 0.9680 using the same classifier. The comparison of the proposed method with the other reported methods concludes that the proposed method outperforms the other existing methods as well as other traditional feature sets used in IBT based breast abnormality detection. Moreover, by using Rank1 and Rank2 singular values, a breast abnormality grading (BAG) index has also been developed for grading the thermograms based on their degree of abnormality.","Gogoi UR
Bhowmik MK
Bhattacharjee D
Ghosh AK
","(PMID:30171500
)",Singular value based characterization and analysis of thermal patches for early breast abnormality detection.,https://europepmc.org/abstract/MED/30171500%0A
"Biologists and environmental scientists now routinely solve computational problems that were unimaginable a generation ago. Examples include processing geospatial data, analyzing -omics data, and running large-scale simulations. Conventional desktop computing cannot handle these tasks when they are large, and high-performance computing is not always available nor the most appropriate solution for all computationally intense problems. High-throughput computing (HTC) is one method for handling computationally intense research. In contrast to high-performance computing, which uses a single ""supercomputer,"" HTC can distribute tasks over many computers (e.g., idle desktop computers, dedicated servers, or cloud-based resources). HTC facilities exist at many academic and government institutes and are relatively easy to create from commodity hardware. Additionally, consortia such as Open Science Grid facilitate HTC, and commercial entities sell cloud-based solutions for researchers who lack HTC at their institution. We provide an introduction to HTC for biologists and environmental scientists. Our examples from biology and the environmental sciences use HTCondor, an open source HTC system.","Erickson RA
Fienen MN
McCalla SG
Weiser EL
Bower ML
Knudson JM
Thain G
","(PMID:30281592
 PMCID:PMC6169842)",Wrangling distributed computing for high-throughput environmental science: An introduction to HTCondor.,https://europepmc.org/abstract/MED/30281592%0A
"In recent years, popularity of radiofrequency (RF) has increased significantly. They are characterized by a low risk of complications and relatively high effectiveness. RF use high-frequency currents causing oscillating motion of ions resulting in temperature rise stimulating skin regeneration processes. The aim of this work was the thermographic evaluation of the skin exposed to RF of different intensity. The dynamic thermal imaging was used to study the temperature of the skin exposed to RF. The research was carried out in two locations with different adipose tissue content: abdomen (ROI1) and forearm (ROI2). In the ROI1 area, RF was applied at nominal power range from 250 to 1750 W, while in ROI2 area: from 250 to 1000 W. The obtained thermographic data were fitted to exponential functions. A clear dependence of obtained thermokinetic parameters with the anatomical location of exposure to RF was demonstrated. Thicker layer of adipose tissue directly under the skin resulted in obtaining higher maximum temperatures of the skin surface during the procedure (maximum obtained temperature equaled 40.8°C). The temperature of the skin under the head of the device does not translate to subjective patient experiences. In anatomic locations filled with less adipose tissue mass, tolerance to RF is much lower. The dynamics of skin temperature changes, after the RF treatment, can be described by means of a single exponential function where the key parameter is the time constant t1 defining the dynamics of skin temperature changes. The depth of the RF influence is slightly correlated with the RF power.","Wilczyński S
Stolecka-Warzecha A
Deda A
Koprowski R
Flasz K
Błoński B
Musioł M
","(PMID:30225860
)",In vivo dynamic thermal imaging of skin radiofrequency treatment.,https://europepmc.org/abstract/MED/30225860%0A
"Diffusion MRI fiber tractography is widely used to probe the structural connectivity of the brain, with a range of applications in both clinical and basic neuroscience. Despite widespread use, tractography has well-known pitfalls that limits the anatomical accuracy of this technique. Numerous modern methods have been developed to address these shortcomings through advances in acquisition, modeling, and computation. To test whether these advances improve tractography accuracy, we organized the 3-D Validation of Tractography with Experimental MRI (3D-VoTEM) challenge at the ISBI 2018 conference. We made available three unique independent tractography validation datasets - a physical phantom and two ex vivo brain specimens - resulting in 176 distinct submissions from 9 research groups. By comparing results over a wide range of fiber complexities and algorithmic strategies, this challenge provides a more comprehensive assessment of tractography's inherent limitations than has been reported previously. The central results were consistent across all sub-challenges in that, despite advances in tractography methods, the anatomical accuracy of tractography has not dramatically improved in recent years. Taken together, our results independently confirm findings from decades of tractography validation studies, demonstrate inherent limitations in reconstructing white matter pathways using diffusion MRI data alone, and highlight the need for alternative or combinatorial strategies to accurately map the fiber pathways of the brain.","Schilling KG
Nath V
Hansen C
Parvathaneni P
Blaber J
Gao Y
Neher P
Aydogan DB
Shi Y
Ocampo-Pineda M
Schiavi S
Daducci A
Girard G
Barakovic M
Rafael-Patino J
Romascano D
Rensonnet G
Pizzolato M
Bates A
Fischi E
Thiran JP
Canales-Rodríguez EJ
Huang C
Zhu H
Zhong L
Cabeen R
Toga AW
Rheault F
Theaud G
Houde JC
Sidhu J
Chamberland M
Westin CF
Dyrby TB
Verma R
Rathi Y
Irfanoglu MO
Thomas C
Pierpaoli C
Descoteaux M
Anderson AW
Landman BA
","(PMID:30317017
)",Limits to anatomical accuracy of diffusion tractography using modern approaches.,https://europepmc.org/abstract/MED/30317017%0A
"BACKGROUND:Emotion recognition is an increasingly important field of research in brain computer interactions. INTRODUCTION:With the advance of technology, automatic emotion recognition systems no longer seem far-fetched. Be that as it may, detecting neural correlates of emotion has remained a substantial bottleneck. Settling this issue will be a breakthrough of significance in the literature. METHODS:The current study aims to identify the correlations between different emotions and brain regions with the help of suitable electrodes. Initially, independent component analysis algorithm is employed to remove artifacts and extract the independent components. The informative channels are then selected based on the thresholded average activity value for obtained components. Afterwards, effective features are extracted from selected channels common between all emotion classes. Features are reduced using the local subset feature selection method and then fed to a new classification model using modified Dempster-Shafer theory of evidence. RESULTS:The presented method is employed to DEAP dataset and the results are compared to those of previous studies, which highlights the significant ability of this method to recognize emotions through electroencephalography, by the accuracy of about 91%. Finally, the obtained results are discussed and new aspects are introduced. CONCLUSIONS:The present study addresses the long-standing challenge of finding neural correlates between human emotions and the activated brain regions. Also, we managed to solve uncertainty problem in emotion classification which is one of the most challenging issues in this field. The proposed method could be employed in other practical applications in future.","Zangeneh Soroush M
Maghooli K
Setarehdan SK
Nasrabadi AM
","(PMID:30382882
 PMCID:PMC6208176)",A novel approach to emotion recognition using local subset feature selection and modified Dempster-Shafer theory.,https://europepmc.org/abstract/MED/30382882%0A
"OBJECTIVE:The objective of this study was to evaluate the clinical outcomes of conventional two-dimensional (2D) endoscope with a novel computer-based three-dimensional (3D) imaging system for otologic surgical procedures. METHODS:A conventional 2D monocular endoscope with a novel computer-based 3D imaging system was applied to 18 otologic surgical procedures, including chronic otitis media (COM), cholesteatoma, otosclerosis, external canal osteoma and cochlear implant. Operation duration and complications of COM and attic cholesteatoma were recorded to compare 2D and 3D endoscopic ear surgery. Questionnaires were completed by 35 observers participating in the procedures and were used to evaluate clinical and potential side effects. RESULTS:The surgical procedures were performed smoothly for all patients. No patient required switching to conventional 2D endoscopic surgery. No significant differences were apparent in operation duration using the 3D imaging system for chronic otitis media and attic cholesteatoma compared with conventional 2D endoscopic ear surgery. Thirty-five observers completed the questionnaires. Most of them agreed that this 3D imaging system enabled them to perceive stereoscopic vision (94%), provide superior depth perception (85%). Furthermore, 97.1% reported no visual fatigue or discomfort when observing the 3D images. CONCLUSION:Our study demonstrated that the computer-based 3D imaging system enables the application of 3D vision technology to otologic surgery. The system has no obvious side effects, such as visual fatigue or time delay. It not only facilitates performing the related surgical procedures but also helps in teaching and learning endoscopic ear surgeries.","Chen CK
Hsieh LC
Hsu TH
","(PMID:30276530
)",Novel three-dimensional image system for endoscopic ear surgery.,https://europepmc.org/abstract/MED/30276530%0A
"2Sound decoding is important for patients with sensory loss, such as the blind. Previous studies on sound categorization were conducted by estimating brain activity using univariate analysis or voxel-wise multivariate decoding methods and suggested some regions were sensitive to auditory categories. It is proposed that feedback connections between brain areas may facilitate auditory object selection. Therefore, it is important to explore whether functional connectivity among regions can be used to decode sound category. In this study, we constructed whole-brain functional connectivity patterns when subjects perceived four different sound categories and combined them with multivariate pattern classification analysis for sound decoding. The categorical discriminative networks and regions were determined based on the weight maps. Results showed that a high accuracy in multi-category classification was obtained based on the whole-brain functional connectivity patterns and the results were verified by different preprocessing parameters. Insight into the category discriminative functional networks showed that contributive connections crossed the left and right brain, and ranged from primary regions to high-level cognitive regions, which provide new evidence for the distributed representation of auditory object. Further analysis of brain regions in the discriminative networks showed that superior temporal gyrus and Heschl's gyrus significantly contributed to discriminating sound categories. Together, the findings reveal that functional connectivity based multivariate classification method provides rich information for auditory category decoding. The successful decoding results implicate the interactive properties of the distributed brain areas in auditory sound representation.","Zhang J
Zhang G
Li X
Wang P
Wang B
Liu B
","(PMID:30361945
)",Decoding sound categories based on whole-brain functional connectivity patterns.,https://europepmc.org/abstract/MED/30361945%0A
"Inspired by classic Generative Adversarial Networks (GANs), we propose a novel end-to-end adversarial neural network, called SegAN, for the task of medical image segmentation. Since image segmentation requires dense, pixel-level labeling, the single scalar real/fake output of a classic GAN's discriminator may be ineffective in producing stable and sufficient gradient feedback to the networks. Instead, we use a fully convolutional neural network as the segmentor to generate segmentation label maps, and propose a novel adversarial critic network with a multi-scale L1 loss function to force the critic and segmentor to learn both global and local features that capture long- and short-range spatial relationships between pixels. In our SegAN framework, the segmentor and critic networks are trained in an alternating fashion in a min-max game: The critic is trained by maximizing a multi-scale loss function, while the segmentor is trained with only gradients passed along by the critic, with the aim to minimize the multi-scale loss function. We show that such a SegAN framework is more effective and stable for the segmentation task, and it leads to better performance than the state-of-the-art U-net segmentation method. We tested our SegAN method using datasets from the MICCAI BRATS brain tumor segmentation challenge. Extensive experimental results demonstrate the effectiveness of the proposed SegAN with multi-scale loss: on BRATS 2013 SegAN gives performance comparable to the state-of-the-art for whole tumor and tumor core segmentation while achieves better precision and sensitivity for Gd-enhance tumor core segmentation; on BRATS 2015 SegAN achieves better performance than the state-of-the-art in both dice score and precision.","Xue Y
Xu T
Zhang H
Long LR
Huang X
","(PMID:29725916
)",SegAN: Adversarial Network with Multi-scale L1 Loss for Medical Image Segmentation.,https://europepmc.org/abstract/MED/29725916%0A
"BACKGROUND AND OBJECTIVES:Retinal fundus image analysis without manual intervention has been rising as an imperative analytical approach for early detection of eye-related diseases such as glaucoma and diabetic retinopathy. For analysis and detection of Glaucoma and some other disease from retinal image, there is a significant role of predicting the bounding box coordinates of Optic Disc (OD) that acts as a Region of Interest (ROI). METHODS:We reframe ROI detection as a solitary regression predicament, from image pixel values to ROI coordinates including class probabilities. A Convolution Neural Network (CNN) has trained on full images to predict bounding boxes along with their analogous probabilities and confidence scores. The publically available MESSIDOR and Kaggle datasets have been used to train the network. We adopted various data augmentation techniques to amplify our dataset so that our network becomes less sensitive to noise. From a very high-level perspective, every image is divided into a 13 × 13 grid. Every grid cell envisages 5 bounding boxes along with the corresponding class probability and a confidence score. Before training, the network and the bounding box priors or anchors are initialized using k-means clustering on the original dataset using a distance metric based on Intersection of the Union (IOU) over ground-truth bounding boxes. During training in fact, a sum-squared loss function is used as the prediction's error function. Finally, Non-maximum suppression is applied by the proposed methodology to reach the concluding prediction. RESULTS:The following projected method accomplish an accuracy of 99.05% and 98.78% on the Kaggle and MESSIDOR test sets for ROI detection. Results of proposed methodology indicates that proposed network is able to perceive ROI in fundus images in 0.0045 s at 25 ms of latency, which is far better than the recent-time and using no handcrafted features. CONCLUSIONS:The network predicts accurate results even on low-quality images without being biased towards any particular type of image. The network prepared to see more summed up depiction rather than past works in the field. Going by the results, our novel method has better diagnosis of eye diseases in the future in a faster and reliable way.","Mitra A
Banerjee PS
Roy S
Roy S
Setua SK
","(PMID:30337079
)",The region of interest localization for glaucoma analysis from retinal fundus image using deep learning.,https://europepmc.org/abstract/MED/30337079%0A
"Networks provide a powerful formalism for modeling complex systems by using a model of pairwise interactions. But much of the structure within these systems involves interactions that take place among more than two nodes at once-for example, communication within a group rather than person to person, collaboration among a team rather than a pair of coauthors, or biological interaction between a set of molecules rather than just two. Such higher-order interactions are ubiquitous, but their empirical study has received limited attention, and little is known about possible organizational principles of such structures. Here we study the temporal evolution of 19 datasets with explicit accounting for higher-order interactions. We show that there is a rich variety of structure in our datasets but datasets from the same system types have consistent patterns of higher-order structure. Furthermore, we find that tie strength and edge density are competing positive indicators of higher-order organization, and these trends are consistent across interactions involving differing numbers of nodes. To systematically further the study of theories for such higher-order structures, we propose higher-order link prediction as a benchmark problem to assess models and algorithms that predict higher-order structure. We find a fundamental difference from traditional pairwise link prediction, with a greater role for local rather than long-range information in predicting the appearance of new interactions.","Benson AR
Abebe R
Schaub MT
Jadbabaie A
Kleinberg J
","(PMID:30413619
)",Simplicial closure and higher-order link prediction.,https://europepmc.org/abstract/MED/30413619%0A
"PURPOSE:Accurately detecting and removing pectoral muscle areas depicting on mediolateral oblique (MLO) view mammograms are an important step to develop a computer-aided detection scheme to assess global mammographic density or tissue patterns. This study aims to develop and test a new fully automated, accurate and robust method for segmenting pectoral muscle in MLO mammograms. METHODS:The new method includes the following steps. First, a small rectangular region in the top-left corner of the MLO mammogram which may contain pectoral muscle is captured and enhanced by the fractional differential method. Next, an improved iterative threshold method is applied to segment a rough binary boundary of the pectoral muscle in the small region. Then, a rough contour is fitted with the least squares method on the basis of points of the rough boundary. Last, the fitting contour is subjected to local active contour evolution to obtain the final pectoral muscle segmentation line. The method has been tested on 720 MLO mammograms. RESULTS:The segmentation results generated using the new scheme were evaluated by two expert mammographic radiologists using a 5-scale rating system. More than 65% were rated above scale 3. When assessing the segmentation results generated using Hough transform, morphologic thresholding methods and Unet-based model, less than 20%, 35% and 47% of segmentation results were rated above scale 3 by two radiologists, respectively. Quantitative data analysis results show that the Dice coefficient of 0.986 ± 0.005 is obtained. In addition, the mean rate of errors and Hausdorff distance between the contours detected by automated and manual segmentation are FP = 1.71 ± 3.82%, FN = 5.20 ± 3.94% and 2.75 ± 1.39 mm separately. CONCLUSION:The proposed method can be used to segment the pectoral muscle in MLO mammograms with higher accuracy and robustness.","Yin K
Yan S
Song C
Zheng B
","(PMID:30288698
)",A robust method for segmenting pectoral muscle in mediolateral oblique (MLO) mammograms.,https://europepmc.org/abstract/MED/30288698%0A
"With quantum computers of significant size now on the horizon, we should understand how to best exploit their initially limited abilities. To this end, we aim to identify a practical problem that is beyond the reach of current classical computers, but that requires the fewest resources for a quantum computer. We consider quantum simulation of spin systems, which could be applied to understand condensed matter phenomena. We synthesize explicit circuits for three leading quantum simulation algorithms, using diverse techniques to tighten error bounds and optimize circuit implementations. Quantum signal processing appears to be preferred among algorithms with rigorous performance guarantees, whereas higher-order product formulas prevail if empirical error estimates suffice. Our circuits are orders of magnitude smaller than those for the simplest classically infeasible instances of factoring and quantum chemistry, bringing practical quantum computation closer to reality.","Childs AM
Maslov D
Nam Y
Ross NJ
Su Y
","(PMID:30190433
)",Toward the first quantum simulation with quantum speedup.,https://europepmc.org/abstract/MED/30190433%0A
"Machine learning based predictions of protein⁻protein interactions (PPIs) could provide valuable insights into protein functions, disease occurrence, and therapy design on a large scale. The intensive feature engineering in most of these methods makes the prediction task more tedious and trivial. The emerging deep learning technology enabling automatic feature engineering is gaining great success in various fields. However, the over-fitting and generalization of its models are not yet well investigated in most scenarios. Here, we present a deep neural network framework (DNN-PPI) for predicting PPIs using features learned automatically only from protein primary sequences. Within the framework, the sequences of two interacting proteins are sequentially fed into the encoding, embedding, convolution neural network (CNN), and long short-term memory (LSTM) neural network layers. Then, a concatenated vector of the two outputs from the previous layer is wired as the input of the fully connected neural network. Finally, the Adam optimizer is applied to learn the network weights in a back-propagation fashion. The different types of features, including semantic associations between amino acids, position-related sequence segments (motif), and their long- and short-term dependencies, are captured in the embedding, CNN and LSTM layers, respectively. When the model was trained on Pan's human PPI dataset, it achieved a prediction accuracy of 98.78% at the Matthew's correlation coefficient (MCC) of 97.57%. The prediction accuracies for six external datasets ranged from 92.80% to 97.89%, making them superior to those achieved with previous methods. When performed on Escherichia coli, Drosophila, and Caenorhabditis elegans datasets, DNN-PPI obtained prediction accuracies of 95.949%, 98.389%, and 98.669%, respectively. The performances in cross-species testing among the four species above coincided in their evolutionary distances. However, when testing Mus Musculus using the models from those species, they all obtained prediction accuracies of over 92.43%, which is difficult to achieve and worthy of note for further study. These results suggest that DNN-PPI has remarkable generalization and is a promising tool for identifying protein interactions.","Li H
Gong XJ
Yu H
Zhou C
","(PMID:30071670
 PMCID:PMC6222503)",Deep Neural Network Based Predictions of Protein Interactions Using Primary Sequences.,https://europepmc.org/abstract/MED/30071670%0A
"In this study, the third-order Møller-Plesset perturbation (MP3) theory using the resolution of the identity (RI) approximation was combined with the fragment molecular orbital (FMO) method to efficiently calculate a high-order electron correlation energy of biomolecular systems. We developed a new algorithm for the RI-MP3 calculation, which can be used with the FMO scheme. After test calculations using a small molecule, the FMO-RI-MP3 calculations were performed for two biomolecular systems comprising a protein and a ligand. The computational cost of these calculations was only around 5 and 4 times higher than those of the FMO-RHF calculations. The error associated with the RI approximation was around 2.0% of the third-order correlation contribution to the total energy. However, the RI approximation error in the interaction energy between the protein and ligand molecule was insignificantly small, which reflected the negligible error in the inter fragment interaction energy. © 2018 Wiley Periodicals, Inc.","Ishikawa T
Sakakura K
Mochizuki Y
","(PMID:30277590
)",RI-MP3 calculations of biomolecules based on the fragment molecular orbital method.,https://europepmc.org/abstract/MED/30277590%0A
"In this study, the laser metal deposition (LMD) of the Inconel 625⁻tungsten carbide (WC) metal matrix composite was investigated. The composite coating was deposited on Inconel 625 substrate by powder method. A powder mixture containing 10 wt% of WC (5 µm) was prepared by wet mixing with dextrin binder. Coating samples obtained by low-power LMD were pore- and crack-free. Ceramic reinforcement was distributed homogenously in the whole volume of the material. Topologically close-packed (TCP) phases were formed at grain boundaries between WC and Inconel 625 matrix as a result of partial dissolution of WC in a nickel-based alloy. Line analysis of the elements revealed very small interference of the coating in the substrate material when compared to conventional coating methods. The average Vickers hardness of the coating was about 25% higher than the hardness of pure Inconel 625 reference samples.","Huebner J
Kata D
Rutkowski P
Petrzak P
Kusiński J
","(PMID:30248949
 PMCID:PMC6213095)",Grain-Boundary Interaction between Inconel 625 and WC during Laser Metal Deposition.,https://europepmc.org/abstract/MED/30248949%0A
"Photocatalysis based on optically active, ""plasmonic"" metal nanoparticles has emerged as a promising approach to facilitate light-driven chemical conversions under far milder conditions than thermal catalysis. However, an understanding of the relation between thermal and electronic excitations has been lacking. We report the substantial light-induced reduction of the thermal activation barrier for ammonia decomposition on a plasmonic photocatalyst. We introduce the concept of a light-dependent activation barrier to account for the effect of light illumination on electronic and thermal excitations in a single unified picture. This framework provides insight into the specific role of hot carriers in plasmon-mediated photochemistry, which is critically important for designing energy-efficient plasmonic photocatalysts.","Zhou L
Swearer DF
Zhang C
Robatjazi H
Zhao H
Henderson L
Dong L
Christopher P
Carter EA
Nordlander P
Halas NJ
","(PMID:30287657
)",Quantifying hot carrier and thermal contributions in plasmonic photocatalysis.,https://europepmc.org/abstract/MED/30287657%0A
"Development of an effective machine-learning model for T-cell Mycobacterium tuberculosis (M. tuberculosis) epitopes is beneficial for saving biologist's time and effort for identifying epitope in a targeted antigen. Existing NetMHC 2.2, NetMHC 2.3, NetMHC 3.0 and NetMHC 4.0 estimate binding capacity of peptide. This is still a challenge for those servers to predict whether a given peptide is M. tuberculosis epitope or non-epitope. One of the servers, CTLpred, works in this category but it is limited to peptide length of 9-mers. Therefore, in this work direct method of predicting M. tuberculosis epitope or non-epitope has been proposed which also overcomes the limitations of above servers. The proposed method is able to work with variable length epitopes having size even greater than 9-mers. Identification of T-cell or B-cell epitopes in the targeted antigen is the main goal in designing epitope-based vaccine, immune-diagnostic tests and antibody production. Therefore, it is important to introduce a reliable system which may help in the diagnosis of M. tuberculosis. In the present study, computational intelligence methods are used to classify T-cell M. tuberculosis epitopes. The caret feature selection approach is used to find out the set of relevant features. The ensemble model is designed by combining three models and is used to predict M. tuberculosis epitopes of variable length (7-40-mers). The proposed ensemble model achieves 82.0% accuracy, 0.89 specificity, 0.77 sensitivity with repeated k-fold cross-validation having average accuracy of 80.61%. The proposed ensemble model has been validated and compared with NetMHC 2.3, NetMHC 4.0 servers and CTLpred T-cell prediction server.","Khanna D
Rana PS
","(PMID:30406342
)",Ensemble Technique for Prediction of T-cell Mycobacterium tuberculosis Epitopes.,https://europepmc.org/abstract/MED/30406342%0A
"In this work we introduce a novel set-based fault tolerant control scheme for linear systems under Gaussian disturbances. In the proposed strategy, actuator faults are detected and diagnosed when residual trajectories enter and remain in certain sets that are computed as probabilistic ultimate bounds. After a fault is diagnosed, the control scheme is reconfigured to take into account the corresponding actuator failure and preserve certain closed loop features. We show that our strategy can detect and diagnose the different faults considered with an arbitrarily small probability of misdetection.","Pizzi N
Kofman E
De Doná JA
Seron MM
","(PMID:30342813
)",Actuator fault tolerant control based on probabilistic ultimate bounds.,https://europepmc.org/abstract/MED/30342813%0A
"Classification of abnormalities from medical images using computer-based approaches is of growing interest in medical imaging. Timely detection of abnormalities due to diabetic retinopathy and age-related macular degeneration is required in order to prevent the prognosis of the disease. Computer-aided systems using machine learning are becoming interesting to ophthalmologists and researchers. We present here one such technique, the Random Forest classifier, to aid medical practitioners in accurate diagnosis of the diseases. A computer-aided diagnosis system is proposed for detecting retina abnormalities, which combines K means-based segmentation of the retina image, after due preprocessing, followed by machine learning techniques, using several low level and statistical features. Abnormalities in the retina that are classified are caused by age-related macular degeneration and diabetic retinopathy. Performance measures used in the analysis are accuracy, sensitivity, specificity, F-measure, and Mathew correlation coefficient. A comparison with another machine learning technique, the Naïve Bayes classifier shows that the classification achieved by Random Forest classifier is 93.58% and it outperforms Naïve Bayes classifier which yields an accuracy of 83.63%. Graphical abstract Random Forest classifier for abnormality detection in retina images.","Chowdhury AR
Chatterjee T
Banerjee S
","(PMID:30076537
)",A Random Forest classifier-based approach in the detection of abnormalities in the retina.,https://europepmc.org/abstract/MED/30076537%0A
"Bridging between brain activity and machine control, brain-computer interface (BCI) can be employed to activate distributed neural circuits implicated in a specific aspect of motor control. Using a motor imagery-based BCI paradigm, we previously found a disinhibition within the primary motor cortex contralateral to the imagined movement, as evidenced by event-related desynchronization (ERD) of oscillatory cortical activity. Yet it is unclear whether this BCI approach does selectively facilitate corticomotor representations targeted by the imagery. To address this question, we used brain state-dependent transcranial magnetic stimulation while participants performed kinesthetic motor imagery of wrist movements with their right hand and received online visual feedback of the ERD. Single and paired-pulse magnetic stimulation were given to the left primary motor cortex at a low or high level of ERD to assess intracortical excitability. While intracortical facilitation showed no modulation by ERD, short-latency intracortical inhibition was reduced the higher the ERD. Intracortical disinhibition was only found in the agonist muscle targeted by motor imagery at high ERD level, but not in the antagonist muscle. Single pulse motor-evoked potential was also increased the higher the ERD. However, at high ERD level, this facilitatory effect on overall corticospinal excitability was not selective to the agonist muscle. Analogous results were found in two independent experiments, in which participants either performed kinesthetic motor imagery of wrist extension or flexion. Our results showed that motor imagery-based BCI can selectively disinhibit the corticomotor output to the agonist muscle, enabling effector-specific training in patients with motor paralysis.","Takemi M
Maeda T
Masakado Y
Siebner HR
Ushiba J
","(PMID:30172003
)",Muscle-selective disinhibition of corticomotor representations using a motor imagery-based brain-computer interface.,https://europepmc.org/abstract/MED/30172003%0A
"Radiation therapy plays an essential role in the treatment of cancer. In radiation therapy, the ideal radiation doses are delivered to the observed tumor while not affecting neighboring normal tissues. In three-dimensional computed tomography (3D-CT) scans, the contours of tumors and organs-at-risk (OARs) are often manually delineated by radiologists. The task is complicated and time-consuming, and the manually delineated results will be variable from different radiologists. We propose a semi-supervised contour detection algorithm, which firstly uses a few points of region of interest (ROI) as an approximate initialization. Then the data sequences are achieved by the closed polygonal line (CPL) algorithm, where the data sequences consist of the ordered projection indexes and the corresponding initial points. Finally, the smooth lung contour can be obtained, when the data sequences are trained by the backpropagation neural network model (BNNM). We use the private clinical dataset and the public Lung Image Database Consortium and Image Database Resource Initiative (LIDC-IDRI) dataset to measure the accuracy of the presented method, respectively. To the private dataset, experimental results on the initial points which are as low as 15% of the manually delineated points show that the Dice coefficient reaches up to 0.95 and the global error is as low as 1.47 × 10-2. The performance of the proposed algorithm is also better than the cubic spline interpolation (CSI) algorithm. While on the public LIDC-IDRI dataset, our method achieves superior segmentation performance with average Dice of 0.83.","Peng T
Wang Y
Xu TC
Shi L
Jiang J
Zhu S
","(PMID:29450843
)",Detection of Lung Contour with Closed Principal Curve and Machine Learning.,https://europepmc.org/abstract/MED/29450843%0A
"Purpose: Technology of reflectance spectroscopy incorporated with auto-fluorescence spectroscopy were employed to increase the safety of epidural placement in regional anesthesia which is generally used for surgery, epidural anesthesia, post-operative pain control and painless childbirth. Method: Ex vivo study of auto-fluorescence spectroscopy was performed for the para-vertebral tissues contained fat, interspinous ligament, supraspinous ligament and ligamentumflavum by multimode microplate reader at wavelength 405 nm for the purpose of tissue differentiation. A specially designed optic-fiber-embedded needle was employed to incorporate with both reflectance and autofluorescence spectroscopies in order to probe the epidural space as double assurance demands. In vivo study was carried out in a Chinese native swine weighted about 30 kg under intubated general anesthesia with ventilation support. The reflective (405 nm) and autofluorescence signals (λ and λ*) were recorded at 5 different sites by an oscilloscope during the needle puncture procedure from skin to epidural space in the back of the swine. Results: Study of either autofluorescence spectroscopy for tissue samples or ex vivo needle puncture in porcine trunk tissues indicates that ligmentumflavum has at least 10-fold higher fluorescence intensity than the other tissues. In the in vivo study, ligamentumflavum shows a double-peak character for both reflectance and autofluorescence signals. The epidural space is located right after the drop from the double-peak. Both peaks of reflectance and fluorescence are coincident which ensures that the epidural space is correctly detected. Conclusions: The fiber-optical technologies of double-assurance demands for tissue discrimination during epidural needle puncture can not only provide an objective visual information in a real-time fashion but also it can help the operator to achieve much higher success rate in this anesthesia procedure.","Gong CA
Lee HC
Chang Y
Ting CK
Tu PH
","(PMID:30360473
)",Double Assurance of Epidural Space Detection Using Fiberoptics-Based Needle Design and Autofluorescence Technologies for Epidural Blockade in Painless Labor.,https://europepmc.org/abstract/MED/30360473%0A
"Informal caregivers of bedridden elders need a respite. One form of obtaining a respite is through volunteers who are contacted by means of information and communication technology (ICT). A qualitative study was carried out in a low-income district in Santiago, Chile, to learn about how caregivers of bedridden elders perceive the possibility of using ICT to access this respite. In-depth interviews were carried out and transcribed verbatim, then analysed using open coding. Results: The results reveal that caregivers are willing to receive a volunteer in their home and use ICT to communicate with them, although a discrepancy exists between the use of devices connected to the Internet and feature phones. Conclusion: This study concludes that informal caregivers of bedridden elders have a favourable disposition towards accessing a respite system by means of ICT based on a peer-to-peer economy.","Abarca E
Campos S
Herskovic V
Fuentes C
","(PMID:29336722
 PMCID:PMC5769803)",Perceptions on technology for volunteer respite care for bedridden elders in Chile.,https://europepmc.org/abstract/MED/29336722%0A
No abstract provided.,"Gavaghan D
","(PMID:30324270
)",Problems with the Current Approach to the Dissemination of Computational Science Research and Its Implications for Research Integrity.,https://europepmc.org/abstract/MED/30324270%0A
"PURPOSE:To reduce the inter- and intra- rater variability as well as time and effort, a method for computer-assisted delineation of hematoma is proposed. Delineation of hematoma is done for further automated analysis such as the volume of hematoma, anatomical location of hematoma, etc. for proper surgical planning. METHODS:Fuzzy-based intensifier was used as a pre-processing technique for enhancing the computed tomography (CT) volume. Autoencoder was trained to detect the CT slices with hematoma for initialization. Then active contour Chan-Vese model was used for automated delineation of hematoma from CT volume. RESULTS:The proposed algorithm was tested on 48 hemorrhagic patients. Two radiologists have independently segmented the hematoma manually from CT volume. The intersection of two volumes was used as ground-truth for comparison with the segmentation performed by the proposed method. The accuracy was determined by using similarity matrices. The result of sensitivity, positive predictive value, Jaccard index and Dice similarity index were calculated as 0.71 ± 0.12, 0.73 ± 0.18, 0.55 ± 0.14, and 0.70 ± 0.12 respectively. CONCLUSIONS:A new approach for delineation of hematoma is proposed. The algorithm works well with the whole volume. Similarity indices of the proposed method are comparable with the existing state of art.","Nag MK
Chatterjee S
Sadhu AK
Chatterjee J
Ghosh N
","(PMID:30377937
)",Computer-assisted delineation of hematoma from CT volume using autoencoder and Chan Vese model.,https://europepmc.org/abstract/MED/30377937%0A
"BACKGROUND:The number of people in the UK with three or more long-term conditions continues to grow and the management of patients with co-morbidities is complex. In treating patients with multimorbidities, a fundamental problem is understanding and detecting points of conflict between different guidelines which to date has relied on individual clinicians collating disparate information. OBJECTIVE:We will develop a framework for modelling a diverse set of care pathways, and investigate how conflicts can be detected and resolved automatically. We will use this knowledge to develop a software tool for use by clinicians that can map guidelines, highlight root causes of conflict between these guidelines and suggest ways they might be resolved. METHOD:Our work consists of three phases. First, we will accurately model clinical pathways for six of the most common chronic diseases; second, we will automatically identify and detect sources of conflict across the pathways and howthey might be resolved. Third, we will present a case study to prove the validity of our approach using a team of clinicians to detect and resolve the conflicts in the treatment of a fictional patient with multiple common morbidities and compare their findings and recommendations with those derived automatically using our novel software. DISCUSSION:This paper describes the development of an important software-based method for identifying a conflict between clinical guidelines. Our findings will support clinicians treating patients with multimorbidity in both primary and secondary care settings.","Litchfield I
Turner A
Backman R
Bosco Ferreira Filho J
Lee M
","(PMID:30398456
)",Automated conflict resolution between multiple clinical pathways: a technology report.,https://europepmc.org/abstract/MED/30398456%0A
No abstract provided.,"Condon A
Kirchner H
Larivière D
Marshall W
Noireaux V
Tlusty T
Fourmentin E
","(PMID:30061101
)",Will biologists become computer scientists? A truly interdisciplinary effort by computer scientists and biologists to understand how cells process information may yield new insights for both fields.,https://europepmc.org/abstract/MED/30061101%0A
"Prioritization of cell cycle-regulated genes from expression time-profiles is still an open problem. The point at issue is the surprisingly poor overlap among ranked lists obtained from different experimental protocols. Instead of developing a general-purpose computational methodology for detecting periodic signals, we focus on the budding yeast mitotic cell cycle. The reason being that the current availability of a total of 12 datasets, produced by 6 independent groups using 4 different synchronization methods, permits a re-analysis and re-consideration of this problem in a more reliable and extensive data domain. Notably, budding yeast is a model organism for studying cancer and testing new drugs. Here we propose a novel multi-feature score (called PERLA, PERiodicity, Regulation and Lag-Autocorrelation) that integrates different features of cell cycle-regulated gene expression time-profiles. We obtained increased performances on a wide range of benchmarks and, most importantly, a substantially increased overlap of the top ranking genes among different datasets, thus proving the effectiveness of the proposed prioritization algorithm. Examples on how to use PERLA to gain new insight into the biology of the cell cycle, are provided in a final dedicated section.","Farina L
Paci P
","(PMID:30261169
)",A feature-based integrated scoring scheme for cell cycle-regulated genes prioritization.,https://europepmc.org/abstract/MED/30261169%0A
"BACKGROUND:Novel sequence motifs detection is becoming increasingly essential in computational biology. However, the high computational cost greatly constrains the efficiency of most motif discovery algorithms. RESULTS:In this paper, we accelerate MEME algorithm targeted on Intel Many Integrated Core (MIC) Architecture and present a parallel implementation of MEME called MIC-MEME base on hybrid CPU/MIC computing framework. Our method focuses on parallelizing the starting point searching method and improving iteration updating strategy of the algorithm. MIC-MEME has achieved significant speedups of 26.6 for ZOOPS model and 30.2 for OOPS model on average for the overall runtime when benchmarked on the experimental platform with two Xeon Phi 3120 coprocessors. CONCLUSIONS:Furthermore, MIC-MEME has been compared with state-of-arts methods and it shows good scalability with respect to dataset size and the number of MICs. Source code: https://github.com/hkwkevin28/MIC-MEME .","Peng S
Cheng M
Huang K
Cui Y
Zhang Z
Guo R
Zhang X
Yang S
Liao X
Lu Y
Zou Q
Shi B
","(PMID:30367570
)",Efficient computation of motif discovery on Intel Many Integrated Core (MIC) Architecture.,https://europepmc.org/abstract/MED/30367570%0A
"The human brain rapidly develops during the first two years following birth. Quantitative susceptibility mapping (QSM) provides information of iron and myelin variations. It is considered to be a valuable tool for studying brain development in early life. In the present work, QSM is performed on neonates, 1-year and 2-year old infants, as well as a group of adults for the purpose of reference. Age-specific templates representing common brain structures are built for each age group. The neonate and infant QSM templates have shown some unique findings compared to conventional T1w and T2w imaging techniques. The contrast between the gray and white matters on the QSM images did not change through brain development from neonate to adult. A linear correlation was found between brain myelination determined in this study and the microscopic myelin degree determined by a previous autopsy study. Also, the magnetic susceptibility values of the cerebral spinal fluid (CSF) exhibit a gradually decreasing trend from birth to 2 years old and to adulthood. The findings suggest that the macromolecular content, myelin, and iron may play the most important contributing factors for the magnetic susceptibility of neonate and infant brain. QSM can be a powerful means to study early brain development and related pathologies that involve alterations in macromolecular content, iron, or brain myelination.","Zhang Y
Shi J
Wei H
Han V
Zhu WZ
Liu C
","(PMID:30315906
)",Neonate and infant brain development from birth to 2 years assessed using MRI-based quantitative susceptibility mapping.,https://europepmc.org/abstract/MED/30315906%0A
"Deep learning has been transforming our ability to execute advanced inference tasks using computers. Here we introduce a physical mechanism to perform machine learning by demonstrating an all-optical diffractive deep neural network (D2NN) architecture that can implement various functions following the deep learning-based design of passive diffractive layers that work collectively. We created 3D-printed D2NNs that implement classification of images of handwritten digits and fashion products, as well as the function of an imaging lens at a terahertz spectrum. Our all-optical deep learning framework can perform, at the speed of light, various complex functions that computer-based neural networks can execute; will find applications in all-optical image analysis, feature detection, and object classification; and will also enable new camera designs and optical components that perform distinctive tasks using D2NNs.","Lin X
Rivenson Y
Yardimci NT
Veli M
Luo Y
Jarrahi M
Ozcan A
","(PMID:30049787
)",All-optical machine learning using diffractive deep neural networks.,https://europepmc.org/abstract/MED/30049787%0A
"There have been tremendous advances in artificial intelligence (AI) and machine learning (ML) within the past decade, especially in the application of deep learning to various challenges. These include advanced competitive games (such as Chess and Go), self-driving cars, speech recognition, and intelligent personal assistants. Rapid advances in computer vision for recognition of objects in pictures have led some individuals, including computer science experts and health care system experts in machine learning, to make predictions that ML algorithms will soon lead to the replacement of the radiologist. However, there are complex technological, regulatory, and medicolegal obstacles facing the implementation of machine learning in radiology that will definitely preclude replacement of the radiologist by these algorithms within the next two decades and beyond. While not a comprehensive review of machine learning, this article is intended to highlight specific features of machine learning which face significant technological and health care systems challenges. Rather than replacing radiologists, machine learning will provide quantitative tools that will increase the value of diagnostic imaging as a biomarker, increase image quality with decreased acquisition times, and improve workflow, communication, and patient safety. In the foreseeable future, we predict that today's generation of radiologists will be replaced not by ML algorithms, but by a new breed of data science-savvy radiologists who have embraced and harnessed the incredible potential that machine learning has to advance our ability to care for our patients. In this way, radiology will remain a viable medical specialty for years to come.","Chan S
Siegel EL
","(PMID:30325645
)",Will machine learning end the viability of radiology as a thriving medical specialty?,https://europepmc.org/abstract/MED/30325645%0A
"Motivation:Biclustering algorithms are commonly used for gene expression data analysis. However, accurate identification of meaningful structures is very challenging and state-of-the-art methods are incapable of discovering with high accuracy different patterns of high biological relevance. Results:In this paper, a novel biclustering algorithm based on evolutionary computation, a sub-field of artificial intelligence, is introduced. The method called EBIC aims to detect order-preserving patterns in complex data. EBIC is capable of discovering multiple complex patterns with unprecedented accuracy in real gene expression datasets. It is also one of the very few biclustering methods designed for parallel environments with multiple graphics processing units. We demonstrate that EBIC greatly outperforms state-of-the-art biclustering methods, in terms of recovery and relevance, on both synthetic and genetic datasets. EBIC also yields results over 12 times faster than the most accurate reference algorithms. Availability and implementation:EBIC source code is available on GitHub at https://github.com/EpistasisLab/ebic. Supplementary information:Supplementary data are available at Bioinformatics online.","Orzechowski P
Sipper M
Huang X
Moore JH
","(PMID:29790909
)",EBIC: an evolutionary-based parallel biclustering algorithm for pattern discovery.,https://europepmc.org/abstract/MED/29790909%0A
"Consumption of energy is a national and international phenomenon that showed increase in market spread and profits from 1990 and made the emergence of many brands. Energy drinks are aggressively marketed with the claim that these products give an energy boost to improve physical and cognitive performance. However, studies supporting these claims are limited. The study examines the new phenomena of energy drinks among university students in Lebanon, based on the participants' personnel characteristics, university grade and the impact on health status. The study also determined whether high frequency of consumption was correlated with negative physical health symptoms. A cross-sectional study survey was undertaken on students aged between 18 and 30 years in private university over three branches (Beirut, Tripoli and Saida). A self-administered questionnaire was used inquiring about socio-demographic characteristics, consumption patterns and side effect of energy drinks. Data was analyzed using SPSS 24. Findings showed a serious concern exists for the health and safety of the most at risk students who engaged in daily energy drink usage when two-thirds of these reported difficulties sleeping, more than one experienced heart palpitation and blood pressure; one-third had anxiety, nervousness and feeling thirsty, and one fifth indicated tiredness and headache. Such symptoms are reported with excessive consumption of caffeine that had adverse health effect on the body.","Dwaidy J
Dwaidy A
Hasan H
Kadry S
Balusamy B
","(PMID:30279985
)",Survey of energy drink consumption and adverse health effects in Lebanon.,https://europepmc.org/abstract/MED/30279985%0A
"Functional connectivity network provides novel insights on how distributed brain regions are functionally integrated, and its deviations from healthy brain have recently been employed to identify biomarkers for neuropsychiatric disorders. However, most of brain network analysis methods utilized features extracted only from one functional connectivity network for brain disease detection and cannot provide a comprehensive representation on the subtle disruptions of brain functional organization induced by neuropsychiatric disorders. Inspired by the principles of multi-view learning which utilizes information from multiple views to enhance object representation, we propose a novel multiple network based framework to enhance the representation of functional connectivity networks by fusing the common and complementary information conveyed in multiple networks. Specifically, four functional connectivity networks corresponding to the four adjacent values of regularization parameter are generated via a sparse regression model with group constraint ( l2,1 -norm), to enhance the common intrinsic topological structure and limit the error rate caused by different views. To obtain a set of more meaningful and discriminative features, we propose using a modified version of weighted clustering coefficients to quantify the subtle differences of each group-sparse network at local level. We then linearly fuse the selected features from each individual network via a multi-kernel support vector machine for autism spectrum disorder (ASD) diagnosis. The proposed framework achieves an accuracy of 79.35%, outperforming all the compared single network methods for at least 7% improvement. Moreover, compared with other multiple network methods, our method also achieves the best performance, that is, with at least 11% improvement in accuracy.","Huang H
Liu X
Jin Y
Lee SW
Wee CY
Shen D
","(PMID:30357998
)",Enhancing the representation of functional connectivity networks by fusing multi-view information for autism spectrum disorder diagnosis.,https://europepmc.org/abstract/MED/30357998%0A
"Provision of smart city services often relies on users contribution, e.g., of data, which can be costly for the users in terms of privacy. Privacy risks, as well as unfair distribution of benefits to the users, should be minimized as they undermine user participation, which is crucial for the success of smart city applications. This paper investigates privacy, fairness, and social welfare in smart city applications by means of computer simulations grounded on real-world data, i.e., smart meter readings and participatory sensing. We generalize the use of public good theory as a model for resource management in smart city applications, by proposing a design principle that is applicable across application scenarios, where provision of a service depends on user contributions. We verify its applicability by showing its implementation in two scenarios: smart grid and traffic congestion information system. Following this design principle, we evaluate different classes of algorithms for resource management, with respect to human-centered measures, i.e., privacy, fairness and social welfare, and identify algorithm-specific trade-offs that are scenario independent. These results could be of interest to smart city application designers to choose a suitable algorithm given a scenario-specific set of requirements, and to users to choose a service based on an algorithm that matches their privacy preferences.","Bennati S
Dusparic I
Shinde R
Jonker CM
","(PMID:30384483
)",Volunteers in the Smart City: Comparison of Contribution Strategies on Human-Centered Measures.,https://europepmc.org/abstract/MED/30384483%0A
"The design of novel proteins has many applications but remains an attritional process with success in isolated cases. Meanwhile, deep learning technologies have exploded in popularity in recent years and are increasingly applicable to biology due to the rise in available data. We attempt to link protein design and deep learning by using variational autoencoders to generate protein sequences conditioned on desired properties. Potential copper and calcium binding sites are added to non-metal binding proteins without human intervention and compared to a hidden Markov model. In another use case, a grammar of protein structures is developed and used to produce sequences for a novel protein topology. One candidate structure is found to be stable by molecular dynamics simulation. The ability of our model to confine the vast search space of protein sequences and to scale easily has the potential to assist in a variety of protein design tasks.","Greener JG
Moffat L
Jones DT
","(PMID:30385875
 PMCID:PMC6212568)",Design of metalloproteins and novel protein folds using variational autoencoders.,https://europepmc.org/abstract/MED/30385875%0A
"Motivation:This study addresses several important questions related to naturally underrepresented sequences: (i) are there permutations of real genomic DNA sequences in a defined length (k-mer) and a given lineage that do not actually exist or underrepresented? (ii) If there are such sequences, what are their characteristics in terms of k-mer length and base composition? (iii) Are they related to CpG or TpA underrepresentation known for human sequences? We propose that the answers to these questions are of great significance for the study of sequence-associated regulatory mechanisms, such cytosine methylation and chromosomal structures in physiological or pathological conditions such as cancer. Results:We empirically defined sequences that were not included in any well-known public databases as lineage-associated underrepresented permutations (LAUPs). Then, we developed a Jellyfish-based LAUPs analysis application (JBLA) to investigate LAUPs for 24 representative species. The present discoveries include: (i) lengths for the shortest LAUPs, ranging from 10 to 14, which collectively constitute a low proportion of the genome. (ii) Common LAUPs showing higher CG content over the analysed mammalian genome and possessing distinct CG*CG motifs. (iii) Neither CpG-containing LAUPs nor CpG island sequences are randomly structured and distributed over the genomes; some LAUPs and most CpG-containing sequences exhibit an opposite trend within the same k and n variants. In addition, we demonstrate that the JBLA algorithm is more efficient than the original Jellyfish for computing LAUPs. Availability and implementation:We developed a Jellyfish-based LAUP analysis (JBLA) application by integrating Jellyfish (Marçais and Kingsford, 2011), MEME (Bailey, et al., 2009) and the NCBI genome database (Pruitt, et al., 2007) applications, which are listed as Supplementary Material. Supplementary information:Supplementary data are available at Bioinformatics online.","Zhang L
Xiao M
Zhou J
Yu J
","(PMID:29762634
)",Lineage-associated underrepresented permutations (LAUPs) of mammalian genomic sequences based on a Jellyfish-based LAUPs analysis application (JBLA).,https://europepmc.org/abstract/MED/29762634%0A
"The Bar-headed Goose is the only true goose species or Anserinae to migrate solely within the Central Asian Flyway, and thus, it is an ideal species for observing the effects of both land use and climate change throughout the flyway. In this paper, we investigate the home range, movement pattern, and habitat selection of Bar-headed Geese (Anser indicus) during the breeding season at Qinghai Lake, which is one of their largest breeding areas and a major migration staging area in the flyway. We identified several areas used by the geese during the breeding season along the shoreline of Qinghai Lake and found that most geese had more than one core use area and daily movements that provided insight into their breeding activity. We also observed the intensive use of specific wetlands and habitats near Qinghai Lake. These data provide interesting insights into the movement ecology of this important species and also provide critical information for managers seeking to understand and respond to conservation concerns threatening Bar-headed Geese, such as landscape and habitat changes.","Zheng R
Smith LM
Prosser DJ
Takekawa JY
Newman SH
Sullivan JD
Luo Z
Yan B
","(PMID:30340319
 PMCID:PMC6209964)","Investigating Home Range, Movement Pattern, and Habitat Selection of Bar-headed Geese during Breeding Season at Qinghai Lake, China.",https://europepmc.org/abstract/MED/30340319%0A
"PURPOSE:Two phase gratings in an X-ray grating interferometers can solve several technical challenges for clinical use of X-ray phase contrast. In this work, we adapt and evaluate this setup design to clinical X-ray sources and detectors in a simulation study. METHODS:For a given set of gratings, we optimize the remaining parameter space of a dual-phase grating setup using a numerical wave front simulation. The simulation results are validated with experimentally obtained visibility measurements on a setup with a microfocus tube and a clinical X-ray detector. We then confirm by simulation that the Lau condition for the [Formula: see text] grating also holds for two phase gratings. Furthermore, we use a [Formula: see text] grating with a fixed period to search for periods of matching phase grating configurations. RESULTS:Simulated and experimental visibilities agree very well. We show that the Lau condition for a dual-phase grating setup requires the interference patterns of the first phase grating to constructively overlay at the second phase grating. Furthermore, a total of three setup variants for given [Formula: see text] periods were designed with the simulation, resulting in visibilities between 4.5 and 9.1%. CONCLUSION:Dual-phase gratings can be used and optimized for a medical X-ray source and detector. The obtained visibilities are somewhat lower than for other Talbot-Lau interferometers and are a tradeoff between setup length and spatial resolution (or additional phase stepping, respectively). However, these disadvantage appears minor compared to the overall better photon statistics, and the fact that dual-phase grating setups can be expected to scale to higher X-ray energies.","Bopp J
Ludwig V
Seifert M
Pelzer G
Maier A
Anton G
Riess C
","(PMID:30349975
)",Simulation study on X-ray phase contrast imaging with dual-phase gratings.,https://europepmc.org/abstract/MED/30349975%0A
"BACKGROUND:This paper aims to move the debate forward regarding the potential of AI and autonomous robotic surgery with a particular focus on ethical and legal aspects. METHODS:We conducted a literature search on current and emerging surgical robot technologies, relevant standards and legal systems worldwide. We provide a discussion of unique challenges for robotic surgery faced by proposals made for AI more generally (e.g. Explainable AI) as well as recommendations for developing/improving relevant standards or legal and regulatory frameworks. CONCLUSION:We distinguished three types of robot responsibility by classifying responsibility into: I. Accountability; II. Liability and III. Culpability. The component which produces the least clarity is Culpability, since it is unthinkable in the current state of technology. We envision in the nearer future that, as with autonomous driving, a robot can learn routine tasks which can then be supervised by the surgeon (a doctor-in-the-loop) being in the driving seat.","O'Sullivan S
Nevejans N
Allen C
Blyth A
Leonard S
Pagallo U
Holzinger K
Holzinger A
Sajid MI
Ashrafian H
","(PMID:30397993
)","Legal, Regulatory and Ethical Frameworks or Standards for AI and Autonomous Robotic Surgery.",https://europepmc.org/abstract/MED/30397993%0A
"PURPOSE:To study the evolution of recent topics in maxillofacial prosthetics (MP) research. MATERIALS AND METHODS:Science mapping analyses were used to measure bibliometric similarities among articles extracted from the Web of Science from the last three decades. RESULTS AND CONCLUSION:Keyword co-occurrence highlighted the rise of computer-aided design/computer-assisted manufacturing, mandibular reconstruction, and extraoral prostheses during the last decade. Citation analysis showed that surgery journals kept the leadership on MP publications, but that prosthodontics journals were closing the gap. The United States was the leading country in MP publications over the last three decades, but their lead is fast dissolving worldwide.","Naveau A
Bou C
Sharma A
","(PMID:30192349
)",Evolution of Topics in Maxillofacial Prosthetics Publications.,https://europepmc.org/abstract/MED/30192349%0A
"Increasing command generation rate of an event-related potential-based brain-robot system is challenging, because of limited information transfer rate of a brain-computer interface system. To improve the rate, we propose a dual stimuli approach that is flashing a robot image and is scanning another robot image simultaneously. Two kinds of event-related potentials, N200 and P300 potentials, evoked in this dual stimuli condition are decoded by a convolutional neural network. Compared with the traditional approaches, this proposed approach significantly improves the online information transfer rate from 23.0 or 17.8 to 39.1 bits/min at an accuracy of 91.7%. These results suggest that combining multiple types of stimuli to evoke distinguishable ERPs might be a promising direction to improve the command generation rate in the brain-computer interface.","Li W
Li M
Zhou H
Chen G
Jin J
Duan F
","(PMID:30185104
)",A Dual Stimuli Approach Combined with Convolutional Neural Network to Improve Information Transfer Rate of Event-Related Potential-Based Brain-Computer Interface.,https://europepmc.org/abstract/MED/30185104%0A
"We investigate the interdisciplinarity of mathematics based on an analysis of projects sponsored by the NSFC (National Natural Science Foundation of China). The motivation of this study lies in obtaining an efficient method to quantify the research interdisciplinarities, revealing the research interdisciplinarity patterns of mathematics discipline, giving insights for mathematics scholars to improve their research, and providing empirical supports for policy making. Our data set includes 6147 NSFC-sponsored projects implemented by 3225 mathematics professors in 177 Chinese universities with established mathematics departments. We propose the weighted-mean DIRD (diversity of individual research disciplines) to quantify interdisciplinarity. In addition, we introduce the matrix computation method, discover several properties of such a matrix, and make the computation cost significantly lower than the bitwise computation method. Finally, we develop an automatic DIRD computing system. The results indicate that mathematics professors at top normal universities in China exhibit strong interdisciplinarity; mathematics professors are most likely to conduct interdisciplinary research involving information science (research department), computer science (research area), computer application technology (research field), and power system bifurcation and chaos (research direction).","Shao ZY
Li YM
Hui F
Zheng Y
Guo YJ
","(PMID:30063757
 PMCID:PMC6067728)",Interdisciplinarity research based on NSFC-sponsored projects: A case study of mathematics in Chinese universities.,https://europepmc.org/abstract/MED/30063757%0A
"A cell contains numerous protein molecules. One of the fundamental goals in molecular cell biology is to determine their subcellular locations since this information is extremely important to both basic research and drug development. In this paper, we report a novel and very powerful predictor called ""pLoc_bal-mHum"" for predicting the subcellular localization of human proteins based on their sequence information alone. Cross-validation tests on exactly the same experiment-confirmed dataset have indicated that the new predictor is remarkably superior to the existing state-of-the-art predictor in identifying the subcellular localization of human proteins. To maximize the convenience for the majority of experimental scientists, a user-friendly web-server for the new predictor has been established at http://www.jci-bioinfo.cn/pLoc_bal-mHum/, by which users can easily get their desired results without the need to go through the detailed mathematics.","Chou KC
Cheng X
Xiao X
","(PMID:30179658
)",pLoc_bal-mHum: Predict subcellular localization of human proteins by PseAAC and quasi-balancing training dataset.,https://europepmc.org/abstract/MED/30179658%0A
"BACKGROUND:The detection of minute amounts of protein biomarkers in body fluids is believed to provide early diagnosis and prognosis of mild traumatic brain injury (mTBI). An ultrasensitive detection method was used to detect S100B, the most studied potential marker for the diagnosis of mTBI. METHODS:The detection method was a modified electrochemical immunoassay technique that provides voltage controlled intrinsic current signal amplification. The sandwich immune complex of S100B was formed on the working electrode of the screen-printed electrode. The gating voltage provides amplification of the current signal that flows through the complex. RESULTS:S100B was spiked in human serum. The limit of detection of S100B in human serum was 10 fg/mL. The calibration curves cover four orders of magnitudes from 10 fg/mL to 10 ng/mL. The specificity of the detection was demonstrated using TAU protein, which is another marker for mTBI. CONCLUSION:The results reported in this work using the field effect enzymatic detection (FEED)-based immunoassay indicate the feasibility of using this method for the detection of extremely low concentrations of markers of mTBI in human serum. This method can be developed as a platform for a range of markers of mTBI.","Mathew AS
Shi X
Yau ST
","(PMID:30377977
)",Detection of a Traumatic Brain Injury Biomarker at the 10 fg/mL Level.,https://europepmc.org/abstract/MED/30377977%0A
[This corrects the article DOI: 10.1155/2017/3587309.].,"Banjar H
Adelson D
Brown F
Chaudhri N
","(PMID:30035126
 PMCID:PMC6033254)","Corrigendum to ""Intelligent Techniques Using Molecular Data Analysis in Leukaemia: An Opportunity for Personalized Medicine Support System"".",https://europepmc.org/abstract/MED/30035126%0A
"The clinical presentation of Alzheimer's disease (AD) is not unitary as heterogeneity exists in the disease's clinical and anatomical characteristics. MRI studies have revealed that heterogeneous gray matter atrophy patterns are associated with specific traits of cognitive decline. Although white matter (WM) impairment also contributes to AD pathology, its heterogeneity remains unclear. The Latent Dirichlet Allocation (LDA) method is a suitable framework to study heterogeneity and allows to identify latent impairment factors of AD instead of simply mapping an overall disease effect. By exploring whole brain WM skeleton images by using LDA, three latent factors were revealed in AD: a temporal-frontal impairment factor (temporal and frontal lobes, especially hippocampus and para-hippocampus), a parietal factor (parietal lobe, especially precuneus), and a long fibre bundle factor (corpus callosum and superior longitudinal fasciculus). As revealed by longitudinal analysis, the latent factors have distinct impact on cognitive decline: for executive function (EF), the temporal-frontal factor was more strongly associated with baseline EF compared with the parietal factor, while the long-fibre bundle factor was most associated with decline rate of EF; for memory, the three factors showed almost equal effect on the baseline memory and decline rate. For each participant, LDA estimates his/her composition profile of latent impairment factors, which indicates disease subtype. We also found that the APOE genotype affects the AD subtype. Specifically, APOE ε4 was more associated with the long fibre bundle factor and APOE ε2 was more associated with temporal-frontal factor. By investigating heterogeneity and subtypes of AD through white matter impairment factors, our study could facilitate precision medicine.","Sui X
Rajapakse JC
Alzheimer's Disease Neuroimaging Initiative
","(PMID:30412925
 PMCID:PMC6226553)",Profiling heterogeneity of Alzheimer's disease using white-matter impairment factors.,https://europepmc.org/abstract/MED/30412925%0A
"Cell⁻substrate interaction plays an important role in intracellular behavior and function. Adherent cell mechanics is directly regulated by the substrate mechanics. However, previous studies on the effect of substrate mechanics only focused on the stiffness relation between the substrate and the cells, and how the substrate stiffness affects the time-scale and length-scale of the cell mechanics has not yet been studied. The absence of this information directly limits the in-depth understanding of the cellular mechanotransduction process. In this study, the effect of substrate mechanics on the nonlinear biomechanical behavior of living cells was investigated using indentation-based atomic force microscopy. The mechanical properties and their nonlinearities of the cells cultured on four substrates with distinct mechanical properties were thoroughly investigated. Furthermore, the actin filament (F-actin) cytoskeleton of the cells was fluorescently stained to investigate the adaptation of F-actin cytoskeleton structure to the substrate mechanics. It was found that living cells sense and adapt to substrate mechanics: the cellular Young's modulus, shear modulus, apparent viscosity, and their nonlinearities (mechanical property vs. measurement depth relation) were adapted to the substrates' nonlinear mechanics. Moreover, the positive correlation between the cellular poroelasticity and the indentation remained the same regardless of the substrate stiffness nonlinearity, but was indeed more pronounced for the cells seeded on the softer substrates. Comparison of the F-actin cytoskeleton morphology confirmed that the substrate affects the cell mechanics by regulating the intracellular structure.","Mollaeian K
Liu Y
Bi S
Wang Y
Ren J
Lu M
","(PMID:30400365
)",Nonlinear Cellular Mechanical Behavior Adaptation to Substrate Mechanics Identified by Atomic Force Microscope.,https://europepmc.org/abstract/MED/30400365%0A
"Efficient and accurate detection of cancer cells (from normal cells) is of great importance in cancer diagnosis and prognosis. In this work, we design a new type of polymeric substrate containing nanoparticles for detecting cancers by the dissipative particle dynamics (DPD) simulation. It is found that the cancer cells and the normal cells can be indeed distinguished since the uptake number of nanoparticles from the substrate is different. The competition between the nanoparticle-cell specific interaction and nanoparticle-polymer non-specific interaction is the main factor for different uptake behaviors. Moreover, the dynamics of the nanoparticle diffusion in the polymer layer also plays an important role in the detection. To improve the detection accuracy, we further investigate the effect of the polymer type and density as well as the ligand type on the detection, and find that there may exist an optimal parameter to maximize the difference between cancer cells and normal cells. The present study may provide useful insights into the design of functionalized substrate-based nanodevices in biomedicine.","Huang LY
Yu YS
Lu X
Ding HM
Ma YQ
","(PMID:30376020
)",Designing a nanoparticle-containing polymeric substrate for detecting cancer cells by computer simulations.,https://europepmc.org/abstract/MED/30376020%0A
"Protein Function Prediction from Protein-Protein Interaction Network (PPIN) and physico-chemical features using the Gene Ontology (GO) classification are indeed very useful for assigning biological or biochemical functions to a protein. They also lead to the identification of those significant proteins which are responsible for the generation of various diseases whose drugs are still yet to be discovered. So, the prediction of GO functional terms from PPIN and sequence is an important field of study. In this work, we have proposed a methodology, Multi Label Protein Function Prediction (ML_PFP) which is based on Neighborhood analysis empowered with physico-chemical features of constituent amino acids to predict the functional group of unannotated protein. A protein does not perform functions in isolation rather it performs functions in a group by interacting with others. So a protein is involved in many functions or, in other words, may be associated with multiple functional groups or labels or GO terms. Though functional group of other known interacting partner protein and its physico-chemical features provide useful information, assignment of multiple labels to unannotated protein is a very challenging task. Here, we have taken Homo sapiens or Human PPIN as well as Saccharomyces cerevisiae or yeast PPIN along with their GO terms to predict functional groups or GO terms of unannotated proteins. This work has become very challenging as both Human and Yeast protein dataset are voluminous and complex in nature and multi-label functional groups assignment has also added a new dimension to this challenge. Our algorithm has been observed to achieve a better performance in Cellular Function, Molecular Function and Biological Process of both yeast and human network when compared with the other existing state-of-the-art methodologies which will be discussed in detail in the results section.","Saha S
Prasad A
Chatterjee P
Basu S
Nasipuri M
","(PMID:30400756
)",Protein function prediction from protein-protein interaction network using gene ontology based neighborhood analysis and physico-chemical features.,https://europepmc.org/abstract/MED/30400756%0A
"Feature extraction and classification are considered to be the major tasks in image processing applications. This paper proposes a novel method to extract the features of a color image for classification. The proposed method, Dominant Local Texture-Color Patterns (DLTCP) is based on the Dominant Texture and Dominant Color channels in a RGB color space. The dominant texture pattern represents a channel among RGB with maximum variations in the texture and the dominant color pattern represents the color channel with the maximum pixel intensity. The combination of channels with dominant texture pattern and dominant color pattern is assigned a unique value which is used to extract the features of an image. The proposed texture-color features is tested for rotational, illumination and scale invariance property using the color images taken from Outex and Vistex databases. It is experimentally shown that the proposed method achieves the highest accuracy in classification using K-Nearest Neighbor (KNN) classifier under various challenges.","Kavitha JC
Suruliandi A
","(PMID:30280254
)",Feature Extraction Using Dominant Local Texture-Color Patterns (DLTCP) and Classification of Color Images.,https://europepmc.org/abstract/MED/30280254%0A
"BACKGROUND: This study aimed to evaluate a new computational histology prediction system based on colorectal polyp textural surface patterns using high definition white light images. METHODS: Textural elements (textons) were characterized according to their contrast with respect to the surface, shape, and number of bifurcations, assuming that dysplastic polyps are associated with highly contrasted, large tubular patterns with some degree of bifurcation. Computer-aided diagnosis (CAD) was compared with pathological diagnosis and the diagnosis made by endoscopists using Kudo and Narrow-Band Imaging International Colorectal Endoscopic classifications. RESULTS: Images of 225 polyps were evaluated (142 dysplastic and 83 nondysplastic). The CAD system correctly classified 205 polyps (91.1 %): 131/142 dysplastic (92.3 %) and 74/83 (89.2 %) nondysplastic. For the subgroup of 100 diminutive polyps (≤ 5 mm), CAD correctly classified 87 polyps (87.0 %): 43/50 (86.0 %) dysplastic and 44/50 (88.0 %) nondysplastic. There were no statistically significant differences in polyp histology prediction between the CAD system and endoscopist assessment. CONCLUSION: A computer vision system based on the characterization of the polyp surface in white light accurately predicted colorectal polyp histology.","Sánchez-Montes C
Sánchez FJ
Bernal J
Córdova H
López-Cerón M
Cuatrecasas M
Rodríguez de Miguel C
García-Rodríguez A
Garcés-Durán R
Pellisé M
Llach J
Fernández-Esparrach G
","(PMID:30360010
)",Computer-aided prediction of polyp histology on white light colonoscopy using surface pattern analysis.,https://europepmc.org/abstract/MED/30360010%0A
"BACKGROUND:Substance misuse, including problematic drug and alcohol use, are significant issues in society that can have multiple detrimental effects. Many people access support for their substance misuse during prison sentences, due to the associations between substance misuse and offending, and the high proportion of the prison population who have drug and alcohol issues. Breaking Free Online Health and Justice is a computer-assisted therapy program that has been developed to support substance-involved offenders to address their substance misuse and associated offending within prison settings. METHODS:This will be a parallel-group randomized controlled trial of 4-week Breaking Free Online Health and Justice program as an adjunct to standard treatment for substance misuse, in comparison to standard treatment only, in a male Category D open prison. Interventional and control groups will be compared in terms of the changes in their scores on multiple measures from baseline to post-treatment assessment at 4-weeks, and then 3- and 6-months follow-up. Participants will be adult male offenders serving sentences in prison in England who have demonstrable difficulties with drugs and/or alcohol for at least the past 12-months. The primary outcome measure will be self-reported substance misuse, with secondary outcomes being standardized psychometric assessments of substance dependence, mental health, biopsychosocial functioning, quality of life and post-release offending. Other secondary measures will include frequency of completion of specific intervention strategies in the program. DISCUSSION:This study will examine whether Breaking Free Online Health and Justice as an adjunct to standard substance misuse interventions in prisons, improves outcomes for substance-involved offenders receiving interventions in custodial settings. Findings from the study will be used to inform further developments of the program and potential improvements to custodial treatment. TRIALS REGISTRATION:ISRCTN09846981 .","Elison-Davies S
Davies G
Ward J
Dugdale S
Weston S
Jones A
Brides M
Weekes J
","(PMID:30392125
)",Protocol for a randomized controlled trial of the Breaking Free Online Health and Justice program for substance misuse in prison settings.,https://europepmc.org/abstract/MED/30392125%0A
"In online health expert question-answering (HQA) services, it is significant to automatically determine the quality of the answers. There are two prominent challenges in this task. First, the answers are usually written in short text, which makes it difficult to absorb the text semantic information. Second, it usually lacks sufficient labeled data but contains a huge amount of unlabeled data. To tackle these challenges, we propose a novel deep co-training framework based on factorization machines (FM) and deep textual views to intelligently and automatically identify the quality of HQA systems. More specifically, we exploit additional domain-specific semantic information from domain-specific word embeddings to expand the semantic space of short text and apply FM to excavate the non-independent interaction relationships among diverse features within individual views for improving the performance of the base classifier via co-training. Our learned deep textual views, the convolutional neural networks (CNN) view which focuses on extracting local features using convolution filters to locally model short text and the dependency-sensitive convolutional neural networks (DSCNN) view which focuses on capturing long-distance dependency information within the text to globally model short text, can then overcome the challenge of feature sparseness in the short text answers from the doctors. The developed co-training framework can effectively mine the highly non-linear semantic information embedded in the unlabeled data and expose the highly non-linear relationships between different views, which minimizes the labeling effort. Finally, we conduct extensive empirical evaluations and demonstrate that our proposed method can significantly improve the predictive performance of the answer quality in the context of HQA services.","Zhang Z
Hu Z
Yang H
Zhu R
Zuo D
","(PMID:30240803
)",Factorization machines and deep views-based co-training for improving answer quality prediction in online health expert question-answering services.,https://europepmc.org/abstract/MED/30240803%0A
"The aim of this work was to investigate of biocompatibility of polymeric implants modified with silver nanoparticles (AgNPs). Middle ear prostheses (otoimplants) made of the (poly)acrylonitrile butadiene styrene (ABS) and ABS modified with silver nanoparticles were prepared through extrusion and injection moulding process. The obtained prostheses were characterized by SEM-EDX, micro-CT and mechanical tests, confirming their proper shape, good AgNPs homogenization and mechanical parameters stability. The biocompatibility of the implants was evaluated in vivo on rats, after 4, 12, 24 and 48 weeks of implantation. The tissue-healing process and cytotoxicity of the implants were evaluated on the basis of microscopic observations of the materials morphology after histochemical staining with cytochrome c oxidase (OCC) and acid phosphatase (AP), as well as via micro-tomography (ex vivo). The in vivo studies confirmed biocompatibility of the implants in the surrounding tissue environment. Both the pure ABS and nanosilver-modified ABS implants exhibited a distinct decrease in the area of granulation tissue which was replaced with the regenerating muscle tissue. Moreover, a slightly smaller area of granulation tissue was observed in the surroundings of the silver-doped prosthesis than in the case of pure ABS prosthesis. The kinetics of silver ions releasing from implants was investigated by ICP-MS spectrometry. The measurement confirmed that concentration of the silver ions increased within the implant's immersion period. Our results showed that middle ear implant with the nanoscale modification is biocompatible and might be used in ossicular reconstruction.","Ziąbka M
Menaszek E
Tarasiuk J
Wroński S
","(PMID:30262741
 PMCID:PMC6215221)",Biocompatible Nanocomposite Implant with Silver Nanoparticles for Otology-In Vivo Evaluation.,https://europepmc.org/abstract/MED/30262741%0A
"Brain-computer interfaces (BCIs) can be used to induce neural plasticity in the human nervous system by pairing motor cortical activity with relevant afferent feedback, which can be used in neurorehabilitation. The aim of this study was to identify the optimal type or combination of afferent feedback modalities to increase cortical excitability in a BCI training intervention. In three experimental sessions, 12 healthy participants imagined a dorsiflexion that was decoded by a BCI which activated relevant afferent feedback: (1) electrical nerve stimulation (ES) (peroneal nerve-innervating tibialis anterior), (2) passive movement (PM) of the ankle joint, or (3) combined electrical stimulation and passive movement (Comb). The cortical excitability was assessed with transcranial magnetic stimulation determining motor evoked potentials (MEPs) in tibialis anterior before, immediately after and 30 min after the BCI training. Linear mixed regression models were used to assess the changes in MEPs. The three interventions led to a significant (p < 0.05) increase in MEP amplitudes immediately and 30 min after the training. The effect sizes of Comb paradigm were larger than ES and PM, although, these differences were not statistically significant (p > 0.05). These results indicate that the timing of movement imagery and afferent feedback is the main determinant of induced cortical plasticity whereas the specific type of feedback has a moderate impact. These findings can be important for the translation of such a BCI protocol to the clinical practice where by combining the BCI with the already available equipment cortical plasticity can be effectively induced. The findings in the current study need to be validated in stroke populations.","Jochumsen M
Cremoux S
Robinault L
Lauber J
Arceo JC
Navid MS
Nedergaard RW
Rashid U
Haavik H
Niazi IK
","(PMID:30400325
)",Investigation of Optimal Afferent Feedback Modality for Inducing Neural Plasticity with A Self-Paced Brain-Computer Interface.,https://europepmc.org/abstract/MED/30400325%0A
No abstract provided.,"Servick K
","(PMID:30237335
)",Brain scientists dive into deep neural networks.,https://europepmc.org/abstract/MED/30237335%0A
"Airtime fairness, or time-based fairness, has been well recognized as a method to solve WiFi performance anomalies and provide a balance between fairness and spectrum efficiency in multi-rate wireless networks. However, the definition of airtime is vague and simplistic. In this paper, it is demonstrated that current airtime fair scheduling results in unfairness in reality because overheads are neglected or unfairly counted. We introduce a notion of responsible airtime, which covers not only the data transmission time, but also all overheads, even a TCP ACK segment in TCP traffic. An approach based on responsible airtime can provide true time-based fairness, but responsible airtime is too complicated to directly handle. A practical method is thus introduced for evaluating responsible airtime fairness indirectly via throughput measurement. The key element, throughput fair share, of a node, is based on the baseline property in time-based fairness. For each node, an achieving ratio of actual throughput to the throughput fair share is determined, and a new fairness index considering deficiency as well as equity is applied. To validate the feasibility of responsible airtime fairness, we have developed a simple responsible airtime fair scheduler in access points for download traffic. Extensive simulation experiments are conducted in various network and traffic environments using the ns3 simulator. The results show that true time-based fairness is achievable in practice.","Yu SI
Park CY
","(PMID:30373299
)",A Responsible Airtime Approach for True Time-Based Fairness in Multi-Rate WiFi Networks.,https://europepmc.org/abstract/MED/30373299%0A
"Experiments were done to investigate in situ colonization of pine wood blocks by marine wood borers at the mouth of a small mountain river in the foothills of the Eastern Pyrenees. Standardized blocks were recovered after remaining underwater for increasingly long durations, until the available resource was exhausted by the shipworms assemblage that developed. Computer-aided tomography (CT) was used for visualizing and quantifying biogenic structures into the wooden blocks. The biodiversity survey of the wood pieces colonized indicated that up to three species of shipworms shared the resource at the same time. The specific wood consumption rate of Nototeredo norvagica was estimated 185 mm3 ind−1 day−1. The quantification of voids created by shipworm crowding indicated that total tunnelling represents, on average, 60% of the initial volume of a wood block, revising upward earlier estimates of wood destruction by 28%. CT analysis provides the quantitative measurements necessary to parameterize individual-based growth models linking wood consumption with the species diversity of shipworm assemblages.","Charles F
François Lantoine
Jean-Marc Guarini
Jennifer Coston-Guarini
","(AGR:IND606067264
)",It’s what’s inside that counts: computer-aided tomography for evaluating the rate and extent of wood consumption by shipworms,https://europepmc.org/abstract/AGR/IND606067264%0A
No abstract provided.,"Wolf SM
Evans BJ
","(PMID:30309935
)",Return of results and data to study participants.,https://europepmc.org/abstract/MED/30309935%0A
"In recent years, natural stimuli such as audio excerpts or video streams have received increasing attention in neuroimaging studies. Compared with conventional simple, idealized and repeated artificial stimuli, natural stimuli contain more unrepeated, dynamic and complex information that are more close to real-life. However, there is no direct correspondence between the stimuli and any sensory or cognitive functions of the brain, which makes it difficult to apply traditional hypothesis-driven analysis methods (e.g., the general linear model (GLM)). Moreover, traditional data-driven methods (e.g., independent component analysis (ICA)) lack quantitative modeling of stimuli, which may limit the power of analysis models. In this paper, we propose a sparse representation based decoding framework to explore the neural correlates between the computational audio features and functional brain activities under free listening conditions. First, we adopt a biologically-plausible auditory saliency feature to quantitatively model the audio excerpts and meanwhile develop sparse representation/dictionary learning method to learn an over-complete dictionary basis of brain activity patterns. Then, we reconstruct the auditory saliency features from the learned fMRI-derived dictionaries. After that, a group-wise analysis procedure is conducted to identify the associated brain regions and networks. Experiments showed that the auditory saliency feature can be well decoded from brain activity patterns by our methods, and the identified brain regions and networks are consistent and meaningful. At last, our method is evaluated and compared with ICA method and experimental results demonstrated the superiority of our methods.","Zhao S
Han J
Jiang X
Huang H
Liu H
Lv J
Guo L
Liu T
","(PMID:29488069
)",Decoding Auditory Saliency from Brain Activity Patterns during Free Listening to Naturalistic Audio Excerpts.,https://europepmc.org/abstract/MED/29488069%0A
"In this study, we evaluated the convolutional neural network (CNN) method for modeling V1 neurons of awake macaque monkeys in response to a large set of complex pattern stimuli. CNN models outperformed all the other baseline models, such as Gabor-based standard models for V1 cells and various variants of generalized linear models. We then systematically dissected different components of the CNN and found two key factors that made CNNs outperform other models: thresholding nonlinearity and convolution. In addition, we fitted our data using a pre-trained deep CNN via transfer learning. The deep CNN's higher layers, which encode more complex patterns, outperformed lower ones, and this result was consistent with our earlier work on the complexity of V1 neural code. Our study systematically evaluates the relative merits of different CNN components in the context of V1 neuron modeling.","Zhang Y
Lee TS
Li M
Liu F
Tang S
","(PMID:29869761
)",Convolutional neural network models of V1 responses to complex patterns.,https://europepmc.org/abstract/MED/29869761%0A
No abstract provided.,"Yang L
","(PMID:30237344
)",Fighting chaos with chaos in lasers.,https://europepmc.org/abstract/MED/30237344%0A
"The process of learning candidate causal relationships involving diseases and symptoms from electronic medical records (EMRs) is the first step towards learning models that perform diagnostic inference directly from real healthcare data. However, the existing diagnostic inference systems rely on knowledge bases such as ontology that are manually compiled through a labour-intensive process or automatically derived using simple pairwise statistics. We explore CBN, a Clinical Bayesian Network construction for medical ontology probabilistic inference, to learn high-quality Bayesian topology and complete ontology directly from EMRs. Specifically, we first extract medical entity relationships from over 10,000 deidentified patient records and adopt the odds ratio (OR value) calculation and the K2 greedy algorithm to automatically construct a Bayesian topology. Then, Bayesian estimation is used for the probability distribution. Finally, we employ a Bayesian network to complete the causal relationship and probability distribution of ontology to enhance the ontology inference capability. By evaluating the learned topology versus the expert opinions of physicians and entropy calculations and by calculating the ontology-based diagnosis classification, our study demonstrates that the direct and automated construction of a high-quality health topology and ontology from medical records is feasible. Our results are reproducible, and we will release the source code and CN-Stroke knowledge graph of this work after publication1.","Shen Y
Zhang L
Zhang J
Yang M
Tang B
Li Y
Lei K
","(PMID:30399432
)",CBN: Constructing a Clinical Bayesian Network based on Data from the Electronic Medical Record.,https://europepmc.org/abstract/MED/30399432%0A
No abstract provided.,"Klæbo Vonstad E
Vereijken B
Nilsen JH
Bach K
","(PMID:30098897
)",P 119 - Machine learning as a tool to ensure movement quality in balance training exergames.,https://europepmc.org/abstract/MED/30098897%0A
"There are still no good quantitative methods to be applied in psychiatric diagnosis. The interview is still the main and most important tool in the psychiatrist work. This paper presents the results of electroencephalographic research with the subjects of a group of 30 patients with psychiatric disorders compared to the control group of healthy volunteers. All subjects were solving working memory task. The digit-span working memory task test was chosen as one of the most popular tasks given to subjects with cognitive dysfunctions, especially for the patients with panic disorders, depression (including the depressive phase of bipolar disorder), phobias, and schizophrenia. Having such cohort of patients some results for the subjects with insomnia and Asperger syndrome are also presented. The cortical activity of their brains was registered by the dense array EEG amplifier. Source localization using the photogrammetry station and the sLORETA algorithm was then performed in five EEG frequency bands. The most active Brodmann Areas are indicated. Methodology for mapping the brain and research protocol are presented. The first results indicate that the presented technique can be useful in finding psychiatric disorder neurophysiological biomarkers. The first attempts were made to associate hyperactivity of selected Brodmann Areas with particular disorders.","Wojcik GM
Masiak J
Kawiak A
Kwasniewicz L
Schneider P
Polak N
Gajos-Balinska A
","(PMID:30405386
 PMCID:PMC6207640)",Mapping the Human Brain in Frequency Band Analysis of Brain Cortex Electroencephalographic Activity for Selected Psychiatric Disorders.,https://europepmc.org/abstract/MED/30405386%0A
"The identification and reconstruction of axonal pathways in the living brain or ""ex-vivo"" is promising a revolution in connectivity studies bridging the gap from animal to human neuroanatomy with extensions to brain structural-functional correlates. Unfortunately, the methods suffer from juvenile drawbacks. In this perspective paper we mention several computational and developmental principles, which might stimulate a new generation of algorithms and a discussion bridging the neuroimaging and neuroanatomy communities.","Innocenti GM
Dyrby TB
Girard G
St-Onge E
Thiran JP
Daducci A
Descoteaux M
","(PMID:30264235
)",Topological principles and developmental algorithms might refine diffusion tractography.,https://europepmc.org/abstract/MED/30264235%0A
"Protein essentiality is fundamental to comprehend the function and evolution of genes. The prediction of protein essentiality is pivotal in identifying disease genes and potential drug targets. Since the experimental methods need many investments in time and funds, it is of great value to predict protein essentiality with high accuracy using computational methods. In this study, we present a novel feature selection named Elite Search mechanism-based Flower Pollination Algorithm (ESFPA) to determine protein essentiality. Unlike other protein essentiality prediction methods, ESFPA uses an improved swarm intelligence⁻based algorithm for feature selection and selects optimal features for protein essentiality prediction. The first step is to collect numerous features with the highly predictive characteristics of essentiality. The second step is to develop a feature selection strategy based on a swarm intelligence algorithm to obtain the optimal feature subset. Furthermore, an elite search mechanism is adopted to further improve the quality of feature subset. Subsequently a hybrid classifier is applied to evaluate the essentiality for each protein. Finally, the experimental results show that our method is competitive to some well-known feature selection methods. The proposed method aims to provide a new perspective for protein essentiality determination.","Fang M
Lei X
Cheng S
Shi Y
Wu FX
","(PMID:29958434
 PMCID:PMC6100311)",Feature Selection via Swarm Intelligence for Determining Protein Essentiality.,https://europepmc.org/abstract/MED/29958434%0A
"Manifold based feature extraction has been proved to be an effective technique in dealing with the unsupervised classification tasks. However, most of the existing works cannot guarantee the global optimum of the learned projection, and they are sensitive to different noises. In addition, many methods cannot catch the discriminative information as much as possible since they only exploit the local structure of data while ignoring the global structure. To address the above problems, this paper proposes a novel graph based feature extraction method named low-rank and sparsity preserving embedding (LRSPE) for unsupervised learning. LRSPE attempts to simultaneously learn the graph and projection in a framework so that the global optimal projection can be obtained. Moreover, LRSPE exploits both global and local information of data for projection learning by imposing the low-rank and sparse constraints on the graph, which promotes the method to obtain a better performance. Importantly, LRSPE is more robust to noise by imposing the l2,1 sparsity norm on the reconstruction errors. Experimental results on both clean and noisy datasets prove that the proposed method can significantly improve classification accuracy and it is robust to different noises in comparison with the state-of-the-art methods.","Zhan S
Wu J
Han N
Wen J
Fang X
","(PMID:30408694
)",Unsupervised feature extraction by low-rank and sparsity preserving embedding.,https://europepmc.org/abstract/MED/30408694%0A
"Protein phosphorylation is one of the most fundamental types of post-translational modifications and it plays a vital role in various cellular processes of eukaryotes. Among three types of phosphorylation i.e. serine, threonine and tyrosine phosphorylation, tyrosine phosphorylation is one of the most frequent and it is important for mediation of signal transduction in eukaryotic cells. Site-directed mutagenesis and mass spectrometry help in the experimental determination of cellular signalling networks, however, these techniques are costly, time taking and labour associated. Thus, efficient and accurate prediction of these sites through computational approaches can be beneficial to reduce cost and time. Here, we present a more accurate and efficient sequence-based computational method for prediction of phosphotyrosine (PhosY) sites by incorporation of statistical moments into PseAAC. The study is carried out based on Chou's 5-step rule, and various position-composition relative features are used to train a neural network for the prediction purpose. Validation of results through Jackknife testing is performed to validate the results of the proposed prediction method. Overall accuracy validated through Jackknife testing was calculated 93.9%. These results suggest that the proposed prediction model can play a fundamental role in the prediction of PhosY sites in an accurate and efficient way.","Khan YD
Rasool N
Hussain W
Khan SA
Chou KC
","(PMID:30311130
)",iPhosY-PseAAC: identify phosphotyrosine sites by incorporating sequence statistical moments into PseAAC.,https://europepmc.org/abstract/MED/30311130%0A
"Hyaline cartilage undergoes many substantial age-related physiochemical and biomechanical changes that reduce its ability to overcome the effects of mechanical stress and injury. In quest of therapeutic options, magnetic stimulation and electrical stimulation have been proposed for improving tissue engineering approaches for the repair of articular cartilage. The aim of the current study is to summarize <i>in silico</i> investigations involving induced electrical properties of cartilage tissue due to various biophysical stimuli along their respective mathematical descriptions. Based on these, a preliminary numerical study involving electromechanical transduction in bovine cartilage tissue has been carried out using an open source finite element computational software. The simulation results have been compared to experimental results from the literature. Our present study serves as a basis for further <i>in silico</i> studies to better understand the behavior of hyaline cartilage tissue due to electrical stimulation and to find an optimal stimulation protocol for the cartilage regeneration. Moreover, it provides an overview of the basic models along with mathematical description and scope for future research regarding electrical behavior of the cartilage tissue using open source software.","Farooqi AR
Bader R
van Rienen U
","(PMID:30351244
)",Numerical study on electromechanics in cartilage tissue with respect to its electrical properties.,https://europepmc.org/abstract/MED/30351244%0A
"The future of Internet of Things (IoT) envisions billions of sensors integrated with the physical environment. At the same time, recharging and replacing batteries on this infrastructure could result not only in high maintenance costs, but also large amounts of toxic waste due to the need to dispose of old batteries. Recently, battery-free sensor platforms have been developed that use supercapacitors as energy storage, promising maintenance-free and perpetual sensor operation. While prior work focused on supercapacitor characterization, modelling and supercapacitor-aware scheduling, the impact of mobility on capacitor charging and overall sensor application performance has been largely ignored. We show that supercapacitor size is critical for mobile system performance and that selecting an optimal value is not trivial: small capacitors charge quickly and enable the node to operate in low energy environments, but cannot support intensive tasks such as communication or reprogramming; increasing the capacitor size, on the other hand, enables the support for energy-intensive tasks, but may prevent the node from booting at all if the node navigates in a low energy area. The paper investigates this problem and proposes a hybrid storage solution that uses an adaptive learning algorithm to predict the amount of available ambient energy and dynamically switch between two capacitors depending on the environment. The evaluation based on extensive simulations and prototype measurements showed up to 40% and 80% improvement compared to a fixed-capacitor approach in terms of the amount of harvested energy and sensor coverage.","Munir B
Dyo V
","(PMID:30360501
)",On the Impact of Mobility on Battery-Less RF Energy Harvesting System Performance.,https://europepmc.org/abstract/MED/30360501%0A
"Photo identification is an important tool for estimating abundance and monitoring population trends over time. However, manually matching photographs to known individuals is time-consuming. Motivated by recent developments in image recognition, we hosted a data science challenge on the crowdsourcing platform Kaggle to automate the identification of endangered North Atlantic right whales (Eubalaena glacialis). The winning solution automatically identified individual whales with 87% accuracy with a series of convolutional neural networks to identify the region of interest on an image, rotate, crop, and create standardized photographs of uniform size and orientation and then identify the correct individual whale from these passport-like photographs. Recent advances in deep learning coupled with this fully automated workflow have yielded impressive results and have the potential to revolutionize traditional methods for the collection of data on the abundance and distribution of wild populations. Presenting these results to a broad audience should further bridge the gap between the data science and conservation science communities.","Bogucki R
Cygan M
Khan CB
Klimek M
Milczek JK
Mucha M
","(PMID:30259577
)",Applying deep learning to right whale photo identification.,https://europepmc.org/abstract/MED/30259577%0A
"BACKGROUND:Electroencephalography (EEG) experiments often require several computers to ensure accurate stimulus presentation and data collection. However, this requirement can make it more difficult to perform such experiments in mobile settings within, or outside, the laboratory. NEW METHOD:Computer miniaturisation and increasing processing power allow for EEG experiments to become more portable. Our goal is to show that a Latte Panda, a small Windows 10 computer, can be used to accurately collect EEG data in a similar manner to a laptop. Using a stationary bike, we also suggest that the Latte Panda will allow for more portable EEG experiments. RESULTS:Significant and reliable MMN and P3 responses, event-related potentials (ERPs) typically associated with auditory oddball tasks, were observed and were consistent when using either the laptop or Latte Panda for EEG data collection. Similar MMN and P3 ERPs were also measured in the sitting and stationary biking conditions while using a Latte Panda for data collection. COMPARISON WITH EXISTING METHOD:Data recorded by the Latte Panda computer produced comparable and equally reliable results to the laptop. As well, similar ERPs during sitting and biking would suggest that EEG experiments can be conducted in more mobile situations despite the increased noise and artifacts associated with muscle movement. CONCLUSIONS:Our results show that the Latte Panda is a low-cost, more portable alternative to a laptop computer for recording EEG data. Such a device will further allow for more portable and mobile EEG experimentation in a wider variety of environments.","Kuziek JWP
Redman EX
Splinter GD
Mathewson KE
","(PMID:30031010
)",Increasing the mobility of EEG data collection using a Latte Panda computer.,https://europepmc.org/abstract/MED/30031010%0A
"Environmental research requires understanding nonlinear ecological dynamics that interact across multiple spatial and temporal scales. The analysis of long-term and high-frequency sensor data combined with simulation modeling enables interpretation of complex ecological phenomena, and the computational skills needed to conduct these analyses are increasingly being integrated into graduate student training programs in ecology. Despite its importance, however, computational literacy-that is, the ability to harness the power of computer technologies to accomplish tasks-is rarely taught in undergraduate ecology classrooms, representing a major gap in training students to tackle complex environmental challenges. Through our experience developing undergraduate curricula in long-term and high-frequency data analysis and simulation modeling for two environmental science pedagogical initiatives, Project EDDIE (Environmental Data-Driven Inquiry and Exploration) and Macrosystems EDDIE, we have found that students often feel intimidated by computational tasks, which is compounded by the lack of familiarity with software (e.g., R) and the steep learning curves associated with script-based analytical tools. The use of prepackaged, flexible modules that introduce programming as a mechanism to explore environmental datasets and teach inquiry-based ecology, such as those developed for Project EDDIE and Macrosystems EDDIE, can significantly increase students' experience and comfort levels with advanced computational tools. These types of modules in turn provide great potential for empowering students with the computational literacy needed to ask ecological questions and test hypotheses on their own. As continental-scale sensor observatory networks rapidly expand the availability of long-term and high-frequency data, students with the skills to manipulate, visualize, and interpret such data will be well-prepared for diverse careers in data science, and will help advance the future of open, reproducible science in ecology.","Farrell KJ
Carey CC
","(PMID:30250659
 PMCID:PMC6144986)","Power, pitfalls, and potential for integrating computational literacy into undergraduate ecology courses.",https://europepmc.org/abstract/MED/30250659%0A
"PURPOSE:With the recent introduction of fully assisting scanner technologies by Siemens Healthineers (Erlangen, Germany), a patient surface model was introduced to the diagnostic imaging device market. Such a patient representation can be used to automate and accelerate the clinical imaging workflow, manage patient dose, and provide navigation assistance for computed tomography diagnostic imaging. In addition to diagnostic imaging, a patient surface model has also tremendous potential to simplify interventional imaging. For example, if the anatomy of a patient was known, a robotic angiography system could be automatically positioned such that the organ of interest is positioned in the system's iso-center offering a good and flexible view on the underlying patient anatomy quickly and without any additional X-ray dose. METHOD:To enable such functionality in a clinical context with sufficiently high accuracy, we present an extension of our previous patient surface model by adding internal anatomical landmarks associated with certain (main) bones of the human skeleton, in particular the spine. We also investigate different approaches to positioning of these landmarks employing CT datasets with annotated internal landmarks as training data. The general pipeline of our proposed method comprises the following steps: First, we train an active shape model using an existing avatar database and segmented CT surfaces. This stage also includes a gravity correction procedure, which accounts for shape changes due to the fact that the avatar models were obtained in standing position, while the CT data were acquired with patients in supine position. Second, we match the gravity-corrected avatar patient surface models to surfaces segmented from the CT datasets. In the last step, we derive the spatial relationships between the patient surface model and internal anatomical landmarks. RESULT:We trained and evaluated our method using cross-validation using 20 datasets, each containing 50 internal landmarks. We further compared the performance of four different generalized linear models' setups to describe the positioning of the internal landmarks relative to the patient surface. The best mean estimation error over all the landmarks was achieved using lasso regression with a mean error of [Formula: see text]. CONCLUSION:Considering that interventional X-ray imaging systems can have detectors covering an area of about [Formula: see text] ([Formula: see text]) at iso-center, this accuracy is sufficient to facilitate automatic positioning of the X-ray system.","Zhong X
Strobel N
Birkhold A
Kowarschik M
Fahrig R
Maier A
","(PMID:30317437
)",A machine learning pipeline for internal anatomical landmark embedding based on a patient surface model.,https://europepmc.org/abstract/MED/30317437%0A
"The effects of eccentric exercises on clinical outcomes and central pain mechanisms are unclear in neck/shoulder pain (NSP). The aims were to (1) evaluate the clinical impact of unilateral eccentric training in female computer users with chronic NSP, (2) compare pressure pain sensitivity, temporal summation of pain (TSP), and conditioned pain modulation (CPM) in female office workers with and without NSP, and (3) assess sensitization and central pain responses after training.In part A, twenty females with NSP were compared with 20 controls. In part B, the NSP group underwent a 5-week upper trapezius eccentric training program. Participants reported their pain intensity, and completed the Neck Disability Index, and the Disabilities of the Arm, Shoulder and Hand questionnaire. Pressure pain thresholds (PPTs) were assessed over the neck and forearm. Cuff algometry identified pain detection (PDT) and tolerance thresholds (PTT). TSP was evaluated by visual analogue scale pain scores during 10 repetitive cuff stimulations. CPM was calculated as the difference in PDT with and without a conditioning painful stimulus. Outcomes were measured at baseline and post-intervention. Pain intensities were collected at 3-month and 6-month follow-up.Pain and disability decreased post-intervention (P<0.05), and at follow-ups (P=0.002). The NSP group demonstrated reduced PTT (P≤0.02), but no differences in TSP (P=0.947) or CPM (P=0.059) compared with controls. After training, females with NSP improved CPM, PPTs, and PTT at the non-treated side (P<0.05).Eccentric training improved pain and disability, reduced sensitization and enhanced CPM efficiency in female computer users with NSP.","Heredia-Rizo AM
Petersen KK
Madeleine P
Arendt-Nielsen L
","(PMID:30222615
)",Clinical Outcomes and Central Pain Mechanisms are Improved after Upper Trapezius Eccentric Training in Female Computer Users with Chronic Neck/Shoulder Pain.,https://europepmc.org/abstract/MED/30222615%0A
[This corrects the article DOI: 10.1155/2018/4149103.].,"Li F
Wang C
Liu X
Peng Y
Jin S
","(PMID:30275821
 PMCID:PMC6157104)","Corrigendum to ""A Composite Model of Wound Segmentation Based on Traditional Methods and Deep Neural Networks"".",https://europepmc.org/abstract/MED/30275821%0A
"Precise simulators can replicate complete understanding of the models. In this survey, we focus on orthopedic simulators that are not only in replicating real-world models but also in educating with complete procedure: surgical, for instance. It covers 18 hip replacement, three-knee replacement, three facial surgeries, one spine surgery and six orthopedic psycho-motor skills training and assessment-based simulators. We also provide comparative studies and highlight current trends and possible challenges. We observed that orthopedic training methodologies have undergone a paradigm shift. This means that the simulators replace the use of sensitive hospital settings for training and skill acquisition. In brief, we address classified overview on existing orthopedic simulators: physical and Virtual Reality (VR)-based simulators. Key steps to develop computer-assisted, VR-based simulator are explored. Experts' opinion on the use of simulation technologies in the field of orthopedics is discussed.","Ruikar DD
Hegadi RS
Santosh KC
","(PMID:30073548
)",A Systematic Review on Orthopedic Simulators for Psycho-Motor Skill and Surgical Procedure Training.,https://europepmc.org/abstract/MED/30073548%0A
"The importance of incorporating Natural Language Processing(NLP) methods in clinical informatics research has been increasingly recognized over the past years, and has led to transformative advances. Typically, clinical NLP systems are developed and evaluated on word, sentence, or document level annotations that model specific attributes and features, such as document content (e.g., patient status, or report type), document section types (e.g., current medications, past medical history, or discharge summary), named entities and concepts (e.g., diagnoses, symptoms, or treatments) or semantic attributes (e.g., negation, severity, or temporality). From a clinical perspective, on the other hand, research studies are typically modelled and evaluated on a patient- or population-level, such as predicting how a patient group might respond to specific treatments or patient monitoring over time. While some NLP tasks consider predictions at the individual or group user level, these tasks still constitute a minority. Owing to the discrepancy between scientific objectives of each field, and because of differences in methodological evaluation priorities, there is no clear alignment between these evaluation approaches. Here we provide a broad summary and outline of the challenging issues involved in defining appropriate intrinsic and extrinsic evaluation methods for NLP research that is to be used for clinical outcomes research, and vice-versa. A particular focus is placed on mental health research, an area still relatively understudied by the clinical NLP research community, but where NLP methods are of notable relevance. Recent advances in clinical NLP method development have been significant, but we propose more emphasis needs to be placed on rigorous evaluation for the field to advance further. To enable this, we provide actionable suggestions, including a minimal protocol that could be used when reporting clinical NLP method development and its evaluation.","Velupillai S
Suominen H
Liakata M
Roberts A
Shah AD
Morley K
Osborn D
Hayes J
Stewart R
Downs J
Chapman W
Dutta R
","(PMID:30368002
)",Using Clinical Natural Language Processing for Health Outcomes Research: Overview and Actionable Suggestions for Future Advances.,https://europepmc.org/abstract/MED/30368002%0A
"Visionaries offer strong claims for the educational benefits of computer games, but there is a need to test those claims with rigorous scientific research and ground them in evidence-based theories of how people learn. Three genres of game research are (a) value-added research, which compares the learning outcomes of groups that learn academic material from playing a base version of a game to the outcomes of those playing the same game with one feature added; (b) cognitive consequences research, which compares improvements in cognitive skills of groups that play an off-the-shelf game to the skill improvements of those who engage in a control activity; and (c) media comparison research, which compares the learning outcomes of groups that learn academic material in a game to the outcomes of those who learn with conventional media. Value-added research suggests five promising features to include in educational computer games: modality, personalization, pretraining, coaching, and self-explanation. Cognitive consequences research suggests two promising approaches to cognitive training with computer games: using first-person shooter games to train perceptual attention skills and using spatial puzzle games to train two-dimensional mental rotation skills. Media comparison research suggests three promising areas where games may be more effective than conventional media: science, mathematics, and second-language learning. Future research is needed to pinpoint the cognitive, motivational, affective, and social processes that underlie learning with educational computer games. Expected final online publication date for the Annual Review of Psychology Volume 70 is January 4, 2019. Please see http://www.annualreviews.org/page/journal/pubdates for revised estimates.","Mayer RE
","(PMID:30231003
)",Computer Games in Education.,https://europepmc.org/abstract/MED/30231003%0A
No abstract provided.,"Arribas E
Ramirez-Vazquez R
Escobar I
","(PMID:30173116
)","Comment on ""Wi-Fi is an important threat to human health"".",https://europepmc.org/abstract/MED/30173116%0A
"The spectral properties of Fano resonance generated in multilayer dielectric gratings (MDGs) are reported and numerically investigated in this paper. We examine the MDG consisting of numerous identically alternative chalcogenide glass (As2S3) and silica (SiO2) multilayers with several grating widths inscribed through the structure, emphasizing quality (Q) and asymmetric (q) factors. Manipulation of Fano lineshape and its linear characteristics can be achieved by tailoring the layers' amount and grating widths so that the proposed structure can be applicable for several optical applications. Moreover, we demonstrate the switching/bistability behaviors of the MDG at Fano resonance which provide a significant switching intensity reduction compared to the established Lorentzian resonant structures.","Hoang TT
Ngo QM
Vu DL
Nguyen HPT
","(PMID:30401800
 PMCID:PMC6219597)",Controlling Fano resonances in multilayer dielectric gratings towards optical bistable devices.,https://europepmc.org/abstract/MED/30401800%0A
"As abundant and user-friendly as computer-aided drug design (CADD) software may seem, there is still a large underserved population of biomedical researchers around the world, particularly those with no computational training and limited research funding. To address this important need and help scientists overcome barriers that impede them from leveraging CADD in their drug discovery work, we have developed ezCADD, a web-based CADD modeling environment that manifests four simple design concepts: easy, quick, user-friendly, and 2D/3D visualization-enabled. In this paper, we describe the features of three fundamental applications that have been implemented in ezCADD: small-molecule docking, protein-protein docking, and binding pocket detection, and their applications in drug design against a pathogenic microbial enzyme as an example. To assess user experience and the effectiveness of our implementation, we introduced ezCADD to first-year pharmacy students as an active learning exercise in the Principles of Drug Action course. The web service robustly handled 95 simultaneous molecular docking jobs. Our survey data showed that among the 95 participating students, 97% completed the molecular docking experiment on their own at least partially without extensive training; 88% considered ezCADD easy and user-friendly; 99-100% agreed that ezCADD enhanced the understanding of drug-receptor structures and recognition; and the student experience in molecular modeling and visualization was significantly improved from zero to a higher level. The student feedback represents the baseline data of user experience from noncomputational researchers. It is demonstrated that in addition to supporting drug discovery research, ezCADD is also an effective tool for promoting science, technology, engineering, and mathematics (STEM) education. More advanced CADD applications are being developed and added to ezCADD, available at http://dxulab.org/software .","Tao A
Huang Y
Shinohara Y
Caylor ML
Pashikanti S
Xu D
","(PMID:30403855
)",ezCADD: A Rapid 2D/3D Visualization-Enabled Web Modeling Environment for Democratizing Computer-Aided Drug Design.,https://europepmc.org/abstract/MED/30403855%0A
"The DTI-based tractography, despite its restrictions, is the most widely utilized fiber tracking method in clinical practice. Its fidelity is strictly dependent on the precision and accuracy of the DTI measurement, which in turn is limited by the linearity of the diffusion sensitizing gradient. The influence of the gradient distortions on the differences between the real and measured orientation of fibers was investigated by computer simulations. In addition, the potential of the b-matrix Spatial Distribution in DTI (BSD-DTI) technique in correcting such kind of errors was demonstrated experimentally. The simulations revealed that the diffusion gradient inhomogeneity, if not corrected, leads to the erroneous indication of the fiber direction. The average and maximum deviations were about 1° and 15°, respectively. Remarkably, the deviation between the real and measured orientation of fibers is directionally dependent, what was confirmed in MRI measurement. The deviation errors can be effectively corrected by preceding the DTI measurement with the BSD-DTI calibration.","Borkowski K
Krzyżak AT
","(PMID:30195248
)",Analysis and correction of errors in DTI-based tractography due to diffusion gradient inhomogeneity.,https://europepmc.org/abstract/MED/30195248%0A
"Ultrasonic imaging is one of the most important techniques to help medical diagnosis. However, obtaining high quality images requires the acquisition, processing, and storage of a large amount of data. In this work, we evaluated a new ultrasound imaging technique based on plane wave and sparse arrays to increase the scan rate and reduce the amount of data amount to be stored. The performance of the proposed method was tested using simulated echo data (from Field II) and phantom data acquired using a Verasonics system equipped with a L11-4v linear array transducer. The tests were done using 128 elements for transmission and 128, 65, 44, and 23 elements sparsely distributed for reception. The simulated data were compared with images obtained with the Delay and Sum (DAS) method and the experimental data were compared with those acquired from Verasonics. The obtained results using the Full Width at Half Maximum (FWHM) criteria at -6 dB showed that the images generated by the proposed method were similar in terms of resolutions (axial and lateral) and contrast to the simulated and the Verasonics commercial ones, indicating that the sparse reception proposed method is suitable for ultrasound imaging.","Schiefler NT Jr
Maia JM
Schneider FK
Zimbico AJ
Assef AA
Costa ET
","(PMID:30373306
)",Generation and Analysis of Ultrasound Images Using Plane Wave and Sparse Arrays Techniques.,https://europepmc.org/abstract/MED/30373306%0A
"Palliation therapy for dysphagia using esophageal stents is the current treatment of choice for those patients with inoperable esophageal malignancies. However, the metallic and plastic stents currently used in the clinical setting may cause complications, such as tumor ingrowth and stent migration into the stomach. To effectively reduce/overcome these complications, we designed a tubular, flexible polymer stent with spirals. The parameters of the spirals were computationally optimized by using a finite element analysis. The designed polymer stents with optimized spirals were then printed by a 3D printing technique. 3D-printed tubular polymer stents without spirals served as controls. The self-expansion and anti-migration properties of the printed stent were characterized in an ex vivo normal porcine esophagus. The biodegradability test of the stent was performed in a neutral buffer and acidic gastric buffer. The cytotoxicity of the new stent was examined through the viability test of human esophagus epithelial cells. Results showed the self-expansion force of the 3D-printed polymer stent with spirals was higher than the stent without spirals. The anti-migration force of the 3D-printed stent with spirals was significantly higher than that of the stent without spirals. Furthermore, the stent with spirals significantly decreased the migration distance compared to the non-spiral 3D-printed polymer stent. Degradation study showed that the polymer materials started to degrade after six weeks and the compressive strength of the stent was not significantly decreased with time. In vitro cell viability results further indicated that the polymer stent does not have any cytotoxicity. Together, these results showed that the 3D-printed stent with spirals has potential applications in the treatment of inoperable esophageal malignancies. STATEMENT OF SIGNIFICANCE: In this study, we developed a new 3D-printed flexible tubular polymeric stent with spirals. The mechanical properties of the 3D-printed polymer stent are modulated by changing the ratios of PLA to TPU. The stent is flexible enough to be compressed in a clinically available stent delivery system, and can self-expand after it is released. The self-expansion force of the stent with spirals is higher than that of non-spiral stents. The spirals on the outside of the stent significantly increased the anti-migration force compared to non-spiral stents in an ex vivo normal pig esophagus. Together, the 3D-printed stent with spirals will bring promising potential in the treatment of inoperable esophagus malignancies or benign strictures.","Lin M
Firoozi N
Tsai CT
Wallace MB
Kang Y
","(PMID:30366130
)",3D-printed flexible polymer stents for potential applications in inoperable esophageal malignancies.,https://europepmc.org/abstract/MED/30366130%0A
"Emergency Room (ER) crowding is one of the more complex issues in the healthcare system worldwide. Crowding gives rise to long ER waiting times, patient dissatisfaction, and negative effects on a healthcare systems' performance. This paper focuses on the utilization of the Collective System Design (CSD) methodology to optimize the performance of an ER, which is of principal importance both from a life-threatening and an economic standpoint. The CSD technique is applied to detect areas of deficiency and to identify the functional requirements of the system to address those issues. The ER and system engineering specialists' team gathered data from the electronic medical center log and their system observation. The team determined the functional requirements and effective solutions, and implemented a continuous improvement plan to enhance ER performance. From a statistical standpoint, a significant decrease in the median of the door-to-doctor time measure (27 min vs 13 min) and a substantial improvement in the patients' level of satisfaction with the quality of health care (20th percentile vs 41th percentile) were observed after the implementation of the CSD methodology. The CSD methodology augments the implementation of lean tools by providing a language for defining the requirements and corresponding solutions for a system design. Using the CSD methodology, results in a significant increase in the ER's capacity to treat patients efficiently.","Cochran D
Swartz J
Elahi B
Smith J
","(PMID:30338399
)",Using the Collective System Design Methodology to Improve a Medical Center Emergency Room Performance.,https://europepmc.org/abstract/MED/30338399%0A
"The main goal of the study was to develop a model of the degree of surface porosity of a biomaterial intended for implants. The model was implemented using MATLAB. A computer simulation was carried out based on the developed model, which resulted in a two-dimensional image of the modelled surface. Then, an algorithm for computerised image analysis of the surface of the actual oxide bioceramic layer was developed, which enabled determining its degree of porosity. In order to obtain the confocal micrographs of a few areas of the biomaterial, measurements were performed using the LEXT OLS4000 confocal laser microscope. The image analysis was carried out using MountainsMap Premium and SPIP. The obtained results allowed determining the input parameters of the program, on the basis of which porous biomaterial surface images were generated. The last part of the study involved verification of the developed model. The modelling method was tested by comparing the obtained results with the experimental data obtained from the analysis of surface images of the test material.","Stach S
Kędzia O
Garczyk Ż
Wróbel Z
","(PMID:29775436
)",Modelling the degree of porosity of the ceramic surface intended for implants.,https://europepmc.org/abstract/MED/29775436%0A
"Decimal reduction time (D-value) based on the first-order survival kinetics model is not sufficient for reliable estimation of the bacterial survivors of inactivation treatment because the model does not consider inactivation curvature. However, even though doubt exists in the calculation of D-value, it is still widely used for risk assessment and sterilisation time estimation. This paper proposes an approach for estimating the time-to-inactivation and death probability of bacterial population that considers individual cell heterogeneity and initial number of cells via computer simulation. In the proposed approach, Weibull and Poisson distributions are respectively used to provide individual cell inactivation time variability and initial number of cells variability. Our simulation results show that the time-to-inactivation significantly depends on kinetics curvature and initial number of cells. For example, with increases in the initial number of cells, the respective variance of the time-to-inactivation of log-linear, concave downward curve, and concave upward curve remains constant, decreases, and increases, respectively. The death probability contour plot was successfully generated via our computer simulation approach without using D-value estimation. Further, the death probability calculated using our stochastic approach was virtually the same as that obtained using inactivation kinetics. We validated the simulation by using literature data for acid inactivation of Salmonella population. The results of this study indicate that inactivation curvature can replace D-value extrapolation to estimate the death probability of bacterial population. Further, our computer simulation facilitates realistic estimation of the time-to-inactivation of bacterial population. The R code used for the above stochastic calculation is outlined.","Koyama K
Abe H
Kawamura S
Koseki S
","(PMID:30326383
)",Stochastic simulation for death probability of bacterial population considering variability in individual cell inactivation time and initial number of cells.,https://europepmc.org/abstract/MED/30326383%0A
"Exploring and detecting the causal relations among variables have shown huge practical values in recent years, with numerous opportunities for scientific discovery, and have been commonly seen as the core of data science. Among all possible causal discovery methods, causal discovery based on a constraint approach could recover the causal structures from passive observational data in general cases, and had shown extensive prospects in numerous real world applications. However, when the graph was sufficiently large, it did not work well. To alleviate this problem, an improved causal structure learning algorithm named brain storm optimization (BSO), is presented in this paper, combining K2 with brain storm optimization (K2-BSO). Here BSO is used to search optimal topological order of nodes instead of graph space. This paper assumes that dataset is generated by conforming to a causal diagram in which each variable is generated from its parent based on a causal mechanism. We designed an elaborate distance function for clustering step in BSO according to the mechanism of K2. The graph space therefore was reduced to a smaller topological order space and the order space can be further reduced by an efficient clustering method. The experimental results on various real-world datasets showed our methods outperformed the traditional search and score methods and the state-of-the-art genetic algorithm-based methods.","Hong Y
Hao Z
Mai G
Huang H
Kumar Sangaiah A
","(PMID:30012940
 PMCID:PMC6100085)",Causal Discovery Combining K2 with Brain Storm Optimization Algorithm.,https://europepmc.org/abstract/MED/30012940%0A
"Cancer onset and progression is often triggered by the accumulation of structural abnormalities in the genome. Somatically acquired large structural variants (SV) are one class of abnormalities that can lead to cancer onset by, for example, deactivating tumor suppressor genes and by upregulating oncogenes. Detecting and classifying these variants can lead to improved therapies and diagnostics for cancer patients.This chapter provides an overview of the problem of computational genomic SV detection using next-generation sequencing (NGS) platforms, along with a brief overview of typical approaches for addressing this problem. It also discusses the general protocol that should be followed to analyze a cancer genome for SV detection in NGS data.","Hayes M
","(PMID:30378069
)",Computational Analysis of Structural Variation in Cancer Genomes.,https://europepmc.org/abstract/MED/30378069%0A
"Technology and science are often successful in discontinuities (""disruptive innovations"" or ""leapfrogging""), in turn allowing true, big societal development by entire changes in technology rather than by minuscule stepwise improvements. Examples are the emergence of modern computer science by inventing the field-effect transistor rather than further fine-tuning the ""Röhrentransistor""; the development of (organic) light-emitting diodes in advance of the ""Gasglühstrumpf""; CRISPR/Cas exceeding any previous genetic method or Ziegler-Natta polymerization enabling stereoregular polypropylene (PP) and high-density polyethylene (HDPE) in advance of free-radical polymerization. Where may the frogs in polymer science in the future ""jump"" to? Contemplating past achievements in (synthetic) polymer science, such as living polymerization, ""click"" chemistry, supramolecular chemistry, the potentially ""leaping"" areas of self-healing and (bio)degradable materials, amyloids, and biomaterials are reflected upon.","Binder WH
","(PMID:30357987
)",The Past 40 Years of Macromolecular Sciences: Reflections on Challenges in Synthetic Polymer and Material Science.,https://europepmc.org/abstract/MED/30357987%0A
"PURPOSE  : Augmented reality (AR) has emerged as a promising approach to support surgeries; however, its application in real world scenarios is still very limited. Besides sophisticated registration tasks that need to be solved, surgical AR visualizations have not been studied in a standardized and comparative manner. To foster the development of future AR applications, a steerable framework is urgently needed to rapidly evaluate new visualization techniques, explore their individual parameter spaces and define relevant application scenarios. METHODS  : Inspired by its beneficial usage in the automotive industry, the underlying concept of virtual reality (VR) is capable of transforming complex real environments into controllable virtual ones. We present an interactive VR framework, called Augmented Visualization Box (AVB), in which visualizations for AR can be systematically investigated without explicitly performing an error-prone registration. As use case, a virtual laparoscopic scenario with anatomical surface models was created in a computer game engine. In a study with eleven surgeons, we analyzed this VR setting under different environmental factors and its applicability for a quantitative assessment of different AR overlay concepts. RESULTS  : According to the surgeons, the visual impression of the VR scene is mostly influenced by 2D surface details and lighting conditions. The AR evaluation shows that, depending on the visualization used and its capability to encode depth, 37% to 91% of the experts made wrong decisions, but were convinced of their correctness. These results show that surgeons have more confidence in their decisions, although they are wrong, when supported by AR visualizations. CONCLUSION  : With AVB, intraoperative situations are realistically simulated to quantitatively benchmark current AR overlay methods. Successful surgical task execution in an AR system can only be facilitated if visualizations are customized toward the surgical task.","Hettig J
Engelhardt S
Hansen C
Mistelbauer G
","(PMID:30043197
)",AR in VR: assessing surgical augmented reality visualizations in a steerable virtual reality environment.,https://europepmc.org/abstract/MED/30043197%0A
No abstract provided.,"Tomasevic I
Tomovic V
Milovanovic B
Lorenzo J
Đorđević V
Karabasil N
Djekic I
","(PMID:30292701
)",Comparison of a computer vision system vs. traditional colorimeter for color evaluation of meat products with various physical properties.,https://europepmc.org/abstract/MED/30292701%0A
"For many biological functions membrane proteins (MPs) are considered crucial. Due to this nature of MPs, many pharmaceutical agents have reflected them as attractive targets. It bears indispensable importance that MPs are predicted with accurate measures using effective and efficient computational models (CMs). Annotation of MPs using in vitro analytical techniques is time-consuming and expensive; and in some cases, it can prove to be intractable. Due to this scenario, automated prediction and annotation of MPs through CM based techniques have appeared to be useful. Based on the use of computational intelligence and statistical moments based feature set, an MP prediction framework is proposed. Furthermore, the previously used dataset has been enhanced by incorporating new MPs from the latest release of UniProtKB. Rigorous experimentation proves that the use of statistical moments with a multilayer neural network, trained using back-propagation based prediction techniques allows more thorough results.","Butt AH
Rasool N
Khan YD
","(PMID:30238411
)",Predicting membrane proteins and their types by extracting various sequence features into Chou's general PseAAC.,https://europepmc.org/abstract/MED/30238411%0A
"OBJECTIVE:The development of a middleware information model to facilitate better interoperability between Personal and Electronic Health Record systems in order to allow exchange of Patient Generated Health Data and Observations of Daily Leaving between patients and providers in order to encourage patient self-management. MATERIALS AND METHODS:An information model based on HL7 standards for interoperability has been extended to support PGHD and ODL data types. The new information models uses HL7 CDA to represent data, is instantiated as a Protégé ontology and uses a set of mapping rules to transfer data between Personal and Electronic Health Record systems. RESULTS:The information model was evaluated by executing a set of use case scenarios containing data exported from three consumer health apps, transformed to CDA according to developed mapping rules and validated against a CDA schema. This allowed various challenges to emerge as well as revealed gaps in current standards in use and the information model has been refined accordingly. DISCUSSION AND CONCLUSION:Our proposed middleware solution offers a number of advantages. When modifications are made to either a Personal or Health Electronic Health Record system or any integrated consumer app, they can be incorporated by altering only the instantiation of the information model. Our proposition uses current standards in use such as CDA. The solution is applicable to any EHR system with HL7 CDA support.","Plastiras P
O'Sullivan D
","(PMID:30409336
)",Exchanging personal health data with electronic health records: A standardized information model for patient generated health data and observations of daily living.,https://europepmc.org/abstract/MED/30409336%0A
"A widely used approach to describe the dynamics of gene regulatory networks is based on the chemical master equation, which considers probability distributions over all possible combinations of molecular counts. The analysis of such models is extremely challenging due to their large discrete state space. We therefore propose a hybrid approximation approach based on a system of partial differential equations, where we assume a continuous-deterministic evolution for the protein counts. We discuss efficient analysis methods for both modeling approaches and compare their performance. We show that the hybrid approach yields accurate results for sufficiently large molecule counts, while reducing the computational effort from one ordinary differential equation for each state to one partial differential equation for each mode of the system. Furthermore, we give an analytical steady-state solution of the hybrid model for the case of a self-regulatory gene.","Kurasov P
Lück A
Mugnolo D
Wolf V
","(PMID:30244015
)",Stochastic hybrid models of gene regulatory networks - A PDE approach.,https://europepmc.org/abstract/MED/30244015%0A
No abstract provided.,"Williams S
Fang H
Alty J
Qahwaji R
Patel P
Graham CD
","(PMID:30242744
)",A smartphone camera reveals an 'invisible' Parkinsonian tremor: a potential pre-motor biomarker?,https://europepmc.org/abstract/MED/30242744%0A
"Computer has wide applicability in many field, and in pharmaceutical science the computer play a crucial role as a commander of all the theoretical aspects and provide a workbench to improve the overall quality system of the pharmaceutical research and development. The aim of this article is to provide computational approach in development of the many booming technology of computer software in the field of clinical pharmacokinetics. The computational technique practiced by clinical pharmacist and scientist with the applied knowledge and skills of dealing with clinical pharmacokinetics problems, which can be applied in routine clinical practices. Methods used to distinguish the pharmacokinetics (PK) and pharmacodynamics (PD) analysis software has evolved greatly in recent years, allowing users to focus on analysis. Clinical pharmacokinetics software like Population pharmacokinetics, Individual pharmacokinetics, ADME pharmacokinetics, in - silico pharmacokinetics like WinNonlin, SAS, Scientist, NONMEM, PK Solution and many more allows quick results to complicated pharmacokinetic equations and modeling of pharmacokinetic processes. This critique attempts to define the common, fundamental aspects of pharmacokinetic software through a discussion of the literature describing the techniques, advantages, and functions and placing them in the appropriate context. This software's also helps in development of experimental study designs, statistical treatment of data and various simulation studies, etc. A robust software solution should be easy to use and address the three main parts of the PK/PD workflow like data management, analysis, and reporting. When selecting pharmacokinetic software programs, the consumer needs to consider several factors, including usability (e.g. user interface, native platform, price, input and output specificity, as well as intuitiveness), content (e.g. algorithms and data output) and support (e.g. technical and clinical).","Dave V
Yadav RB
Yadav S
Sharma S
Sahu RK
Ajayi AF
","(PMID:30360723
)",A critique on computer simulation software's used in pharmacokinetics and pharmacodynamics analysis.,https://europepmc.org/abstract/MED/30360723%0A
"In this paper, we present an iterative reconstruction for photon-counting CT using prior image constrained total generalized variation (PICTGV). This work aims to exploit structural correlation in the energy domain to reduce image noise in photon-counting CT with narrow energy bins. This is motived by the fact that the similarity between high-quality full-spectrum image and target image is an important prior knowledge for photon-counting CT reconstruction. The PICTGV method is implemented using a splitting-based fast iterative shrinkage-threshold algorithm (FISTA). Evaluations conducted with simulated and real photon-counting CT data demonstrate that PICTGV method outperforms the existing prior image constrained compressed sensing (PICCS) method in terms of noise reduction, artifact suppression and resolution preservation. In the simulated head data study, the average relative root mean squared error is reduced from 2.3% in PICCS method to 1.2% in PICTGV method, and the average universal quality index increases from 0.67 in PICCS method to 0.76 in PICTGV method. The results show that the present PICTGV method improves the performance of the PICCS method for photon-counting CT reconstruction with narrow energy bins.","Niu S
Zhang Y
Zhong Y
Liu G
Lu S
Zhang X
Hu S
Wang T
Yu G
Wang J
","(PMID:30384175
)",Iterative reconstruction for photon-counting CT using prior image constrained total generalized variation.,https://europepmc.org/abstract/MED/30384175%0A
"The main focus of the current work is on the investigation and application of a missing variable approach in principal component analysis (PCA) model for decentralized process monitoring purpose. Given that the widely studied PCA algorithm can recover the correlations between measured variables, a missing variable approach is employed for computing score estimation error and residual estimation error from the developed PCA model. Through assuming but only one variable is missing in sequence, the residual between the actual and estimated components is generated and then monitored instead of the original data. The presented method implements a missing variable based offline modeling and online monitoring in a decentralized manner. Generally, the generated residual is expected to follow or at least become much closer to a Gaussian distribution, the resulted model has no restriction on Gaussian distributed dataset and can achieve salient monitoring performance in contrast to its counterparts. Finally, its superiority and effectiveness have been demonstrated by conducting comparisons on two industrial examples.","Tong C
Lan T
Zhu Y
Shi X
Chen Y
","(PMID:30262178
)",A missing variable approach for decentralized statistical process monitoring.,https://europepmc.org/abstract/MED/30262178%0A
"Treating an abdominal aortic aneurysm (AAA) with a stent graft (SG) and a multilayer stent (MS) is a key technology in isolating flow fields. Clinically, dual stents (an SG in the proximal and an MS in the distal of AAA) are used for treatment of AAA, but only a few studies have examined the relationship between SG coverage and treatment effects. Through numerical simulation of the hemodynamics after SG and MS implantation, the SG coverage and position were simulated at 0% (0 mm), 25% (13.75 mm), 50% (27.5 mm), and 75% (41.25 mm). With increasing SG coverage, the pressure on the aneurysm sac wall and the flow of branch vessels gradually decreased, and the lower wall shear stress (WSS) gradually increased. The changes in pressure, lower WSS, and the mass flow rate of the branch vessels did not change significantly. The coverage of the SG has a nonsignificant effect on hemodynamics in the treatment of AAA; the implantation position need not be very precise. This research can provide theoretic support for clinicians' decision-making.","Ding Y
Zhongyou L
Wentao J
Yinci Z
Zhenze W
Yu C
","(PMID:30397213
 PMCID:PMC6218544)",Stent graft coverage of dual-stent strategy in the management of abdominal aortic aneurysms.,https://europepmc.org/abstract/MED/30397213%0A
"The first protein structures revealed a complex web of weak interactions stabilising the three-dimensional shape of the molecule. Small molecule ligands were then found to exploit these same weak binding events to modulate protein function or act as substrates in enzymatic reactions. As the understanding of ligand-protein binding grew, it became possible to firstly predict how and where a particular small molecule might interact with a protein, and then to identify putative ligands for a specific protein site. Computer-aided drug discovery, based on the structure of target proteins, is now a well-established technique that has produced several marketed drugs. We present here an overview of the various methodologies being used for structure-based computer-aided drug discovery and comment on possible future developments in the field.","Nero TL
Parker MW
Morton CJ
","(PMID:30242117
)",Protein structure and computational drug discovery.,https://europepmc.org/abstract/MED/30242117%0A
"PURPOSE:The purpose of the present study was to compare scanning trueness and precision between an abutment impression and a stone model according to dental computer-aided design/computer-aided manufacturing (CAD/CAM) evaluation standards. MATERIALS AND METHODS:To evaluate trueness, the abutment impression and stone model were scanned to obtain the first 3-dimensional (3-D) stereolithography (STL) file. Next, the abutment impression or stone model was removed from the scanner and re-fixed on the table; scanning was then repeated so that 11 files were obtained for each scan type. To evaluate precision, the abutment impression or stone model was scanned to obtain the first 3-D STL file. Without moving it, scanning was performed 10 more times, so that 11 files were obtained for each scan type. By superimposing the first scanned STL file onto the other STL files one by one, 10 color-difference maps and reports were obtained; i.e., 10 experimental scans per type. The independent t-test was used to compare root mean square (RMS) data between the groups (α=.05). RESULTS:The RMS±SD values of scanning trueness of the abutment impression and stone model were 22.4±4.4 and 17.4±3.5 µm, respectively (P<.012). The RMS±SD values of scanning precision of the abutment impression and stone model were 16.4±2.9 and 14.6±1.6 µm, respectively (P=.108). CONCLUSION:There was a significant difference in scanning trueness between the abutment impression and stone model, as evaluated according to dental CAD/CAM standards. However, all scans showed high trueness and precision.","Jeon JH
Hwang SS
Kim JH
Kim WC
","(PMID:30370023
 PMCID:PMC6202429)",Trueness and precision of scanning abutment impressions and stone models according to dental CAD/CAM evaluation standards.,https://europepmc.org/abstract/MED/30370023%0A
"The science of solving clinical problems by analyzing images generated in clinical practice is known as medical image analysis. The aim is to extract information in an affective and efficient manner for improved clinical diagnosis. The recent advances in the field of biomedical engineering have made medical image analysis one of the top research and development area. One of the reasons for this advancement is the application of machine learning techniques for the analysis of medical images. Deep learning is successfully used as a tool for machine learning, where a neural network is capable of automatically learning features. This is in contrast to those methods where traditionally hand crafted features are used. The selection and calculation of these features is a challenging task. Among deep learning techniques, deep convolutional networks are actively used for the purpose of medical image analysis. This includes application areas such as segmentation, abnormality detection, disease classification, computer aided diagnosis and retrieval. In this study, a comprehensive review of the current state-of-the-art in medical image analysis using deep convolutional networks is presented. The challenges and potential of these techniques are also highlighted.","Anwar SM
Majid M
Qayyum A
Awais M
Alnowami M
Khan MK
","(PMID:30298337
)",Medical Image Analysis using Convolutional Neural Networks: A Review.,https://europepmc.org/abstract/MED/30298337%0A
"Membrane fluidity, essential for cell functions, is obviously affected by copper, but the molecular mechanism is poorly understood. Here, we unexpectedly observed that a decrease in phospholipid (PL) bilayer fluidity caused by Cu2+ was more significant than those by Zn2+ and Ca2+, while a comparable reduction occurred in the last two ions. This finding disagrees with the placement in the periodic table of Cu just next to Zn and far from Ca. The physical nature was revealed to be an anomalous attraction between Cu+ cations, as well as the induced motif of two phospholipids coupled by Cu-Cu bond (PL-diCu-PL). Namely, upon Cu2+ ion binding to a negatively charged phosphate group of lipid, Cu2+ was reduced to Cu+. The attraction of the cations then caused one Cu+ ion simultaneously binding to two lipids and another Cu+, resulting in the formation of PL-diCu-PL structure. In contrast, this attraction cannot occur in the cases of Zn and Ca ions. Remarkably, besides lipids, the phosphate group also widely exists in other biological molecules, including DNA, RNA, ADP and ATP. Our findings thus provide a new view for understanding the biological functions of copper and the mechanism underlying copper-related diseases, as well as lipid assembly.","Jiang X
Zhang J
Zhou B
Li P
Hu X
Zhu Z
Tan Y
Chang C
Lü J
Song B
","(PMID:30237448
)",Anomalous behavior of membrane fluidity caused by copper-copper bond coupled phospholipids.,https://europepmc.org/abstract/MED/30237448%0A
"PURPOSE:Convolutional neural networks have become rapidly popular for image recognition and image analysis because of its powerful potential. In this paper, we developed a method for classifying subtypes of lung adenocarcinoma from pathological images using neural network whose that can evaluate phenotypic features from wider area to consider cellular distributions. METHODS:In order to recognize the types of tumors, we need not only to detail features of cells, but also to incorporate statistical distribution of the different types of cells. Variants of autoencoders as building blocks of pre-trained convolutional layers of neural networks are implemented. A sparse deep autoencoder which minimizes local information entropy on the encoding layer is then proposed and applied to images of size [Formula: see text]. We applied this model for feature extraction from pathological images of lung adenocarcinoma, which is comprised of three transcriptome subtypes previously defined by the Cancer Genome Atlas network. Since the tumor tissue is composed of heterogeneous cell populations, recognition of tumor transcriptome subtypes requires more information than local pattern of cells. The parameters extracted using this approach will then be used in multiple reduction stages to perform classification on larger images. RESULTS:We were able to demonstrate that these networks successfully recognize morphological features of lung adenocarcinoma. We also performed classification and reconstruction experiments to compare the outputs of the variants. The results showed that the larger input image that covers a certain area of the tissue is required to recognize transcriptome subtypes. The sparse autoencoder network with [Formula: see text] input provides a 98.9% classification accuracy. CONCLUSION:This study shows the potential of autoencoders as a feature extraction paradigm and paves the way for a whole slide image analysis tool to predict molecular subtypes of tumors from pathological features.","Antonio VAA
Ono N
Saito A
Sato T
Altaf-Ul-Amin M
Kanaya S
","(PMID:30159833
 PMCID:PMC6223755)",Classification of lung adenocarcinoma transcriptome subtypes from pathological images using deep convolutional networks.,https://europepmc.org/abstract/MED/30159833%0A
"Cell-penetrating peptides (CPPs) have been shown to be a transport vehicle for delivering cargoes into live cells, offering great potential as future therapeutics. It is essential to identify CPPs for better understanding of their functional mechanisms. Machine learning-based methods have recently emerged as a main approach for computational identification of CPPs. However, one of the main challenges and difficulties is to propose an effective feature representation model that sufficiently exploits the inner difference and relevance between CPPs and non-CPPs, in order to improve the predictive performance. In this paper, we have developed CPPred-FL, a powerful bioinformatics tool for fast, accurate and large-scale identification of CPPs. In our predictor, we introduce a new feature representation learning scheme that enables one to learn feature representations from totally 45 well-trained random forest models with multiple feature descriptors from different perspectives, such as compositional information, position-specific information and physicochemical properties, etc. We integrate class and probabilistic information into our feature representations. To improve the feature representation ability, we further remove redundant and irrelevant features by feature space optimization. Benchmarking experiments showed that CPPred-FL, using 19 informative features only, is able to achieve better performance than the state-of-the-art predictors. We anticipate that CPPred-FL will be a powerful tool for large-scale identification of CPPs, facilitating the characterization of their functional mechanisms and accelerating their applications in clinical therapy.","Qiang X
Zhou C
Ye X
Du PF
Su R
Wei L
","(PMID:30239616
)",CPPred-FL: a sequence-based predictor for large-scale identification of cell-penetrating peptides by feature representation learning.,https://europepmc.org/abstract/MED/30239616%0A
"BACKGROUND:Several smartphone applications aim at facilitating communication between patients and healthcare providers. In this review, we evaluate and compare the most promising applications in the field of diabetes mellitus (DM) and obesity. Most applications monitor body weight, fasting or postprandial blood glucose, glycosylated hemoglobin (Hgb) A1c (HgbA1c), and units and types of insulin used. METHODS:Nine clinically tested applications and two Web platforms were grouped into three categories that were evaluated and compared. Group 1 included seven applications focusing mainly on monitoring DM, fitness and weight, blood glucose levels, and HbA1c. Group 2 included two applications that focus on insulin dosage calculators and glucose self-monitoring tests. Group 3 included two web-platforms that interact with patients via SMS (short message service) messaging. RESULTS:A common feature of the applications examined was the limited number of clinical parameters tested, the small number of subjects taking part in the evaluation, and the fact that the controls were not randomized. Furthermore, the interfaces of the applications varied and were not standardized. Finally, another common characteristic across applications was the lack of standardization of the interface and the overall structure due to language barriers, the devices usually having been designed around a specific language. Lastly, most applications lacked a critical mass of evaluators and were thus not worthy of being considered of serious clinical relevance. CONCLUSIONS:The current smartphone applications for DM are characterized by a limited number of participants, a small number of parameters, and a lack of standardization.","Ersotelos NT
Margioris AN
Zhang X
Dong F
","(PMID:30317460
)",Review of mobile applications for optimizing the follow-up care of patients with diabetes.,https://europepmc.org/abstract/MED/30317460%0A
"Perovskite solar cells (PSCs) have witnessed rapidly rising power conversion efficiencies, together with advances in stability and upscaling. Despite these advances, their limited stability and need to prove upscaling remain crucial hurdles on the path to commercialization. We summarize recent advances toward commercially viable PSCs and discuss challenges that remain. We expound the development of standardized protocols to distinguish intrinsic and extrinsic degradation factors in perovskites. We review accelerated aging tests in both cells and modules and discuss the prediction of lifetimes on the basis of degradation kinetics. Mature photovoltaic solutions, which have demonstrated excellent long-term stability in field applications, offer the perovskite community valuable insights into clearing the hurdles to commercialization.","Rong Y
Hu Y
Mei A
Tan H
Saidaminov MI
Seok SI
McGehee MD
Sargent EH
Han H
","(PMID:30237326
)",Challenges for commercializing perovskite solar cells.,https://europepmc.org/abstract/MED/30237326%0A
"Implant treatment is one of the most important surgical processes in teeth which reduces the difficulties in teeth by providing the interface between bone and jaw. The established implant treatment used to support the denture, bridge and teeth crown. Even though it supports many dental related activities, the successive measure of implant treatment is fail to manage because it fully depends on the patient's personal activities and health condition of mouth tissues. So, the successive rate of implant treatment process is identified by applying the memetic search optimization along with Genetic scale recurrent neural network method. The introduced method analyzes the patient characteristics which helps to recognize the successive and failure rate of implant treatment process. The quality of the implant treatment of using simulation results in terms of sensitivity, specificity and accuracy metrics.","Alarifi A
AlZubi AA
","(PMID:30225666
)",Memetic Search Optimization Along with Genetic Scale Recurrent Neural Network for Predictive Rate of Implant Treatment.,https://europepmc.org/abstract/MED/30225666%0A
"BACKGROUND AND OBJECTIVE:Cloud computing plays a vital role in big data science with its scalable and cost-efficient architecture. Large-scale genome data storage and computations would benefit from using these latest cloud computing infrastructures, to save cost and speedup discoveries. However, due to the privacy and security concerns, data owners are often disinclined to put sensitive data in a public cloud environment without enforcing some protective measures. An ideal solution is to develop secure genome database that supports encrypted data deposition and query. METHODS:Nevertheless, it is a challenging task to make such a system fast and scalable enough to handle real-world demands providing data security as well. In this paper, we propose a novel, secure mechanism to support secure count queries on an open source graph database (Neo4j) and evaluated the performance on a real-world dataset of around 735,317 Single Nucleotide Polymorphisms (SNPs). In particular, we propose a new tree indexing method that offers constant time complexity (proportion to the tree depth), which was the bottleneck of existing approaches. RESULTS:The proposed method significantly improves the runtime of query execution compared to the existing techniques. It takes less than one minute to execute an arbitrary count query on a dataset of 212  GB, while the best-known algorithm takes around 7  min. CONCLUSIONS:The outlined framework and experimental results show the applicability of utilizing graph database for securely storing large-scale genome data in untrusted environment. Furthermore, the crypto-system and security assumptions underlined are much suitable for such use cases which be generalized in future work.","Chen L
Aziz MM
Mohammed N
Jiang X
","(PMID:30337067
)",Secure large-scale genome data storage and query.,https://europepmc.org/abstract/MED/30337067%0A
"Multiple pedagogical approaches, such as experimental experiences or computer-based activities, have been shown to increase student learning and engagement. We have developed a laboratory module that includes both a traditional ""live"" experimental component and a student-designed ""virtual"" computer simulation component. This laboratory employs the mating pathway of Saccharomyces cerevisiae (yeast) to demonstrate four fundamental cell and molecular biology concepts: cell signaling, cytoskeleton, cell cycle, and cell cycle checkpoints. In the live laboratory, students add mating pheromone to cultures, then measure changes in cell division and morphology characteristics of the S. cerevisiae mating response. We also developed a ""virtual"" complement to this laboratory. Using the principles of Design Thinking and Agile methodology, we collaborated with an undergraduate Computer Science course to generate two computer simulations which can support the live laboratory or provide a virtual laboratory experience. We assessed how both the live and virtual laboratories contributed to learning gains in analytical skills and course content. Students who performed the simulation alone or the simulation plus live lab demonstrated learning gains, with greater gains for the live lab, but students who performed neither lab did not. Attitudinal assessment demonstrated increased student engagement and self-efficacy after performing the live and virtual labs. © 2018 by The International Union of Biochemistry and Molecular Biology, 46:361-372, 2018.","Goudsouzian LK
Riola P
Ruggles K
Gupta P
Mondoux MA
","(PMID:29984456
)",Integrating cell and molecular biology concepts: Comparing learning gains and self-efficacy in corresponding live and virtual undergraduate laboratory experiences.,https://europepmc.org/abstract/MED/29984456%0A
No abstract provided.,"Hinton G
","(PMID:30178065
)",Deep Learning-A Technology With the Potential to Transform Health Care.,https://europepmc.org/abstract/MED/30178065%0A
"On-demand computing is a popular enterprise model in which the computing resources are made available to the users as needed. On-demand computing based transaction processing system which has grown rapidly in recent years is an information processing system with the stringent requirements of resources to meet the fluctuating demands. Concepts such as grid computing, utility computing, autonomic computing, and adaptive management seem very similar to the concept of on-demand computing. When demands of resources fluctuate, the system needs load balancing for the efficient utilization of the computational resources. Furthermore, scheduling is needed to assign the transactions to the appropriate resources. Thus, modeling of load balanced scheduling along with reliability analysis for this system is a challenging task. This paper presents the load balanced scheduling and reliability modeling in such an environment by using colored Petri nets (CPNs). CPNs which combine Petri nets with programming languages is a powerful modeling technique. The proposed CPN-based modeling pattern formally describes the process of transaction distribution and execution within the on-demand computing environment. Moreover, the CPN-based model uses the hierarchical modeling capability of CPNs, including different levels of abstraction (sub-modules). This helps easily handling and extending the model. Since, on-demand computing based transaction processing system executes a number of concurrent transactions. The CPN-based model is extended to express the concurrency, thus improving the reliability results. This paper takes the example of grid transaction processing (GTP) system with the problem of load balanced scheduling modeling and reliability evaluation.","Mahato DP
Singh RS
","(PMID:30342814
)",Load balanced scheduling and reliability modeling of grid transaction processing system using colored Petri nets.,https://europepmc.org/abstract/MED/30342814%0A
"Neurofeedback requires a direct translation of neuronal brain activity to sensory input given to the user or subject. However, decoding certain states, e.g., mindfulness or wandering thoughts, from ongoing brain activity remains an unresolved problem. In this study, we used magnetoencephalography (MEG) to acquire brain activity during mindfulness meditation and thought-inducing tasks mimicking wandering thoughts. We used a novel real-time feature extraction to decode the mindfulness, i.e., to discriminate it from the thought-inducing tasks. The key methodological novelty of our approach is usage of MEG power spectra and functional connectivity of independent components as features underlying mindfulness states. Performance was measured as the classification accuracy on a separate session but within the same subject. We found that the spectral- and connectivity-based classification approaches allowed discriminating mindfulness and thought-inducing tasks with an accuracy around 60% compared to the 50% chance-level. Both classification approaches showed similar accuracy, although the connectivity approach slightly outperformed the spectral one in a few cases. Detailed analysis showed that the classification coefficients and the associated independent components were highly individual among subjects and a straightforward transfer of the coefficients over subjects provided near chance-level classification accuracy. Thus, discriminating between mindfulness and wandering thoughts seems to be possible, although with limited accuracy, by machine learning, especially on the subject-level. Our hope is that the developed spectral- and connectivity-based decoding methods can be utilized in real-time neurofeedback to decode mindfulness states from ongoing neuronal activity, and hence, provide a basis for improved, individualized mindfulness training.","Zhigalov A
Heinilä E
Parviainen T
Parkkonen L
Hyvärinen A
","(PMID:30317018
)",Decoding attentional states for neurofeedback: Mindfulness vs. wandering thoughts.,https://europepmc.org/abstract/MED/30317018%0A
"It is easy for today's students and researchers to believe that modern bioinformatics emerged recently to assist next-generation sequencing data analysis. However, the very beginnings of bioinformatics occurred more than 50 years ago, when desktop computers were still a hypothesis and DNA could not yet be sequenced. The foundations of bioinformatics were laid in the early 1960s with the application of computational methods to protein sequence analysis (notably, de novo sequence assembly, biological sequence databases and substitution models). Later on, DNA analysis also emerged due to parallel advances in (i) molecular biology methods, which allowed easier manipulation of DNA, as well as its sequencing, and (ii) computer science, which saw the rise of increasingly miniaturized and more powerful computers, as well as novel software better suited to handle bioinformatics tasks. In the 1990s through the 2000s, major improvements in sequencing technology, along with reduced costs, gave rise to an exponential increase of data. The arrival of 'Big Data' has laid out new challenges in terms of data mining and management, calling for more expertise from computer science into the field. Coupled with an ever-increasing amount of bioinformatics tools, biological Big Data had (and continues to have) profound implications on the predictive power and reproducibility of bioinformatics results. To overcome this issue, universities are now fully integrating this discipline into the curriculum of biology students. Recent subdisciplines such as synthetic biology, systems biology and whole-cell modeling have emerged from the ever-increasing complementarity between computer science and biology.","Gauthier J
Vincent AT
Charette SJ
Derome N
","(PMID:30084940
)",A brief history of bioinformatics.,https://europepmc.org/abstract/MED/30084940%0A
"The novel gadgets are associated constantly at a quick phase for the development of Internet of Things (IoT). Wearable gadgets are another gathering development in those available gadgets. The recent method in gadgets is to coordinate with IoT and idea is implementing the remote sensor systems that convey novel encounters in day by day exercises. Here, I exhibit a regular day to day existence application including a Wireless Sensor Networks (WSN) for gaming situation. By using this, the physical factors of sports person are estimated and directed by wearable gadgets to Wireless Sensor Networks. The end goal to incorporate diverse equipment stages and to present an administration situated semantic middleware arrangement hooked on a solitary request also utilization of Enterprise Service Bus (ESB) is introduced as a scaffold to ensure coordination of the distinctive conditions and interoperability. Through proposed method everyone can procure information by introducing framework to fresh client. Those clients would be able to get to the information through a wide assortment of gadgets (cell phones, tablets, and PCs) and working frameworks (Android, Windows, Linux, iOS, and so on). Finally we introduced one case study of football match for monitoring 11 players and acquiring data's and to predict the real time situation in football ground.","Krishnan S
Lokesh S
Ramya Devi M
","(PMID:30311001
)",Internet of things for knowledge administrations by wearable gadgets.,https://europepmc.org/abstract/MED/30311001%0A
"Big data, smart data, predictive analytics, and other similar terms are ubiquitous in the lay and scientific literature. However, despite the frequency of usage, these terms are often poorly understood, and evidence of their disruption to clinical care is hard to find. This article aims to address these issues by first defining and elucidating the term big data, exploring the ways in which modern medical data, both inside and outside the electronic medical record, meet the established definitions of big data. We then define the term smart data and discuss the transformations necessary to make big data into smart data. Finally, we examine the ways in which this transition from big to smart data will affect what we do in research, retrospective work, and ultimately patient care.","Hofer IS
Halperin E
Cannesson M
","(PMID:29847384
)",Opening the Black Box: Understanding the Science Behind Big Data and Predictive Analytics.,https://europepmc.org/abstract/MED/29847384%0A
"Microarray datasets play a crucial role in cancer detection. But the high dimension of these datasets makes the classification challenging due to the presence of many irrelevant and redundant features. Hence, feature selection becomes irreplaceable in this field because of its ability to remove the unrequired features from the system. As the task of selecting the optimal number of features is an NP-hard problem, hence, some meta-heuristic search technique helps to cope up with this problem. In this paper, we propose a 2-stage model for feature selection in microarray datasets. The ranking of the genes for the different filter methods are quite diverse and effectiveness of rankings is datasets dependent. First, we develop an ensemble of filter methods by considering the union and intersection of the top-n features of ReliefF, chi-square, and symmetrical uncertainty. This ensemble allows us to combine all the information of the three rankings together in a subset. In the next stage, we use genetic algorithm (GA) on the union and intersection to get the fine-tuned results, and union performs better than the latter. Our model has been shown to be classifier independent through the use of three classifiers-multi-layer perceptron (MLP), support vector machine (SVM), and K-nearest neighbor (K-NN). We have tested our model on five cancer datasets-colon, lung, leukemia, SRBCT, and prostate. Experimental results illustrate the superiority of our model in comparison to state-of-the-art methods. Graphical abstract ᅟ.","Ghosh M
Adhikary S
Ghosh KK
Sardar A
Begum S
Sarkar R
","(PMID:30069674
)",Genetic algorithm based cancerous gene identification from microarray data using ensemble of filter methods.,https://europepmc.org/abstract/MED/30069674%0A
"Although shotgun metagenomic sequencing of microbiome samples enables partial reconstruction of strain-level community structure, obtaining high-quality microbial genome drafts without isolation and culture remains difficult. Here, we present an application of read clouds, short-read sequences tagged with long-range information, to microbiome samples. We present Athena, a de novo assembler that uses read clouds to improve metagenomic assemblies. We applied this approach to sequence stool samples from two healthy individuals and compared it with existing short-read and synthetic long-read metagenomic sequencing techniques. Read-cloud metagenomic sequencing and Athena assembly produced the most comprehensive individual genome drafts with high contiguity (>200-kb N50, fewer than ten contigs), even for bacteria with relatively low (20×) raw short-read-sequence coverage. We also sequenced a complex marine-sediment sample and generated 24 intermediate-quality genome drafts (>70% complete, <10% contaminated), nine of which were complete (>90% complete, <5% contaminated). Our approach allows for culture-free generation of high-quality microbial genome drafts by using a single shotgun experiment.","Bishara A
Moss EL
Kolmogorov M
Parada AE
Weng Z
Sidow A
Dekas AE
Batzoglou S
Bhatt AS
","(PMID:30320765
)",High-quality genome sequences of uncultured microbes by assembly of read clouds.,https://europepmc.org/abstract/MED/30320765%0A
No abstract provided.,"Service RF
","(PMID:12829754
)",Computer science. Scientists launch global Internet research lab.,https://europepmc.org/abstract/MED/12829754%0A
"INTRODUCTION:Phosphatase and tensin homolog (PTEN) loss is frequently observed in NSCLC and associated with both phosphoinositide 3-kinase activation and tumoral immunosuppression. PTEN immunohistochemistry is a valuable readout, but lacks standardized staining protocol and cutoff value. METHODS:After an external quality assessment using SP218, 138G6 and 6H2.1 anti-PTEN antibodies, scored on webbook and tissue microarray, the European Thoracic Oncology Platform cohort samples (n = 2245 NSCLC patients, 8980 tissue microarray cores) were stained with SP218. All cores were H-scored by pathologists and by computerized pixel-based intensity measurements calibrated by pathologists. RESULTS:All three antibodies differentiated six PTEN+ versus six PTEN- cases on external quality assessment. For 138G6 and SP218, high sensitivity and specificity was found for all H-score threshold values including prospectively defined 0, calculated 8 (pathologists), and calculated 5 (computer). High concordance among pathologists in setting computer-based intensities and between pathologists and computer in H-scoring was observed. Because of over-integration of the human eye, pixel-based computer H-scores were overall 54% lower. For all cutoff values, PTEN- was associated with smoking history, squamous cell histology, and higher tumor stage (p < 0.001). In adenocarcinomas, PTEN- was associated with poor survival. CONCLUSION:Calibration of immunoreactivity intensities by pathologists following computerized H-score measurements has the potential to improve reproducibility and homogeneity of biomarker detection regarding epitope validation in multicenter studies.","Rulle U
Tsourti Z
Casanova R
Deml KF
Verbeken E
Thunnissen E
Warth A
Cheney R
Sejda A
Speel EJ
Madsen LB
Nonaka D
Navarro A
Sansano I
Marchetti A
Finn SP
Monkhorst K
Kerr KM
Haberecker M
Wu C
Zygoura P
Kammler R
Geiger T
Gendreau S
Schulze K
Vrugt B
Wild P
Moch H
Weder W
Ciftlik AT
Dafni U
Peters S
Bubendorf L
Stahel RA
Soltermann A
","(PMID:30240851
)",Computer-Based Intensity Measurement Assists Pathologists in Scoring Phosphatase and Tensin Homolog Immunohistochemistry - Clinical Associations in NSCLC Patients of the European Thoracic Oncology Platform Lungscape Cohort.,https://europepmc.org/abstract/MED/30240851%0A
"Consumer genomics databases have reached the scale of millions of individuals. Recently, law enforcement authorities have exploited some of these databases to identify suspects via distant familial relatives. Using genomic data of 1.28 million individuals tested with consumer genomics, we investigated the power of this technique. We project that about 60% of the searches for individuals of European descent will result in a third-cousin or closer match, which theoretically allows their identification using demographic identifiers. Moreover, the technique could implicate nearly any U.S. individual of European descent in the near future. We demonstrate that the technique can also identify research participants of a public sequencing project. On the basis of these results, we propose a potential mitigation strategy and policy implications for human subject research.","Erlich Y
Shor T
Pe'er I
Carmi S
","(PMID:30309907
)",Identity inference of genomic data using long-range familial searches.,https://europepmc.org/abstract/MED/30309907%0A
A correction to this article has been published and is linked from the HTML and PDF versions of this paper. The error has been fixed in the paper.,"Wang P
Ge R
Liu L
Xiao X
Li Y
Cai Y
","(PMID:29934539
 PMCID:PMC6015071)",Author Correction: Multi-label Learning for Predicting the Activities of Antimicrobial Peptides.,https://europepmc.org/abstract/MED/29934539%0A
"Genome-wide phylogeny reconstruction is becoming increasingly common, and one driving factor behind these phylogenomic studies is the promise that the potential discordance between gene trees and the species tree can be modeled. Incomplete lineage sorting is one cause of discordance that bridges population genetic and phylogenetic processes. ASTRAL is a species tree reconstruction method that seeks to find the tree with minimum quartet distance to an input set of inferred gene trees. However, the published ASTRAL algorithm only works with one sample per species. To account for polymorphisms in present-day species, one can sample multiple individuals per species to create multi-allele datasets. Here, we introduce how ASTRAL can handle multi-allele datasets. We show that the quartet-based optimization problem extends naturally, and we introduce heuristic methods for building the search space specifically for the case of multi-individual datasets. We study the accuracy and scalability of the multi-individual version of ASTRAL-III using extensive simulation studies and compare it to NJst, the only other scalable method that can handle these datasets. We do not find strong evidence that using multiple individuals dramatically improves accuracy. When we study the trade-off between sampling more genes versus more individuals, we find that sampling more genes is more effective than sampling more individuals, even under conditions that we study where trees are shallow (median length: ≈1Ne) and ILS is extremely high.","Rabiee M
Sayyari E
Mirarab S
","(PMID:30393186
)",Multi-allele species reconstruction using ASTRAL.,https://europepmc.org/abstract/MED/30393186%0A
"In 2015, a picture of a Dress (henceforth the Dress) triggered popular and scientific interest; some reported seeing the Dress in white and gold (W&G) and others in blue and black (B&B). We aimed to describe the phenomenon and investigate the role of contextualization. Few days after the Dress had appeared on the Internet, we projected it to 240 students on two large screens in the classroom. Participants reported seeing the Dress in B&B (48%), W&G (38%), or blue and brown (B&Br; 7%). Amongst numerous socio-demographic variables, we only observed that W&G viewers were most likely to have always seen the Dress as W&G. In the laboratory, we tested how much contextual information is necessary for the phenomenon to occur. Fifty-seven participants selected colours most precisely matching predominant colours of parts or the full Dress. We presented, in this order, small squares (a), vertical strips (b), and the full Dress (c). We found that (1) B&B, B&Br, and W&G viewers had selected colours differing in lightness and chroma levels for contextualized images only (b, c conditions) and hue for fully contextualized condition only (c) and (2) B&B viewers selected colours most closely matching displayed colours of the Dress. Thus, the Dress phenomenon emerges due to inter-individual differences in subjectively perceived lightness, chroma, and hue, at least when all aspects of the picture need to be integrated. Our results support the previous conclusions that contextual information is key to colour perception; it should be important to understand how this actually happens.","Jonauskaite D
Dael N
Parraga CA
Chèvre L
García Sánchez A
Mohr C
","(PMID:30259092
)",Stripping #The Dress: the importance of contextual information on inter-individual differences in colour perception.,https://europepmc.org/abstract/MED/30259092%0A
"PURPOSE:Soft robots are highly flexible and adaptable instruments that have proven extremely useful, especially in the surgical environment where compliance allows for improved maneuverability throughout the body. Endoscopic devices are a primary example of an instrument that physicians use to navigate to difficult-to-reach areas inside the body. This paper presents a modular soft robotic pneumatic actuator as a proof of concept for a compliant endoscopic device. METHODS:The actuator is 3D printed using an FDM printer. Maximum bending angle is measured using image processing in MATLAB at a gauge pressure level of 35 psi. End-effector displacement is measured using electromagnetic tracking as gauge pressure ranges from 10 to 35 psi, and uniaxial tensile loading ranges from 0 to 120 g. RESULTS:The actuator achieves a maximum bending angle of 145°. Fourth-order polynomial regression is used to model the actuator displacement upon inflation and tensile loading with an average coefficient of correlation value of 0.998. We also develop a feedforward neural network as a robust computer-assisted method for controlling the actuator that achieves a coefficient of correlation value of 0.996. CONCLUSION:We propose a novel modular soft robotic pneumatic actuator that is developed via rapid prototyping and evaluated using image processing and machine learning models. The curled resting shape allows for simple manufacturing and achieves a greater range of bending than other actuators of its kind. A feedforward neural network provides accurate prediction of end-effector displacement upon inflation and loading to deliver precise manipulation and control.","Taylor AJ
Montayre R
Zhao Z
Kwok KW
Tse ZTH
","(PMID:30088209
)",Modular force approximating soft robotic pneumatic actuator.,https://europepmc.org/abstract/MED/30088209%0A
"The assessment of clients with speech disorders presents challenges for speech-language pathologists. For example, having a reliable way of measuring the severity of the case, determining which remedial program is aligned with a patient's needs, and measuring of treatment processes. There is potential for brain-computer interface (BCI) applications to enhance speech therapy sessions by providing objective insights and real-time visualization of brain activity during the sessions. This paper presents a study on emotional state detection during speech pathology. The goal of this study is to investigate affective-motivational brain responses to stimuli in children who stutter. To this end, we conducted an experiment that involved recording frontal electroencephalography (EEG) activity from fifteen children with stuttering whilst they looked at visual stimuli. The contribution of our study is to provide a comprehensive background and a framework for emotional state detection experiments as assessment and monitoring tool in speech pathology. It mainly discusses the feasibility and potential benefits of applying EEG-based emotion detection in speech-language therapy contexts of use. The findings of our research indicate that emotional recognition using non-invasive EEG-based BCI system is sufficient to differentiate between affective states of individuals in treatment contexts.","Al-Nafjan A
Al-Wabil A
AlMudhi A
Hosny M
","(PMID:30278338
)",Measuring and monitoring emotional changes in children who stutter.,https://europepmc.org/abstract/MED/30278338%0A
"With the fast development of various techniques, more and more data have been accumulated with the unique properties of large size (tall) and high dimension (wide). The era of big data is coming. How to understand and discover new knowledge from these data has attracted more and more scholars' attention and has become the most important task in data mining. As one of the most important techniques in data mining, clustering analysis, a kind of unsupervised learning, could group a set data into objectives(clusters) that are meaningful, useful, or both. Thus, the technique has played very important role in knowledge discovery in big data. However, when facing the large-sized and high-dimensional data, most of the current clustering methods exhibited poor computational efficiency and high requirement of computational source, which will prevent us from clarifying the intrinsic properties and discovering the new knowledge behind the data. Based on this consideration, we developed a powerful clustering method, called MUFOLD-CL. The principle of the method is to project the data points to the centroid, and then to measure the similarity between any two points by calculating their projections on the centroid. The proposed method could achieve linear time complexity with respect to the sample size. Comparison with K-Means method on very large data showed that our method could produce better accuracy and require less computational time, demonstrating that the MUFOLD-CL can serve as a valuable tool, at least may play a complementary role to other existing methods, for big data clustering. Further comparisons with state-of-the-art clustering methods on smaller datasets showed that our method was fastest and achieved comparable accuracy. For the convenience of most scholars, a free soft package was constructed.","Wu Y
He Z
Lin H
Zheng Y
Zhang J
Xu D
","(PMID:29882026
)",A Fast Projection-Based Algorithm for Clustering Big Data.,https://europepmc.org/abstract/MED/29882026%0A
"Proteins are the utmost multi-purpose macromolecules, which play a crucial function in many aspects of biological processes. For a long time, sequence arrangement of amino acid has been utilized for the prediction of protein secondary structure. Besides, in major methods for the prediction of protein secondary structure, impact of the Gaussian noise on sequence representation of amino acids has not been considered until now; which is one of the important constraints for the functionality of a protein.In the present research, the prediction of protein secondary structure was accomplished by integrated application of Stockwell transformation and amino acid composition (AAC), on equivalent electron-ion interaction potential (EIIP) representation of raw amino acid sequence. The introduced method was evaluated by using 4 benchmark datasets of low sequence homology, namely PDB25, 498, 277, and 204. Furthermore, randomforest algorithm together with out-of-bag error estimate and support vector machine (SVM), using k-fold cross validation demonstrated high feature representation potential of our reported approach.The overall prediction accuracy for PDB25, 498, 277, and 204 datasets with randomforest classifier are 92.5%, 94.79%, 92.45%, and 88.04% respectively, whereas with SVM the results are 84.66%, 95.32%, 89.29%, and 84.37 respectively.An integrated-order-function-frequency-time (OFFT) model is proposed for the prediction of protein secondary structure. For the first time, we report the effect of Gaussian noise on the prediction accuracy of protein secondary structure and proposed a robust integrated-OFFT model, which is effectively noise resistant.","Panda B
Majhi B
Thakur A
","(PMID:30152288
)",An integrated-OFFT model for the prediction of protein secondary structure.,https://europepmc.org/abstract/MED/30152288%0A
"Chiral ITP of the weak base methadone using inverse cationic configurations with H+ as leading component and multiple isomer sulfated β-CD (S-β-CD) as leading electrolyte (LE) additive, has been studied utilizing dynamic computer simulation, a calculation model based on steady-state values of the ITP zones, and capillary ITP. By varying the amount of acidic S-β-CD in the LE composed of 3-morpholino-2-hydroxypropanesulfonic acid and the chiral selector, and employing glycylglycine as terminating electrolyte (TE), inverse cationic ITP provides systems in which either both enantiomers, only the enantiomer with weaker complexation, or none of the two enantiomers form cationic ITP zones. For the configuration studied, the data reveal that only S-methadone migrates isotachophoretically when the S-β-CD concentration in the LE is between about 0.484 and 1.113 mM. Under these conditions, R-methadone migrates zone electrophoretically in the TE. An S-β-CD concentration between about 0.070 and 0.484 mM results in both S- and R-methadone forming ITP zones. With >1.113 mM and < about 0.050 mM of S-β-CD in the LE both enantiomers are migrating within the TE and LE, respectively. Chiral inverse cationic ITP with acidic S-β-CD in the LE is demonstrated to permit selective ITP trapping and concentration of the less interacting enantiomer of a weak base.","Mikkonen S
Caslavska J
Gebauer P
Thormann W
","(PMID:30311251
)",Inverse cationic ITP for separation of methadone enantiomers with sulfated β-cyclodextrin as chiral selector.,https://europepmc.org/abstract/MED/30311251%0A
"During seizures, a myriad of clinical manifestations may occur. The analysis of these signs, known as seizure semiology, gives clues to the underlying cerebral networks involved. When patients with drug-resistant epilepsy are monitored to assess their suitability for epilepsy surgery, semiology is a vital component to the presurgical evaluation. Specific patterns of facial movements, head motions, limb posturing and articulations, and hand and finger automatisms may be useful in distinguishing between mesial temporal lobe epilepsy (MTLE) and extratemporal lobe epilepsy (ETLE). However, this analysis is time-consuming and dependent on clinical experience and training. Given this limitation, an automated analysis of semiological patterns, i.e., detection, quantification, and recognition of body movement patterns, has the potential to help increase the diagnostic precision of localization. While a few single modal quantitative approaches are available to assess seizure semiology, the automated quantification of patients' behavior across multiple modalities has seen limited advances in the literature. This is largely due to multiple complicated variables commonly encountered in the clinical setting, such as analyzing subtle physical movements when the patient is covered or room lighting is inadequate. Semiology encompasses the stepwise/temporal progression of signs that is reflective of the integration of connected neuronal networks. Thus, single signs in isolation are far less informative. Taking this into account, here, we describe a novel modular, hierarchical, multimodal system that aims to detect and quantify semiologic signs recorded in 2D monitoring videos. Our approach can jointly learn semiologic features from facial, body, and hand motions based on computer vision and deep learning architectures. A dataset collected from an Australian quaternary referral epilepsy unit analyzing 161 seizures arising from the temporal (n = 90) and extratemporal (n = 71) brain regions has been used in our system to quantitatively classify these types of epilepsy according to the semiology detected. A leave-one-subject-out (LOSO) cross-validation of semiological patterns from the face, body, and hands reached classification accuracies ranging between 12% and 83.4%, 41.2% and 80.1%, and 32.8% and 69.3%, respectively. The proposed hierarchical multimodal system is a potential stepping-stone towards developing a fully automated semiology analysis system to support the assessment of epilepsy.","Ahmedt-Aristizabal D
Fookes C
Denman S
Nguyen K
Fernando T
Sridharan S
Dionisio S
","(PMID:30173017
)",A hierarchical multimodal system for motion analysis in patients with epilepsy.,https://europepmc.org/abstract/MED/30173017%0A
"In this work, we extend measures of distance between permutations to support incomplete permutations. Modeling and comparing incomplete permutations are a challenging computational problem of practical importance in many applications in bioinformatics and social science. We show that the proposed distance measure admits a closed-form expression and can be efficiently computed on sets of permutations involving several missing elements. We demonstrate the proposed method on the classification of bacteria from different phyla based on gene order.","Zhou X
Amir A
Guerra C
Landau G
Rossignac J
","(PMID:30113868
)",EDoP Distance Between Sets of Incomplete Permutations: Application to Bacteria Classification Based on Gene Order.,https://europepmc.org/abstract/MED/30113868%0A
"Biomarker detection is one of the more important biomedical questions for high-throughput 'omics' researchers, and almost all existing biomarker detection algorithms generate one biomarker subset with the optimized performance measurement for a given dataset. However, a recent study demonstrated the existence of multiple biomarker subsets with similarly effective or even identical classification performances. This protocol presents a simple and straightforward methodology for detecting biomarker subsets with binary classification performances, better than a user-defined cutoff. The protocol consists of data preparation and loading, baseline information summarization, parameter tuning, biomarker screening, result visualization and interpretation, biomarker gene annotations, and result and visualization exportation at publication quality. The proposed biomarker screening strategy is intuitive and demonstrates a general rule for developing biomarker detection algorithms. A user-friendly graphical user interface (GUI) was developed using the programming language Python, allowing biomedical researchers to have direct access to their results. The source code and manual of kSolutionVis can be downloaded from http://www.healthinformaticslab.org/supp/resources.php.","Feng X
Wang S
Liu Q
Li H
Liu J
Xu C
Yang W
Shu Y
Zheng W
Yu B
Qi M
Zhou W
Zhou F
","(PMID:30371672
)",Selecting Multiple Biomarker Subsets with Similarly Effective Binary Classification Performances.,https://europepmc.org/abstract/MED/30371672%0A
"Nucleosome is a central element of eukaryotic chromatin, which composes of histone proteins and DNA molecules. It performs vital roles in many eukaryotic intra-nuclear processes, for instance, chromatin structure and transcriptional regulation formation. Identification of nucleosome positioning via wet lab is difficult; so, the attention is diverted towards the accurate intelligent automated prediction. In this regard, a novel intelligent automated model ""iNuc-ext-PseTNC"" is developed to identify the nucleosome positioning in genomes accurately. In this predictor, the sequences of DNA are mathematically represented by two different discrete feature extraction techniques, namely pseudo-tri-nucleotide composition (PseTNC) and pseudo-di-nucleotide composition. Several contemporary machine learning algorithms were examined. Further, the predictions of individual classifiers were integrated through an evolutionary genetic algorithm. The success rates of the ensemble model are higher than individual classifiers. After analyzing the prediction results, it is noticed that iNuc-ext-PseTNC model has achieved better performance in combination with PseTNC feature space, which are 94.3%, 93.14%, and 88.60% of accuracies using six-fold cross-validation test for the three benchmark datasets S1, S2, and S3, respectively. The achieved outcomes exposed that the results of iNuc-ext-PseTNC model are prominent compared to the existing methods so far notifiable in the literature. It is ascertained that the proposed model might be more fruitful and a practical tool for rudimentary academia and research.","Tahir M
Hayat M
Khan SA
","(PMID:30291426
)",iNuc-ext-PseTNC: an efficient ensemble model for identification of nucleosome positioning by extending the concept of Chou's PseAAC to pseudo-tri-nucleotide composition.,https://europepmc.org/abstract/MED/30291426%0A
"Drug-disease associations provide important information for drug discovery and drug repositioning. Drug-disease associations can induce different effects, and the therapeutic effect attracts wide spread interest. Therefore, developing drug-disease association prediction methods is an important task, and differentiating therapeutic associations from other associations is also very important. In this paper, we formulate the known drug-disease associations as a bipartite network, and then present a novel representation for drugs and diseases based on the bipartite network and linear neighborhood similarity. Thus, we propose the network topological similarity-based inference method (NTSIM) to predict unobserved drug-disease associations. Further, we extend the work to the association classification, and propose the network topological similarity-based classification method (NTSIM-C) to differentiate therapeutic associations from others. Compared with existing drug-disease association prediction methods, NTSIM can produce superior performances in predicting drug-disease associations, and NTSIM-C can accurately classify drug-disease associations. Further, we analyze the capability of proposed methods by using several case studies. The studies show the usefulness of NTSIM and NTSIM-C in the real applications. In conclusion, NTSIM and NTSIM-C are promising for predicting drug-disease associations and their therapeutic functions.","Zhang W
Yue X
Huang F
Liu R
Chen Y
Ruan C
","(PMID:29879508
)",Predicting drug-disease associations and their therapeutic function based on the drug-disease association bipartite network.,https://europepmc.org/abstract/MED/29879508%0A
"Personal health records (PHRs) offer patients a portal to view lab results, communicate with their doctors, and refill medications. Expanding PHR access to mobile devices could increase patients' engagement with their PHRs. We examined whether access to a mobile-optimized PHR changed the frequency and timeliness of PHR use among adult patients with diabetes in an integrated delivery system. Among patients originally using the PHR only by computer, PHR use frequency increased with mobile access. Non-White patients were more likely to view their lab results within 7 days if they had computer and mobile access compared with computer only; however, there were no statistically significant differences among White patients. More frequent and timely mobile access to PHR data and tools may lead to convenient and effective PHR engagement to support patient self-management. Future studies should evaluate whether PHR use with a mobile device is associated with changes in self-management and outcomes.","Graetz I
Huang J
Brand R
Hsu J
Reed ME
","(PMID:30358866
)",Mobile-accessible personal health records increase the frequency and timeliness of PHR use for patients with diabetes.,https://europepmc.org/abstract/MED/30358866%0A
"Magnetic dummy molecularly imprinted polymers (MDMIPs) were prepared by combining the surface imprinting technique with computer simulation for selective recognition of phthalate esters (PAEs). A computational study based on the density functional theory was performed to evaluate the template-monomer geometry and interaction energy in the prepolymerization mixture. The MDMIPs were characterized by transmission electron microscopy, scanning electron microscopy, vibrating sample magnetometry, X-ray diffraction, and Fourier transform infrared spectroscopy. They exhibited (a) high saturation magnetization of 53.14 emu g-1 (leading to fast separation), and (b) large adsorption capacity, fast binding kinetics, and high selectivity for PAEs. Subsequently, a molecularly imprinted solid-phase extraction procedure followed by GC-MS was established for selective extraction and determination of 10 PAEs in food samples. Under the optimal experimental conditions, the response (peak area) was linear in the 0.5-100 ng mL-1 concentration range. The limits of detection ranged from 0.15 to 1.64 ng g-1. The method was applied to the determination of PAEs in spiked real samples. The recoveries for 10 PAEs from various foods were in the range of 73.7%-98.1%, with relative standard deviations of 1.7%-10.2%. Graphical abstract Magnetic dummy molecularly imprinted polymers (MDMIPs) were prepared and successfully were applied as a special sorbent for the selective recognition and fast enrichment of 10 PAEs from different complex matrix.","Lu C
Tang Z
Gao X
Ma X
Liu C
","(PMID:30003399
)",Computer-aided design of magnetic dummy molecularly imprinted polymers for solid-phase extraction of ten phthalates from food prior to their determination by GC-MS/MS.,https://europepmc.org/abstract/MED/30003399%0A
"Recently, we showed that presenting salient names (i.e., a participant's first name) on the fringe of awareness (in rapid serial visual presentation, RSVP) breaks through into awareness, resulting in the generation of a P3, which (if concealed information is presented) could be used to differentiate between deceivers and nondeceivers. The aim of the present study was to explore whether face stimuli can be used in an ERP-based RSVP paradigm to infer recognition of broadly familiar faces. To do this, we explored whether famous faces differentially break into awareness when presented in RSVP and, importantly, whether ERPs can be used to detect these breakthrough events on an individual basis. Our findings provide evidence that famous faces are differentially perceived and processed by participants' brains as compared to novel (or unfamiliar) faces. EEG data revealed large differences in brain responses between these conditions.","Alsufyani A
Hajilou O
Zoumpoulaki A
Filetti M
Alsufyani H
Solomon CJ
Gibson SJ
Alroobaea R
Bowman H
","(PMID:30288755
)",Breakthrough percepts of famous faces.,https://europepmc.org/abstract/MED/30288755%0A
"OBJECTIVE:Diabetic retinopathy (DR) is one of the most serious complications of diabetes. Early detection and treatment of DR are key public health interventions that can significantly reduce the risk of vision loss. How to effectively screen and diagnose the retinal fundus image in order to identify retinopathy in time is a major challenge. In the traditional DR screening system, the accuracy of micro-aneurysm (MA) and hemorrhagic (H) lesion detection determines the final screening performance. The detection method produced a large number of false positive samples for guaranteeing high sensitivity, and the classification model was not effective in removing false positives since the suspicious lesions lack label information. METHODS:In order to solve the problem of supervised learning in the diagnosis of DR, we formulate weakly supervised multi-class DR grading as a multi-class multi-instance problem where each image (bag) is labeled as healthy or abnormal and consists of unlabeled candidate lesion regions (instances). Specifically, we proposed a multi-kernel multi-instance learning method based on graph kernel. Moreover, we develop an under-sampling from instance level and over-sampling from bag level to improve the performance of the multi-instance learning in the diagnosis of DR. RESULTS:Through empirical evaluation and comparison with different baselinemethods and the state-of-the-art methods on data from Messidor, we illustrate that the proposed method reports favorable results, with an overall classification accuracy of 0.916 and an AUC of 0.957. CONCLUSIONS:The experiments results demonstrate that the proposed multi-kernel multi-instance learning framework with bi-level re-sampling can solve the problem in the imbalanced and weakly supervised data for grading diabetic retinopathy, and it improves the diagnosis performance over several state-of-the-art competing methods.","Cao P
Ren F
Wan C
Yang J
Zaiane O
","(PMID:30237145
)",Efficient multi-kernel multi-instance learning using weakly supervised and imbalanced data for diabetic retinopathy diagnosis.,https://europepmc.org/abstract/MED/30237145%0A
The present study proposes a computational method to identify the unloaded corneal shape based on the prescribed surface profile of the cornea acquired from in vivo measurements. Variational shape optimization of the unloaded corneal shape was formulated to satisfy that the corneal shape at the mechanical equilibrium state in the physiological situation corresponded to the prescribed surface profile. The shape variation was calculated using the Lagrange multiplier method with a finite element solution. Numerical solution showed that the optimized corneal shape was in excellent agreement with the prescribed surface profile of the cornea without μm-scale surface irregularities.,"Otani T
Tanaka M
","(PMID:30370799
)",Unloaded shape identification of human cornea by variational shape optimization.,https://europepmc.org/abstract/MED/30370799%0A
"In scanning electron microscopy (SEM), an intensive beam of electrons is utilized to generate high-quality images that can be used across scientific disciplines including biology and medicine. However, the images produced by different SEM devices are often degraded by a low-contrast effect as a result of various existing limitations. Hence, an improved contrast equalization technique is proposed in this article to ameliorate the contrast of SEM images and provide better visual quality results. The proposed technique consists of two major phases; the first includes a two-step regularization process used to regularize the intensities of the input image, while the second includes a two-step mapping process used to further improve the contrast and to remap image intensities to their natural dynamic range. The proposed technique is tested with many real-degraded and synthetic-degraded SEM images, and its results are compared with six well-known contrast enhancement techniques. Accordingly, the comparison results are evaluated using four advanced image quality assessment metrics. Intensive experiments and comparisons exhibited the favorability of the proposed technique, in that it provided visually pleasing results with no visible flaws and outperformed the comparison techniques in terms of perceived quality and scored accuracy.","Al-Ameen Z
","(PMID:30198214
)",An improved contrast equalization technique for contrast enhancement in scanning electron microscopy images.,https://europepmc.org/abstract/MED/30198214%0A
"OBJECTIVE:Increasing physical activity has been identified as one of the most important factors in lifestyle modification. Previous studies have reported the effectiveness of using the Internet in motivating behavioral modifications of physical activities. The aim of this study is to identify the persuasive system features most frequently used in computer-mediated physical activities in the current literature. MATERIALS AND METHODS:In this review, intervention studies were identified through a structured computerized search of PubMed, PsychInfo, and Web of Science. The results of the search were analyzed using the persuasive systems design (PSD) features identified by Oinas-Kukkonen and Harjumaa (2009). RESULTS:Thirty-eight articles were reviewed, and the features of the physical activity interventions described were mapped to the identified facets of PSD. The PSD features used most often by researchers in the studies considered in this research included tailoring, tunneling, reminders, trustworthiness, and expertise. The effectiveness of the interventions described in the studies was also compared. The stage of change theory was applied in several intervention studies, and the importance of stage of change has been identified in effectiveness of persuasion toward physical activity.","Win KT
Roberts MRH
Oinas-Kukkonen H
","(PMID:30351975
)",Persuasive system features in computer-mediated lifestyle modification interventions for physical activity.,https://europepmc.org/abstract/MED/30351975%0A
"Distinct electrophysiological phenotypes are exhibited by biological cells that have differentiated into particular cell types. The usual approach when simulating the cardiac electrophysiology of tissue that includes different cell types is to model the different cell types as occupying spatially distinct yet coupled regions. Instead, we model the electrophysiology of well-mixed cells by using homogenisation to derive an extension to the commonly used monodomain or bidomain equations. These new equations permit spatial variations in the distribution of the different subtypes of cells and will reduce the computational demands of solving the governing equations. We validate the homogenisation computationally, and then use the new model to explain some experimental observations from stem cell-derived cardiomyocyte monolayers.","Bowler LA
Gavaghan DJ
Mirams GR
Whiteley JP
","(PMID:30291590
)",Representation of Multiple Cellular Phenotypes Within Tissue-Level Simulations of Cardiac Electrophysiology.,https://europepmc.org/abstract/MED/30291590%0A
"The TP53 gene is frequently mutated in human cancer. Research has focused predominantly on six major ""hotspot"" codons, which account for only ∼30% of cancer-associated p53 mutations. To comprehensively characterize the consequences of the p53 mutation spectrum, we created a synthetically designed library and measured the functional impact of ∼10,000 DNA-binding domain (DBD) p53 variants in human cells in culture and in vivo. Our results highlight the differential outcome of distinct p53 mutations in human patients and elucidate the selective pressure driving p53 conservation throughout evolution. Furthermore, while loss of anti-proliferative functionality largely correlates with the occurrence of cancer-associated p53 mutations, we observe that selective gain-of-function may further favor particular mutants in vivo. Finally, when combined with additional acquired p53 mutations, seemingly neutral TP53 SNPs may modulate phenotypic outcome and, presumably, tumor progression.","Kotler E
Shani O
Goldfeld G
Lotan-Pompan M
Tarcic O
Gershoni A
Hopf TA
Marks DS
Oren M
Segal E
","(PMID:29979965
)",A Systematic p53 Mutation Library Links Differential Functional Impact to Cancer Mutation Pattern and Evolutionary Conservation.,https://europepmc.org/abstract/MED/29979965%0A
"PURPOSE:The purpose of this study was to correlate diffusion and perfusion quantitative and semi-quantitative MR parameters, on patients with peripheral arterial disease. In addition, we investigated which perfusion model better describes the behavior of the dynamic contrast-enhanced (DCE) MR data signal on ischemic regions of the lower limb. METHODS:Linear and nonlinear least squares algorithms, were incorporated for the quantification of the parameters through a variety of widely used models, able to extract physiological information from each imaging technique. All numerical calculations were implemented in Python 3.5 and include the: Intra voxel incoherent motion for diffusion and Patlak's, Extended Toft's and Gamma Capillary Transit time (GCTT) models for perfusion MRI. RESULTS:Our initial voxel by voxel correlation analysis didn't show any significant correlation based on the Pearson's Correlation metric between diffusion and perfusion parameters. To account for the inherited noise from the raw data, a Gaussian filter was applied to the parametric maps in order for the data to be comparable. By repeating our analysis in the filtered image maps, a good correlation (>0.5) of diffusion and perfusion parameters was achieved. CONCLUSIONS:Perfusion and diffusion MRI quantitative and semi-quantitative parameters can be obtained through a variety of physiological-pharmacokinetic models. This paper compares most of the widely-known models and parameters in both techniques with data from patients with peripheral arterial disease. Initial analysis showed no correlation in the perfusion parametric maps of DWI and DCE MRI data but a good correlation was obtained after smoothing the parametric maps indicating that perfusion information could be obtained from diffusion MRI images in patients with peripheral arterial disease.","Ioannidis GS
Marias K
Galanakis N
Perisinakis K
Hatzidakis A
Tsetis D
Karantanas A
Maris TG
","(PMID:30121254
)",A correlative study between diffusion and perfusion MR imaging parameters on peripheral arterial disease data.,https://europepmc.org/abstract/MED/30121254%0A
"BACKGROUND AND OBJECTIVE:Drug-target interaction prediction plays an intrinsic role in the drug discovery process. Prediction of novel drugs and targets helps in identifying optimal drug therapies for various stringent diseases. Computational prediction of drug-target interactions can help to identify potential drug-target pairs and speed-up the process of drug repositioning. In our present, work we have focused on machine learning algorithms for predicting drug-target interactions from the pool of existing drug-target data. The key idea is to train the classifier using existing DTI so as to predict new or unknown DTI. However, there are various challenges such as class imbalance and high dimensional nature of data that need to be addressed before developing optimal drug-target interaction model. METHODS:In this paper, we propose a bagging based ensemble framework named BE-DTI' for drug-target interaction prediction using dimensionality reduction and active learning to deal with class-imbalanced data. Active learning helps to improve under-sampling bagging based ensembles. Dimensionality reduction is used to deal with high dimensional data. RESULTS:Results show that the proposed technique outperforms the other five competing methods in 10-fold cross-validation experiments in terms of AUC=0.927, Sensitivity=0.886, Specificity=0.864, and G-mean=0.874. CONCLUSION:Missing interactions and new interactions are predicted using the proposed framework. Some of the known interactions are removed from the original dataset and their interactions are recalculated to check the accuracy of the proposed framework. Moreover, validation of the proposed approach is performed using the external dataset. All these results show that structurally similar drugs tend to interact with similar targets.","Sharma A
Rani R
","(PMID:30337070
)",BE-DTI': Ensemble framework for drug target interaction prediction using dimensionality reduction and active learning.,https://europepmc.org/abstract/MED/30337070%0A
"The assembling of the soluble N-ethylmaleimide-sensitive factor attachment protein receptor protein complex is a fundamental step in neuronal exocytosis, and it has been extensively studied in the last two decades. Yet, many details of this process remain inaccessible with the current experimental space and time resolution. Here, we study the zipping mechanism of the soluble N-ethylmaleimide-sensitive factor attachment protein receptor complex computationally by using a coarse-grained model. We explore the different pathways available and analyze their dependence on the computational model employed. We reveal and characterize multiple intermediate states, in agreement with previous experimental findings. We use our model to analyze the influence of single-residue mutations on the thermodynamics of the folding process.","Pinamonti G
Campo G
Chen J
Kluber A
Clementi C
","(PMID:30268539
)",Simulations Reveal Multiple Intermediates in the Unzipping Mechanism of Neuronal SNARE Complex.,https://europepmc.org/abstract/MED/30268539%0A
"The investigation of the luminescence properties of CdTe/KBr composites with encapsulated quantum dots (QDs) of different sizes was performed and the influence of the KBr matrix on the luminescence properties of CdTe QDs was studied. Encapsulation of nanoparticles by a solid matrix caused a bathochromic shift in the luminescence peak and the shift value was the larger the smaller the size of the quantum dots. Interband quantum transition theory was used to explain the influence of the matrix on the luminescence properties of the capsulated CdTe QDs. Theoretical calculations showed that the observed QD luminescence peak corresponded to a 1 s-1 s electronic transition, and its low-energy shift after the transfer of QDs from dielectric water to the KBr matrix was due to a corresponding decrease in the depths of electrons and holes potential wells.","Okrepka G
Khalavka Y
Seti Y
","(PMID:30328244
)",Influence of the KBr matrix on the luminescence properties of CdTe quantum dots.,https://europepmc.org/abstract/MED/30328244%0A
"In the current study, we investigated the ways in which the acquisition and transfer of spatial knowledge were affected by (a) the type of spatial relations predominately experienced during learning (routes determined by walkways vs. straight-line paths between locations); (b) environmental complexity; and (c) the availability of rotational body-based information. Participants learned the layout of a virtual shopping mall by repeatedly searching for target storefronts located in 1 of the buildings. We created 2 novel learning conditions to encourage participants to use either route knowledge (paths on walkways between buildings) or survey knowledge (straight-line distances and directions from storefront to storefront) to find the target, and measured the development of route and survey knowledge in both learning conditions. Environmental complexity was manipulated by varying the alignment of the buildings with the enclosure, and the visibility within space. Body-based information was manipulated by having participants perform the experiment in front of a computer monitor or using a head-mounted display. After navigation, participants pointed to various storefronts from a fixed position and orientation. Results showed that the frequently used spatial knowledge could be developed similarly across environments with different complexities, but the infrequently used spatial knowledge was less developed in the complex environment. Furthermore, rotational body-based information facilitated spatial learning under certain conditions. Our results suggest that path integration may play an important role in spatial knowledge transfer, both from route to survey knowledge (cognitive map construction), and from survey to route knowledge (using cognitive map to guide wayfinding). (PsycINFO Database Record","He Q
McNamara TP
Bodenheimer B
Klippel A
","(PMID:30124310
)",Acquisition and transfer of spatial knowledge during wayfinding.,https://europepmc.org/abstract/MED/30124310%0A
"The emergence of numerous genome projects has made the experimental classification of the protein localization almost impossible due to the exponential increase in the number of protein samples. However, most of the applications are merely developed for single-plex and completely ignored the presence of one protein at two or more locations in a cell. In this regard, few attempts were carried out to target Multi-label protein localizations; consequently, undesirable accuracies are achieved. This paper presents a novel approach, in which a discrete feature extraction method is fused with physicochemical properties of amino acids by using Chou's general form of Pseudo Amino Acid Composition. The technique is tested on two benchmark datasets namely: Gpos-mploc and Virus-mPLoc. The empirical results demonstrated that the proposed method yields better results via two examined classifiers i.e. ML-KNN and Rank-SVM. It is established that the proposed model has improved values in all performance measures considered for the comparison.","Javed F
Hayat M
","(PMID:30196077
)",Predicting subcellular localization of multi-label proteins by incorporating the sequence features into Chou's PseAAC.,https://europepmc.org/abstract/MED/30196077%0A
"<label>OBJECTIVE</label>To identify the common aeroallergens causing allergy symptoms among the allergic rhinitis patients.<label>STUDY DESIGN</label>Cross-sectional study.<label>PLACE AND DURATION OF STUDY</label>Department of Immunology, Armed Forces Institute of Pathology (AFIP), Rawalpindi, from January to July 2016.<label>METHODOLOGY</label>Patients with a clinical diagnosis of allergic rhinitis were enrolled. Skin Prick Test (SPT) was performed on these patients using 12 common aeroallergens along with positive (histamine hydrochloride, 10 mg/ml) and negative (glycerin saline) controls. Results were recorded after 15 minutes, considering a wheal diameter >3 mm as positive. Chi-square test was used to compare frequencies; and p-value of less than 0.05 was considered significant.<label>RESULTS</label>Out of 130 patients, 78 (60%) were males and 52 (40%) were females. The rate of sensitization to any allergen was 90%. One hundred and two (78%) were poly-sensitized to more than two allergens and 20% were sensitized to more than six allergens. Most common outdoor and indoor allergens were Broussonetia papyrifera (50.7%) and Dermatophagoides farina (42.3%), respectively. Dog epithelia and aspergillus were the least prevalent allergens (13.8% each).<label>CONCLUSION</label>This study highlighted an increased overall frequency of sensitization to any allergen and significance of tree and weed allergens; especially, Broussonetia papyrifera and Cannabis sativa. It also emphasized increased prevalence of skin reactivity to indoor allergen, Dermatophagoides farina in the city.","Saleem N
Waqar S
Shafi A
","(PMID:30266121
)",Skin Prick Test Reactivity to Common Aeroallergens among Allergic Rhinitis Patients.,https://europepmc.org/abstract/MED/30266121%0A
"Cancer belongs to a class of highly aggressive diseases and a leading cause of death in the world. With more than 100 types of cancers, breast, lung and prostate cancer remain to be the most common types. To identify essential network markers (NMs) and therapeutic targets in these cancers, the authors present a novel approach which uses gene expression data from microarray and RNA-seq platforms and utilises the results from this data to evaluate protein-protein interaction (PPI) network. Differentially expressed genes (DEGs) are extracted from microarray data using three different statistical methods in R, to produce a consistent set of genes. Also, DEGs are extracted from RNA-seq data for the same three cancer types. DEG sets found to be common in both platforms are obtained at three fold change (FC) cut-off levels to accurately identify the level of change in expression of these genes in all three cancers. A cancer network is built using PPI data characterising gene sets at log-FC (LFC)>1, LFC>1.5 and LFC>2, and interconnection between principal hub nodes of these networks is observed. Resulting network of hubs at three FC levels highlights prime NMs with high confidence in multiple cancers as validated by Gene Ontology functional enrichment and maximal complete subgraphs from CFinder.","Makhijani RK
Raut SA
Purohit HJ
","(PMID:30259866
)","Fold change based approach for identification of significant network markers in breast, lung and prostate cancer.",https://europepmc.org/abstract/MED/30259866%0A
"In the post-genome age, it is more urgent to understand the functions of genes and proteins. Since experimental methods are usually costly and time consuming, computational predictions are recognized as an alternative approach. In developing a predictive method for functional genomics and proteomics, one of the most important steps is to represent biological sequences with a fixed length numerical form, which can be further analyzed using machine learning algorithms. Chou's pseudo-amino acid compositions and the pseudo k-nucleotide compositions are algorithms for this purpose. Since the appearance of these algorithms, several software tools have been developed as implementations. These software tools facilitate the application of these algorithms. As these software tools are developed with different technologies and for different application scenarios, we will briefly review the technical aspect of these software tools in this short review.","Zhao W
Wang L
Zhang TX
Zhao ZN
Du PF
","(PMID:30182829
)",A brief review on software tools in generating Chou's pseudo-factor representations for all types of biological sequences.,https://europepmc.org/abstract/MED/30182829%0A
"Electric power line equipment such as insulators, cut-out-switches, and lightning-arresters play important roles in ensuring a safe and uninterrupted power supply. Unfortunately, their continuous exposure to rugged environmental conditions may cause physical or electrical defects in them which may lead to the failure to the electrical system. In this paper, we present an automatic real-time electrical equipment detection and defect analysis system. Unlike previous handcrafted feature-based approaches, the proposed system utilizes a Convolutional Neural Network (CNN)-based equipment detection framework, making it possible to detect 17 different types of powerline insulators in a highly cluttered environment. We also propose a novel rotation normalization and ellipse detection method that play vital roles in the defect analysis process. Finally, we present a novel defect analyzer that is capable of detecting gunshot defects occurring in electrical equipment. The proposed system uses two cameras; a low-resolution camera that detects insulators from long-shot images, and a high-resolution camera which captures close-shot images of the equipment at high-resolution that helps for effective defect analysis. We demonstrate the performances of the proposed real-time equipment detection with up to 93% recall with 92% precision, and defect analysis system with up to 98% accuracy, on a large evaluation dataset. Experimental results show that the proposed system achieves state-of-the-art performance in automatic powerline equipment inspection.","Siddiqui ZA
Park U
Lee SW
Jung NJ
Choi M
Lim C
Seo JH
","(PMID:30413123
)",Robust Powerline Equipment Inspection System Based on a Convolutional Neural Network.,https://europepmc.org/abstract/MED/30413123%0A
"Genotype imputation has been widely utilized for two reasons in the analysis of genome-wide association studies (GWAS). One reason is to increase the power for association studies when causal single nucleotide polymorphisms are not collected in the GWAS. The second reason is to aid the interpretation of a GWAS result by predicting the association statistics at untyped variants. In this article, we show that prediction of association statistics at untyped variants that have an influence on the trait produces is overly conservative. Current imputation methods assume that none of the variants in a region (locus consists of multiple variants) affect the trait, which is often inconsistent with the observed data. In this article, we propose a new method, CAUSAL-Imp, which can impute the association statistics at untyped variants while taking into account variants in the region that may affect the trait. Our method builds on recent methods that impute the marginal statistics for GWAS by utilizing the fact that marginal statistics follow a multivariate normal distribution. We utilize both simulated and real data sets to assess the performance of our method. We show that traditional imputation approaches underestimate the association statistics for variants involved in the trait, and our results demonstrate that our approach provides less biased estimates of these association statistics.","Wu Y
Hormozdiari F
Joo JWJ
Eskin E
","(PMID:30272994
)",Improving Imputation Accuracy by Inferring Causal Variants in Genetic Studies.,https://europepmc.org/abstract/MED/30272994%0A
"Visual cortex forms the basis of visual processing and plays important roles in visual encoding. By using the recently published Allen Brain Observatory dataset consisting of large-scale calcium imaging of mouse V1 activities under visual stimuli, we were able to obtain high-quality data capturing simultaneous neuronal activities at multiple sub-areas and cortical depths of V1. Using prediction models, we analyzed the activity profiles related to static and drifting grating stimuli. We conducted a comprehensive survey of the coding ability of multiple cortical locations toward different stimulus attributes. Specifically, we focused on orientations and spatial frequencies (for static stimuli), as well as moving directions and speed (for drifting stimuli). By using results produced from a prediction model, we quantified the decoding performance profile at different sub-areas and layers of V1. In addition, we analyzed the interactions and interference between different stimulus attributes. The insights obtained from these discoveries would contribute to more precise and quantitative understanding of V1 coding mechanisms.","Cai L
Wu B
Ji S
","(PMID:29404932
)",Neuronal Activities in the Mouse Visual Cortex Predict Patterns of Sensory Stimuli.,https://europepmc.org/abstract/MED/29404932%0A
"The increasing expansion of the cities together with activities carried out on the environment by men have contributed to the deterioration of air quality. Air quality index measures how much air is free from pollution. Being aware of the healthiness of the breathed air is a right for the people. Public authorities must constantly inform the population on air quality status. Even though several pollutants are monitored by the air quality monitoring networks, providing a significant amount of data, their interpretation and presentation to the population by the public authorities is a difficult task. Some countries, for several years, have adopted evaluation procedures through daily indices that succinctly describe the air quality status in different areas of the city. The use of an index which is able to give a simple and quick information to the population represents a possible solution for the public authorities. Concerning a Mediterranean area, it has not yet been possible to adopt a single indicator to be used for informing the population. In this work, the air quality status is highlighted by the air quality index (AQI) whose purpose is to inform, in a simple and immediate way, the population. Analyzing the AQI's trend from 2013 to 2015, it was possible to assess the air quality status, obtaining an overall scenario for the purpose of protecting human health and the ecosystems. We point out that this kind of research could be applied to every region or municipality.","Monforte P
Ragusa MA
","(PMID:30280278
)",Evaluation of the air pollution in a Mediterranean region by the air quality index.,https://europepmc.org/abstract/MED/30280278%0A
"Efficient matching of incoming events of data streams to persistent queries is fundamental to event stream processing systems in wireless sensor networks. These applications require dealing with high volume and continuous data streams with fast processing time on distributed complex event processing (CEP) systems. Therefore, a well-managed parallel processing technique is needed for improving the performance of the system. However, the specific properties of pattern operators in the CEP systems increase the difficulties of the parallel processing problem. To address these issues, a parallelization model and an adaptive parallel processing strategy are proposed for the complex event processing by introducing a histogram and utilizing the probability and queue theory. The proposed strategy can estimate the optimal event splitting policy, which can suit the most recent workload conditions such that the selected policy has the least expected waiting time for further processing of the arriving events. The proposed strategy can keep the CEP system running fast under the variation of the time window sizes of operators and the input rates of streams. Finally, the utility of our work is demonstrated through the experiments on the StreamBase system.","Xiao F
Aritsugi M
","(PMID:30400158
)",An Adaptive Parallel Processing Strategy for Complex Event Processing Systems over Data Streams in Wireless Sensor Networks.,https://europepmc.org/abstract/MED/30400158%0A
"PURPOSE:To develop a deep learning bone age assessment model based on pelvic radiographs for forensic age estimation and compare its performance to that of the existing cubic regression model. MATERIALS AND METHOD:A retrospective collection data of 1875 clinical pelvic radiographs between 10 and 25 years of age was obtained to develop the model. Model performance was assessed by comparing the testing results to estimated ages calculated directly using the existing cubic regression model based on ossification staging methods. The mean absolute error (MAE) and root-mean-squared error (RMSE) between the estimated ages and chronological age were calculated for both models. RESULTS:For all test samples (between 10 and 25 years old), the mean MAE and RMSE between the automatic estimates using the proposed deep learning model and the reference standard were 0.94 and 1.30 years, respectively. For the test samples comparable to those of the existing cubic regression model (between 14 and 22 years old), the mean MAE and RMSE for the deep learning model were 0.89 and 1.21 years, respectively. For the existing cubic regression model, the mean MAE and RMSE were 1.05 and 1.61 years, respectively. CONCLUSION:The deep learning convolutional neural network model achieves performance on par with the existing cubic regression model, demonstrating predictive ability capable of automated skeletal bone assessment based on pelvic radiographic images. KEY POINTS:• The pelvis has considerable value in determining the bone age. • Deep learning can be used to create an automated bone age assessment model based on pelvic radiographs. • The deep learning convolutional neural network model achieves performance on par with the existing cubic regression model.","Li Y
Huang Z
Dong X
Liang W
Xue H
Zhang L
Zhang Y
Deng Z
","(PMID:30402703
)",Forensic age estimation for pelvic X-ray images using deep learning.,https://europepmc.org/abstract/MED/30402703%0A
"BACKGROUND:Nowadays, according to valuable resources of high-quality genome sequences, reference-based assembly methods with high accuracy and efficiency are strongly required. Many different algorithms have been designed for mapping reads onto a genome sequence which try to enhance the accuracy of reconstructed genomes. In this problem, one of the challenges occurs when some reads are aligned to multiple locations due to repetitive regions in the genomes. RESULTS:In this paper, our goal is to decrease the error rate of rebuilt genomes by resolving multi-mapping reads. To achieve this purpose, we reduce the search space for the reads which can be aligned against the genome with mismatches, insertions or deletions to decrease the probability of incorrect read mapping. We propose a pipeline divided to three steps: ExactMapping, InExactMapping, and MergingContigs, where exact and inexact reads are aligned in two separate phases. We test our pipeline on some simulated and real data sets by applying some read mappers. The results show that the two-step mapping of reads onto the contigs generated by a mapper such as Bowtie2, BWA and Yara is effective in improving the contigs in terms of error rate. CONCLUSIONS:Assessment results of our pipeline suggest that reducing the error rate of read mapping, not only can improve the genomes reconstructed by reference-based assembly in a reasonable running time, but can also have an impact on improving the genomes generated by de novo assembly. In fact, our pipeline produces genomes comparable to those of a multi-mapping reads resolution tool, namely MMR by decreasing the number of multi-mapping reads. Consequently, we introduce EIM as a post-processing step to genomes reconstructed by mappers.","Salari F
Zare-Mirakabad F
Sadeghi M
Rokni-Zadeh H
","(PMID:30400807
 PMCID:PMC6220446)",Assessing the impact of exact reads on reducing the error rate of read mapping.,https://europepmc.org/abstract/MED/30400807%0A
"The efficient operation of wastewater treatment plants (WWTPs) is key to ensuring a sustainable and friendly green environment. Monitoring wastewater processes is helpful not only for evaluating the process operating conditions but also for inspecting product quality. This paper presents a flexible and efficient fault detection approach based on unsupervised deep learning to monitor the operating conditions of WWTPs. Specifically, this approach integrates a deep belief networks (DBN) model and a one-class support vector machine (OCSVM) to separate normal from abnormal features by simultaneously taking advantage of the feature-extraction capability of DBNs and the superior predicting capacity of OCSVM. Here, the DBN model, which is a powerful tool with greedy learning features, accounts for the nonlinear aspects of WWTPs, while OCSVM is used to reliably detect the faults. The developed DBN-OCSVM approach is tested through a practical application on data from a decentralized WWTP in Golden, CO, USA. The results from the DBN-OCSVM are compared with two other detectors: DBN-based K-nearest neighbor and K-means algorithms. The results show the capability of the developed strategy to monitor the WWTP, suggesting that it can raise an early alert to the abnormal conditions.","Harrou F
Dairi A
Sun Y
Senouci M
","(PMID:29986328
)",Statistical monitoring of a wastewater treatment plant: A case study.,https://europepmc.org/abstract/MED/29986328%0A
"To quantify the inter-observer variability of manual delineation of lesions and organ contours in CT to establish a reference standard for volumetric measurements for clinical decision making and for the evaluation of automatic segmentation algorithms.Eleven radiologists manually delineated 3193 contours of liver tumours (896), lung tumours (1085), kidney contours (434) and brain hematomas (497) on 490 slices of clinical CT scans. A comparative analysis of the delineations was then performed to quantify the inter-observer delineation variability with standard volume metrics and with new group-wise metrics for delineations produced by groups of observers.The mean volume overlap variability values and ranges (in %) between the delineations of two observers were: liver tumours 17.8 [-5.8,+7.2]%, lung tumours 20.8 [-8.8,+10.2]%, kidney contours 8.8 [-0.8,+1.2]% and brain hematomas 18 [-6.0,+6.0] %. For any two randomly selected observers, the mean delineation volume overlap variability was 5-57%. The mean variability captured by groups of two, three and five observers was 37%, 53% and 72%; eight observers accounted for 75-94% of the total variability. For all cases, 38.5% of the delineation non-agreement was due to parts of the delineation of a single observer disagreeing with the others. No statistical difference was found for the delineation variability between the observers based on their expertise.The variability in manual delineations for different structures and observers is large and spans a wide range across a variety of structures and pathologies. Two and even three observers may not be sufficient to establish the full range of inter-observer variability.• This study quantifies the inter-observer variability of manual delineation of lesions and organ contours in CT. • The variability of manual delineations between two observers can be significant. Two and even three observers capture only a fraction of the full range of inter-observer variability observed in common practice. • Inter-observer manual delineation variability is necessary to establish a reference standard for radiologist training and evaluation and for the evaluation of automatic segmentation algorithms.","Joskowicz L
Cohen D
Caplan N
Sosna J
","(PMID:30194472
)",Inter-observer variability of manual contour delineation of structures in CT.,https://europepmc.org/abstract/MED/30194472%0A
"BACKGROUND:Software designed to accurately estimate food calories from still images could help users and health professionals identify dietary patterns and food choices associated with health and health risks more effectively. However, calorie estimation from images is difficult, and no publicly available software can do so accurately while minimizing the burden associated with data collection and analysis. OBJECTIVE:The aim of this study was to determine the accuracy of crowdsourced annotations of calorie content in food images and to identify and quantify sources of bias and noise as a function of respondent characteristics and food qualities (eg, energy density). METHODS:We invited adult social media users to provide calorie estimates for 20 food images (for which ground truth calorie data were known) using a custom-built webpage that administers an online quiz. The images were selected to provide a range of food types and energy density. Participants optionally provided age range, gender, and their height and weight. In addition, 5 nutrition experts provided annotations for the same data to form a basis of comparison. We examined estimated accuracy on the basis of expertise, demographic data, and food qualities using linear mixed-effects models with participant and image index as random variables. We also analyzed the advantage of aggregating nonexpert estimates. RESULTS:A total of 2028 respondents agreed to participate in the study (males: 770/2028, 37.97%, mean body mass index: 27.5 kg/m2). Average accuracy was 5 out of 20 correct guesses, where ""correct"" was defined as a number within 20% of the ground truth. Even a small crowd of 10 individuals achieved an accuracy of 7, exceeding the average individual and expert annotator's accuracy of 5. Women were more accurate than men (P<.001), and younger people were more accurate than older people (P<.001). The calorie content of energy-dense foods was overestimated (P=.02). Participants performed worse when images contained reference objects, such as credit cards, for scale (P=.01). CONCLUSIONS:Our findings provide new information about how calories are estimated from food images, which can inform the design of related software and analyses.","Zhou J
Bell D
Nusrat S
Hingle M
Surdeanu M
Kobourov S
","(PMID:30401671
)",Calorie Estimation From Pictures of Food: Crowdsourcing Study.,https://europepmc.org/abstract/MED/30401671%0A
"Computer vision applications in livestock are appealing since they enable measurement of traits of interest without the need to directly interact with the animals. This allows the possibility of multiple measurements of traits of interest with minimal animal stress. In the current study, an automated computer vision system was devised and evaluated for extraction of features of interest, as body measurements and shape descriptors, and prediction of body weight in pigs. From the 655 pigs that had data collected 580 had more than 5 frames recorded and were used for development of the predictive models. The cross-validation for the models developed with data from nursery and finishing pigs presented an R2 ranging from 0.86 (random selected image) to 0.94 (median of images truncated on the 3rd quartile). While, with the dataset without nursery pigs, the R2 estimates ranged from 0.70 (random selected image) to 0.84 (median of images truncated on the 3rd quartile). However, overall the mean absolute error was lower for the models fitted without data on nursery animals. From the body measures extracted from the image, body volume, area and length were the most informative for prediction of body weight. The inclusion of the remaining body measurements (width and heights) or shape descriptors to the model promoted significant improvement of the predictions, while the further inclusion of sex and line effects were not significant.","Fernandes AFA
Dórea JRR
Fitzgerald R
Herring W
Rosa GJM
","(PMID:30371785
)","A novel automated system to acquire biometric and morphological measurements, and predict body weight of pigs via 3D computer vision.",https://europepmc.org/abstract/MED/30371785%0A
No abstract provided.,"Cinelli C
Judea P
","(PMID:30272612
)",RE: A Practical Example Demonstrating the Utility of Single-world Intervention Graphs.,https://europepmc.org/abstract/MED/30272612%0A
"Phasing of diffraction data from two-dimensional crystals using only minimal molecular envelope information is investigated by simulation. Two-dimensional crystals are an attractive target for studying membrane proteins using X-ray free-electron lasers, particularly for dynamic studies at room temperature. Simulations using an iterative projection algorithm show that phasing is feasible with fairly minimal molecular envelope information, supporting recent uniqueness results for this problem [Arnal & Millane (2017). Acta Cryst. A73, 438-448]. The effects of noise and likely requirements for structure determination using X-ray free-electron laser sources are investigated.","Arnal RD
Zhao Y
Mitra AK
Spence JCH
Millane RP
","(PMID:30182940
)",The phase problem for two-dimensional crystals. II. Simulations.,https://europepmc.org/abstract/MED/30182940%0A
"Immune checkpoint blockade (ICB) therapy provides remarkable clinical gains and has been very successful in treatment of melanoma. However, only a subset of patients with advanced tumors currently benefit from ICB therapies, which at times incur considerable side effects and costs. Constructing predictors of patient response has remained a serious challenge because of the complexity of the immune response and the shortage of large cohorts of ICB-treated patients that include both 'omics' and response data. Here we build immuno-predictive score (IMPRES), a predictor of ICB response in melanoma which encompasses 15 pairwise transcriptomics relations between immune checkpoint genes. It is based on two key conjectures: (i) immune mechanisms underlying spontaneous regression in neuroblastoma can predict melanoma response to ICB, and (ii) key immune interactions can be captured via specific pairwise relations of the expression of immune checkpoint genes. IMPRES is validated on nine published datasets1-6 and on a newly generated dataset with 31 patients treated with anti-PD-1 and 10 with anti-CTLA-4, spanning 297 samples in total. It achieves an overall accuracy of AUC = 0.83, outperforming existing predictors and capturing almost all true responders while misclassifying less than half of the nonresponders. Future studies are warranted to determine the value of the approach presented here in other cancer types.","Auslander N
Zhang G
Lee JS
Frederick DT
Miao B
Moll T
Tian T
Wei Z
Madan S
Sullivan RJ
Boland G
Flaherty K
Herlyn M
Ruppin E
","(PMID:30127394
)",Robust prediction of response to immune checkpoint blockade therapy in metastatic melanoma.,https://europepmc.org/abstract/MED/30127394%0A
"PURPOSE:In this paper, we present a vein imaging system to combine reflectance mode visible spectrum images (VIS) with transmission mode near-infrared (NIR) images in real time. Clear vessel localization is achieved in this manner with combined NIR-VIS dual-modal imaging. METHODS:Transmission and reflectance mode optical instrumentation is used to combine VIS and NIR images. Two methods of displaying the combined images are demonstrated here. We have conducted experiments to determine the system's resolution, alignment accuracy, and depth penetration. Vein counts were taken from the hands of test subjects using the system and compared with vein counts taken by visual analysis. RESULTS:Results indicate that the system can improve vein detection in the human hand while detecting veins of a diameter < 0.5 mm at any working distance and of a 0.25 mm diameter at an optimal working distance of about 30 cm. The system has also been demonstrated to clearly detect silicone vessels with artificial blood of diameter 2, 1, and 0.5 mm diameter under a tissue depth of 3 mm. In a study involving 25 human subjects, we have demonstrated that vein visibility was significantly increased using our system. CONCLUSIONS:The results indicate that the device is a high-resolution solution to near-surface venous imaging. This technology can be applied for IV placement, morphological analysis for disease state detection, and biometric analysis.","Mela CA
Lemmer DP
Bao FS
Papay F
Hicks T
Liu Y
","(PMID:30291592
)",Real-time dual-modal vein imaging system.,https://europepmc.org/abstract/MED/30291592%0A
No abstract provided.,"Saria S
","(PMID:30397359
)",Individualized sepsis treatment using reinforcement learning.,https://europepmc.org/abstract/MED/30397359%0A
No abstract provided.,"Perkel JM
","(PMID:30375502
)",Why Jupyter is data scientists' computational notebook of choice.,https://europepmc.org/abstract/MED/30375502%0A
"We propose a software platform that integrates methods and tools for multi-objective parameter auto-tuning in tissue image segmentation workflows. The goal of our work is to provide an approach for improving the accuracy of nucleus/cell segmentation pipelines by tuning their input parameters. The shape, size, and texture features of nuclei in tissue are important biomarkers for disease prognosis, and accurate computation of these features depends on accurate delineation of boundaries of nuclei. Input parameters in many nucleus segmentation workflows affect segmentation accuracy and have to be tuned for optimal performance. This is a time-consuming and computationally expensive process; automating this step facilitates more robust image segmentation workflows and enables more efficient application of image analysis in large image datasets. Our software platform adjusts the parameters of a nuclear segmentation algorithm to maximize the quality of image segmentation results while minimizing the execution time. It implements several optimization methods to search the parameter space efficiently. In addition, the methodology is developed to execute on high-performance computing systems to reduce the execution time of the parameter tuning phase. These capabilities are packaged in a Docker container for easy deployment and can be used through a friendly interface extension in 3D Slicer. Our results using three real-world image segmentation workflows demonstrate that the proposed solution is able to (1) search a small fraction (about 100 points) of the parameter space, which contains billions to trillions of points, and improve the quality of segmentation output by × 1.20, × 1.29, and × 1.29, on average; (2) decrease the execution time of a segmentation workflow by up to 11.79× while improving output quality; and (3) effectively use parallel systems to accelerate parameter tuning and segmentation phases.","Taveira LFR
Kurc T
Melo ACMA
Kong J
Bremer E
Saltz JH
Teodoro G
","(PMID:30402669
)",Multi-objective Parameter Auto-tuning for Tissue Image Segmentation Workflows.,https://europepmc.org/abstract/MED/30402669%0A
"Objective: To evaluate the use of virtual planning and 3D printing modeling in mandibular reconstruction and compare the operation time and surgical outcome of this technique with conventional method. Methods: Between June 2013 and June 2017, A total of 18 patients underwent the mandibular reconstruction with fibula free flap in the Affiliated Hospital of Qingdao University.Among 18 patients, there were 11 males and 7 females with an average age of 36.5 years (21-73 years). Nine patients underwent vascularized fibula flap mandibular reconstruction using virtual planning and 3D printing modeling.Titanium plates were pre-bent using the models and cutting guides which were used for osteotomies.Another 9 patients who underwent mandibular reconstruction using fibula flap without aid of virtual planning and 3D printing models were selected as control group. The operation time was recorded and compared in two groups. Accuracy of reconstruction was measured by superimposing the preoperative image onto the postoperative image of mandible. The selected bony landmark, distance and angle were measured. Results: The mean total operation time were 4.7-6.2(5.5±0.5) h in computer-assisted group and 5.6-7.5(6.6±0.7) h in conventional group, respectively. The operation time was shorter in computer-assisted group. The difference between the preoperative and postoperative intercondylar distances, intergonial angle distances, anteroposterior distances were(2.6±1.4)vs(4.4±1.6)mm, (2.9±1.2)vs(4.7±1.7)mm, (4.2±1.4) vs(5.9±1.8)mm in the computer-assisted and conventional group, respectively. The differences between the preoperative and postoperative mandible were smaller in the computer-assisted group. Conclusions: Virtual planning and 3D printing modeling have the potential to increase mandibular reconstruction accuracy and reduce operation time. We believe that this technology for mandibular reconstruction in selected patients can significantly improve the quality of reconstruction.","Ren WH
Gao L
Li SM
Li F
Zhi Y
Song JZ
Wang QB
Xue LF
Qu ZG
Zhi KQ
","(PMID:30220156
)",[Virtual planning and 3D printing modeling for mandibular reconstruction with fibula free flap].,https://europepmc.org/abstract/MED/30220156%0A
"A prevailing way of extracting valuable information from biomedical literature is to apply text mining methods on unstructured texts. However, the massive amount of literature that needs to be analyzed poses a big data challenge to the processing efficiency of text mining. In this paper, we address this challenge by introducing parallel processing on a supercomputer. We developed paraBTM, a runnable framework that enables parallel text mining on the Tianhe-2 supercomputer. It employs a low-cost yet effective load balancing strategy to maximize the efficiency of parallel processing. We evaluated the performance of paraBTM on several datasets, utilizing three types of named entity recognition tasks as demonstration. Results show that, in most cases, the processing efficiency can be greatly improved with parallel processing, and the proposed load balancing strategy is simple and effective. In addition, our framework can be readily applied to other tasks of biomedical text mining besides NER.","Xing Y
Wu C
Yang X
Wang W
Zhu E
Yin J
","(PMID:29702574
 PMCID:PMC6099625)",ParaBTM: A Parallel Processing Framework for Biomedical Text Mining on Supercomputers.,https://europepmc.org/abstract/MED/29702574%0A
"Alzheimer's disease (AD) is characterized by gradual neurodegeneration and loss of brain function, especially for memory during early stages. Regression analysis has been widely applied to AD research to relate clinical and biomarker data such as predicting cognitive outcomes from MRI measures. Recently, multi-task based feature learning (MTFL) methods with sparsity-inducing [Formula: see text]-norm have been widely studied to select a discriminative feature subset from MRI features by incorporating inherent correlations among multiple clinical cognitive measures. However, existing MTFL assumes the correlation among all tasks is uniform, and the task relatedness is modeled by encouraging a common subset of features via sparsity-inducing regularizations that neglect the inherent structure of tasks and MRI features. To address this issue, we proposed a fused group lasso regularization to model the underlying structures, involving 1) a graph structure within tasks and 2) a group structure among the image features. To this end, we present a multi-task feature learning framework with a mixed norm of fused group lasso and [Formula: see text]-norm to model these more flexible structures. For optimization, we employed the alternating direction method of multipliers (ADMM) to efficiently solve the proposed non-smooth formulation. We evaluated the performance of the proposed method using the Alzheimer's Disease Neuroimaging Initiative (ADNI) datasets. The experimental results demonstrate that incorporating the two prior structures with fused group lasso norm into the multi-task feature learning can improve prediction performance over several competing methods, with estimated correlations of cognitive functions and identification of cognition-relevant imaging markers that are clinically and biologically meaningful.","Liu X
Cao P
Wang J
Kong J
Zhao D
","(PMID:30284672
)",Fused Group Lasso Regularized Multi-Task Feature Learning and Its Application to the Cognitive Performance Prediction of Alzheimer's Disease.,https://europepmc.org/abstract/MED/30284672%0A
"The National Cancer Institute developed the Health Disparities Calculator (HD*Calc) to facilitate research on health disparities. HD*Calc calculates multiple measures of health disparities using data collected from population-based disease surveillance systems, such as cancer registries. In this paper, we extend the use of HD*Calc to complex survey data by developing plug-in point estimators and Taylor linearization variance estimators that consider complex designs: stratification, multistage clustering, and differential weighting. Our simulation indicates that the plug-in estimators are approximately unbiased and the Taylor linearization variance estimators are accurate. Using 2011-2016 data from the National Health and Nutrition Examination Survey, we demonstrate the use of these estimators in evaluating socioeconomic disparities in the prevalence of child and adolescent (ages 2-18 years) obesity in the United States. Statistical software has been developed for ease of disparity analyses using complex survey data.","Li Y
Yu M
Zhang J
","(PMID:30383261
)",Statistical Inference on Health Disparity Indices for Complex Surveys.,https://europepmc.org/abstract/MED/30383261%0A
"This work considers using camera sensors to detect fire smoke. Static features including texture, wavelet, color, edge orientation histogram, irregularity, and dynamic features including motion direction, change of motion direction and motion speed, are extracted from fire smoke to train and test with different combinations. A robust AdaBoost (RAB) classifier is proposed to improve training and classification accuracy. Extensive experiments on well known challenging datasets and application for fire smoke detection demonstrate that the proposed fire smoke detector leads to a satisfactory performance.","Wu X
Lu X
Leung H
","(PMID:30400645
)",A Video Based Fire Smoke Detection Using Robust AdaBoost.,https://europepmc.org/abstract/MED/30400645%0A
"A molecular interpretation of the eutectic behavior of a binary mixture of tristearin (SSS) and tripalmitin (PPP) triglycerides was formulated using computer simulations and experimental techniques (calorimetry and X-ray scattering). A eutectic composition was identified using both experimental and computer simulation techniques at a composition of 70% PPP and 30% SSS, in agreement with previous findings in the literature. The decrease in the melting temperature at the eutectic composition can be ascribed to an interplay between enthalpic and entropic effects. In particular, a lower global melting enthalpy at the eutectic composition was detected here, caused by a less efficient packing of the triglycerides in the crystal. On the other hand, a higher crystalline disorder is reflected in a lower change in the entropy of melting. The simultaneous decrease in global enthalpy and entropy has a contrasting effect on the melting temperature, with a slight melting point depression found in both experiment and simulations, resulting from a combination of enthalpic and entropic factors. Computer simulations showed, in fact, that the eutectic effect can be ascribed to the reduction of crystalline order when SSS molecules are incorporated into the PPP crystal structure. This decrease of the crystalline order is due to the protrusion of SSS end-chains (last three carbons of each alkyl chain) into the interlamellar space between adjacent lamella. These end-chains disturb the orderly stacking of the lamella, as evidenced by low-density regions in the interlamellar space. Thus, the greater disorder of the last atoms of the SSS alkyl chains is consequently due to the greater conformational freedom. At molecular level, in fact, the conformational freedom of terminal atoms of SSS surrounded by shorter PPP molecules is larger than the conformational freedom of longer SSS in the neighborhood of short PPP.","Pizzirusso A
Peyronel F
Co ED
Marangoni AG
Milano G
","(PMID:30178998
)",Molecular Insights into the Eutectic Tripalmitin/Tristearin Binary System.,https://europepmc.org/abstract/MED/30178998%0A
"Functionally similar non-coding RNAs are expected to be similar in certain regions of their secondary structures. These similar regions are called common structure motifs, and are structurally conserved throughout evolution to maintain their functional roles. Common structure motif identification is one of the critical tasks in RNA secondary structure analysis. Nevertheless, current approaches suffer several limitations, and/or do not scale with both structure size and the number of input secondary structures. In this work, we present a method to transform the conserved base pair stems into transaction items and apply frequent itemset mining to identify common structure motifs existing in a majority of input structures. Our experimental results on telomerase and ribosomal RNA secondary structures report frequent stem patterns that are of biological significance. Moreover, the algorithms utilized in our method are scalable and frequent stem patterns can be identified efficiently among many large structures.","Chiu JKH
Dillon TS
Chen YP
","(PMID:30036526
)",Large-scale frequent stem pattern mining in RNA families.,https://europepmc.org/abstract/MED/30036526%0A
"Learning in physical neural systems must rely on learning rules that are local in both space and time. Optimal learning in deep neural architectures requires that non-local information be available to the deep synapses. Thus, in general, optimal learning in physical neural systems requires the presence of a deep learning channel to communicate non-local information to deep synapses, in a direction opposite to the forward propagation of the activities. Theoretical arguments suggest that for circular autoencoders, an important class of neural architectures where the output layer is identical to the input layer, alternative algorithms may exist that enable local learning without the need for additional learning channels, by using the forward activation channel as the deep learning channel. Here we systematically identify, classify, and study several such local learning algorithms, based on the general idea of recirculating information from the output layer to the hidden layers. We show through simulations and mathematical derivations that these algorithms are robust and converge to critical points of the global error function. In most cases, we show that these recirculation algorithms are very similar to an adaptive form of random backpropagation, where each hidden layer receives a linearly transformed, slowly-varying, version of the output error.","Baldi P
Sadowski P
","(PMID:30317133
)",Learning in the machine: Recirculation is random backpropagation.,https://europepmc.org/abstract/MED/30317133%0A
"The original version of this Article contained errors in the affiliations of the authors Ibrahim Numanagić and Thomas A. Courtade, which were incorrectly given as 'Department of Electrical Engineering and Computer Sciences, University of California, Berkeley, CA 94720, USA' and 'Computer Science & Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA 02139, USA', respectively. Also, the hyperlink for the source code in the Data Availability section was incorrectly given as https://github.iu.edu/kzhu/assembltrie , which links to a page that is not publicly accessible. The source code is publicly accessible at https://github.com/kyzhu/assembltrie . Furthermore, in the PDF version of the Article, the right-hand side of Figure 3 was inadvertently cropped. These errors have now been corrected in both the PDF and HTML versions of the Article.","Ginart AA
Hui J
Zhu K
Numanagić I
Courtade TA
Sahinalp SC
Tse DN
","(PMID:29700301
 PMCID:PMC5919963)",Publisher Correction: Optimal compressed representation of high throughput sequence data via light assembly.,https://europepmc.org/abstract/MED/29700301%0A
"Breast cancer is one of the leading cancer type among women in worldwide. Many breast cancer patients die every year due to the late diagnosis and treatment. Thus, in recent years, early breast cancer detection systems based on patient's imagery are in demand. Deep learning attracts many researchers recently and many computer vision applications have come out in various environments. Convolutional neural network (CNN) which is known as deep learning architecture, has achieved impressive results in many applications. CNNs generally suffer from tuning a huge number of parameters which bring a great amount of complexity to the system. In addition, the initialization of the weights of the CNN is another handicap that needs to be handle carefully. In this paper, transfer learning and deep feature extraction methods are used which adapt a pre-trained CNN model to the problem at hand. AlexNet and Vgg16 models are considered in the presented work for feature extraction and AlexNet is used for further fine-tuning. The obtained features are then classified by support vector machines (SVM). Extensive experiments on a publicly available histopathologic breast cancer dataset are carried out and the accuracy scores are calculated for performance evaluation. The evaluation results show that the transfer learning produced better result than deep feature extraction and SVM classification.","Deniz E
Şengür A
Kadiroğlu Z
Guo Y
Bajaj V
Budak Ü
","(PMID:30279988
)",Transfer learning based histopathologic image classification for breast cancer detection.,https://europepmc.org/abstract/MED/30279988%0A
"In this work, ultrathin Ti3C2-MXene nanosheets were synthesized by minimally intensive layer delamination methods, and uniformly functionalized with aminosilane (f-Ti3C2-MXene) to provide a covalent binding for the immobilized bio-receptor (anti-CEA) for label free, ultrasensitive detection of cancer biomarker (carcinoembryonic antigen, CEA). The effect of different redox probes on the electrochemical behavior of f-Ti3C2-MXene was investigated and found that hexaammineruthenium ([Ru(NH3)6]3+) is the preferable redox probe for biosensing. The fabricated biofunctionalized Ti3C2-MXene exhibits a linear detection range of 0.0001-2000 ng mL-1 with sensitivity of 37.9 µA ng-1 mL cm-2 per decade. The wider linear detection range of our f-Ti3C2-MXene is not only higher than previously reported pristine 2D nanomaterials, but is even comparable to other hybrid 2D nanomaterials. We believe that this work opens a new window for development of MXene-based highly sensitive DNA, aptamer, enzyme, antibody, and cell based biosensors, and could be further used in drug delivery application.","Kumar S
Lei Y
Alshareef NH
Quevedo-Lopez MA
Salama KN
","(PMID:30219724
)",Biofunctionalized two-dimensional Ti3C2 MXenes for ultrasensitive detection of cancer biomarker.,https://europepmc.org/abstract/MED/30219724%0A
"The change in the spectrum of sustained /a/ vowels was mapped over the voice range from low to high fundamental frequency and low to high sound pressure level (SPL), in the form of the so-called voice range profile (VRP). In each interval of one semitone and one decibel, narrowband spectra were averaged both within and across subjects. The subjects were groups of 7 male and 12 female singing students, as well as a group of 16 untrained female voices. For each individual and also for each group, pairs of VRP recordings were made, with stringent separation of the modal/chest and falsetto/head registers. Maps are presented of eight scalar metrics, each of which was chosen to quantify a particular feature of the voice spectrum, over fundamental frequency and SPL. Metrics 1 and 2 chart the role of the fundamental in relation to the rest of the spectrum. Metrics 3 and 4 are used to explore the role of resonances in relation to SPL. Metrics 5 and 6 address the distribution of high frequency energy, while metrics 7 and 8 seek to describe the distribution of energy at the low end of the voice spectrum. Several examples are observed of phenomena that are difficult to predict from linear source-filter theory, and of the voice source being less uniform over the voice range than is conventionally assumed. These include a high-frequency band-limiting at high SPL and an unexpected persistence of the second harmonic at low SPL. The two voice registers give rise to clearly different maps. Only a few effects of training were observed, in the low frequency end below 2kHz. The results are of potential interest in voice analysis, voice synthesis and for new insights into the voice production mechanism.","Pabon P
Ternström S
","(PMID:30269894
)",Feature Maps of the Acoustic Spectrum of the Voice.,https://europepmc.org/abstract/MED/30269894%0A
"There is a huge amount of rare diseases, many of which have associated important disabilities. It is paramount to know in advance the evolution of the disease in order to limit and prevent the appearance of disabilities and to prepare the patient to manage the future difficulties. Rare disease associations are making an effort to manually collect this information, but it is a long process. A lot of information about the consequences of rare diseases is published in scientific papers, and our goal is to automatically extract disabilities associated with diseases from them.This work presents a new corpus of abstracts from scientific papers related to rare diseases, which has been manually annotated with disabilities. This corpus allows to train machine and deep learning systems that can automatically process other papers, thus extracting new information about the relations between rare diseases and disabilities. The corpus is also annotated with negation and speculation when they appear affecting disabilities. The corpus has been made publicly accessible.We have devised some experiments using deep learning techniques to show the usefulness of the developed corpus. Specifically, we have designed a long short-term memory based architecture for disabilities identification, as well as a convolutional neural network for detecting their relationships to diseases. The systems designed do not need any preprocessing of the data, but only low dimensional vectors representing the words.The developed corpus will allow to train systems to identify disabilities in biomedical documents, which the current annotation systems are not able to detect. The system could also be trained to detect relationships between them and diseases, as well as negation and speculation, that can change the meaning of the language. The deep learning models designed for identifying disabilities and their relationships to diseases in new documents show that the corpus allows obtaining an F-measure of around 81% for the disability recognition and 75% for relation extraction.","Fabregat H
Araujo L
Martinez-Romo J
","(PMID:30195420
)",Deep neural models for extracting entities and relationships in the new RDD corpus relating disabilities and rare diseases.,https://europepmc.org/abstract/MED/30195420%0A
"Lasers and light emitters do not typically radiate fields with orbital angular momentum (OAM). Here we show that a suitable scheme of spatiotemporal modulation of a microring cavity laser can impart a synthetic angular momentum, resulting in beams with well-defined OAM. The phenomenon relies on a traveling wave modulation of the refractive index of the microring, which breaks the degeneracy of oppositely oriented whispering gallery modes. In parallel, a static structural grating on the periphery of the microring enables efficient vertical radiation. The proposed structure is inherently tunable and can also emit fields with zero net OAM while retaining toroidal energy distributions similar to the effect of an axicon lens.","Mock A
Sounas D
Alù A
","(PMID:30240264
)",Tunable Orbital Angular Momentum Radiation from Angular-Momentum-Biased Microcavities.,https://europepmc.org/abstract/MED/30240264%0A
"Adolescents take more risks when peers monitor their behavior. However, it is largely unknown how different types of peer influence affect adolescent decision-making. In this study, we investigate how information about previous choices of peers differentially influences decision-making in adolescence and young adulthood. Participants (N = 99, age range 12-22) completed an economic choice task in which choice options were systematically varied on levels of risk and ambiguity. On each trial, participants selected between a safer choice (low variability in outcome) and a riskier choice (high variability in outcome). Participants made choices in three conditions: a solo condition in which they made choices with no additional information, a social condition in which they saw choices of supposed peers, and a computer condition in which they saw choices of a computer. Results showed that participants' choices conform to the choices made by the peers, but not a computer. Furthermore, when peers chose the safe option, late adolescents were especially likely to make a safe choice. Conversely, when the peer made a risky choice, late adolescents were least likely to follow choices made by the peer. We did not find evidence for differential influence of social information on decisions depending on their level of risk and ambiguity. These results show that information about previous decisions of peers are a powerful modifier for behavior and that the effect of peers on adolescents' decisions is less ubiquitous and more specific than previously assumed.","Braams BR
Davidow JY
Somerville LH
","(PMID:30105854
)",Developmental patterns of change in the influence of safe and risky peer choices on risky decision-making.,https://europepmc.org/abstract/MED/30105854%0A
No abstract provided.,"Frenkel-Morgenstern M
Welch L
Gaeta B
Kovats DE
","(PMID:29734340
 PMCID:PMC5937733)",Art in Science Competition invites artworks to the annual exhibition on ISMB 2018 in Chicago.,https://europepmc.org/abstract/MED/29734340%0A
"Shotgun metaproteomics has the potential to reveal the functional landscape of microbial communities but lacks appropriate methods for complex samples with unknown compositions. In the absence of prior taxonomic information, tandem mass spectra would be searched against large pan-microbial databases, which requires heavy computational workload and reduces sensitivity. We present ProteoStorm, an efficient database search framework for large-scale metaproteomics studies, which identifies high-confidence peptide-spectrum matches (PSMs) while achieving a two-to-three orders-of-magnitude speedup over popular tools. A reanalysis of a urinary tract infection (UTI) dataset of 110 individuals revealed a complex pattern of polymicrobial expression, including sub-types of UTIs, cases of bacterial vaginosis, and evidence of no underlying disease. Importantly, compared to the initial UTI study that restricted the search database to a manually curated list of 20 genera, ProteoStorm identified additional genera that were previously unreported, including a case of infection with the rare pathogen Propionimicrobium.","Beyter D
Lin MS
Yu Y
Pieper R
Bafna V
","(PMID:30268435
)",ProteoStorm: An Ultrafast Metaproteomics Database Search Framework.,https://europepmc.org/abstract/MED/30268435%0A
"Population size estimation is relevant to social and ecological sciences. Exhaustive manual counting, the density method and automated computer vision are some of the estimation methods that are currently used. Some of these methods may work in concrete cases but they do not provide a fast, efficient and unbiased estimation in general. Recently, the CountEm method, based on systematic sampling with a grid of quadrats, was proposed. It offers an unbiased estimation that can be applied to any population. However, choosing suitable grid parameters is sometimes cumbersome. Here we define a more intuitive grid parametrization, using initial number of quadrats and sampling fraction. A crowd counting dataset with 51 images and their corresponding, manually annotated position point patterns, are used to analyze the variation of the coefficient of error with respect to different parameter choices. Our Monte Carlo resampling results show that the error depends on the sample size and the number of nonempty quadrats, but not on the size of the target population. A procedure to choose suitable parameter values is described, and the expected coefficients of error are given. Counting about 100 particles in 30 nonempty quadrats usually yields coefficients of error below 10%.","Cruz M
González-Villa J
","(PMID:30372479
 PMCID:PMC6205639)",Simplified procedure for efficient and unbiased population size estimation.,https://europepmc.org/abstract/MED/30372479%0A
"This article presents a new deep learning approach for cardiac arrhythmia (17 classes) detection based on long-duration electrocardiography (ECG) signal analysis. Cardiovascular disease prevention is one of the most important tasks of any health care system as about 50 million people are at risk of heart disease in the world. Although automatic analysis of ECG signal is very popular, current methods are not satisfactory. The goal of our research was to design a new method based on deep learning to efficiently and quickly classify cardiac arrhythmias. Described research are based on 1000 ECG signal fragments from the MIT - BIH Arrhythmia database for one lead (MLII) from 45 persons. Approach based on the analysis of 10-s ECG signal fragments (not a single QRS complex) is applied (on average, 13 times less classifications/analysis). A complete end-to-end structure was designed instead of the hand-crafted feature extraction and selection used in traditional methods. Our main contribution is to design a new 1D-Convolutional Neural Network model (1D-CNN). The proposed method is 1) efficient, 2) fast (real-time classification) 3) non-complex and 4) simple to use (combined feature extraction and selection, and classification in one stage). Deep 1D-CNN achieved a recognition overall accuracy of 17 cardiac arrhythmia disorders (classes) at a level of 91.33% and classification time per single sample of 0.015 s. Compared to the current research, our results are one of the best results to date, and our solution can be implemented in mobile devices and cloud computing.","Yıldırım Ö
Pławiak P
Tan RS
Acharya UR
","(PMID:30245122
)",Arrhythmia detection using deep convolutional neural network with long duration ECG signals.,https://europepmc.org/abstract/MED/30245122%0A
"<label>Motivation</label>Accumulating evidences indicate that long non-coding RNAs (lncRNAs) play pivotal roles in various biological processes. Mutations and dysregulations of lncRNAs are implicated in miscellaneous human diseases. Predicting lncRNA-disease associations is beneficial to disease diagnosis as well as treatment. Although many computational methods have been developed, precisely identifying lncRNA-disease associations, especially for novel lncRNAs, remains challenging.<label>Results</label>In this study, we propose a method (named SIMCLDA) for predicting potential lncRNA-disease associations based on inductive matrix completion. We compute Gaussian interaction profile kernel of lncRNAs from known lncRNA-disease interactions and functional similarity of diseases based on disease-gene and gene-gene onotology associations. Then, we extract primary feature vectors from Gaussian interaction profile kernel of lncRNAs and functional similarity of diseases by principal component analysis, respectively. For a new lncRNA, we calculate the interaction profile according to the interaction profiles of its neighbors. At last, we complete the association matrix based on the inductive matrix completion framework using the primary feature vectors from the constructed feature matrices. Computational results show that SIMCLDA can effectively predict lncRNA-disease associations with higher accuracy compared with previous methods. Furthermore, case studies show that SIMCLDA can effectively predict candidate lncRNAs for renal cancer, gastric cancer and prostate cancer.<label>Availability and implementation</label>https://github.com//bioinfomaticsCSU/SIMCLDA.<label>Supplementary information</label>Supplementary data are available at Bioinformatics online.","Lu C
Yang M
Luo F
Wu FX
Li M
Pan Y
Li Y
Wang J
","(PMID:29718113
)",Prediction of lncRNA-disease associations based on inductive matrix completion.,https://europepmc.org/abstract/MED/29718113%0A
"Both simulation and high-fidelity simulation involving manikins, clinical training suites, wards, computer programs and theatres have established themselves in medical undergraduate and postgraduate education. Popular among students, they have been shown to be effective learning tools. Contrasted with this is the potential risk to patients and their proxy associated with learning 'at the bedside', which can pose a real challenge in medical and palliative settings. The need for education and training methods that do not expose the patient to preventable communication blunders from less experienced practitioners is a priority.Here, we provide a summary review on the current literature and evidence for simulation and high-fidelity simulation in palliative and end-of-life care settings, and discuss potential uses of technologies including virtual and augmented reality in future training.The most common form of simulation in palliative medicine is often an actor-based role-play scenario with particular emphasis on communication skills. This is expensive and time-consuming to set up. Less evidence was found on the use of high-fidelity simulation in end-of-life care teaching.Palliative medicine has been slow to adapt to an educational method and environment that now is widely used across other areas of healthcare. There has been less emphasis on training with manikins and even less on using computer simulation and virtual reality environments to recreate challenging end-of-life care scenarios. We provide some examples of where this could benefit the curriculum.","Evans L
Taubert M
","(PMID:30254018
)",State of the science: the doll is dead: simulation in palliative care education.,https://europepmc.org/abstract/MED/30254018%0A
"We construct two ordinary-differential-equation models of a predator feeding adaptively on two prey types, and we evaluate the models' ability to fit data on freshwater plankton. We model the predator's switch from one prey to the other in two different ways: (i) smooth switching using a hyperbolic tangent function; and (ii) by incorporating a parameter that changes abruptly across the switching boundary as a system variable that is coupled to the population dynamics. We conduct linear stability analyses, use approximate Bayesian computation (ABC) combined with a population Monte Carlo (PMC) method to fit model parameters, and compare model results quantitatively to data for ciliate predators and their two algal prey groups collected from Lake Constance on the German-Swiss-Austrian border. We show that the two models fit the data well when the smooth transition is steep, supporting the simplifying assumption of a discontinuous prey-switching behavior for this scenario. We thus conclude that prey switching is a possible mechanistic explanation for the observed ciliate-algae dynamics in Lake Constance in spring, but that these data cannot distinguish between the details of prey switching that are encoded in these different models.","Piltz SH
Harhanen L
Porter MA
Maini PK
","(PMID:30009794
)",Inferring parameters of prey switching in a 1 predator-2 prey plankton system with a linear preference tradeoff.,https://europepmc.org/abstract/MED/30009794%0A
"Glioblastoma cells adopt migration strategies to invade into the brain parenchyma ranging from individual to collective mechanisms, whose role and dynamics are not yet fully understood. In this work, we explore Glioblastoma heterogeneity and recapitulate its invasive patterns both in vitro, by utilizing primary cells along with the U87MG cell line, and in silico, by adopting discrete, individual cell-based mathematics. Glioblastoma cells are cultured three-dimensionally in an ECM-like substrate. The primary Glioblastoma spheroids adopt a novel cohesive pattern, mimicking perivascular invasion in the brain, while the U87MG adopt a typical, starburst invasive pattern under the same experimental setup. Mathematically, we focus on the role of the intrinsic heterogeneity with respect to cell-to-cell adhesion. Our proposed mathematical approach mimics the invasive morphologies observed in vitro and predicts the dynamics of tumour expansion. The role of the proliferation and migration is also explored showing that their effect on tumour morphology is different per cell type. The proposed model suggests that allowing cell-to-cell adhesive heterogeneity within the tumour population is sufficient for variable invasive morphologies to emerge which remain originally undetectable by conventional imaging, indicating that exploration in pathological samples is needed to improve our understanding and reveal potential patient-specific therapeutic targets.","Oraiopoulou ME
Tzamali E
Tzedakis G
Liapis E
Zacharakis G
Vakis A
Papamatheakis J
Sakkalis V
","(PMID:30385804
 PMCID:PMC6212459)",Integrating in vitro experiments with in silico approaches for Glioblastoma invasion: the role of cell-to-cell adhesion heterogeneity.,https://europepmc.org/abstract/MED/30385804%0A
"Wireless body area networks (WBANs) comprises a number of sensor nodes and the portable mobile device such as smartphone. It is used to monitor the physical condition and provide a reliable healthcare system. Utilizing the wireless communication network, sensor nodes collect the physiological data of one patient to the portable mobile device and the latter analyzes and transmits them to the application providers. Therefore, the personal data confidentiality and user privacy are cores of WBANs. Recently, Shen et al. presented a multi-layer authentication protocol for WBANs, which is lightweight and much easier to implement. However, we observe that their authentication between sensor nodes and the portable mobile device could ensure the forward security property only when the sensor nodes are changed (add or delete). When the sensor nodes are constant, the security property is not satisfied. Meanwhile, the authentication between the portable mobile device and application provider is prone to mutual impersonation attack, so the critical goal of mutual authentication can not be achieved. In this paper, an improved two-layer authentication scheme is proposed to remove the flaws. The analysis shows that our method is more secure and could withstand various attacks.","Liu X
Jin C
Li F
","(PMID:29959607
)",An Improved Two-Layer Authentication Scheme for Wireless Body Area Networks.,https://europepmc.org/abstract/MED/29959607%0A
"BACKGROUND:Physical motor exercise aided by an electroencephalogram (EEG)-based brain-computer interface (BCI) is known to improve motor recovery in patients with stroke. In such a BCI paradigm, event-related desynchronization (ERD) in the alpha and beta bands extracted from EEG recorded over the primary sensorimotor area (SM1) is often used, since ERD has been suggested to be associated with an increase of corticospinal excitability. Recently, we demonstrated a novel online lock-in amplifier (LIA) algorithm to estimate the amplitude modulation of motor-related SM1 ERD. With this algorithm, the delay time, accuracy, and stability to estimate motor-related SM1 ERD were significantly improved compared with the conventional fast Fourier transformation (FFT) algorithm. These technical improvements to extract an ERD trace imply a potential advantage for a better trace of the excitatory status of the SM1 in a BCI context. Therefore, the aim of this study was to assess the precision of LIA-based ERD tracking for estimation of corticospinal excitability using a transcranial magnetic stimulation (TMS) paradigm. METHODS:The motor evoked potentials (MEPs) induced by single-pulse TMS over the primary motor cortex depending on the magnitudes of SM1 ERD (i.e., 35% and 70%) extracted by the online LIA or FFT algorithm were monitored during a motor imagery task of wrist extension in 17 healthy participants. Then, the peak-to-peak amplitudes of MEPs and their variabilities were assessed to investigate the precision of the algorithms. RESULTS:We found greater MEP amplitude evoked by single-pulse TMS triggered by motor imagery-related alpha SM1 ERD than at rest. This enhancement was associated with the magnitude of ERD in both FFT and LIA algorithms. Moreover, we found that the variabilities of peak-to-peak MEP amplitudes at 35% and 70% ERDs calculated by the novel online LIA algorithm were smaller than those extracted using the conventional FFT algorithm. CONCLUSIONS:The present study demonstrated that the calculation of motor imagery-related SM1 ERDs using the novel online LIA algorithm led to a more precise estimation of corticospinal excitability than when the ordinary FFT-based algorithm was used.","Takahashi K
Kato K
Mizuguchi N
Ushiba J
","(PMID:30384845
 PMCID:PMC6211493)",Precise estimation of human corticospinal excitability associated with the levels of motor imagery-related EEG desynchronization extracted by a locked-in amplifier algorithm.,https://europepmc.org/abstract/MED/30384845%0A
"To summarize significant research contributions published in 2017 on Human Factors and Organizational Issues (HFOI) in medical informatics. An extensive search using PubMed/Medline and Web of Science® was conducted to identify the scientific contributions published in 2017 that HFOI issues in medical informatics. The selection process comprised three steps: (i) 15 candidate best papers out of 695 references were first selected by the two section editors, (ii) external reviewers from internationally renowned research teams reviewed each candidate best paper, and (iii) the final selection of five best papers was conducted by the editorial board of the Yearbook. The five best papers offer a glimpse of the quality and breadth of the work being conducted in the HFOI community. The selection of the HFOI section of the 2018 IMIA Yearbook highlights a growing number of high quality studies. There are especially more studies interested in testing Human Factors and Ergonomics methods and demonstrating the benefits.","Pelayo S
Kaipio J
Section Editors for the IMIA Yearbook Section on Human Factors and Organizational Issues
","(PMID:30157509
)",Findings from the 2018 Yearbook Section on Human Factors and Organizational Issues.,https://europepmc.org/abstract/MED/30157509%0A
"How do people pursue rewards in risky environments, where some outcomes should be avoided at all costs? We investigate how participant search for spatially correlated rewards in scenarios where one must avoid sampling rewards below a given threshold. This requires not only the balancing of exploration and exploitation, but also reasoning about how to avoid potentially risky areas of the search space. Within risky versions of the spatially correlated multi-armed bandit task, we show that participants' behavior is aligned well with a Gaussian process function learning algorithm, which chooses points based on a safe optimization routine. Moreover, using leave-one-block-out cross-validation, we find that participants adapt their sampling behavior to the riskiness of the task, although the underlying function learning mechanism remains relatively unchanged. These results show that participants can adapt their search behavior to the adversity of the environment and enrich our understanding of adaptive behavior in the face of risk and uncertainty.","Schulz E
Wu CM
Huys QJM
Krause A
Speekenbrink M
","(PMID:30390325
)",Generalization and Search in Risky Environments.,https://europepmc.org/abstract/MED/30390325%0A
"Artificial intelligence (AI) has emerged as a major frontier in computer science research. Although AI has broad application across many medical fields, it will have particular utility in ophthalmology and will dramatically change the diagnostic and treatment pathways for many eye conditions such as corneal ectasias, glaucoma, age-related macular degeneration and diabetic retinopathy. However, given that AI has primarily been driven as a computer science, its concepts and terminology are unfamiliar to many medical professionals. Important key terms such as machine learning and deep learning are often misunderstood and incorrectly used interchangeably. This article presents an overview of AI and new developments relevant to ophthalmology.","Hogarty DT
Mackey DA
Hewitt AW
","(PMID:30155978
)",Current state and future prospects of artificial intelligence in ophthalmology: a review.,https://europepmc.org/abstract/MED/30155978%0A
"Computational imaging combines measurement and computational methods with the aim of forming images even when the measurement conditions are weak, few in number, or highly indirect. The recent surge in quantum-inspired imaging sensors, together with a new wave of algorithms allowing on-chip, scalable and robust data processing, has induced an increase of activity with notable results in the domain of low-light flux imaging and sensing. We provide an overview of the major challenges encountered in low-illumination (e.g., ultrafast) imaging and how these problems have recently been addressed for imaging applications in extreme conditions. These methods provide examples of the future imaging solutions to be developed, for which the best results are expected to arise from an efficient codesign of the sensors and data analysis tools.","Altmann Y
McLaughlin S
Padgett MJ
Goyal VK
Hero AO
Faccio D
","(PMID:30115781
)",Quantum-inspired computational imaging.,https://europepmc.org/abstract/MED/30115781%0A
"Prediction of functional outcome after stroke based on initial presentation remains an open challenge, suggesting that an important aspect is missing from these prediction models. There exists the notion of a protective mechanism called brain reserve, which may be utilized to understand variations in disease outcome. In this work, we expand the concept of brain reserve (effective reserve) to improve prediction models of functional outcome after acute ischemic stroke (AIS). Consecutive AIS patients with acute brain magnetic resonance imaging (<48 hours) were eligible for this study. White matter hyperintensity and acute infarct volume were determined on T2 fluid attenuated inversion recovery and diffusion weighted images, respectively. Modified Rankin Scale scores were obtained at 90days poststroke. Effective reserve was defined as a latent variable using structural equation modeling by including age, systolic blood pressure, and intracranial volume measurements. Of 453 AIS patients (mean age 66.6 ± 14.7 years), 36% were male and 311 hypertensive. There was inverse association between effective reserve and 90-day modified Rankin Scale scores (path coefficient -0.18 ± 0.01, P < .01). Compared to a model without effective reserve, correlation between predicted and observed modified Rankin Scale scores improved in the effective-reserve-based model (Spearman's ρ 0.29 ± 0.18 versus 0.15 ± 0.17, P < .001). Furthermore, hypertensive patients exhibited lower effective reserve (P < 10-6). Using effective reserve in prediction models of stroke outcome is feasible and leads to better model performance. Furthermore, higher effective reserve is associated with more favorable functional poststoke outcome and might correspond to an overall better vascular health.","Schirmer MD
Etherton Md PhD MR
Dalca PhD AV
Giese Md AK
Cloonan MSc L
Wu PhD O
Golland PhD P
Rost Md Mph Faan NS
","(PMID:30269881
)",Effective Reserve: A Latent Variable to Improve Outcome Prediction in Stroke.,https://europepmc.org/abstract/MED/30269881%0A
"Medical digital imaging is the basis of effective medical diagnosis and is now in the mainstream of a dynamically developing branch of science. Optical coherence tomography (OCT) enables real-time in situ imaging of tissues without the need for biopsy, histological procedures or X-rays.The aim of the study was to evaluate the application of OCT in orthodontic diagnostics and clinical practice by assessing the thickness of the enamel before and after orthodontic treatment.A hundred and eighty teeth in this in vitro study were divided into 3 groups of 60 teeth each. In each group (Group 1 - metal brackets, Group 2 - ceramic brackets and Group 3 - composite brackets), the orthodontic brackets were attached to the enamel using the 5th-generation adhesive system. The image of the enamel tissue was captured with a 3D-OCT camera before installing orthodontic brackets and after debonding and mechanical processing. The obtained OCT scans were subjected to expert IT analysis. For the statistical analysis, the Shapiro-Wilk test, the median test, the Mann-Whitney U test, Friedman 2-way analysis of variance (ANOVA), Wilcoxon matched pairs signed ranks test, the χ2 test of independence with Yates's correction, and Fisher's exact test were used. Maxwell's general principle was followed when using this type of test. The level of significance was set at p = 0.05.The thickness of the enamel varied least when metal brackets were used. The changes in enamel thickness in the composite and ceramic bracket groups were not statistically significant.Optical coherence tomography is an effective diagnostic tool to evaluate the thickness of the enamel tissue before and after orthodontic treatment. Changes in the enamel layer thickness after orthodontic treatment are determined by the type of material which the orthodontic bracket is made of.","Machoy ME
Koprowski R
Szyszka-Sommerfeld L
Safranow K
Gedrange T
Woźniak K
","(PMID:30048049
)",Optical coherence tomography as a non-invasive method of enamel thickness diagnosis after orthodontic treatment by 3 different types of brackets.,https://europepmc.org/abstract/MED/30048049%0A
"Finding similarities and differences between metagenomic samples within large repositories has been rather a significant issue for researchers. Over the recent years, content-based retrieval has been suggested by various studies from different perspectives. In this study, a content-based retrieval framework for identifying relevant metagenomic samples is developed. The framework consists of feature extraction, selection methods and similarity measures for whole metagenome sequencing samples. Performance of the developed framework was evaluated on given samples. A ground truth was used to evaluate the system performance such that if the system retrieves patients with the same disease, -called positive samples-, they are labeled as relevant samples otherwise irrelevant. The experimental results show that relevant experiments can be detected by using different fingerprinting approaches. We observed that Latent Semantic Analysis (LSA) Method is a promising fingerprinting approach for representing metagenomic samples and finding relevance among them. Source codes and executable files are available at www.baskent.edu.tr/∼hogul/WMS_retrieval.rar.","Şener DD
Santoni D
Felici G
Oğul H
","(PMID:30367805
)",A Content-Based Retrieval Framework for Whole Metagenome Sequencing Samples.,https://europepmc.org/abstract/MED/30367805%0A
"Single nucleotide polymorphism (SNP) interactions can explain the missing heritability of common complex diseases. Many interaction detection methods have been proposed in genome-wide association studies, and they can be divided into two types: population-based and family-based. Compared with population-based methods, family-based methods are robust vs. population stratification. Several family-based methods have been proposed, among which Multifactor Dimensionality Reduction (MDR)-based methods are popular and powerful. However, current MDR-based methods suffer from heavy computational burden. Furthermore, they do not allow for main effect adjustment. In this work we develop a two-stage model-based MDR approach (TrioMDR) to detect multi-locus interaction in trio families (i.e., two parents and one affected child). TrioMDR combines the MDR framework with logistic regression models to check interactions, so TrioMDR can adjust main effects. In addition, unlike consuming permutation procedures used in traditional MDR-based methods, TrioMDR utilizes a simple semi-parameter P-values correction procedure to control type I error rate, this procedure only uses a few permutations to achieve the significance of a multi-locus model and significantly speeds up TrioMDR. We performed extensive experiments on simulated data to compare the type I error and power of TrioMDR under different scenarios. The results demonstrate that TrioMDR is fast and more powerful in general than some recently proposed methods for interaction detection in trios. The R codes of TrioMDR are available at: https://github.com/TrioMDR/TrioMDR.","Liu J
Yu G
Ren Y
Guo M
Wang J
","(PMID:30055230
)",TrioMDR: Detecting SNP interactions in trio families with model-based multifactor dimensionality reduction.,https://europepmc.org/abstract/MED/30055230%0A
"In this introductory paper, we begin by making the case for Computational Health Science, which we define as the interdisciplinary efforts of health scientists, computer scientists, engineers, psychologists, and other social scientists, to conduct innovative research that will inform future practice directed at changing health behavior through improved communication, networking, and social capital. We recognize and discuss some of the main challenges involved with such an enterprise, but also highlight the associated benefits, which, we argue, significantly outweigh them. We then provide a brief summary of the contributions to this first Special Issue on Computational Health Science.","Barnes M
Hanson C
Giraud-Carrier C
","(PMID:29974076
 PMCID:PMC5999136)",The Case for Computational Health Science.,https://europepmc.org/abstract/MED/29974076%0A
"When do children acquire the ability to understand recursion-that is, repeated loops of actions, as in cookery recipes or computer programs? Hitherto, studies have focused either on unconscious recursions in language and vision or on the difficulty of conscious recursions-even for adults-when learning to program. In contrast, we examined 10- to 11-year-old fifth-graders' ability to deduce the consequences of loops of actions in informal algorithms and to create such algorithms for themselves. In our experiments, the children tackled problems requiring the rearrangement of cars on a toy railway with a single track and a siding-an environment that in principle allows for the execution of any algorithm-that is, it has the power of a universal Turing machine. The children were not allowed to move the cars, so each problem's solution called for them to envision the movements of cars on the track. We describe a theory of recursive thinking, which is based on kinematic simulations and which we have implemented in a computer program embodying mental models of the cars and track. Experiment 1 tested children's ability to deduce rearrangements of the cars in a train from descriptions of algorithms containing a single loop of actions. Experiment 2 assessed children's spontaneous creation of similar sorts of algorithms. The results showed that fifth-grade children with no training in computer programming have systematic abilities to deduce from and to create informal recursive algorithms.","Bucciarelli M
Mackiewicz R
Khemlani SS
Johnson-Laird PN
","(PMID:29995302
)",Simulation in children's conscious recursive reasoning.,https://europepmc.org/abstract/MED/29995302%0A
"Evidence suggests a link between deficits in visuo-spatial attention, and subsequent reading ability. However, all the research in the area thus far has been conducted using traditional, lab-based psychophysics, with very tightly controlled visual parameters. In order to take this research further, such as using visuo-spatial tasks for remediation purposes, it must be established that such tasks can be taken out of the laboratory, 'gamified', and still predict reading ability. This study aimed to determine if subtle visual deficits in poor readers could be detected outside a traditional laboratory, in relatively uncontrolled settings using portable game-like technology. Classic visual search and change detection programs, thought to rely on the visual dorsal stream, were modified to a game-like format. They were administered on a portable computer tablet within the participants' school setting. Whilst IQ predicted reading rate, visuo-spatial tasks such as visual search speed, and change detection, each accounted for unique variance in reading rate over and above IQ, age and phonological ability. These results are consistent with the visuo-spatial attention deficit hypothesis, and provide support for the development of portable computerised games that may assess and potentially target this deficit in poor readers.","Tulloch K
Pammer K
","(PMID:30030193
)",Tablet computer games to measure dorsal stream performance in good and poor readers.,https://europepmc.org/abstract/MED/30030193%0A
"Multiple degrees of freedom (DOF) commands are required for a brain-actuated virtual automatic car, which makes the brain-computer interface (BCI) control strategy a big challenge. In order to solve the challenging issue, a mixed model of BCI combining P300 potentials and motor imagery had been realized in our previous study. However, compared with single model BCI, more training procedures are needed for the mixed model and more mental workload for users to bear. In the present study, we propose a multiple patterns of motor imagery (MPMI) BCI method, which is based on the traditional two patterns of motor imagery. Our motor imagery BCI approach had been extended to multiple patterns: right-hand motor imagery, left-hand motor imagery, foot motor imagery, and both hands motor imagery resulting in turning right, turning left, acceleration, and deceleration for a virtual automatic car control. Ten healthy subjects participated in online experiments, the experimental results not only show the efficiency of our proposed MPMI-BCI strategy but also indicate that those users can control the virtual automatic car spontaneously and efficiently without any other visual attention. Furthermore, the metric of path length optimality ratio (1.23) is very encouraging and the time optimality ratio (1.28) is especially remarkable. Graphical Abstract The paradigm of multiple patterns of motor imagery detection and the relevant topographies of CSP weights for different MI patterns.","Wang H
Li T
Bezerianos A
Huang H
He Y
Chen P
","(PMID:30101383
)",The control of a virtual automatic car based on multiple patterns of motor imagery BCI.,https://europepmc.org/abstract/MED/30101383%0A
"As one of important epigenetic modifications, DNA N4-methylcytosine (4mC) is recently shown to play crucial roles in restriction-modification systems. For better understanding of their functional mechanisms, it is fundamentally important to identify 4mC modification. Machine learning methods have recently emerged as an effective and efficient approach for the high-throughput identification of 4mC sites, although high predictive error rates are still challenging for existing methods. Therefore, it is highly desirable to develop a computational method to more accurately identify m4C sites.In this study, we propose a machine learning based predictor, namely 4mcPred-SVM, for the genome-wide detection of DNA 4mC sites. In this predictor, we present a new feature representation algorithm that sufficiently exploits sequence-based information. To improve the feature representation ability, we use a two-step feature optimization strategy, thereby obtaining the most representative features. Using the resulting features and Support Vector Machine (SVM), we adaptively train the optimal models for different species. Comparative results on benchmark datasets from six species indicate that our predictor is able to achieve generally better performance in predicting 4mC sites as compared to the state-of-the-art predictors. Importantly, the sequence-based features can reliably and robust predict 4mC sites, facilitating the discovery of potentially important sequence characteristics for the prediction of 4mC sites.The user-friendly webserver that implements the proposed 4mcPred-SVM is well established, and is freely accessible at http://server.malab.cn/4mcPred-SVM.Supplementary data are available at Bioinformatics online.","Wei L
Luan S
Nagai LAE
Su R
Zou Q
","(PMID:30239627
)",Exploring sequence-based features for the improved prediction of DNA N4-methylcytosine sites in multiple species.,https://europepmc.org/abstract/MED/30239627%0A
"A hallmark of metazoan evolution is the emergence of genomic mechanisms that implement cell-type-specific functions. However, the evolution of metazoan cell types and their underlying gene regulatory programmes remains largely uncharacterized. Here, we use whole-organism single-cell RNA sequencing to map cell-type-specific transcription in Porifera (sponges), Ctenophora (comb jellies) and Placozoa species. We describe the repertoires of cell types in these non-bilaterian animals, uncovering diverse instances of previously unknown molecular signatures, such as multiple types of peptidergic cells in Placozoa. Analysis of the regulatory programmes of these cell types reveals variable levels of complexity. In placozoans and poriferans, sequence motifs in the promoters are predictive of cell-type-specific programmes. By contrast, the generation of a higher diversity of cell types in ctenophores is associated with lower specificity of promoter sequences and the existence of distal regulatory elements. Our findings demonstrate that metazoan cell types can be defined by networks of transcription factors and proximal promoters, and indicate that further genome regulatory complexity may be required for more diverse cell type repertoires.","Sebé-Pedrós A
Chomsky E
Pang K
Lara-Astiaso D
Gaiti F
Mukamel Z
Amit I
Hejnol A
Degnan BM
Tanay A
","(PMID:29942020
)",Early metazoan cell type diversity and the evolution of multicellular gene regulation.,https://europepmc.org/abstract/MED/29942020%0A
"The optimal application of Pulsed Electric Fields (PEF) technology, used by food industry to assist mass transfer processes, depends on the effectiveness of the induced electroporation. The present work aimed at exploring the application of Magnetic Resonance Imaging (MRI) combined with Computer Vision System (CVS) analysis to assess the spatial distribution of electroporation in apple tissue. PEF-treated apple samples were compared with Dipping (Dip) and Vacuum Impregnation (VI) to gain insight into the spatial distribution of mechanisms that lead to microstructural modifications over time.CVS showed that electroporation modified heterogeneously apple microstructure, causing enzymatic browning unevenly across the samples. MRI transverse relaxation times (T2) maps and longitudinal relaxation times (T1)-weighted images throughout apple tissue confirmed the inhomogeneous distribution and extent of the cell disruption, along with the release of intracellular content toward the external solution.The novel applications of pulsed electric fields require fast and reliable methods to detect and estimate the breakage of the membranes integrity in order to boost their industrial adoption and optimization. The present study provided analytical tools able to monitor the spatial distribution of electroporation in plant tissue samples within minutes and consequently to speed up and improve the assessment of different PEF treatments.","Dellarosa N
Angelo Galante
Brigida Ranieri
Luca Laghi
Luigi Ragni
Marcello Alecci
Marco Dalla Rosa
Tiziana Marilena Florio
","(AGR:IND606122199
)",Pulsed electric fields processing of apple tissue: Spatial distribution of electroporation by means of magnetic resonance imaging and computer vision system,https://europepmc.org/abstract/AGR/IND606122199%0A
"The use of data issued from high throughput technologies in drug target problems is widely widespread during the last decades. This study proposes a meta-heuristic framework using stochastic local search (SLS) combined with random forest (RF) where the aim is to specify the most important genes and proteins leading to the best classification of Acute Myeloid Leukemia (AML) patients. First we use a stochastic local search meta-heuristic as a feature selection technique to select the most significant proteins to be used in the classification task step. Then we apply RF to classify new patients into their corresponding classes. The evaluation technique is to run the RF classifier on the training data to get a model. Then, we apply this model on the test data to find the appropriate class. We use as metrics the balanced accuracy (BAC) and the area under the receiver operating characteristic curve (AUROC) to measure the performance of our model. The proposed method is evaluated on the dataset issued from DREAM 9 challenge. The comparison is done with a pure random forest (without feature selection), and with the two best ranked results of the DREAM 9 challenge. We used three types of data: only clinical data, only proteomics data, and finally clinical and proteomics data combined. The numerical results show that the highest scores are obtained when using clinical data alone, and the lowest is obtained when using proteomics data alone. Further, our method succeeds in finding promising results compared to the methods presented in the DREAM challenge.","Chebouba L
Boughaci D
Guziolowski C
","(PMID:29869179
)",Proteomics Versus Clinical Data and Stochastic Local Search Based Feature Selection for Acute Myeloid Leukemia Patients' Classification.,https://europepmc.org/abstract/MED/29869179%0A
"One of the hottest topics in molecular cell biology is to determine the subcellular localization of proteins from various different organisms. This is because it is crucially important for both basic research and drug development. Recently, a predictor called ""pLoc-mGneg"" was developed for identifying the subcellular localization of Gram-negative bacterial proteins. Its performance is overwhelmingly better than that of the other predictors for the same purpose, particularly in dealing with multi-label systems in which some proteins, called ""multiplex proteins"", may simultaneously occur in two or more subcellular locations. Although it is indeed a very powerful predictor, more efforts are definitely needed to further improve it. This is because pLoc-mGneg was trained by an extremely skewed dataset in which some subset (subcellular location) was about 5 to 70 times the size of the other subsets. Accordingly, it cannot avoid the biased consequence caused by such an uneven training dataset. To alleviate such a consequence, we have developed a new and bias-reducing predictor called pLoc_bal-mGneg by quasi-balancing the training dataset. Cross-validation tests on exactly the same experiment-confirmed dataset have indicated that the proposed new predictor is remarkably superior to pLoc-mGneg, the existing state-of-the-art predictor in identifying the subcellular localization of Gram-negative bacterial proteins. To maximize the convenience for most experimental scientists, a user-friendly web-server for the new predictor has been established at http://www.jci-bioinfo.cn/pLoc_bal-mGneg/, by which users can easily get their desired results without the need to go through the detailed mathematics.","Cheng X
Xiao X
Chou KC
","(PMID:30201434
)",pLoc_bal-mGneg: Predict subcellular localization of Gram-negative bacterial proteins by quasi-balancing training dataset and general PseAAC.,https://europepmc.org/abstract/MED/30201434%0A
"Holographic microscopy presents challenges for color reproduction due to the usage of narrow-band illumination sources, which especially impacts the imaging of stained pathology slides for clinical diagnoses. Here, an accurate color holographic microscopy framework using absorbance spectrum estimation is presented. This method uses multispectral holographic images acquired and reconstructed at a small number (e.g., three to six) of wavelengths, estimates the absorbance spectrum of the sample, and projects it onto a color tristimulus. Using this method, the wavelength selection is optimized to holographically image 25 pathology slide samples with different tissue and stain combinations to significantly reduce color errors in the final reconstructed images. The results can be used as a practical guide for various imaging applications and, in particular, to correct color distortions in holographic imaging of pathology samples spanning different dyes and tissue types.","Zhang Y
Liu T
Huang Y
Teng D
Bian Y
Wu Y
Rivenson Y
Feizi A
Ozcan A
","(PMID:30353662
)",Accurate color imaging of pathology slides using holography and absorbance spectrum estimation of histochemical stains.,https://europepmc.org/abstract/MED/30353662%0A
"The Clinical Oncology of American Society report in 2016 predicted deaths are increased upto 9570 due to oral cancer. This cancer occurs due to abnormal tissue growth in the oral cavity. This cancer has limited symptoms, so, it has been difficult to recognize in the early stages. To reduce the death rate of this oral cavity cancer, an automatic system has been developed by applying the optimization techniques in both image processing and machine learning techniques. Even though these methods are successfully recognizing the cancer, the detection accuracy is still one of the major issues because of complex oral tissue structure. So, this paper introduces the Gravitational Search Optimized Echo state neural networks for predicting the oral cancer with effective manner. Initially the X-ray images are collected from the oral cancer database which contains several noises that has to be eliminated with the help of the adaptive wiener filter. Then the affected part has been segmented with the help of the enhanced Markov Stimulated Annealing and the features are derived from segmented region. The derived features are analyzed with the help of the proposed classifier. The excellence of the oral cancer detection system is evaluated using simulation results.","Al-Ma'aitah M
AlZubi AA
","(PMID:30238196
)",Enhanced Computational Model for Gravitational Search Optimized Echo State Neural Networks Based Oral Cancer Detection.,https://europepmc.org/abstract/MED/30238196%0A
"Feature selection is commonly used as a preprocessing step to machine learning for improving learning performance, lowering computational complexity and facilitating model interpretation. This paper proposes the application of boosting feature selection to improve the classification performance of standard feature selection algorithms evaluated for the prediction of P-gp inhibitors and substrates. Two well-known classification algorithms, decision trees and support vector machines, were used to classify the chemical compounds. The experimental results showed better performance for boosting feature selection with respect to the standard feature selection algorithms while maintaining the capability for feature reduction.","Cerruela García G
García-Pedrajas N
","(PMID:30367310
)",Boosted feature selectors: a case study on prediction P-gp inhibitors and substrates.,https://europepmc.org/abstract/MED/30367310%0A
"Following publication of the original article [1], the authors reported that there was an error in the spelling of the name of one of the authors.","Ozsoy MG
Özyer T
Polat F
Alhajj R
","(PMID:29966513
 PMCID:PMC6027555)",Correction to: Realizing drug repositioning by adapting a recommendation system to handle the process.,https://europepmc.org/abstract/MED/29966513%0A
"OBJECTIVE:Systematic reviews and meta-analyses are labor-intensive and time-consuming. Automated extraction of quantitative data from primary studies can accelerate this process. ClinicalTrials.gov, launched in 2000, is the world's largest trial repository of results data from clinical trials; it has been used as a source instead of journal articles. We have developed a web application called EXACT that allows users without advanced programming skills to automatically extract data from ClinicalTrials.gov in analysis-ready format. We have also used the automatically extracted data to examine the reproducibility of meta-analyses in three published systematic reviews. STUDY DESIGN:We developed a Python-based software application (EXACT, Extracting Accurate efficacy and safety information from ClinicalTrials.gov) that automatically extracts data required for meta-analysis from the ClinicalTrials.gov database in a spreadsheet format. We confirmed the accuracy of the extracted data and then used those data to repeat meta-analyses in three published systematic reviews. To ensure that we used the same statistical methods and outcomes as the published systematic reviews, we repeated the statistics using data manually extracted from the relevant journal articles. For the outcomes whose results we were able to reproduce using those journal article data, we examined the usability of ClinicalTrials.gov data. RESULTS:EXACT extracted data at ClincalTrials.gov with 100% accuracy, and it required 60% less time than the usual practice of manually extracting data from journal articles. We found that 87% of the data elements extracted using EXACT matched those extracted manually from the journal articles. We were able to reproduce 24 of 28 outcomes using the journal article data. Of these 24 outcomes, we were able to reproduce 83.3% of the published estimates using data at ClinicalTrials.gov. CONCLUSION:EXACT (http://bio-nlp.org/EXACT) automatically and accurately extracted data elements from ClinicalTrials.gov and thus reduced time in data extraction. The ClinicalTrials.gov data reproduced most meta-analysis results in our study, but this conclusion needs further validation.","Pradhan R
Hoaglin DC
Cornell M
Liu W
Wang V
Yu H
","(PMID:30257185
)",Automatic extraction of quantitative data from ClinicalTrials.gov to conduct meta-analyses.,https://europepmc.org/abstract/MED/30257185%0A
"This paper presents a systematic literature review concerning 3D segmentation algorithms for computerized tomographic imaging. This analysis covers articles published in the range 2006-March 2018 found in four scientific databases (Science Direct, IEEEXplore, ACM, and PubMed), using the methodology for systematic review proposed by Kitchenham. We present the analyzed segmentation methods categorized according to its application, algorithmic strategy, validation, and use of prior knowledge, as well as its general conceptual description. Additionally, we present a general overview, discussions, and further prospects for the 3D segmentation methods applied for tomographic images.","Carvalho LE
Sobieranski AC
von Wangenheim A
","(PMID:29915942
)",3D Segmentation Algorithms for Computerized Tomographic Imaging: a Systematic Literature Review.,https://europepmc.org/abstract/MED/29915942%0A
"Optogenetics has emerged as an exciting tool for manipulating neural activity, which in turn, can modulate behavior in live organisms. However, detecting the response to the optical stimulation requires electrophysiology with physical contact or fluorescent imaging at target locations, which is often limited by photobleaching and phototoxicity. In this paper, we show that phase imaging can report the intracellular transport induced by optogenetic stimulation. We developed a multimodal instrument that can both stimulate cells with subcellular spatial resolution and detect optical pathlength (OPL) changes with nanometer scale sensitivity. We found that OPL fluctuations following stimulation are consistent with active organelle transport. Furthermore, the results indicate a broadening in the transport velocity distribution, which is significantly higher in stimulated cells compared to optogenetically inactive cells. It is likely that this label-free, contactless measurement of optogenetic response will provide an enabling approach to neuroscience.","Hu C
Sam R
Shan M
Nastasa V
Wang M
Kim T
Gillette M
Sengupta P
Popescu G
","(PMID:30311744
)",Optical excitation and detection of neuronal activity.,https://europepmc.org/abstract/MED/30311744%0A
"RNA secondary structure is a useful representation for studying the function of RNA, which captures most of the free energy of RNA folding. Using empirically determined energy parameters, secondary structures of nucleic acids can be efficiently computed by recursive algorithms. Several software packages supporting this task are readily available. As RNA secondary structures are outerplanar graphs, they can be drawn without intersection in the plane. Interpretation by the practitioner is eased when these drawings conform to a series of additional constraints beyond outerplanarity. These constraints are the reason why RNA drawing is difficult. Many RNA drawing algorithms therefore do not always produce intersection-free (outerplanar) drawings.To remedy this shortcoming, we propose here the RNApuzzler algorithm, which is guaranteed to produce intersection-free drawings. It is based on a drawing algorithm respecting constraints based on nucleotide distances (RNAturtle). We investigate relaxations of these constraints allowing for intersection-free drawings. Based on these relaxations, we implemented a fully automated, simple, and robust algorithm that produces aesthetic drawings adhering to previously established guidelines. We tested our algorithm using the RFAM database and found that we can compute intersection-free drawings of all RNAs therein efficiently.The software can be accessed freely at: https://github.com/dwiegreffe/RNApuzzler.Supplementary data are available at Bioinformatics online.","Wiegreffe D
Alexander D
Stadler PF
Zeckzer D
","(PMID:30239566
)",RNApuzzler: Efficient Outerplanar Drawing of RNA-Secondary Structures.,https://europepmc.org/abstract/MED/30239566%0A
No abstract provided.,"Romá-Ferri MT
Tosal Herrero B
","(PMID:17961474
)",[Computer science: a core subject in undergraduate nursing?].,https://europepmc.org/abstract/MED/17961474%0A
"In this paper, we discuss the relevance of sensing and biosensing for the ongoing revolution in science and technology as a product of the merging of machine learning and Big Data into affordable technologies and accessible everyday products. Possible scenarios for the next decades are described with examples of intelligent systems for various areas, most of which will rely on ubiquitous sensing. The technological and societal challenges for developing the full potential of such intelligent systems are also addressed.","Paulovich FV
De Oliveira MCF
Oliveira ON Jr
","(PMID:30004210
)",A Future with Ubiquitous Sensing and Intelligent Systems.,https://europepmc.org/abstract/MED/30004210%0A
"Traditional methods for detection of metabolically-active bacterial cells, while effective, require several days to complete. Development of sensitive electrical biosensors is highly desirable for rapid detection and counting of pathogens in food, water, or clinical samples. Herein, we develop a highly-sensitive non-Faradaic impedance sensor which detects metabolic activity of E. coli cells in a mere 1 μl of sample volume and without any sample filtration/purification. The three dimensional (3D) interdigitated electrodes (IDEs) along with self-assembled gold-nickel (Au-Ni) nanostructures significantly amplify the sensitivity by increasing the sensing area almost three-fold. The developed microsystem is integrated with an agar-based growth medium and monitors the metabolism of bacterial cells, enabling bacterial detection in approximately one hour after inoculation, i.e. in the lag-phase. Incorporation of a secondary agar layer as a biocompatible passivation layer protects the IDEs from potential Faradaic reactions and enhances sensitivity to modulation of the non-Faradaic impedance due to cellular metabolism. The resultant label-free sensor is capable of selective identification of metabolizing cells (vs. dead cells) across a wide linear range (10-1000 cells/μl). These results help pave the way for rapid antibacterial susceptibility testing at the point-of-need, which is currently a major challenge in healthcare.","Butler D
Goel N
Goodnight L
Tadigadapa S
Ebrahimi A
","(PMID:30297173
)",Detection of bacterial metabolism in lag-phase using impedance spectroscopy of agar-integrated 3D microelectrodes.,https://europepmc.org/abstract/MED/30297173%0A
"We report on novel supervised algorithms for single-trial brain state decoding. Their reliability and robustness are essential to efficiently perform neurotechnological applications in closed-loop. When brain activity is assessed by multichannel recordings, spatial filters computed by the source power comodulation (SPoC) algorithm allow identifying oscillatory subspaces. They regress to a known continuous trial-wise variable reflecting, e.g. stimulus characteristics, cognitive processing or behavior. In small dataset scenarios, this supervised method tends to overfit to its training data as the involved recordings via electroencephalogram (EEG), magnetoencephalogram or local field potentials generally provide a low signal-to-noise ratio. To improve upon this, we propose and characterize three types of regularization techniques for SPoC: approaches using Tikhonov regularization (which requires model selection via cross-validation), combinations of Tikhonov regularization and covariance matrix normalization as well as strategies exploiting analytical covariance matrix shrinkage. All proposed techniques were evaluated both in a novel simulation framework and on real-world data. Based on the simulation findings, we saw our expectations fulfilled, that SPoC regularization generally reveals the largest benefit for small training sets and under severe label noise conditions. Relevant for practitioners, we derived operating ranges of regularization hyperparameters for cross-validation based approaches and offer open source code. Evaluating all methods additionally on real-world data, we observed an improved regression performance mainly for datasets from subjects with initially poor performance. With this proof-of-concept paper, we provided a generalizable regularization framework for SPoC which may serve as a starting point for implementing advanced techniques in the future.","Meinel A
Castaño-Candamil S
Blankertz B
Lotte F
Tangermann M
","(PMID:30128674
)",Characterizing Regularization Techniques for Spatial Filter Optimization in Oscillatory EEG Regression Problems : Guidelines Derived from Simulation and Real-World Data.,https://europepmc.org/abstract/MED/30128674%0A
"The hypervolume indicator has frequently been used for comparing evolutionary multi-objective optimization (EMO) algorithms. A reference point is needed for hypervolume calculation. However, its specification has not been discussed in detail from a viewpoint of fair performance comparison. A slightly worse point than the nadir point is usually used for hypervolume calculation in the EMO community. In this paper, we propose a reference point specification method for fair performance comparison of EMO algorithms. First, we discuss the relation between the reference point specification and the optimal distribution of solutions for hypervolume maximization. It is demonstrated that the optimal distribution of solutions strongly depends on the location of the reference point when a multi-objective problem has an inverted triangular Pareto front. Next, we propose a reference point specification method based on theoretical discussions on the optimal distribution of solutions. The basic idea is to specify the reference point so that a set of well-distributed solutions over the entire linear Pareto front has a large hypervolume and all solutions in such a solution set have similar hypervolume contributions. Then, we examine whether the proposed method can appropriately specify the reference point through computational experiments on various test problems. Finally, we examine the usefulness of the proposed method in a hypervolume-based EMO algorithm. Our discussions and experimental results clearly show that a slightly worse point than the nadir point is not always appropriate for performance comparison of EMO algorithms.","Ishibuchi H
Imada R
Setoguchi Y
Nojima Y
","(PMID:29786458
)",How to Specify a Reference Point in Hypervolume Calculation for Fair Performance Comparison.,https://europepmc.org/abstract/MED/29786458%0A
"Bilateral teleoperation systems connected to computer networks such as the internet must be able to operate with varying time delays since such systems can easily become unstable. A passivity concept has been used as the framework to solve the stability problem in the bilateral control of teleoperation systems. Passivity and tracking performance are recovered using a control architecture that incorporates time varying gains into the transmission path, feedforward, and feedback position control. The proposed architecture has an inner component that can accommodate any configuration but still remain stable and passive even with varying time delay. The simulation results for a single degree of freedom master/slave system demonstrate the performance of the proposed control architecture.","Kostyukova O
Vista FP 4th
Chong KT
","(PMID:30385035
)",Design of feedforward and feedback position control for passive bilateral teleoperation with delays.,https://europepmc.org/abstract/MED/30385035%0A
"OBJECTIVES:To understand how Twitter bots and trolls (""bots"") promote online health content. METHODS:We compared bots' to average users' rates of vaccine-relevant messages, which we collected online from July 2014 through September 2017. We estimated the likelihood that users were bots, comparing proportions of polarized and antivaccine tweets across user types. We conducted a content analysis of a Twitter hashtag associated with Russian troll activity. RESULTS:Compared with average users, Russian trolls (χ2(1) = 102.0; P < .001), sophisticated bots (χ2(1) = 28.6; P < .001), and ""content polluters"" (χ2(1) = 7.0; P < .001) tweeted about vaccination at higher rates. Whereas content polluters posted more antivaccine content (χ2(1) = 11.18; P < .001), Russian trolls amplified both sides. Unidentifiable accounts were more polarized (χ2(1) = 12.1; P < .001) and antivaccine (χ2(1) = 35.9; P < .001). Analysis of the Russian troll hashtag showed that its messages were more political and divisive. CONCLUSIONS:Whereas bots that spread malware and unsolicited content disseminated antivaccine messages, Russian trolls promoted discord. Accounts masquerading as legitimate users create false equivalency, eroding public consensus on vaccination. Public Health Implications. Directly confronting vaccine skeptics enables bots to legitimize the vaccine debate. More research is needed to determine how best to combat bot-driven content.","Broniatowski DA
Jamison AM
Qi S
AlKulaib L
Chen T
Benton A
Quinn SC
Dredze M
","(PMID:30138075
)",Weaponized Health Communication: Twitter Bots and Russian Trolls Amplify the Vaccine Debate.,https://europepmc.org/abstract/MED/30138075%0A
"The falx cerebri and the tentorium cerebelli are two projections of the dura mater in the cranial cavity which ossify to varying degrees in some mammalian species. The idea that the ossification of these structures may be necessary to support the loads arising during feeding has been proposed and dismissed in the past, but never tested quantitatively. To address this, a biomechanical model of a domestic cat (Felis silvestris catus) skull was created and the material properties of the falx and tentorium were varied for a series of loading regimes incorporating the main masticatory and neck muscles during biting. Under these loading conditions, ossification of the falx cerebri does not have a significant impact on the stress in the cranial bones. In the case of the tentorium, however, a localized increase in stress was observed in the parietal and temporal bones, including the tympanic bulla, when a non-ossified tentorium was modelled. These effects were consistent across the different analyses, irrespective of loading regime. The results suggest that ossification of the tentorium cerebelli may play a minor role during feeding activities by decreasing the stress in the back of the skull.","Sellés de Lucas V
Dutel H
Evans SE
Gröning F
Sharp AC
Watson PJ
Fagan MJ
","(PMID:30355804
)",An assessment of the role of the falx cerebri and tentorium cerebelli in the cranium of the cat (Felis silvestris catus).,https://europepmc.org/abstract/MED/30355804%0A
"Circulating tumor cells (CTCs) are a major contributor of cancer metastases and hold a promising prognostic significance in cancer detection. Performing functional and molecular characterization of CTCs provides an in-depth knowledge about this lethal disease. Researchers are making efforts to design devices and develop assays for enumeration of CTCs with a high capture and detection efficiency from whole blood of cancer patients. The existing and on-going research on CTC isolation methods has revealed cell characteristics which are helpful in cancer monitoring and designing of targeted cancer treatments. In this review paper, a brief summary of existing CTC isolation methods is presented. We also discuss methods of detaching CTC from functionalized surfaces (functional assays/devices) and their further use for ex-vivo culturing that aid in studies regarding molecular properties that encourage metastatic seeding. In the clinical applications section, we discuss a number of cases that CTCs can play a key role for monitoring metastases, drug treatment response, and heterogeneity profiling regarding biomarkers and gene expression studies that bring treatment design further towards personalized medicine.","Sharma S
Zhuang R
Long M
Pavlovic M
Kang Y
Ilyas A
Asghar W
","(PMID:29559380
)","Circulating tumor cell isolation, culture, and downstream molecular analysis.",https://europepmc.org/abstract/MED/29559380%0A
"Bulgaria created a pioneering center in late 1990 to tackle the threat that its homegrown computer viruses posed to the world; according to experts, it has been a major force in reining in that threat. Now the lab is struggling to stave off obsolescence on a budget of roughly half of what a single Western whiz kid fresh out of college might earn in a year.","Koenig R
","(PMID:17839928
)",COMPUTER SCIENCE: Flushing Out Nasty Viruses in the Balkans.,https://europepmc.org/abstract/MED/17839928%0A
"PURPOSE:Electromagnetic (EM) tracking is a key technology in image-guided therapy. A new EM Micro Sensor was presented by Polhemus Inc.; it is the first to enable localization of medical instruments through their trackers. Different field generators (FGs) are available by Polhemus, one being almost as small as a sugar cube. As accuracy and robustness of tracking are known challenges to using EM trackers in clinical environments, the goal of this study was a standardized assessment of the Micro Sensor in both a laboratory (lab) and a computed tomography (CT) environment METHODS: The Micro Sensor was assessed by means of Hummel et al.'s standardized protocol; it was assessed in conjunction with a Polhemus Liberty tracker and three FGs - with edge lengths of 1 (TX1), 2 (TX2) and 4 (TX4) inches. Precision as well as positional and rotational accuracy were determined in a lab and a CT suite. Distortions by four different metallic cylinders and tracking of two typical medical instruments-a hypodermic needle and a exible endoscope|were also tested. RESULTS:A jitter of 0.02 mm or less was found for all FGs in the different environments, except for the TX2 FG for which no valid data could be obtained in the CT. Errors of 5 cm distance measurements were 0.6 mm or less for all FGs in the lab. While the distance errors of the TX1 FG were only slightly increased up to 1.6 mm in the CT, those of the TX4 FG were found to be up to around 10% of the measured distance (5.4 mm on average). The mean orientation error was found to be 0.9° / 0.5° / 0.1° for the TX4 / TX2 / TX1 FG in the lab. In the CT environment, rotation errors were in the same range: less than 1.2° / 0.1° for the TX4 / TX1 FG. Deviation under presence of metallic cylinders stayed below 1 mm in most cases. Precision and orientational accuracy do not seem to be affected by instrument tracking and stayed in the same range as for the other measurements whereas distance errors were slightly increased up to 1.7 mm. CONCLUSION:This study shows that accurate tracking of medical instruments is possible with the new Micro Sensor; it demonstrated a jitter of 0.01 mm or less, position errors below 2 mm and rotation errors of less than 0.3°. As with other EM trackers, errors increase when large tracking volumes with ranges of up to 50 cm are required in clinical environments. For smaller tracking volumes with ranges of up to 15 cm, a high accuracy and robustness was found. This is interesting especially for the TX1 FG which can easily be placed in close vicinity to the region of interest. This article is protected by copyright. All rights reserved.","Franz AM
Seitel A
Cheray D
Maier-Hein L
","(PMID:30414277
)",Polhemus EM Tracked Micro Sensor for CT-guided Interventions.,https://europepmc.org/abstract/MED/30414277%0A
"PURPOSE:To determine the feasibility of using high dimensional computer-extracted features, known as radiomics features, in differentiating primary central nervous system lymphoma (PCNSL) from glioblastoma on multi-parametric MR imaging including diffusion-weighted imaging. METHODS:Retrospective evaluation of data was approved by the local ethics committee and informed consent was waived. A total of 143 patients (two independent cohorts for discovery [n = 86; glioblastoma = 49, PCNSL = 37] and validation [n = 57; glioblastoma = 29, PCNSL = 28]) with newly diagnosed glioblastoma and PCNSL were subjected to radiomics analysis using the multi-parametric MRI (contrast-enhanced T1-weighted imaging, T2-weighted imaging, and diffusion-weighted imaging). Radiomics analyses were performed for two types of regions of interest (ROI) covering contrast-enhancing tumor and whole (enhancing or non-enhancing) tumor plus peritumoral edema. A total of 127 radiomics features were calculated. Feature selection was performed to identify the most discriminating features for every MR image in the discovery cohort. The identified features were used to calculate radiomics scores, which were later used in logistic regression to distinguish between PCNSL and glioblastoma. The classification model was further tested on the independent validation cohort. RESULTS:Fifteen features were selected as significant features in the discovery cohort. Using the identified features and calculated radiomics scores, the logistic regression-based classifier yielded an area under the curve (AUC) of 0.979, sensitivity of 0.938, and specificity of 0.944 in the discovery cohort to distinguish between glioblastoma and PCNSL. A similarly high rate of performance was observed in the validation cohort (AUC = 0.956). CONCLUSIONS:Radiomics features derived from multi-parametric MRI can be used to differentiate PCNSL from glioblastoma effectively.","Kim Y
Cho HH
Kim ST
Park H
Nam D
Kong DS
","(PMID:30232517
)",Radiomics features to distinguish glioblastoma from primary central nervous system lymphoma on multi-parametric MRI.,https://europepmc.org/abstract/MED/30232517%0A
"Organ segmentation is an important pre-processing step in surgery planning and computer-aided diagnosis. In this paper, we propose a fast and accurate liver segmentation framework. Our proposed method combines a knowledge-based slice-by-slice Random Walk (RW) segmentation algorithm (proposed in our previous work) with a superpixel algorithm called the Contrast-enhanced Compact Watershed (CCWS) method to reduce computing time and memory costs. Compared to the commonly used Simple Linear Iterative Clustering (SLIC), we demonstrate that our CCWS is more appropriate for liver segmentation. To improve the methods accuracy, we use a modified narrow band active contour model as a refinement after the initial segmentation. The experiments showed that the superpixel-based slice-by-slice RW could segment the entire liver with improved speed, and the modified active contour model is more precise than the original Chan-Vese Model. As a result, the proposed framework is able to quickly and accurately segment the entire liver.","Yuan Y
Chen YW
Dong C
Yu H
Zhu Z
","(PMID:30359946
)","Hybrid method combining superpixel, random walk and active contour model for fast and accurate liver segmentation.",https://europepmc.org/abstract/MED/30359946%0A
"Intelligent wheelchair technology has recently been utilised to address several mobility problems. Techniques based on brain-computer interface (BCI) are currently used to develop electric wheelchairs. Using human brain control in wheelchairs for people with disability has elicited widespread attention due to its flexibility.This study aims to determine the background of recent studies on wheelchair control based on BCI for disability and map the literature survey into a coherent taxonomy. The study intends to identify the most important aspects in this emerging field as an impetus for using BCI for disability in electric-powered wheelchair (EPW) control, which remains a challenge. The study also attempts to provide recommendations for solving other existing limitations and challenges.We systematically searched all articles about EPW control based on BCI for disability in three popular databases: ScienceDirect, IEEE and Web of Science. These databases contain numerous articles that considerably influenced this field and cover most of the relevant theoretical and technical issues.We selected 100 articles on the basis of our inclusion and exclusion criteria. A large set of articles (55) discussed on developing real-time wheelchair control systems based on BCI for disability signals. Another set of articles (25) focused on analysing BCI for disability signals for wheelchair control. The third set of articles (14) considered the simulation of wheelchair control based on BCI for disability signals. Four articles designed a framework for wheelchair control based on BCI for disability signals. Finally, one article reviewed concerns regarding wheelchair control based on BCI for disability signals.Since 2007, researchers have pursued the possibility of using BCI for disability in EPW control through different approaches. Regardless of type, articles have focused on addressing limitations that impede the full efficiency of BCI for disability and recommended solutions for these limitations.Studies on wheelchair control based on BCI for disability considerably influence society due to the large number of people with disability. Therefore, we aim to provide researchers and developers with a clear understanding of this platform and highlight the challenges and gaps in the current and future studies.","Al-Qaysi ZT
Zaidan BB
Zaidan AA
Suzani MS
","(PMID:29958722
)","A review of disability EEG based wheelchair control system: Coherent taxonomy, open challenges and recommendations.",https://europepmc.org/abstract/MED/29958722%0A
No abstract provided.,"Alex Nguyen PA
Jack Li YC
","(PMID:29903500
)",Improving the quality healthcare through the efficient computer-aided prediction models.,https://europepmc.org/abstract/MED/29903500%0A
"Incoherent broadband cavity-enhanced absorption spectroscopy (IBBCEAS) is of importance for gas detection in environmental monitoring. This review summarizes the unique properties, development and recent progress of the IBBCEAS technique. Principle of IBBCEAS for gas sensing is described, and the development of IBBCEAS from the perspective of system structure is elaborated, including light source, cavity and detection scheme. Performances of the reported IBBCEAS sensor system in laboratory and field measurements are reported. Potential applications of this technique are discussed.","Zheng K
Zheng C
Zhang Y
Wang Y
Tittel FK
","(PMID:30373252
)",Review of Incoherent Broadband Cavity-Enhanced Absorption Spectroscopy (IBBCEAS) for Gas Sensing.,https://europepmc.org/abstract/MED/30373252%0A
"Ground-glass opacity (GGO) is a common CT imaging sign on high-resolution CT, which means the lesion is more likely to be malignant compared to common solid lung nodules. The automatic recognition of GGO CT imaging signs is of great importance for early diagnosis and possible cure of lung cancers. The present GGO recognition methods employ traditional low-level features and system performance improves slowly. Considering the high-performance of CNN model in computer vision field, we proposed an automatic recognition method of 3D GGO CT imaging signs through the fusion of hybrid resampling and layer-wise fine-tuning CNN models in this paper. Our hybrid resampling is performed on multi-views and multi-receptive fields, which reduces the risk of missing small or large GGOs by adopting representative sampling panels and processing GGOs with multiple scales simultaneously. The layer-wise fine-tuning strategy has the ability to obtain the optimal fine-tuning model. Multi-CNN models fusion strategy obtains better performance than any single trained model. We evaluated our method on the GGO nodule samples in publicly available LIDC-IDRI dataset of chest CT scans. The experimental results show that our method yields excellent results with 96.64% sensitivity, 71.43% specificity, and 0.83 F1 score. Our method is a promising approach to apply deep learning method to computer-aided analysis of specific CT imaging signs with insufficient labeled images. Graphical abstract We proposed an automatic recognition method of 3D GGO CT imaging signs through the fusion of hybrid resampling and layer-wise fine-tuning CNN models in this paper. Our hybrid resampling reduces the risk of missing small or large GGOs by adopting representative sampling panels and processing GGOs with multiple scales simultaneously. The layer-wise fine-tuning strategy has ability to obtain the optimal fine-tuning model. Our method is a promising approach to apply deep learning method to computer-aided analysis of specific CT imaging signs with insufficient labeled images.","Han G
Liu X
Zheng G
Wang M
Huang S
","(PMID:29873026
)",Automatic recognition of 3D GGO CT imaging signs through the fusion of hybrid resampling and layer-wise fine-tuning CNNs.,https://europepmc.org/abstract/MED/29873026%0A
"Currently in the United States, the remains of thousands of unidentified human decedents are housed in medical, law enforcement, and forensic facilities throughout the country. A number of digital data repositories have been established to curate and disseminate the details of these unidentified decedent cases; some repositories also maintain records of missing persons. Although a cross-reference for textual data similarity occurs between the missing persons and unidentified decedent records in some repositories, no repository is currently known to employ an image analysis technology for cross-referencing image data. Results suggest that the computer-generated facial approximations used in this research were consistently included in prioritized candidate lists when used in an automated facial recognition context. Two concurrent studies exploring the specific use-case discussed here were executed. The first employed an optimally-conditioned facial image gallery (g=6159) (i.e., a gallery comprised of highly consistent facial images), a research design intended to establish the ceiling performance of the combined use of the two software programs employed. The second employed a gallery (g=1816) compiled from a real-world dataset of missing persons' facial images, a research design intended to inform potential operational performance when using the highly varied facial images typically comprising public databases. Multiple types of facial approximations (reconstructions) with varying degrees of weight adjustments, age adjustments, or the presence (or absence) of visible eyes, and combinations of these variables, were evaluated. Overall, in the larger, optimally modeled study, 53% of the facial approximations for the t=159 test subjects examined were matched to his or her corresponding life photo within the top 50 images of a candidate list generated from a blind (unrestricted) search of the highly consistent gallery (g=6159). In the operationally modeled study, 31% of the test subjects' (t=16) facial approximations were matched to their corresponding life photos within the top 50 images of a candidate list generated from a blind search of the gallery populated with images from an operational dataset (g=1816). As anticipated, candidate list inclusion rates improved with the use of demographic filters. No significantly different inclusion rates were observed between the sex or age cohorts examined. Significant differences were, however, observed across population cohorts. Entities curating missing and unidentified decedent records may benefit from a paired implementation of facial recognition technology and computer-generated approximations as part of a comprehensive investigative strategy for the specific envisioned use-case discussed in this research.","Parks CL
Monson KL
","(PMID:30108019
)",Recognizability of computer-generated facial approximations in an automated facial recognition context for potential use in unidentified persons data repositories: Optimally and operationally modeled conditions.,https://europepmc.org/abstract/MED/30108019%0A
"Pattern recognition and classification of images are key challenges throughout the life sciences. We combined two approaches for large-scale classification of fluorescence microscopy images. First, using the publicly available data set from the Cell Atlas of the Human Protein Atlas (HPA), we integrated an image-classification task into a mainstream video game (EVE Online) as a mini-game, named Project Discovery. Participation by 322,006 gamers over 1 year provided nearly 33 million classifications of subcellular localization patterns, including patterns that were not previously annotated by the HPA. Second, we used deep learning to build an automated Localization Cellular Annotation Tool (Loc-CAT). This tool classifies proteins into 29 subcellular localization patterns and can deal efficiently with multi-localization proteins, performing robustly across different cell types. Combining the annotations of gamers and deep learning, we applied transfer learning to create a boosted learner that can characterize subcellular protein distribution with F1 score of 0.72. We found that engaging players of commercial computer games provided data that augmented deep learning and enabled scalable and readily improved image classification.","Sullivan DP
Winsnes CF
Åkesson L
Hjelmare M
Wiking M
Schutten R
Campbell L
Leifsson H
Rhodes S
Nordgren A
Smith K
Revaz B
Finnbogason B
Szantner A
Lundberg E
","(PMID:30125267
)",Deep learning is combined with massive-scale citizen science to improve large-scale image classification.,https://europepmc.org/abstract/MED/30125267%0A
"Parkinson's Disease (PD) is associated with decreased ability to perform habitual tasks, relying instead on goal-directed behaviour subserved by different cortical/subcortical circuits, including parts of the putamen. We explored the functional subunits in the putamen in PD using novel dynamic connectivity features derived from resting state fMRI recorded from thirty PD subjects and twenty-eight age-matched healthy controls (HC). Dynamic functional segmentation of the putamina was obtained by determining the correlation between each voxel in each putamen along a moving window and applying a joint temporal clustering algorithm to establish cluster membership of each voxel at each window. Contiguous voxels that had consistent cluster membership across all windows were then considered to be part of a homogeneous functional subunit. As PD subjects robustly had two homogenous clusters in the putamina, we also segmented the putamina in HC into two dynamic clusters for a fair comparison. We then estimated the dynamic connectivity using sliding windowed correlation between the mean signal from the identified homogenous subunits and 56 other predefined cortical and subcortical ROIs. Specifically, the mean dynamic connectivity strength and connectivity deviation were then compared to evaluate subregional differences. HC subjects had significant differences in mean dynamic connectivity and connectivity deviation between the two putaminal subunits. The posterior subunit connected strongly to sensorimotor areas, the cerebellum, as well as the middle frontal gyrus. The anterior subunit had strong mean dynamic connectivity to the nucleus accumbens, hippocampus, amygdala, caudate and cingulate. In contrast, PD subjects had fewer differences in mean dynamic connectivity between subunits, indicating a degradation of subregional specificity. Overall UPDRS III and MoCA scores could be predicted using mean dynamic connectivity strength and connectivity deviation. Side of onset of the disease was also jointly related with functional connectivity features. Our results suggest a robust loss of specificity of mean dynamic connectivity and connectivity deviation in putaminal subunits in PD that is sensitive to disease severity. In addition, altered mean dynamic connectivity and connectivity deviation features in PD suggest that looking at connectivity dynamics offers an additional dimension for assessment of neurodegenerative disorders.","Liu A
Lin SJ
Mi T
Chen X
Chan P
Wang ZJ
McKeown MJ
","(PMID:30388599
 PMCID:PMC6214880)",Decreased subregional specificity of the putamen in Parkinson's Disease revealed by dynamic connectivity-derived parcellation.,https://europepmc.org/abstract/MED/30388599%0A
"Entropy has become increasingly popular in computer science and information theory because it can be used to measure the predictability and redundancy of knowledge bases, especially ontologies. However, current entropy applications that evaluate ontologies consider only single-point connectivity rather than path connectivity, and they assign equal weights to each entity and path.We propose an Entropy-Aware Path-Based (EAPB) metric for ontology quality by considering the path information between different vertices and textual information included in the path to calculate the connectivity path of the whole network and dynamic weights between different nodes. The information obtained from structure-based embedding and text-based embedding is multiplied by the connectivity matrix of the entropy computation. EAPB is analytically evaluated against the state-of-the-art criteria. We have performed empirical analysis on real-world medical ontologies and a synthetic ontology based on the following three aspects: ontology statistical information (data quantity), entropy evaluation (data quality), and a case study (ontology structure and text visualization). These aspects mutually demonstrate the reliability of the proposed metric. The experimental results show that the proposed EAPB can effectively evaluate ontologies, especially those in the medical informatics field.We leverage path information and textual information to enrich the network representational learning and aid in entropy computation. The analytics and assessments of semantic web can benefit from the structure information but also the text information. We believe that EAPB is helpful for managing ontology development and evaluation projects. Our results are reproducible and we will release the source code and ontology of this work after publication. (Source code and ontology: https://github.com/AnonymousResearcher1/ontologyEvaluate ).","Shen Y
Chen D
Tang B
Yang M
Lei K
","(PMID:30097014
 PMCID:PMC6086046)",EAPB: entropy-aware path-based metric for ontology quality.,https://europepmc.org/abstract/MED/30097014%0A
"Current Chinese medicine has an urgent demand for convenient medical services. When facing a large number of patients, understanding patients' questions automatically and precisely is useful. Different from the high professional medical text, patients' questions contain only a small amount of descriptions regarding the symptoms, and the questions are slightly professional and colloquial.The aim of this paper is to implement a department classification system for patient questions. Patients' questions will be classified into 11 departments, such as surgery and others.This paper presents a morpheme growth model that enhances the memories of key elements in questions, and later extracts the ""label-indicators"" and germinates the expansion vectors around them. Finally, the model inputs the expansion vectors into a neural network to assign department labels for patients' questions.All compared methods are validated by experiments on three datasets that are composed of real patient questions. The proposed method has some ability to improve the performance of the classification.The proposed method is effective for the departments classification of patients questions and serves as a useful system for the automatic understanding of patient questions.","Hu Y
Wen G
Ma J
Li D
Wang C
Li H
Huan E
","(PMID:29705197
)",Label-indicator morpheme growth on LSTM for Chinese healthcare question department classification.,https://europepmc.org/abstract/MED/29705197%0A
"BACKGROUND:Shape and density of intracerebral hemorrhage (ICH) are associated with a higher risk of poor treatment outcome. However, methods of assessment for the features are still inconclusive. Therefore, we decided to measure ICH shape irregularity using shape factors to achieve objective results. METHODS:We retrospectively analyzed 48 patients with spontaneous ICH confirmed by head computed tomography (CT) scan. We obtained detailed medical history and blood test results from medical records. On admission patients were assessed using Glasgow Coma Scale score, and on discharge patients were assessed using Glasgow Outcome Scale (GOS) score. GOS score of less than 3 was defined as poor outcome. For each slice of CT scan with visible ICH, we extracted its contour and calculated the fractal dimension (FD), compactness (C), and Fourier factor (FF). We also calculated the circle factor (CF), which was defined as the contour perimeter/perimeter of the biggest circle that can be inscribed into the contour, and density heterogeneity, defined as the variance of pixel density. RESULTS:A total of 28 patients (58.33%) had poor treatment outcome. Those patients had significantly higher C (0.71 ± 0.09 vs. 0.59 ± 0.09; P < 0.01), FD (1.42 ± 0.12 vs. 1.27 ± 0.09; P < 0.01), and CF (3.59 ± 0.92 vs. 2.63 ± 0.63; P < 0.01). In multivariate logistic regression analysis, FD (odds ratio, 4.176; 95% confidence interval, 1.551-15.577; P = 0.012) remained independently associated with higher risk of poor treatment outcome. CONCLUSIONS:Each of the shape descriptors, except FF, was associated with treatment outcome after ICH. FD can be used as an independent predictor of outcome.","Kliś KM
Krzyżewski RM
Kwinta BM
Stachura K
Gąsowski J
","(PMID:30189314
)",Computer-Assisted Analysis of Intracerebral Hemorrhage Shape and Density.,https://europepmc.org/abstract/MED/30189314%0A
"Contrary to the criticism that mysterious, unaccountable black-box software systems threaten to make the logic of critical decisions inscrutable, we argue that algorithms are fundamentally understandable pieces of technology. Software systems are designed to interact with the world in a controlled way and built or operated for a specific purpose, subject to choices and assumptions. Traditional power structures can and do turn systems into opaque black boxes, but technologies can always be understood at a higher level, intensionally in terms of their designs and operational goals and extensionally in terms of their inputs, outputs and outcomes. The mechanisms of a system's operation can always be examined and explained, but a focus on machinery obscures the key issue of power dynamics. While structural inscrutability frustrates users and oversight entities, system creators and operators always determine that the technologies they deploy are fit for certain uses, making no system wholly inscrutable. We investigate the contours of inscrutability and opacity, the way they arise from power dynamics surrounding software systems, and the value of proposed remedies from disparate disciplines, especially computer ethics and privacy by design. We conclude that policy should not accede to the idea that some systems are of necessity inscrutable. Effective governance of algorithms comes from demanding rigorous science and engineering in system design, operation and evaluation to make systems verifiably trustworthy. Rather than seeking explanations for each behaviour of a computer system, policies should formalize and make known the assumptions, choices, and adequacy determinations associated with a system.This article is part of the theme issue 'Governing artificial intelligence: ethical, legal, and technical opportunities and challenges'.","Kroll JA
","(PMID:30322999
)",The fallacy of inscrutability.,https://europepmc.org/abstract/MED/30322999%0A
"Flagellar rotation regulates the phenomenon of chemotaxis in bacteria. The interaction between the stator unit and the rotor unit of the flagellar motors is responsible for switching the direction of bacterial flagellar rotation. However, the molecular interaction mechanism between the stator (MotA/MotB) and the rotor (FliG/FliM/FliN) proteins for the flagellar rotational direction switching was not very clear. To address this, the asymmetry in the copies of FliG, FliM, and FliN molecules was resolved by reconstructing the switch complex using a modeled rotor unit that fulfills the experimentally available geometric constraints. The diameter of our assembled switch complex supported the existing literature. Experimental evidence and the conformational spread model validates our constructed switch complex. Subsequently, normal mode analysis (NMA) on these constructed protomer units revealed that the most fluctuating molecule in the rotor unit is FliG, which interacts with the bacterial stator through its C-terminal domain. NMA also facilitates our understanding of the reorientation mechanism of FliG between the two states of its flagellar rotation, i.e., counter-clockwise to clockwise and vice versa. Our observations regarding speed regulation, the gap between rotor and stator, and the flagellar switching due to the activity of cytoplasmic proteins, indicate that the bacterial flagellar motor uses the same mechanism as that of an electric motor. Graphical abstract Molecular mechanism of the bacterial flagellar switch.","Maiti S
Mitra P
","(PMID:30215219
)",Bacterial flagellar switching: a molecular mechanism directed by the logic of an electric motor.,https://europepmc.org/abstract/MED/30215219%0A
"The increasing use of colorectal cancer screening programs has contributed to the growing number of colonoscopies performed by health centers. Hence, in recent years there has been a tendency to develop medical diagnosis support tools in order to assist specialists. This research has designed an automatized polyp detection system that allows a reduction in the rate of missed polyps that can lead to interval cancer; one of the main risks existing in colonoscopy. A characterization has therefore been made of the shape, color and curvature of edges and their regions, enabling the segmentation of polyps present in colonoscopy images. A 90.53% polyp detection rate has been achieved using the designed system, and 76.29% and 71.57% segmentation quality for the Annotated Area Covered and Dice Coefficient indicators respectively. This system aims to offer assistance with medical diagnosis that has a positive impact on patient health.","Sánchez-González A
García-Zapirain B
Sierra-Sosa D
Elmaghraby A
","(PMID:30015012
)",Automatized colon polyp segmentation via contour region analysis.,https://europepmc.org/abstract/MED/30015012%0A
No abstract provided.,"Brendel VP
","(PMID:30324739
)",From small RNA discoveries to a new paradigm in computational genomics?,https://europepmc.org/abstract/MED/30324739%0A
"As funding agencies embrace open science principles that encourage sharing data and computer code developed to produce research outputs, we must respond with new modes of publication. Furthermore, as we address the expanding reproducibility crisis in the sciences, we must work to release research materials in ways that enable reproducibility-publishing data, computer code, and research products in addition to the traditional journal article. Toward addressing these needs, we present an example framework to model and map soil organic carbon (SOC) in the cereal grains production region of the northwestern United States. Primarily associated with soil organic matter, SOC relates to many soil properties that influence resiliency and soil health for agriculture. It is also critical for understanding soil-atmospheric C flux, a significant part of the overall C budget of the Earth. The technique for modeling soil properties uses seven categories of environmental input data to make predictions: known soil attributes, climatic values, organisms present, relief, parent material, age, and spatial location. We gather data representing these categories from various public sources. The map is produced using a random forest statistical model with inputs to predict SOC content on a 30-m spatial grid. All modeling components including input data, metadata, computer code, and output products are made freely available under an explicit open-source license. In this way, reproducibility is supported, the methods and code released are available to be reused by other researchers, and the research products are open to critical review and improvement.","Flathers E
Gessler PE
","(PMID:30025068
)",Building an Open Science Framework to Model Soil Organic Carbon.,https://europepmc.org/abstract/MED/30025068%0A
"Posttranslational modification (PTM) is a biological mechanism involved in the enzymatic modification of proteins after translation by ribosomes. Two or more modifications occurring at one residue can be transformed into a multi-label system. Two or more simultaneous modifications on a residue is more common than single PTMs. Lysine residues in proteins can be subjected to a variety of PTMs, such as ubiquitination, acetylation, sumoylation, methylation, and succinylation. Identification of uncharacterized sequences in proteins is a highly significant and state-of-the-art issue. Notably, in order to provide a method of processing multi-label sequences of lysine residues, it is highly desirable to develop computational methods to predict lysine acetylation and sumoylation modifications.In this paper, we first launched an integrated approach, known as the five-step prediction method (FSPM), to solve the problem effectively by (1) using one-sided selection (OSS) to deal with imbalanced data, (2) extracting binary features from protein sequences, (3) incorporating binary relevance, classifier chains and multi-class transformation methods to simplify multi-label problems, (4) constructing different classifiers, and (5) implementing cross-validation and evaluating these classifiers. In 10-fold cross-validation, FSPM achieved an accuracy of 61.49% and an absolute-true rate of 60.17%. The results showed that FSPM is accurate and could be used as a powerful engine in multi-label systems. We also conducted a variety of statistical analyses of the predicted results to discuss the biological functions of lysine acetylation and sumoylation.","Yang Y
Wang H
Ding J
Xu Y
","(PMID:30015011
)",iAcet-Sumo: Identification of lysine acetylation and sumoylation sites in proteins by multi-class transformation methods.,https://europepmc.org/abstract/MED/30015011%0A
"In recent years DNA microarray technology, leading to the generation of high-volume biological data, has gained significant attention. To analyze this high volume gene-expression data, one such powerful tool is Clustering. For any clustering algorithm, its efficiency majorly depends upon the underlying similarity/dissimilarity measure. During the analysis of such data often there is a need to further explore the similarity of genes not only with respect to their expression values but also with respect to their functional annotations, which can be obtained from Gene Ontology (GO) databases. In the existing literature, several novel clustering and bi-clustering approaches were proposed to identify co-regulated genes from gene-expression datasets. Identifying co-regulated genes from gene expression data misses some important biological information about functionalities of genes, which is necessary to identify semantically related genes. In this paper, we have proposed sixteen different semantic gene-gene dissimilarity measures utilizing biological information of genes retrieved from a global biological database namely Gene Ontology (GO). Four proximity measures, viz. Euclidean, Cosine, point symmetry and line symmetry are utilized along with four different representations of gene-GO-term annotation vectors to develop total sixteen gene-gene dissimilarity measures. In order to illustrate the profitability of developed dissimilarity measures, some multi-objective as well as single-objective clustering algorithms are applied utilizing proposed measures to identify functionally similar genes from Mouse genome and Yeast datasets. Furthermore, we have compared the performance of our proposed sixteen dissimilarity measures with three existing state-of-the-art semantic similarity and distance measures.","Acharya S
Saha S
Pradhan P
","(PMID:30184472
)",Novel symmetry-based gene-gene dissimilarity measures utilizing Gene Ontology: Application in gene clustering.,https://europepmc.org/abstract/MED/30184472%0A
"BACKGROUND:Identifying cancer biomarkers from transcriptomics data is of importance to cancer research. However, transcriptomics data are often complex and heterogeneous, which complicates the identification of cancer biomarkers in practice. Currently, the heterogeneity still remains a challenge for detecting subtle but consistent changes of gene expression in cancer cells. RESULTS:In this paper, we propose to adaptively capture the heterogeneity of expression across samples in a gene regulation space instead of in a gene expression space. Specifically, we transform gene expression profiles into gene regulation profiles and mathematically formulate gene regulation probabilities (GRPs)-based statistics for characterizing differential expression of genes between tumor and normal tissues. Finally, an unbiased estimator (aGRP) of GRPs is devised that can interrogate and adaptively capture the heterogeneity of gene expression. We also derived an asymptotical significance analysis procedure for the new statistic. Since no parameter needs to be preset, aGRP is easy and friendly to use for researchers without computer programming background. We evaluated the proposed method on both simulated data and real-world data and compared with previous methods. Experimental results demonstrated the superior performance of the proposed method in exploring the heterogeneity of expression for capturing subtle but consistent alterations of gene expression in cancer. CONCLUSIONS:Expression heterogeneity largely influences the performance of cancer biomarker identification from transcriptomics data. Models are needed that efficiently deal with the expression heterogeneity. The proposed method can be a standalone tool due to its capacity of adaptively capturing the sample heterogeneity and the simplicity in use. SOFTWARE AVAILABILITY:The source code of aGRP can be downloaded from https://github.com/hqwang126/aGRP .","Xie XP
Xie YF
Liu YT
Wang HQ
","(PMID:30390627
 PMCID:PMC6215657)",Adaptively capturing the heterogeneity of expression for cancer biomarker identification.,https://europepmc.org/abstract/MED/30390627%0A
"In this paper, we develop a method for the simultaneous estimation of spectral density functions (SDFs) for a collection of stationary time series that share some common features. Due to the similarities among the SDFs, the log-SDF can be represented using a common set of basis functions. The basis shared by the collection of the log-SDFs is estimated as a low-dimensional manifold of a large space spanned by a prespecified rich basis. A collective estimation approach pools information and borrows strength across the SDFs to achieve better estimation efficiency. Moreover, each estimated spectral density has a concise representation using the coefficients of the basis expansion, and these coefficients can be used for visualization, clustering, and classification purposes. The Whittle pseudo-maximum likelihood approach is used to fit the model and an alternating blockwise Newton-type algorithm is developed for the computation. A web-based shiny App found at ""https://ncsde.shinyapps.io/NCSDE"" is developed for visualization, training, and learning the SDFs collectively using the proposed technique. Finally, we apply our method to cluster similar brain signals recorded by the for identifying synchronized brain regions according to their spectral densities.","Maadooliat M
Sun Y
Chen T
","(PMID:30259540
)",Nonparametric collective spectral density estimation with an application to clustering the brain signals.,https://europepmc.org/abstract/MED/30259540%0A
"By introducing sign constraints on the weights, this paper proposes sign constrained rectifier networks (SCRNs), whose training can be solved efficiently by the well known majorization-minimization (MM) algorithms. We prove that the proposed two-hidden-layer SCRNs, which exhibit negative weights in the second hidden layer and negative weights in the output layer, are capable of separating any number of disjoint pattern sets. Furthermore, the proposed two-hidden-layer SCRNs can decompose the patterns of each class into several clusters so that each cluster is convexly separable from all the patterns from the other classes. This provides a means to learn the pattern structures and analyse the discriminant factors between different classes of patterns. Experimental results are provided to show the benefits of sign constraints in improving classification performance and the efficiency of the proposed MM algorithm.","An S
Boussaid F
Bennamoun M
Sohel F
","(PMID:29945061
)",Exploiting layerwise convexity of rectifier networks with sign constrained weights.,https://europepmc.org/abstract/MED/29945061%0A
"Further improvements in the clinical care of our most vulnerable patients-preterm infants-are needed. Novel diagnostic and surveillance tools facilitate such advances. The GASMAS technique has shown potential to become a tool to, noninvasively, monitor gas in the lungs of preterm infants, by placing a laser source and a detector on the chest wall skin. It is believed that this technology will become a valuable clinical diagnostic tool for monitoring the lung function of these patients. Today, the technology is, for this application, in an early stage and further investigations are needed. In the present study, a three-dimensional computer model of the thorax of an infant is constructed, from a set of CT images. Light transport simulations are performed to provide information about the position dependence of the laser- and detector probe on the thorax of the infant. The result of the simulations, based on the study method and the specified model used in this work, indicates that measurement geometries in front and on the side of the lung are favorable in order to obtain a good gas absorption signal.","Liao P
Larsson J
Krite Svanberg E
Lundin P
Swartling J
Lewander Xu M
Bood J
Andersson-Engels S
","(PMID:29978572
)",Computer simulation analysis of source-detector position for percutaneously measured O2 -gas signal in a three-dimensional preterm infant lung.,https://europepmc.org/abstract/MED/29978572%0A
"The human cerebellum plays an essential role in motor control, is involved in cognitive function (i.e., attention, working memory, and language), and helps to regulate emotional responses. Quantitative in-vivo assessment of the cerebellum is important in the study of several neurological diseases including cerebellar ataxia, autism, and schizophrenia. Different structural subdivisions of the cerebellum have been shown to correlate with differing pathologies. To further understand these pathologies, it is helpful to automatically parcellate the cerebellum at the highest fidelity possible. In this paper, we coordinated with colleagues around the world to evaluate automated cerebellum parcellation algorithms on two clinical cohorts showing that the cerebellum can be parcellated to a high accuracy by newer methods. We characterize these various methods at four hierarchical levels: coarse (i.e., whole cerebellum and gross structures), lobe, subdivisions of the vermis, and the lobules. Due to the number of labels, the hierarchy of labels, the number of algorithms, and the two cohorts, we have restricted our analyses to the Dice measure of overlap. Under these conditions, machine learning based methods provide a collection of strategies that are efficient and deliver parcellations of a high standard across both cohorts, surpassing previous work in the area. In conjunction with the rank-sum computation, we identified an overall winning method.","Carass A
Cuzzocreo JL
Han S
Hernandez-Castillo CR
Rasser PE
Ganz M
Beliveau V
Dolz J
Ben Ayed I
Desrosiers C
Thyreau B
Romero JE
Coupé P
Manjón JV
Fonov VS
Collins DL
Ying SH
Onyike CU
Crocetti D
Landman BA
Mostofsky SH
Thompson PM
Prince JL
","(PMID:30099076
)",Comparing fully automated state-of-the-art cerebellum parcellation from magnetic resonance images.,https://europepmc.org/abstract/MED/30099076%0A
No abstract provided.,"Klimburg A
","(PMID:30301995
)","Trolling, hacking and the 2016 US presidential election.",https://europepmc.org/abstract/MED/30301995%0A
No abstract provided.,"Matthews D
","(PMID:30279599
)",Supercharge your data wrangling with a graphics card.,https://europepmc.org/abstract/MED/30279599%0A
No abstract provided.,"Adhikari A
","(PMID:30270821
 PMCID:PMC6166413)",Computer assisted orthopaedic surgery - current state and impact.,https://europepmc.org/abstract/MED/30270821%0A
No abstract provided.,"Maxmen A
","(PMID:30356197
)",Self-driving car dilemmas reveal that moral choices are not universal.,https://europepmc.org/abstract/MED/30356197%0A
"Hypertensive Retinopathy (HR) caused by hypertension is a retinal disease which may leads to vision loss and blindness. Computer aided diagnostic systems for various diseases are being used in clinics but there is a need to develop an automated system that detects and grades HR disease. In this paper, an automated system is presented that detects and grades HR disease using Arteriovenous Ratio (AVR).The presented system includes three modules i.e. main component extraction, artery/vein (A/V) classification and finally AVR calculation and grading of HR. Proposed system uses vascular map and a set of hybrid features for A/V classification. The evaluation of proposed system is carried out using three datasets. The proposed system shows average accuracies of 95.14% for images of INSPIRE-AVR database, 96.82% for images of VICAVR database and 98.76% for local dataset AVRDB. These results support that the proposed system is trustworthy for clinical use in detection and grading of HR disease. Main contribution of proposed system is that it utilizes complete blood vessel map for A/V classification. These arteries and veins are then used to calculate AVR and grade HR cases based on AVR values. Another contribution of this article is that it presents a new dataset AVRDB for A/V classification and HR detection.","Akbar S
Akram MU
Sharif M
Tariq A
Khan SA
","(PMID:30041920
)",Decision support system for detection of hypertensive retinopathy using arteriovenous ratio.,https://europepmc.org/abstract/MED/30041920%0A
"The study of neuronal morphology in relation to function, and the development of effective medicines to positively impact this relationship in patients suffering from neurodegenerative diseases, increasingly involves image-based high-content screening and analysis. The first critical step toward fully automated high-content image analyses in such studies is to detect all neuronal cells and distinguish them from possible non-neuronal cells or artifacts in the images. Here we investigate the performance of well-established machine learning techniques for this purpose. These include support vector machines, random forests, k-nearest neighbors, and generalized linear model classifiers, operating on an extensive set of image features extracted using the compound hierarchy of algorithms representing morphology, and the scale-invariant feature transform. We present experiments on a dataset of rat hippocampal neurons from our own studies to find the most suitable classifier(s) and subset(s) of features in the common practical setting where there is very limited annotated data for training. The results indicate that a random forests classifier using the right feature subset ranks best for the considered task, although its performance is not statistically significantly better than some support vector machine based classification models.","Mata G
Radojević M
Fernandez-Lozano C
Smal I
Werij N
Morales M
Meijering E
Rubio J
","(PMID:30215167
)",Automated Neuron Detection in High-Content Fluorescence Microscopy Images Using Machine Learning.,https://europepmc.org/abstract/MED/30215167%0A
"The functional brain network has gained increased attention in the neuroscience community because of its ability to reveal the underlying architecture of human brain. In general, majority work of functional network connectivity is built based on the correlations between discrete-time-series signals that link only two different brain regions. However, these simple region-to-region connectivity models do not capture complex connectivity patterns between three or more brain regions that form a connectivity subnetwork, or subnetwork for short. To overcome this current limitation, a hypergraph learning-based method is proposed to identify subnetwork differences between two different cohorts. To achieve our goal, a hypergraph is constructed, where each vertex represents a subject and also a hyperedge encodes a subnetwork with similar functional connectivity patterns between different subjects. Unlike previous learning-based methods, our approach is designed to jointly optimize the weights for all hyperedges such that the learned representation is in consensus with the distribution of phenotype data, i.e. clinical labels. In order to suppress the spurious subnetwork biomarkers, we further enforce a sparsity constraint on the hyperedge weights, where a larger hyperedge weight indicates the subnetwork with the capability of identifying the disorder condition. We apply our hypergraph learning-based method to identify subnetwork biomarkers in Autism Spectrum Disorder (ASD) and Attention Deficit Hyperactivity Disorder (ADHD). A comprehensive quantitative and qualitative analysis is performed, and the results show that our approach can correctly classify ASD and ADHD subjects from normal controls with 87.65 and 65.08% accuracies, respectively.","Zu C
Gao Y
Munsell B
Kim M
Peng Z
Cohen JR
Zhang D
Wu G
","(PMID:29948906
)",Identifying disease-related subnetwork connectome biomarkers by sparse hypergraph learning.,https://europepmc.org/abstract/MED/29948906%0A
"The interaction of N two-level atoms with a single-mode light field is an extensively studied many-body problem in quantum optics, first analyzed by Dicke in the context of superradiance. A characteristic of such systems is the cooperative enhancement of the coupling strength by a factor of N. In this study, we extended this cooperatively enhanced coupling to a solid-state system, demonstrating that it also occurs in a magnetic solid in the form of matter-matter interaction. Specifically, the exchange interaction of N paramagnetic erbium(III) (Er3+) spins with an iron(III) (Fe3+) magnon field in erbium orthoferrite (ErFeO3) exhibits a vacuum Rabi splitting whose magnitude is proportional to N. Our results provide a route for understanding, controlling, and predicting novel phases of condensed matter using concepts and tools available in quantum optics.","Li X
Bamba M
Yuan N
Zhang Q
Zhao Y
Xiang M
Xu K
Jin Z
Ren W
Ma G
Cao S
Turchinovich D
Kono J
","(PMID:30139871
)",Observation of Dicke cooperativity in magnetic interactions.,https://europepmc.org/abstract/MED/30139871%0A
"Individual perspiration level indicates a person's physical status as well as their comfort level. Therefore, continuous perspiration level measurement enables people to monitor these conditions for applications including fitness assessment, athlete physical status monitoring, and patient/elderly care. Prior work on perspiration (sweat) sensing required the user either to be static or to wear the adhesive sensor directly on the skin, which limits users' mobility and comfort. In this paper, we present a novel conductive thread-based textile sensor that measures an individual's on-cloth sweat quantity. The sensor consists of three conductive threads. Each conductive thread is surrounded by a braided cotton cover. An additional braided cotton cover is placed outside the three conductive threads, holding them in a position that is stable for measurement. the sensor can be embedded at various locations on a person's clothing. When the person sweats, the cotton braids absorb the sweat and change the conductivity (resistance) between conductive threads. We used a voltage dividing circuit to measure this resistance as the sensor output (DC). We then conducted a sensor calibration to map this measured voltage to the quantity of electrolyte solution (with the same density as sweat) applied to the sensor. We used this sensor to measure individuals' perspiration quantity and infer their perceived perspiration levels. The system is able to limit the average prediction error to 0.4 levels when compared to five pre-defined perceived perspiration levels.","Jia J
Xu C
Pan S
Xia S
Wei P
Noh HY
Zhang P
Jiang X
","(PMID:30400608
)",Conductive Thread-Based Textile Sensor for Continuous Perspiration Level Monitoring.,https://europepmc.org/abstract/MED/30400608%0A
"BACKGROUND:SAM (Self-help for Anxiety Management) is a mobile phone app that provides self-help for anxiety management. Launched in 2013, the app has achieved over one million downloads on the iOS and Android platform app stores. Key features of the app are anxiety monitoring, self-help techniques, and social support via a mobile forum (""the Social Cloud""). This paper presents unique insights into eMental health app usage patterns and explores user behaviors and usage of self-help techniques. OBJECTIVE:The objective of our study was to investigate behavioral engagement and to establish discernible usage patterns of the app linked to the features of anxiety monitoring, ratings of self-help techniques, and social participation. METHODS:We use data mining techniques on aggregate data obtained from 105,380 registered users of the app's cloud services. RESULTS:Engagement generally conformed to common mobile participation patterns with an inverted pyramid or ""funnel"" of engagement of increasing intensity. We further identified 4 distinct groups of behavioral engagement differentiated by levels of activity in anxiety monitoring and social feature usage. Anxiety levels among all monitoring users were markedly reduced in the first few days of usage with some bounce back effect thereafter. A small group of users demonstrated long-term anxiety reduction (using a robust measure), typically monitored for 12-110 days, with 10-30 discrete updates and showed low levels of social participation. CONCLUSIONS:The data supported our expectation of different usage patterns, given flexible user journeys, and varying commitment in an unstructured mobile phone usage setting. We nevertheless show an aggregate trend of reduction in self-reported anxiety across all minimally-engaged users, while noting that due to the anonymized dataset, we did not have information on users also enrolled in therapy or other intervention while using the app. We find several commonalities between these app-based behavioral patterns and traditional therapy engagement.","Matthews P
Topham P
Caleb-Solly P
","(PMID:30287415
)",Interaction and Engagement with an Anxiety Management App: Analysis Using Large-Scale Behavioral Data.,https://europepmc.org/abstract/MED/30287415%0A
"Computer-aided diagnosis systems for assisting the classification of various diseases have the potential to improve radiologists' diagnostic accuracy and efficiency, as reported in several studies. Conventional systems generally provide the probabilities of disease types in terms of numerical values, a method that may not be efficient for radiologists who are trained by reading a large number of images. Presentation of reference images similar to those of a new case being diagnosed can supplement the probability outputs based on computerized analysis as an intuitive guide, and it can assist radiologists in their diagnosis, reporting, and treatment planning. Many studies on content-based medical image retrievals have been reported on. For retrieval of perceptually similar and diagnostically relevant images, incorporation of perceptual similarity data by radiologists has been suggested. In this paper, studies on image retrieval methods are reviewed with a special focus on quantification, utilization, and the evaluation of subjective similarities between pairs of images.","Muramatsu C
","(PMID:29740749
)",Overview on subjective similarity of images for content-based medical image retrieval.,https://europepmc.org/abstract/MED/29740749%0A
"We generalize chaos game representation (CGR) to higher dimensional spaces while maintaining its bijection, keeping such method sufficiently representative and mathematically rigorous compare to previous attempts. We first state and prove the asymptotic property of CGR and our generalized chaos game representation (GCGR) method. The prediction follows that the dissimilarity of sequences which possess identical subsequences but distinct positions would be lowered exponentially by the length of the identical subsequence; this effect was taking place unbeknownst to researchers. By shining a spotlight on it now, we show the effect fundamentally supports (G)CGR as a similarity measure or feature extraction technique. We develop two feature extraction techniques: GCGR-Centroid and GCGR-Variance. We use the GCGR-Centroid to analyze the similarity between protein sequences by using the datasets 9 ND5, 24 TF and 50 beta-globin proteins. We obtain consistent results compared with previous studies which proves the significance thereof. Finally, by utilizing support vector machines, we train the anticancer peptide prediction model by using both GCGR-Centroid and GCGR-Variance, and achieve a significantly higher prediction performance by employing the 3 well-studied anticancer peptide datasets.","Ge L
Liu J
Zhang Y
Dehmer M
","(PMID:30291366
)",Identifying anticancer peptides by using a generalized chaos game representation.,https://europepmc.org/abstract/MED/30291366%0A
"Age-related macular degeneration (ARMD) is one of the most common retinal syndromes that occurs in elderly people. Different eye testing techniques such as fundus photography and optical coherence tomography (OCT) are used to clinically examine the ARMD-affected patients. Many researchers have worked on detecting ARMD from fundus images, few of them also worked on detecting ARMD from OCT images. However, there are only few systems that establish the correspondence between fundus and OCT images to give an accurate prediction of ARMD pathology. In this paper, we present fully automated decision support system that can automatically detect ARMD by establishing correspondence between OCT and fundus imagery. The proposed system also distinguishes between early, suspect and confirmed ARMD by correlating OCT B-scans with respective region of the fundus image. In first phase, proposed system uses different B-scan based features along with support vector machine (SVM) to detect the presence of drusens and classify it as ARMD or normal case. In case input OCT scan is classified as ARMD, region of interest from corresponding fundus image is considered for further evaluation. The analysis of fundus image is performed using contrast enhancement and adaptive thresholding to detect possible drusens from fundus image and proposed system finally classified it as early stage ARMD or advance stage ARMD. The proposed system is tested on local data set of 100 patients with100 fundus images and 6800 OCT B-scans. Proposed system detects ARMD with the accuracy, sensitivity, and specificity ratings of 98.0, 100, and 97.14%, respectively.","Khalid S
Akram MU
Hassan T
Jameel A
Khalil T
","(PMID:29204763
)",Automated Segmentation and Quantification of Drusen in Fundus and Optical Coherence Tomography Images for Detection of ARMD.,https://europepmc.org/abstract/MED/29204763%0A
"BACKGROUND:Biomedical event extraction is a crucial task in biomedical text mining. As the primary forum for international evaluation of different biomedical event extraction technologies, BioNLP Shared Task represents a trend in biomedical text mining toward fine-grained information extraction (IE). The fourth series of BioNLP Shared Task in 2016 (BioNLP-ST'16) proposed three tasks, in which the Bacteria Biotope event extraction (BB) task has been put forward in the earlier BioNLP-ST. Deep learning methods provide an effective way to automatically extract more complex features and achieve notable results in various natural language processing tasks. RESULTS:The experimental results show that the presented approach can achieve an F-score of 57.42% in the test set, which outperforms previous state-of-the-art official submissions to BioNLP-ST 2016. CONCLUSIONS:In this paper, we propose a novel Gated Recurrent Unit Networks framework integrating attention mechanism for extracting biomedical events between biotope and bacteria from biomedical literature, utilizing the corpus from the BioNLP'16 Shared Task on Bacteria Biotope task. The experimental results demonstrate the potential and effectiveness of the proposed framework.","Li L
Wan J
Zheng J
Wang J
","(PMID:30367569
)",Biomedical event extraction based on GRU integrating attention mechanism.,https://europepmc.org/abstract/MED/30367569%0A
"Multiple instance learning (MIL) is a variation of traditional supervised learning problems where data (referred to as bags) are composed of sub-elements (referred to as instances) and only bag labels are available. MIL has a variety of applications such as content-based image retrieval, text categorization, and medical diagnosis. Most of the previous work for MIL assume that training bags are fully labeled. However, it is often difficult to obtain an enough number of labeled bags in practical situations, while many unlabeled bags are available. A learning framework called PU classification (positive and unlabeled classification) can address this problem. In this paper, we propose a convex PU classification method to solve an MIL problem. We experimentally show that the proposed method achieves better performance with significantly lower computation costs than an existing method for PU-MIL.","Bao H
Sakai T
Sato I
Sugiyama M
","(PMID:29804041
)",Convex formulation of multiple instance learning from positive and unlabeled bags.,https://europepmc.org/abstract/MED/29804041%0A
"The article Medical Image Retrieval Using Vector Quantization and Fuzzy S-tree, written by Jana Nowaková, Michal Prílepok and Václav Snášel, was originally published electronically on the publisher's internet portal (currently SpringerLink) on December 15, 2016 without open access.","Nowaková J
Prílepok M
Snášel V
","(PMID:29687340
)",Correction to: Medical Image Retrieval Using Vector Quantization and Fuzzy S-Tree.,https://europepmc.org/abstract/MED/29687340%0A
"Riboswitches are non-coding RNAs that regulate gene expression by altering the structural conformation of mRNA transcripts. Their regulation mechanism might be exploited for interesting biomedical applications such as drug targets and biosensors. A major challenge consists in accurately identifying metabolite-binding RNA switches which are structurally complex and diverse. In this regard, we investigated the classification of 16 riboswitch families using supervised learning algorithms trained solely with sequence-based features. We generated a reduced feature set and proposed a visual representation to explore its components. We induced Support Vector Machine, Random Forest, Naive Bayes, J48, and HyperPipes classifiers with our proposed feature set and tested their performance over independent data. Our best multi-class classifier achieved F-measure values of 0.996 and 0.966 in the training and test phases, respectively, outperforming those of a previous approach. When compared against BLAST, our best classifiers yielded competitive results. This work shows that the classifiers trained with our sequence-based feature set accurately discriminate riboswitches.","Guillén-Ramírez HA
Martínez-Pérez IM
","(PMID:30205141
)",Classification of riboswitch sequences using k-mer frequencies.,https://europepmc.org/abstract/MED/30205141%0A
"The increasing throughput and sharing of proteomics mass spectrometry data have now yielded over one-third of a million public mass spectrometry runs. However, these discoveries are not continuously aggregated in an open and error-controlled manner, which limits their utility. To facilitate the reusability of these data, we built the MassIVE Knowledge Base (MassIVE-KB), a community-wide, continuously updating knowledge base that aggregates proteomics mass spectrometry discoveries into an open reusable format with full provenance information for community scrutiny. Reusing >31 TB of public human data stored in a mass spectrometry interactive virtual environment (MassIVE), the MassIVE-KB contains >2.1 million precursors from 19,610 proteins (48% larger than before; 97% of the total) and doubles proteome coverage to 6 million amino acids (54% of the proteome) with strict library-scale false discovery controls, thereby providing evidence for 430 proteins for which sufficient protein-level evidence was previously missing. Furthermore, MassIVE-KB can inform experimental design, helps identify and quantify new data, and provides tools for community construction of specialized spectral libraries.","Wang M
Wang J
Carver J
Pullman BS
Cha SW
Bandeira N
","(PMID:30172843
)",Assembling the Community-Scale Discoverable Human Proteome.,https://europepmc.org/abstract/MED/30172843%0A
"Projection pursuit is a classical exploratory data analysis method to detect interesting low-dimensional structures in multivariate data. Originally, projection pursuit was applied mostly to data of moderately low dimension. Motivated by contemporary applications, we here study its properties in high-dimensional settings. Specifically, we analyze the asymptotic properties of projection pursuit on structureless multivariate Gaussian data with an identity covariance, as both dimension p and sample size n tend to infinity, with [Formula: see text] Our main results are that (i) if [Formula: see text] then there exist projections whose corresponding empirical cumulative distribution function can approximate any arbitrary distribution; and (ii) if [Formula: see text], not all limiting distributions are possible. However, depending on the value of γ, various non-Gaussian distributions may still be approximated. In contrast, if we restrict to sparse projections, involving only a few of the p variables, then asymptotically all empirical cumulative distribution functions are Gaussian. And (iii) if [Formula: see text], then asymptotically all projections are Gaussian. Some of these results extend to mean-centered sub-Gaussian data and to projections into k dimensions. Hence, in the ""small n, large p"" setting, unless sparsity is enforced, and regardless of the chosen projection index, projection pursuit may detect an apparent structure that has no statistical significance. Furthermore, our work reveals fundamental limitations on the ability to detect non-Gaussian signals in high-dimensional data, in particular through independent component analysis and related non-Gaussian component analysis.","Bickel PJ
Kur G
Nadler B
","(PMID:30150379
)",Projection pursuit in high dimensions.,https://europepmc.org/abstract/MED/30150379%0A
"Ferrimagnetic materials combine the advantages of the low magnetic moment of an antiferromagnet and the ease of realizing magnetic reading of a ferromagnet. Recently, it was demonstrated that compensated ferrimagnetic half metals can be realized in Heusler alloys, where high spin polarization, zero magnetic moment, and low magnetic damping can be achieved at the same time. In this work, by studying the spin-orbit torque induced switching in the Heusler alloy Mn2 Ru1- x Ga, it is found that efficient current-induced magnetic switching can be realized in a nearly compensated sample with strong perpendicular anisotropy and large film thickness. This work demonstrates the possibility of employing compensated Heusler alloys for fast, energy-efficient spintronic devices.","Finley J
Lee CH
Huang PY
Liu L
","(PMID:30412315
)",Spin-Orbit Torque Switching in a Nearly Compensated Heusler Ferrimagnet.,https://europepmc.org/abstract/MED/30412315%0A
No abstract provided.,"Hashimoto DA
Rosman G
Rus DL
Meireles OR
","(PMID:29995685
)",Response: Artificial Intelligence in Surgery Requires Interdisciplinary Collaboration and Understanding.,https://europepmc.org/abstract/MED/29995685%0A
"BACKGROUND:In the clinical practice, the objective quantification of histological results is essential not only to define objective and well-established protocols for diagnosis, treatment, and assessment, but also to ameliorate disease comprehension. SOFTWARE:The software MIAQuant_Learn presented in this work segments, quantifies and analyzes markers in histochemical and immunohistochemical images obtained by different biological procedures and imaging tools. MIAQuant_Learn employs supervised learning techniques to customize the marker segmentation process with respect to any marker color appearance. Our software expresses the location of the segmented markers with respect to regions of interest by mean-distance histograms, which are numerically compared by measuring their intersection. When contiguous tissue sections stained by different markers are available, MIAQuant_Learn aligns them and overlaps the segmented markers in a unique image enabling a visual comparative analysis of the spatial distribution of each marker (markers' relative location). Additionally, it computes novel measures of markers' co-existence in tissue volumes depending on their density. CONCLUSIONS:Applications of MIAQuant_Learn in clinical research studies have proven its effectiveness as a fast and efficient tool for the automatic extraction, quantification and analysis of histological sections. It is robust with respect to several deficits caused by image acquisition systems and produces objective and reproducible results. Thanks to its flexibility, MIAQuant_Learn represents an important tool to be exploited in basic research where needs are constantly changing.","Casiraghi E
Huber V
Frasca M
Cossa M
Tozzi M
Rivoltini L
Leone BE
Villa A
Vergani B
","(PMID:30367588
)","A novel computational method for automatic segmentation, quantification and comparative analysis of immunohistochemically labeled tissue sections.",https://europepmc.org/abstract/MED/30367588%0A
"BACKGROUND:R has become the de-facto reference analysis environment in Bioinformatics. Plenty of tools are available as packages that extend the R functionality, and many of them target the analysis of biological networks. Several algorithms for graphs, which are the most adopted mathematical representation of networks, are well-known examples of applications that require high-performance computing, and for which classic sequential implementations are becoming inappropriate. In this context, parallel approaches targeting GPU architectures are becoming pervasive to deal with the execution time constraints. Although R packages for parallel execution on GPUs are already available, none of them provides graph algorithms. RESULTS:This work presents cuRnet, a R package that provides a parallel implementation for GPUs of the breath-first search (BFS), the single-source shortest paths (SSSP), and the strongly connected components (SCC) algorithms. The package allows offloading computing intensive applications to GPU devices for massively parallel computation and to speed up the runtime up to one order of magnitude with respect to the standard sequential computations on CPU. We have tested cuRnet on a benchmark of large protein interaction networks and for the interpretation of high-throughput omics data thought network analysis. CONCLUSIONS:cuRnet is a R package to speed up graph traversal and analysis through parallel computation on GPUs. We show the efficiency of cuRnet applied both to biological network analysis, which requires basic graph algorithms, and to complex existing procedures built upon such algorithms.","Bonnici V
Busato F
Aldegheri S
Akhmedov M
Cascione L
Carmena AA
Bertoni F
Bombieri N
Kwee I
Giugno R
","(PMID:30367572
)",cuRnet: an R package for graph traversing on GPU.,https://europepmc.org/abstract/MED/30367572%0A
"BACKGROUND:Several problems in network biology and medicine can be cast into a framework where entities are represented through partially labeled networks, and the aim is inferring the labels (usually binary) of the unlabeled part. Connections represent functional or genetic similarity between entities, while the labellings often are highly unbalanced, that is one class is largely under-represented: for instance in the automated protein function prediction (AFP) for most Gene Ontology terms only few proteins are annotated, or in the disease-gene prioritization problem only few genes are actually known to be involved in the etiology of a given disease. Imbalance-aware approaches to accurately predict node labels in biological networks are thereby required. Furthermore, such methods must be scalable, since input data can be large-sized as, for instance, in the context of multi-species protein networks. RESULTS:We propose a novel semi-supervised parallel enhancement of COSNET, an imbalance-aware algorithm build on Hopfield neural model recently suggested to solve the AFP problem. By adopting an efficient representation of the graph and assuming a sparse network topology, we empirically show that it can be efficiently applied to networks with millions of nodes. The key strategy to speed up the computations is to partition nodes into independent sets so as to process each set in parallel by exploiting the power of GPU accelerators. This parallel technique ensures the convergence to asymptotically stable attractors, while preserving the asynchronous dynamics of the original model. Detailed experiments on real data and artificial big instances of the problem highlight scalability and efficiency of the proposed method. CONCLUSIONS:By parallelizing COSNET we achieved on average a speed-up of 180x in solving the AFP problem in the S. cerevisiae, Mus musculus and Homo sapiens organisms, while lowering memory requirements. In addition, to show the potential applicability of the method to huge biomolecular networks, we predicted node labels in artificially generated sparse networks involving hundreds of thousands to millions of nodes.","Frasca M
Grossi G
Gliozzo J
Mesiti M
Notaro M
Perlasca P
Petrini A
Valentini G
","(PMID:30367594
)",A GPU-based algorithm for fast node label learning in large and unbalanced biomolecular networks.,https://europepmc.org/abstract/MED/30367594%0A
"Aging biomarkers are the qualitative and quantitative indicators of the aging processes of the human body. Estimation of biological age is important for assessing the physiological state of an organism. The advent of machine learning lead to the development of the many age predictors commonly referred to as the ""aging clocks"" varying in biological relevance, ease of use, cost, actionability, interpretability, and applications. Here we present and investigate a novel non-invasive class of visual photographic biomarkers of aging. We developed a simple and accurate predictor of chronological age using just the anonymized images of eye corners called the PhotoAgeClock. Deep neural networks were trained on 8414 anonymized high-resolution images of eye corners labeled with the correct chronological age. For people within the age range of 20 to 80 in a specific population, the model was able to achieve a mean absolute error of 2.3 years and 95% Pearson and Spearman correlation.","Bobrov E
Georgievskaya A
Kiselev K
Sevastopolsky A
Zhavoronkov A
Gurov S
Rudakov K
Del Pilar Bonilla Tobar M
Jaspers S
Clemann S
","(PMID:30414596
)",PhotoAgeClock: deep learning algorithms for development of non-invasive visual biomarkers of aging.,https://europepmc.org/abstract/MED/30414596%0A
"BACKGROUND:High throughput technologies have provided the scientific community an unprecedented opportunity for large-scale analysis of genomes. Non-coding RNAs (ncRNAs), for a long time believed to be non-functional, are emerging as one of the most important and large family of gene regulators and key elements for genome maintenance. Functional studies have been able to assign to ncRNAs a wide spectrum of functions in primary biological processes, and for this reason they are assuming a growing importance as a potential new family of cancer therapeutic targets. Nevertheless, the number of functionally characterized ncRNAs is still too poor if compared to the number of new discovered ncRNAs. Thus platforms able to merge information from available resources addressing data integration issues are necessary and still insufficient to elucidate ncRNAs biological roles. RESULTS:In this paper, we describe a platform called Arena-Idb for the retrieval of comprehensive and non-redundant annotated ncRNAs interactions. Arena-Idb provides a framework for network reconstruction of ncRNA heterogeneous interactions (i.e., with other type of molecules) and relationships with human diseases which guide the integration of data, extracted from different sources, via mapping of entities and minimization of ambiguity. CONCLUSIONS:Arena-Idb provides a schema and a visualization system to integrate ncRNA interactions that assists in discovering ncRNA functions through the extraction of heterogeneous interaction networks. The Arena-Idb is available at http://arenaidb.ba.itb.cnr.it.","Bonnici V
Caro G
Constantino G
Liuni S
D'Elia D
Bombieri N
Licciulli F
Giugno R
","(PMID:30367585
)",Arena-Idb: a platform to build human non-coding RNA interaction networks.,https://europepmc.org/abstract/MED/30367585%0A
"Protein⁻ligand docking is a molecular modeling technique that is used to predict the conformation of a small molecular ligand at the binding pocket of a protein receptor. There are many protein⁻ligand docking tools, among which AutoDock Vina is the most popular open-source docking software. In recent years, there have been numerous attempts to optimize the search process in AutoDock Vina by means of heuristic optimization methods, such as genetic and particle swarm optimization algorithms. This study, for the first time, explores the use of cuckoo search (CS) to solve the protein⁻ligand docking problem. The result of this study is CuckooVina, an enhanced conformational search algorithm that hybridizes cuckoo search with differential evolution (DE). Extensive tests using two benchmark datasets, PDBbind 2012 and Astex Diverse set, show that CuckooVina improves the docking performances in terms of RMSD, binding affinity, and success rate compared to Vina though it requires about 9⁻15% more time to complete a run than Vina. CuckooVina predicts more accurate docking poses with higher binding affinities than PSOVina with similar success rates. CuckooVina's slower convergence but higher accuracy suggest that it is better able to escape from local energy minima and improves the problem of premature convergence. As a summary, our results assure that the hybrid CS⁻DE process to continuously generate diverse solutions is a good strategy to maintain the proper balance between global and local exploitation required for the ligand conformational search.","Lin H
Siu SWI
","(PMID:30326669
 PMCID:PMC6214097)",A Hybrid Cuckoo Search and Differential Evolution Approach to Protein⁻Ligand Docking.,https://europepmc.org/abstract/MED/30326669%0A
"Two genes are xenologs in the sense of Fitch if they are separated by at least one horizontal gene transfer event. Horizonal gene transfer is asymmetric in the sense that the transferred copy is distinguished from the one that remains within the ancestral lineage. Hence xenology is more precisely thought of as a non-symmetric relation: y is xenologous to x if y has been horizontally transferred at least once since it diverged from the least common ancestor of x and y. We show that xenology relations are characterized by a small set of forbidden induced subgraphs on three vertices. Furthermore, each xenology relation can be derived from a unique least-resolved edge-labeled phylogenetic tree. We provide a linear-time algorithm for the recognition of xenology relations and for the construction of its least-resolved edge-labeled phylogenetic tree. The fact that being a xenology relation is a heritable graph property, finally has far-reaching consequences on approximation problems associated with xenology relations.","Geiß M
Anders J
Stadler PF
Wieseke N
Hellmuth M
","(PMID:29951855
)",Reconstructing gene trees from Fitch's xenology relation.,https://europepmc.org/abstract/MED/29951855%0A
"Objective: Breast Cancer is the most invasive disease and fatal disease next to lung cancer in human. Early detection
of breast cancer is accomplished by X-ray mammography. Mammography is the most effective and efficient technique
used for detection of breast cancer in women and also to improve the breast cancer prognosis. The numbers of images
need to be examined by the radiologists, the resulting may be misdiagnosis due to human errors by visual Fatigue.
In order to avoid human errors, Computer Aided Diagnosis is implemented. In Computer Aided Diagnosis system,
number of processing and analysis of an image is done by the suitable algorithm. Methods: This paper proposed a
technique to aid radiologist to diagnosis breast cancer using Shearlet transform image enhancement method. Similar to
wavelet filter, Shearlet coefficients are more directional sensitive than wavelet filters which helps detecting the cancer
cells particularly for small contours. After enhancement of an image, segmentation algorithm is applied to identify the
suspicious region. Result: Many features are extracted and utilized to classify the mammographic images into harmful
or harmless tissues using neural network classifier. Conclusions: Multi-scale Shearlet transform because more details on
data phase, directionality and shift invariance than wavelet based transforms. The proposed Shearlet transform gives multi
resolution result and generate malign and benign classification more accurate up to 93.45% utilizing DDSM database.","P S
R T
","(PMID:30256567
)",Aiding the Digital Mammogram for Detecting the Breast Cancer Using Shearlet Transform and Neural Network,https://europepmc.org/abstract/MED/30256567%0A
No abstract provided.,"Lo CM
Jack Li YC
","(PMID:30337085
)",The use of multimedia medical data and machine learning for various diagnoses.,https://europepmc.org/abstract/MED/30337085%0A
"BACKGROUND AND OBJECTIVES:Glaucoma is an eye condition which leads to permanent blindness when the disease progresses to an advanced stage. It occurs due to inappropriate intraocular pressure within the eye, resulting in damage to the optic nerve. Glaucoma does not exhibit any symptoms in its nascent stage and thus, it is important to diagnose early to prevent blindness. Fundus photography is widely used by ophthalmologists to assist in diagnosis of glaucoma and is cost-effective. METHODS:The morphological features of the disc that is characteristic of glaucoma are clearly seen in the fundus images. However, manual inspection of the acquired fundus images may be prone to inter-observer variation. Therefore, a computer-aided detection (CAD) system is proposed to make an accurate, reliable and fast diagnosis of glaucoma based on the optic nerve features of fundus imaging. In this paper, we reviewed existing techniques to automatically diagnose glaucoma. RESULTS:The use of CAD is very effective in the diagnosis of glaucoma and can assist the clinicians to alleviate their workload significantly. We have also discussed the advantages of employing state-of-art techniques, including deep learning (DL), when developing the automated system. The DL methods are effective in glaucoma diagnosis. CONCLUSIONS:Novel DL algorithms with big data availability are required to develop a reliable CAD system. Such techniques can be employed to diagnose other eye diseases accurately.","Hagiwara Y
Koh JEW
Tan JH
Bhandary SV
Laude A
Ciaccio EJ
Tong L
Acharya UR
","(PMID:30337064
)",Computer-aided diagnosis of glaucoma using fundus images: A review.,https://europepmc.org/abstract/MED/30337064%0A
No abstract provided.,"Yang HC
Islam MM
Jack Li YC
","(PMID:29852972
)",Potentiality of deep learning application in healthcare.,https://europepmc.org/abstract/MED/29852972%0A
"We investigated the impact of age-related macular degeneration (AMD) on visual acuity and the visual white matter. We combined an adaptive cortical atlas and diffusion-weighted magnetic resonance imaging (dMRI) and tractography to separate optic radiation (OR) projections to different retinal eccentricities in human primary visual cortex. We exploited the known anatomical organization of the OR and clinically relevant data to segment the OR into three primary components projecting to fovea, mid- and far-periphery. We measured white matter tissue properties-fractional anisotropy, linearity, planarity, sphericity-along the aforementioned three components of the optic radiation to compare AMD patients and controls. We found differences in white matter properties specific to OR white matter fascicles projecting to primary visual cortex locations corresponding to the location of retinal damage (fovea). Additionally, we show that the magnitude of white matter properties in AMD patients' correlates with visual acuity. In sum, we demonstrate a specific relation between visual loss, anatomical location of retinal damage and white matter damage in AMD patients. Importantly, we demonstrate that these changes are so profound that can be detected using magnetic resonance imaging data with clinical resolution. The conserved mapping between retinal and white matter damage suggests that retinal neurodegeneration might be a primary cause of white matter degeneration in AMD patients. The results highlight the impact of eye disease on brain tissue, a process that may become an important target to monitor during the course of treatment.","Yoshimine S
Ogawa S
Horiguchi H
Terao M
Miyazaki A
Matsumoto K
Tsuneoka H
Nakano T
Masuda Y
Pestilli F
","(PMID:29951918
)",Age-related macular degeneration affects the optic radiation white matter projecting to locations of retinal damage.,https://europepmc.org/abstract/MED/29951918%0A
"Discovering the evolution of a tumor may help identify driver mutations and provide a more comprehensive view on the history of the tumor. Recent studies have tackled this problem using multiple samples sequenced from a tumor, and due to clinical implications, this has attracted great interest. However, such samples usually mix several distinct tumor subclones, which confounds the discovery of the tumor phylogeny.We study a natural problem formulation requiring to decompose the tumor samples into several subclones with the objective of forming a minimum perfect phylogeny. We propose an Integer Linear Programming formulation for it, and implement it into a method called MIPUP. We tested the ability of MIPUP and of four popular tools LICHeE, AncesTree, CITUP, Treeomics to reconstruct the tumor phylogeny. On simulated data, MIPUP shows up to a 34% improvement under the ancestor-descendant relations metric. On four real datasets, MIPUP's reconstructions proved to be generally more faithful than those of LICHeE.MIPUP is available at https://github.com/zhero9/MIPUP as open source.Supplementary data are available at Bioinformatics online.","Husic E
Li X
Hujdurovic A
Mehine M
Rizzi R
Mäkinen V
Milanic M
Tomescu AI
","(PMID:30101335
)",MIPUP: Minimum perfect unmixed phylogenies for multi-sampled tumors via branchings and ILP.,https://europepmc.org/abstract/MED/30101335%0A
"This paper is an interdisciplinary study of novel applications of techniques and tools of an area of brain science, known as Synesthesia (involving associations and/or confusion between distinct senses), to area of Computer Science known as Immersive Virtual Reality (VR), that makes the subject&rsquo;s awareness of physical self be diminished by being surrounded in an engrossing artificial environment.&nbsp; Natural Synesthesia has for the last decade been an important emerging area in brain science but is present in only a small proportion of the population. For example a person with Natural Synesthesia, when viewing a grapheme, may perceive a color additionally to be associated to the grapheme. In contrast, Artificial synesthesia (also known as virtual synesthesia or synthetic synesthesia) has been defined as the sensory joining due a cross-modal mapping device, where information of one sense is accompanied by an induced perception in another sense. In particular, we propose use of a multimodal manner of displaying information in VR to increase and concentrate attention. Artificial Synesthesia to synthetically create induced associations between senses, allowing Artificial Synesthesia to be experienced by anyone using a VR system. The paper describes the enhancement of immersive VR by use of Artificial Synesthesia to improve the system&rsquo;s performance at steering and directing the attention of the user. We describe techniques for an enhanced immersive VR that displays associations between a variety of senses: between colors and characters, also between colors and sounds, and between sounds and the position of tactile sensations. The sense association provided by Artificial Synesthesia allows the system to better capture the user&rsquo;s attention and better direct that attention. &nbsp;A major application of our work in VR-induced Artificial Synesthesia is to provide an enhanced methodology for controlling the attention of the subject, and to improve the direction of attention of subjects undergoing guided imagery therapies for pain relief. Other potential high-impact applications include improved immersive VR, more programmable human/computer interfaces and other medical therapies.","Reif JH
Alhalabi W
","(PPR:PPR48311
)",Advancing Attention Control Using VR-Induced Multimodal Artificial Synesthesia,https://europepmc.org/abstract/PPR/PPR48311%0A
"In bacterial DNA, there are specific sequences of nucleotides called promoters that can bind to the RNA polymerase. Sigma70 ([Formula: see text]) is one of the most important promoter sequences due to its presence in most of the DNA regulatory functions. In this paper, we identify the most effective and optimal sequence-based features for prediction of [Formula: see text] promoter sequences in a bacterial genome. We used both short-range and long-range DNA sequences in our proposed method. A very small number of effective features are selected from a large number of the extracted features using multi-window of different sizes within the DNA sequences. We call our prediction method iPro70-FMWin and made it freely accessible online via a web application established at http://ipro70.pythonanywhere.com/server for the sake of convenience of the researchers. We have tested our method using a standard benchmark dataset. In the experiments, iPro70-FMWin has achieved an area under the curve of the receiver operating characteristic and accuracy of 0.959 and 90.57%, respectively, which significantly outperforms the state-of-the-art predictors.","Rahman MS
Aktar U
Jani MR
Shatabda S
","(PMID:30187132
)",iPro70-FMWin: identifying Sigma70 promoters using multiple windowing and minimal features.,https://europepmc.org/abstract/MED/30187132%0A
"Cancer is a complex disease that is caused by rapid alteration of genes. Prediction of the state of cancer in advance contributes to a better understanding of its mechanism and improves the cancer therapy process. For example, predicting the malignancy of tumors in advance can prevent the development of cancer through the early treatment and clinical management of tumor progression. Despite generation of extensive clinical data obtained from the high-throughput technologies, it is necessary to develop machine learning algorithms to guide the prediction process. In the study, we utilize boosting and develop three computational methods to increase the performance of support vector machines (SVM). The aforementioned methods improve the performance over existing state-of-the-art algorithms, including SVM and xgboost. We evaluate the proposed boosting approach relative to the existing algorithms by using several gene expression data related to oral cancer, breast cancer, pheochromocytomas and paragangliomas, bladder cancer, and gastric cancer. The reported results using several performance measures indicate that algorithms employing the proposed approach outperform algorithms employing the baseline approach.","Turki T
Wei Z
","(PMID:30216829
)",Boosting support vector machines for cancer discrimination tasks.,https://europepmc.org/abstract/MED/30216829%0A
"BACKGROUND:Continuous glucose monitoring (CGM) is a method of estimating blood glucose values from those recorded in the interstitial fluid. Because increasingly longer CGM measurements are possible, errors and data loss become more and more likely and potentially more damaging to accurate calculations of glycemic variability (GV) indices. Our research investigates the resistance of the CGM recording to data loss. METHODS:We collected 71 CGM recordings (duration of min: 2, max: 265, median: 42 days) from patients with type 1 diabetes and used three algorithms to introduce missing data. We calculated mean and standard deviation (SD) of absolute percentage error of 12 variability indices and correlated those with the percentage of missing data and duration of the measurements. RESULTS:Mean absolute percentage error of variability indices increased linearly with the percentage of missing data along with SD of absolute percentage error. Except for mean amplitude of glycemic excursions and time spent in hypoglycemia, all absolute errors never exceeded 25%, while mean absolute errors stayed below 5%. The gradient removal algorithm introduced errors larger than the single datapoint and block removal algorithms. The absolute percentage error of variability indices correlated negatively with the duration of the CGM measurements. CONCLUSIONS:Standard GV measurements in long-term glucose monitoring are robustly resistant to data loss.","Kucharski P
Pagacz K
Szadkowska A
Młynarski W
Romanowski A
Fendler W
","(PMID:30403500
)",Resistance to Data Loss of Glycemic Variability Measurements in Long-Term Continuous Glucose Monitoring.,https://europepmc.org/abstract/MED/30403500%0A
"In order to decode human brain, Multivariate Pattern (MVP) classification generates cognitive models by using functional Magnetic Resonance Imaging (fMRI) datasets. As a standard pipeline in the MVP analysis, brain patterns in multi-subject fMRI dataset must be mapped to a shared space and then a classification model is generated by employing the mapped patterns. However, the MVP models may not provide stable performance on a new fMRI dataset because the standard pipeline uses disjoint steps for generating these models. Indeed, each step in the pipeline includes an objective function with independent optimization approach, where the best solution of each step may not be optimum for the next steps. For tackling the mentioned issue, this paper introduces Multi-Objective Cognitive Model (MOCM) that utilizes an integrated objective function for MVP analysis rather than just using those disjoint steps. For solving the integrated problem, we proposed a customized multi-objective optimization approach, where all possible solutions are firstly generated, and then our method ranks and selects the robust solutions as the final results. Empirical studies confirm that the proposed method can generate superior performance in comparison with other techniques.","Yousefnezhad M
Zhang D
","(PMID:30094688
)",Multi-Objective Cognitive Model: a Supervised Approach for Multi-subject fMRI Analysis.,https://europepmc.org/abstract/MED/30094688%0A
"How to read Uyghur text from biomedical graphic images is a challenge problem due to the complex layout and cursive writing of Uyghur. In this paper, we propose a system that extracts text from Uyghur biomedical images, and matches the text in a specific lexicon for semantic analysis. The proposed system possesses following distinctive properties: first, it is an integrated system which firstly detects and crops the Uyghur text lines using a single fully convolutional neural network, and then keywords in the lexicon are matched by a well-designed matching network. Second, to train the matching network effectively an online sampling method is applied, which generates synthetic data continually. Finally, we propose a GPU acceleration scheme for matching network to match a complete Uyghur text line directly rather than a single window. Experimental results on benchmark dataset show our method achieves a good performance of F-measure 74.5%. Besides, our system keeps high efficiency with 0.5s running time for each image due to the GPU acceleration scheme.","Fang S
Xie H
Chen Z
Liu Y
Li Y
","(PMID:29350328
)",Uyghur Text Matching in Graphic Images for Biomedical Semantic Analysis.,https://europepmc.org/abstract/MED/29350328%0A
"OBJECTIVES:An Electroencephalogram (EEG) is the result of co-operative actions performed by brain cells. In other words, it can be defined as the time course of extracellular field potentials that are generated due to the synchronous action of cells. It is widely used for the analysis and diagnosis of several conditions. But this clinical data use to be multi-dimensional, context-dependent, complex, and it causes a concoction of various computing related research challenges. The objective of this study was to develop a computer-aided diagnosis system for epilepsy detection using EEG signals to ease the diagnosis process. MATERIALS:In this study, EEG datasets for epilepsy disease detection were taken from a public domain (Bonn University, Germany). These EEG recordings contain 100 single-channel EEG signals with maximum duration of 23.6 seconds. This data set was recorded intra-cranially and extra-cranially with the help of a 128-channel amplifier system using a common reference point. RESULTS:For a unique set of EEG signal features, the Optimized Artificial Neural Network model for classification and validation was developed with optimum neurons in the hidden layer. Results were tested on the basis of accuracy, sensitivity, precision, and specificity for all classes. The proposed Particle Swarm Optimized Artificial Neural Network provided 99.3% accuracy for EEG signal classification. DISCUSSION:Our results indicate that artificial neural network has efficiency to provide higher accuracy for epilepsy detection if the statistical features are extracted carefully. It is also possible to improve results for real time diagnosis by using optimization technique for error reduction. ABBREVIATIONS:EEG: Electroencephalogram CAD: Computer-Aided Diagnosis ANN: Artificial Neural Network PSO: Particle Swarm Optimization FIR: Finite Impulse Response IIR: Infinite Impulse Response MSE: Mean Square Error.","Saini J
Dutta M
","(PMID:30156138
)",Epilepsy classification using optimized artificial neural network.,https://europepmc.org/abstract/MED/30156138%0A
"Suspicious lesion or organ segmentation is a challenging task to be solved in most of the medical image analyses, medical diagnoses and computer diagnosis systems. Nevertheless, various image segmentation methods were proposed in the previous studies with varying success levels. But, the image segmentation problems such as lack of versatility, low robustness, high complexity and low accuracy in up-to-date image segmentation practices still remain unsolved. Fuzzy c-means clustering (FCM) methods are very well suited for segmenting the regions. The noise-free images are effectively segmented using the traditional FCM method. However, the segmentation result generated is highly sensitive to noise due to the negligence of spatial information. To solve this issue, super-pixel-based FCM (SPOFCM) is implemented in this paper, in which the influence of spatially neighbouring and similar super-pixels is incorporated. Also, a crow search algorithm is adopted for optimizing the influential degree; thereby, the segmentation performance is improved. In clinical applications, the SPOFCM feasibility is verified using the multi-spectral MRIs, mammograms and actual single spectrum on performing tumour segmentation tests for SPOFCM. Ultimately, the competitive, renowned segmentation techniques such as k-means, entropy thresholding (ET), FCM, FCM with spatial constraints (FCM_S) and kernel FCM (KFCM) are used to compare the results of proposed SPOFCM. Experimental results on multi-spectral MRIs and actual single-spectrum mammograms indicate that the proposed algorithm can provide a better performance for suspicious lesion or organ segmentation in computer-assisted clinical applications.","Kumar SN
Fred AL
Varghese PS
","(PMID:30402671
)","Suspicious Lesion Segmentation on Brain, Mammograms and Breast MR Images Using New Optimized Spatial Feature Based Super-Pixel Fuzzy C-Means Clustering.",https://europepmc.org/abstract/MED/30402671%0A
"This paper studies the event-triggered H∞ static output feedback control of linear systems with unreliable communication. The unreliable phenomenon between the event-triggering unit and the controller is described by a stochastic variable with Bernoulli random binary distribution. To cast the considered problem in the robust control framework, the event-triggering scheme is presented by a time-delay form. A vertex structure separation strategy is utilized to handle control gain with interval variations, which could alleviate computation burden heavily. Resorting to a division of control gain from Lyapunov variable, a new method for the non-fragile H∞ controller synthesis is established in the framework of linear matrix inequalities. Simulations are executed to show the validity of the proposed approach.","Shen M
Yan S
Sun Y
Zhang G
","(PMID:30342810
)",Nonfragile H∞ output feedback control of linear systems with an event-triggered scheme against unreliable communication links.,https://europepmc.org/abstract/MED/30342810%0A
"In this paper, we provide a novel approach to the architectural design of deep Recurrent Neural Networks using signal frequency analysis. In particular, focusing on the Reservoir Computing framework and inspired by the principles related to the inherent effect of layering, we address a fundamental open issue in deep learning, namely the question of how to establish the number of layers in recurrent architectures in the form of deep echo state networks (DeepESNs). The proposed method is first analyzed and refined on a controlled scenario and then it is experimentally assessed on challenging real-world tasks. The achieved results also show the ability of properly designed DeepESNs to outperform RC approaches on a speech recognition task, and to compete with the state-of-the-art in time-series prediction on polyphonic music tasks.","Gallicchio C
Micheli A
Pedrelli L
","(PMID:30138751
)",Design of deep echo state networks.,https://europepmc.org/abstract/MED/30138751%0A
"A powerful technique for the analysis of nonlinear oscillators is the rigorous reduction to phase models, with a single variable describing the phase of the oscillation with respect to some reference state. An analog to phase reduction has recently been proposed for systems with a stable fixed point, and phase reduction for periodic orbits has recently been extended to take into account transverse directions and higher-order terms. This tutorial gives a unified treatment of such phase reduction techniques and illustrates their use through mathematical and biological examples. It also covers the use of phase reduction for designing control algorithms which optimally change properties of the system, such as the phase of the oscillation. The control techniques are illustrated for example neural and cardiac systems.","Monga B
Wilson D
Matchen T
Moehlis J
","(PMID:30203130
)",Phase reduction and phase-based optimal control for biological systems: a tutorial.,https://europepmc.org/abstract/MED/30203130%0A
"Attention-deficit/hyperactivity disorder (ADHD) is a neurodevelopmental disorder that is characterized by inattention, hyperactivity, and impulsivity but also by negative emotionality. The aim of the present study was to investigate whether subclinical ADHD tendencies are associated with negative emotionality in healthy adult samples. The present study is of special interest since it investigated negative emotionality with a questionnaire anchored in Neuroscience Theory-the Affective Neuroscience Personality Scales (ANPS). Furthermore, through the investigation of samples in two countries, namely Germany and China, the study aims to replicate the results across different cultures. German (n = 377; age: M = 23.25, SD = 8.47; 117 males) and Chinese (n = 389; age: M = 20.74, SD = 2.47; 279 males) subjects completed ANPS (primary emotional traits) and ASRS (ADHD tendencies) questionnaires in an online survey. Principal component analysis of the ANPS revealed one factor for negative emotionality and one factor for positive emotionality. Partial correlations between ANPS and ASRS (controlled for age) were conducted separately for nation and gender. The same correlation patterns between ADHD tendencies and negative emotionality could be found in male and female German/Chinese participants (range r = .189 to r = .352). Higher negative emotionality was always significantly associated with more inattentive, hyperactive/impulsive, or combined tendencies. However, significant negative correlations between ADHD tendencies and positive emotionality could only be observed in Chinese males (range r = - .264 to r = - .296). The results are in line with former findings in children and show that also in healthy adults, associations between negative emotionality and ADHD tendencies are robustly visible. The results were independent of the cultural background, indicating a general association between ADHD tendencies and negative emotionality, even in healthy adults.","Wernicke J
Li M
Sha P
Zhou M
Sindermann C
Becker B
Kendrick KM
Montag C
","(PMID:30306405
)",Individual differences in tendencies to attention-deficit/hyperactivity disorder and emotionality: empirical evidence in young healthy adults from Germany and China.,https://europepmc.org/abstract/MED/30306405%0A
"RNA 5-methylcytosine (m5C) is an important post-transcriptional modification that plays an indispensable role in biological processes. The accurate identification of m5C sites from primary RNA sequences is especially useful for deeply understanding the mechanisms and functions of m5C. Due to the difficulty and expensive costs of identifying m5C sites with wet-lab techniques, developing fast and accurate machine-learning-based prediction methods is urgently needed. In this study, we proposed a new m5C site predictor, called M5C-HPCR, by introducing a novel heuristic nucleotide physicochemical property reduction (HPCR) algorithm and classifier ensemble. HPCR extracts multiple reducts of physical-chemical properties for encoding discriminative features, while the classifier ensemble is applied to integrate multiple base predictors, each of which is trained based on a separate reduct of the physical-chemical properties obtained from HPCR. Rigorous jackknife tests on two benchmark datasets demonstrate that M5C-HPCR outperforms state-of-the-art m5C site predictors, with the highest values of MCC (0.859) and AUC (0.962). We also implemented the webserver of M5C-HPCR, which is freely available at http://cslab.just.edu.cn:8080/M5C-HPCR/.","Zhang M
Xu Y
Li L
Liu Z
Yang X
Yu DJ
","(PMID:29649472
)",Accurate RNA 5-methylcytosine site prediction based on heuristic physical-chemical properties reduction and classifier ensemble.,https://europepmc.org/abstract/MED/29649472%0A
"Living systems are inherently stochastic and operate in a noisy environment, yet despite all these uncertainties, they perform their functions in a surprisingly reliable way. The biochemical mechanisms used by natural systems to tolerate and control noise are still not fully understood, and this issue also limits our capacity to engineer reliable, quantitative synthetic biological circuits. We study how representative models of biochemical systems propagate and attenuate noise, accounting for intrinsic as well as extrinsic noise. We investigate three molecular noise-filtering mechanisms, study their noise-reduction capabilities and limitations, and show that nonlinear dynamics such as complex formation are necessary for efficient noise reduction. We further suggest that the derived molecular filters are widespread in gene expression and regulation and, particularly, that microRNAs can serve as such noise filters. To our knowledge, our results provide new insight into how biochemical networks control noise and could be useful to build robust synthetic circuits.","Laurenti L
Csikasz-Nagy A
Kwiatkowska M
Cardelli L
","(PMID:29925035
)",Molecular Filters for Noise Reduction.,https://europepmc.org/abstract/MED/29925035%0A
"Replicability and reproducibility of computational models has been somewhat understudied by ""the replication movement."" In this paper, we draw on methodological studies into the replicability of psychological experiments and on the mechanistic account of explanation to analyze the functions of model replications and model reproductions in computational neuroscience. We contend that model replicability, or independent researchers' ability to obtain the same output using original code and data, and model reproducibility, or independent researchers' ability to recreate a model without original code, serve different functions and fail for different reasons. This means that measures designed to improve model replicability may not enhance (and, in some cases, may actually damage) model reproducibility. We claim that although both are undesirable, low model reproducibility poses more of a threat to long-term scientific progress than low model replicability. In our opinion, low model reproducibility stems mostly from authors' omitting to provide crucial information in scientific papers and we stress that sharing all computer code and data is not a solution. Reports of computational studies should remain selective and include all and only relevant bits of code.","Miłkowski M
Hensel WM
Hohol M
","(PMID:30377880
)",Replicability or reproducibility? On the replication crisis in computational neuroscience and sharing only relevant detail.,https://europepmc.org/abstract/MED/30377880%0A
"The Japanese clouded salamander (Hynobius nebulosus) is a lentic-breeding species distributed throughout western Japan. Threats, such as habitat loss, have led to it being categorized as a vulnerable species. To explore the phylogeographic features and population differentiation among clouded salamanders in Shiga prefecture, we analyzed sequences of the mitochondrial cytochrome b gene. DNA samples were collected from 29 distinct breeding sites, and 53 cytochrome b haplotypes were identified. On the basis of comparison of the composition and frequency of haplotypes in each breeding site, salamanders in each habitat appeared to have distinct characteristics. Significant genetic differentiation was observed in 93.3% of possible pairs of habitats in Shiga prefecture, and 67.7% of habitat pairs within the same locality were found to be significantly different. These results suggest that the salamanders' poor locomotion combined with topographic effects may have contributed to the diversity of locally distributed salamanders in Shiga. Phylogenetic analysis showed that haplotypes of H. nebulosus in Shiga can be divided into five groups (the Nagahama-Maibara group, Otsu group, Konan group 1, Konan group 2, and Takashima group), each with a distinct geographical distribution. Haplotypes of the Otsu group, however, were exceptionally widely distributed. The results of the present study will contribute to the future of H. nebulosus conservation management in Shiga.","Mito N
Ohshima K
Saitoh O
","(PMID:30298788
)",Genetic Diversity among Clouded Salamanders (Hynobius nebulosus) in Shiga Prefecture.,https://europepmc.org/abstract/MED/30298788%0A
"Ergonomics science recommends office chairs that promote active sitting to reduce sitting related complaints. Since current office chairs do not fulfill this recommendation, a new chair was developed by inverting an existing dynamic chair principle. This study compares active sitting on the inverted chair during a simulated computer-based office task to two existing dynamic office chairs (n = 8). Upper body stability was analysed using Friedman ANOVA (p = .01). In addition, participants completed a questionnaire to rate their comfort and activity after half a working day. The inverted chair allowed the participants to perform a substantial range of lateral spine flexion (11.5°) with the most stable upper body posture (≤11 mm, ≤2°, p ≤ .01). The results of this study suggest that the inverted chair supports active sitting with backrest support during computer-based office work. However, according to comfort and activity ratings, results should be verified in a future field study with 24 participants. Practitioner Summary: This experimental laboratory study analyses the feasibility of active sitting with a backrest support during common office work on a new type of dynamic office chair. The results demonstrate that active sitting with a backrest support is feasible on the new but limited on existing chairs.","Kuster RP
Bauer CM
Gossweiler L
Baumgartner D
","(PMID:30169988
)",Active sitting with backrest support: Is it feasible?,https://europepmc.org/abstract/MED/30169988%0A
"Visual inspection of electroencephalogram (EEG) recordings for epilepsy diagnosis is very time-consuming. Therefore, much research is devoted to developing a computer-assisted diagnostic system to relieve the workload of neurologists. In this study, a kernel version of the robust probabilistic collaborative representation-based classifier (R-ProCRC) is proposed for the detection of epileptic EEG signals. The kernel R-ProCRC jointly maximizes the likelihood that a test EEG sample belongs to each of the two classes (seizure and non-seizure), and uses the kernel function method to map the EEG samples into the higher dimensional space to relieve the problem that they are linearly non-separable in the original space. The wavelet transform with five scales is first employed to process the raw EEG signals. Next, the test EEG samples are collaboratively represented on the training sets by the kernel R-ProCRC and they are categorized by checking which class has the maximum likelihood. Finally, post-processing is deployed to reduce misjudgment and acquire more stable results. This method is evaluated on two EEG databases and yields an accuracy of 99.3% for interictal and ictal EEGs on the Bonn database. In addition, the average sensitivity of 97.48% and specificity of 96.81% are achieved from the Freiburg database. Graphical abstract Visual inspection of EEG recordings for epilepsy diagnosis is very time-consuming. Therefore, many researchers are devoted to developing a computer-assisted diagnostic system to relieve the workload of neurologists. In this paper, a kernel version of the robust probabilistic collaborative representation based classifier (R-ProCRC) is proposed for the detection of epileptic EEG signals. The kernel R-ProCRC jointly maximizes the likelihood that a test EEG sample belongs to each of the two classes, i.e., seizure and non-seizure, and uses the kernel function method to map the EEG samples into the higher dimensional space to relieve the problem that they are linearly non-separable in the original space. The main procedures of the proposed method are exhibited in the two figures as following, Fig. 1 The main procedures of the proposed method. (a) The schematic diagram of EEG classification based on the Freiburg database. (b) The detailed procedures of the kernel R-ProCRC This method has been evaluated on two different types of EEG databases and shows superior performance.","Yu Z
Zhou W
Zhang F
Xu F
Yuan S
Leng Y
Li Y
Yuan Q
","(PMID:30076538
)",Automatic seizure detection based on kernel robust probabilistic collaborative representation.,https://europepmc.org/abstract/MED/30076538%0A
"This contribution sketches a work flow to design an RNA switch that is able to adapt two structural conformations in a ligand-dependent way. A well characterized RNA aptamer, i.e., knowing its Kd and adaptive structural features, is an essential ingredient of the described design process. We exemplify the principles using the well-known theophylline aptamer throughout this work. The aptamer in its ligand-binding competent structure represents one structural conformation of the switch while an alternative fold that disrupts the binding-competent structure forms the other conformation. To keep it simple we do not incorporate any regulatory mechanism to control transcription or translation. We elucidate a commonly used design process by explicitly dissecting and explaining the necessary steps in detail. We developed a novel objective function which specifies the mechanistics of this simple, ligand-triggered riboswitch and describe an extensive in silico analysis pipeline to evaluate important kinetic properties of the designed sequences. This protocol and the developed software can be easily extended or adapted to fit novel design scenarios and thus can serve as a template for future needs.","Findeiß S
Hammer S
Wolfinger MT
Kühnl F
Flamm C
Hofacker IL
","(PMID:29660485
)",In silico design of ligand triggered RNA switches.,https://europepmc.org/abstract/MED/29660485%0A
"Biomedical researchers have always sought innovative methodologies to elucidate the underlying biology in their experimental models. As the pace of research has increased with new technologies that 'scale-up' these experiments, researchers have developed acute needs for the information technologies which assist them in managing and processing their experiments and results into useful data analyses that support scientific discovery. The application of information technology to support this discovery process is often called bioinformatics. We have observed a 'gap' in the training of those individuals who traditionally aid in the delivery of information technology at the level of the end-user (e.g. a systems analyst working with a biomedical researcher) which can negatively impact the successful application of technological solutions to biomedical research problems. In this paper we describe the roots and branches of bioinformatics to illustrate a range of applications and technologies that it encompasses. We then propose a taxonomy of bioinformatics as a framework for the identification of skills employed in the field. The taxonomy can be used to assess a set of skills required by a student to traverse this hierarchy from one area to another. We then describe a curriculum that attempts to deliver the identified skills to a broad audience of participants, and describe our experiences with the curriculum to show how it can help bridge the 'gap'.","Dubay C
Brundege JM
Hersh W
Spackman K
","(PMID:12463819
 PMCID:PMC2244217)",Delivering bioinformatics training: bridging the gaps between computer science and biomedicine.,https://europepmc.org/abstract/MED/12463819%0A
No abstract provided.,"Li H
Steckl AJ
","(PMID:30257554
)",Paper Microfluidics for Point-of-Care Blood-Based Analysis and Diagnostics.,https://europepmc.org/abstract/MED/30257554%0A
"Heterogeneous wireless sensor networks (HWSNs) are employed in many real-time applications, such as Internet of sensors (IoS), Internet of vehicles (IoV), healthcare monitoring, and so on. As wireless sensor nodes have constrained computing, storage and communication capabilities, designing energy-efficient authentication protocols is a very important issue in wireless sensor network security. Recently, Amin et al. presented an untraceable and anonymous three-factor authentication (3FA) scheme for HWSNs and argued that their protocol is efficient and can withstand the common security threats in this sort of networks. In this article, we show how their protocol is not immune to user impersonation, de-synchronization and traceability attacks. In addition, an adversary can disclose session key under the typical assumption that sensors are not tamper-resistant. To overcome these drawbacks, we improve the Amin et al.'s protocol. First, we informally show that our improved scheme is secure against the most common attacks in HWSNs in which the attacks against Amin et al.'s protocol are part of them. Moreover, we verify formally our proposed protocol using the BAN logic. Compared with the Amin et al.'s scheme, the proposed protocol is both more efficient and more secure to be employed which renders the proposal suitable for HWSN networks.","Aghili SF
Mala H
Peris-Lopez P
","(PMID:30380595
)",Securing Heterogeneous Wireless Sensor Networks: Breaking and Fixing a Three-Factor Authentication Protocol.,https://europepmc.org/abstract/MED/30380595%0A
"Sequence-level searches on large collections of RNA sequencing experiments, such as the NCBI Sequence Read Archive (SRA), would enable one to ask many questions about the expression or variation of a given transcript in a population. Existing approaches, such as the sequence Bloom tree, suffer from fundamental limitations of the Bloom filter, resulting in slow build and query times, less-than-optimal space usage, and potentially large numbers of false-positives. This paper introduces Mantis, a space-efficient system that uses new data structures to index thousands of raw-read experiments and facilitates large-scale sequence searches. In our evaluation, index construction with Mantis is 6× faster and yields a 20% smaller index than the state-of-the-art split sequence Bloom tree (SSBT). For queries, Mantis is 6-108× faster than SSBT and has no false-positives or -negatives. For example, Mantis was able to search for all 200,400 known human transcripts in an index of 2,652 RNA sequencing experiments in 82 min; SSBT took close to 4 days.","Pandey P
Almodaresi F
Bender MA
Ferdman M
Johnson R
Patro R
","(PMID:29936185
)","Mantis: A Fast, Small, and Exact Large-Scale Sequence-Search Index.",https://europepmc.org/abstract/MED/29936185%0A
"Single-photon switches and transistors generate strong photon-photon interactions that are essential for quantum circuits and networks. However, the deterministic control of an optical signal with a single photon requires strong interactions with a quantum memory, which has been challenging to achieve in a solid-state platform. We demonstrate a single-photon switch and transistor enabled by a solid-state quantum memory. Our device consists of a semiconductor spin qubit strongly coupled to a nanophotonic cavity. The spin qubit enables a single 63-picosecond gate photon to switch a signal field containing up to an average of 27.7 photons before the internal state of the device resets. Our results show that semiconductor nanophotonic devices can produce strong and controlled photon-photon interactions that could enable high-bandwidth photonic quantum information processing.","Sun S
Kim H
Luo Z
Solomon GS
Waks E
","(PMID:29976819
)",A single-photon switch and transistor enabled by a solid-state quantum memory.,https://europepmc.org/abstract/MED/29976819%0A
"An automatic system of clinical-diagnostic information has been applied to workers exposed to ionising radiation at the University of Naples Federico II with reference to the last 5 years. For every person exposed a computerized case sheet was elaborated recording clinical, biological, dosimetric and other preventive data. In the localized risk, capillaroscopic monitoring was used. This research has highlighted the role of medical surveillance in developing health promotion criteria and the planning of the interventions with the complete control of all data in real time.","Pennarola R
Porzio G
Cavaliere L
","(PMID:18409960
)",Health promotion and computer science in radiation protection,https://europepmc.org/abstract/MED/18409960%0A
"The healthcare data is an important asset and rich source of healthcare intellect. Medical databases, if created properly, will be large, complex, heterogeneous and time varying. The main challenge nowadays is to store and process this data efficiently so that it can benefit humans. Heterogeneity in the healthcare sector in the form of medical data is also considered to be one of the biggest challenges for researchers. Sometimes, this data is referred to as large-scale data or big data. Blockchain technology and the Cloud environment have proved their usability separately. Though these two technologies can be combined to enhance the exciting applications in healthcare industry. Blockchain is a highly secure and decentralized networking platform of multiple computers called nodes. It is changing the way medical information is being stored and shared. It makes the work easier, keeps an eye on the security and accuracy of the data and also reduces the cost of maintenance. A Blockchain-based platform is proposed that can be used for storing and managing electronic medical records in a Cloud environment.","Kaur H
Alam MA
Jameel R
Mourya AK
Chang V
","(PMID:29987560
)",A Proposed Solution and Future Direction for Blockchain-Based Heterogeneous Medicare Data in Cloud Environment.,https://europepmc.org/abstract/MED/29987560%0A
"Rigid body orientation determined by IMU (Inertial Measurement Unit) is widely applied in robotics, navigation, rehabilitation, and human-computer interaction. In this paper, aiming at dynamically fusing quaternions computed from angular rate integration and FQA algorithm, a quaternion-based complementary filter algorithm is proposed to support a computationally efficient, wearable motion-tracking system. Firstly, a gradient descent method is used to determine a function from several sample points. Secondly, this function is used to dynamically estimate the fusion coefficient based on the deviation between measured magnetic field, gravity vectors and their references in Earth-fixed frame. Thirdly, a test machine is designed to evaluate the performance of designed filter. Experimental results validate the filter design and show its potential of real-time human motion tracking.","Yi C
Ma J
Guo H
Han J
Gao H
Jiang F
Yang C
","(PMID:30400359
)",Estimating Three-Dimensional Body Orientation Based on an Improved Complementary Filter for Human Motion Tracking.,https://europepmc.org/abstract/MED/30400359%0A
"To exploit the full potential of big routine data in healthcare and to efficiently communicate and collaborate with information technology specialists and data analysts, healthcare epidemiologists should have some knowledge of large-scale analysis techniques, particularly about machine learning. This review focuses on the broad area of machine learning and its first applications in the emerging field of digital healthcare epidemiology.","Roth JA
Battegay M
Juchler F
Vogt JE
Widmer AF
","(PMID:30394238
)",Introduction to Machine Learning in Digital Healthcare Epidemiology.,https://europepmc.org/abstract/MED/30394238%0A
"[Purpose] Academic performance of college students can be impacted by the efficacy of students' ability and teaching methods. It is important to assess the progression of college students' cognitive abilities among different college majors and as they move from junior to senior levels. However, dearth of studies have been examined the role of cognitive ability tests as a tool to determine the aptitude of the perspective students. Therefore, this study assessed cognitive abilities of computer science and ART students. [Subjects and Methods] Participants were 130 college students (70 computer and 60 art students) in their first and final years of study at King Saud University. Cognitive ability was assessed using the Test of Nonverbal Intelligence, Third Edition. [Results] The cognitive ability of computer science students were statistically better than that of art students and were shown improvement from junior to senior levels, while the cognitive ability of art students did not. [Conclusion] The cognitive ability of computer science college students was superior compared to those in art, indicating the importance of cognitive ability assessment for high school graduates prior to choosing a college major. Cognitive scales should be included as an aptitude assessment tool for decision-makers and prospective students to determine an appropriate career, which might reduce the rate of university drop out.","AlAbdulwahab SS
Kachanathu SJ
AlSaeed AS
","(PMID:29545701
 PMCID:PMC5851370)",Role of cognitive assessment for high school graduates prior to choosing their college major.,https://europepmc.org/abstract/MED/29545701%0A
"Human physiology is a core physical sciences course for health professions students, such as nurses and exercise science majors. The concepts of human physiology lay the foundation for health professions courses, such as pathophysiology. The National Council Licensing Exam for registered nurses (a timed nursing licensure exam) and the American College of Sports Medicine timed licensure exams for exercise sciences students have a framework consisting of human physiology concepts and are computer adaptive testing (CAT) assessments. This provides a case for electronic testing (in the undergraduate class setting) as a preparatory measure for CAT licensing exams. Case studies have illustrated a high information retention rate, with students completing online homework vs. paper, as well. Additionally, in recent years, virtual laboratories for non-physical science majors have been described as safer and effective for the purposes of educating students in laboratory techniques and experimental measures. Lastly, a successful learning approach utilized by museums has been found to be effective in younger students as well: ""touch learning"" (tactile learning). It also is important to note that student discussions and the face-to-face teaching dynamic play a critical role in the undergraduate education process. As such, the teaching methodology discussed here combines e-learning, virtual laboratories, tactile learning, and face-to-face didactic instruction of human physiology in developing a course to engage undergraduate health professions students, increase retention of human physiology course materials, and simultaneously prepare students for the CAT assessments that are licensing exams.","Mahaffey AL
","(PMID:30035633
)",Interfacing virtual and face-to-face teaching methods in an undergraduate human physiology course for health professions students.,https://europepmc.org/abstract/MED/30035633%0A
"Nucleic acid are the key unit and predominant genetic material for interpreting the fundamental basis of genetic information in an organism and now it's used for the evolution of a novel group of therapeutics. To identify the potential impact in the biological science, it receives high recognition in therapeutic applications.Due to their selective recognition of molecular targets and pathways, DNA significantly imparts tremendous specificity of action. With its high advantages in the assembly of device, interconnects and computational elements DNA has shown great potential fabrication and construction of nanostructures and devices. The interaction of low molecular weight small molecules with DNA is significant feature in pharmacology. Based on mode of binding mechanisms small molecules are categorized as intercalators and groove binders which has significant role in target-based drug development. The understanding mechanism of drug-DNA interaction plays a crucial part in the development of novel drug molecules with more effective and lesser side effects. This article is attempts to outline those interactions of drug-DNA with both experimental and computational advances, including ultraviolet (UV)-visible spectroscopy, fluorescent spectroscopy, circular dichroism, Nuclear magnetic resonance (NMR), molecular docking & dynamics and quantum mechanical applications.","Selvaraj C
Singh SK
","(PMID:30398109
)",Computational and experimental binding mechanism ofDNA- drug interactions.,https://europepmc.org/abstract/MED/30398109%0A
No abstract provided.,"Brandwein M
Fuks G
Israel A
Nejman D
Straussman R
Hodak E
Harari M
Steinberg D
Bentwich Z
Shental N
Meshner S
","(PMID:29962038
)",Identification of a unique Staphylococcus aureus ribosomal signature in severe atopic dermatitis.,https://europepmc.org/abstract/MED/29962038%0A
"Detecting driver modules is a key challenge for understanding the mechanisms of carcinogenesis at the pathway level. Identifying cancer specific driver modules is helpful for interpreting the different principles of different cancer types. However, most methods are proposed to identify driver modules in one cancer, but few methods are introduced to detect cancer specific driver modules. We propose a network-based method to detect cancer specific driver modules (CSDM) in a certain cancer type to other cancer types. We construct the specific network of a cancer by combining specific coverage and mutual exclusivity in all cancer types, to catch the specificity of the cancer at the pathway level. To illustrate the performance of the method, we apply CSDM on 12 TCGA cancer types. When we compare CSDM with SpeMDP and HotNet2 with regard to specific coverage and the enrichment of GO terms and KEGG pathways, CSDM is more accurate. We find that the specific driver modules of two different cancers have little overlap, which indicates that the driver modules detected by CSDM are specific. Finally, we also analyze three specific driver modules of BRCA, BLCA, and LAML intersecting with well-known pathways. The source code of CSDM is freely accessible at https://github.com/fengli28/CSDM.git.","Li F
Gao L
Wang P
Hu Y
","(PMID:29738475
 PMCID:PMC6100049)",Identifying Cancer Specific Driver Modules Using a Network-Based Method.,https://europepmc.org/abstract/MED/29738475%0A
"To achieve confidentiality, authentication, integrity of medical data, and support fine-grained access control, we propose a secure electronic health record (EHR) system based on attribute-based cryptosystem and blockchain technology. In our system, we use attribute-based encryption (ABE) and identity-based encryption (IBE) to encrypt medical data, and use identity-based signature (IBS) to implement digital signatures. To achieve different functions of ABE, IBE and IBS in one cryptosystem, we introduce a new cryptographic primitive, called combined attribute-based/identity-based encryption and signature (C-AB/IB-ES). This greatly facilitates the management of the system, and does not need to introduce different cryptographic systems for different security requirements. In addition, we use blockchain techniques to ensure the integrity and traceability of medical data. Finally, we give a demonstrating application for medical insurance scene.","Wang H
Song Y
","(PMID:29974270
)",Secure Cloud-Based EHR System Using Attribute-Based Cryptosystem and Blockchain.,https://europepmc.org/abstract/MED/29974270%0A
"The impact of molecular dynamics (MD) simulations in molecular biology and drug discovery has expanded dramatically in recent years. These simulations capture the behavior of proteins and other biomolecules in full atomic detail and at very fine temporal resolution. Major improvements in simulation speed, accuracy, and accessibility, together with the proliferation of experimental structural data, have increased the appeal of biomolecular simulation to experimentalists-a trend particularly noticeable in, although certainly not limited to, neuroscience. Simulations have proven valuable in deciphering functional mechanisms of proteins and other biomolecules, in uncovering the structural basis for disease, and in the design and optimization of small molecules, peptides, and proteins. Here we describe, in practical terms, the types of information MD simulations can provide and the ways in which they typically motivate further experimental work.","Hollingsworth SA
Dror RO
","(PMID:30236283
)",Molecular Dynamics Simulation for All.,https://europepmc.org/abstract/MED/30236283%0A
"Visualization algorithms are fundamental tools for interpreting single-cell data. However, standard methods, such as t-stochastic neighbor embedding (t-SNE), are not scalable to datasets with millions of cells and the resulting visualizations cannot be generalized to analyze new datasets. Here we introduce net-SNE, a generalizable visualization approach that trains a neural network to learn a mapping function from high-dimensional single-cell gene-expression profiles to a low-dimensional visualization. We benchmark net-SNE on 13 different datasets, and show that it achieves visualization quality and clustering accuracy comparable with t-SNE. Additionally we show that the mapping function learned by net-SNE can accurately position entire new subtypes of cells from previously unseen datasets and can also be used to reduce the runtime of visualizing 1.3 million cells by 36-fold (from 1.5 days to an hour). Our work provides a framework for bootstrapping single-cell analysis from existing datasets.","Cho H
Berger B
Peng J
","(PMID:29936184
)",Generalizable and Scalable Visualization of Single-Cell Data Using Neural Networks.,https://europepmc.org/abstract/MED/29936184%0A
"The purpose of this systematic review was to examine literature on workplace factors associated with neck pain or symptoms in computer users performing clerical functions.A systematic search of the Cochrane, Medline, CINAHL, and EMBASE databases was conducted for observational and experimental studies published since 2000. This review applied the case definition of The Bone and Joint Decade 2000-2010 Task Force on Neck Pain and Its Associated Disorders.Seven hundred twenty-nine studies were identified. Seven hundred and two studies were excluded. Twenty-seven studies fulfilled inclusion criteria and were assessed for risk of bias. Cross-sectional studies were commonly at risk from nonresponse bias and lack of adequate case definitions. Experimental studies were mostly at risk of bias due to confounding and participant recruitment methods.Neck pain was not significantly associated with high job demands, low skill discretion, low decision authority, or low peer support. However, when these variables were combined with increased duration of computing tasks, or ergonomic demands, they reached significance. Supervisor support was found to be the only significant buffer capable of preventing these variables reaching significance in female office workers.","Keown GA
Tuchin PA
","(PMID:30025880
)",Workplace Factors Associated With Neck Pain Experienced by Computer Users: A Systematic Review.,https://europepmc.org/abstract/MED/30025880%0A
"Although the human mirror neuron system (MNS) is critical for action observation and imitation, most MNS investigations overlook the visuospatial transformation processes that allow individuals to interpret and imitate actions observed from differing perspectives. This problem is not trivial since accurately reaching for and grasping an object requires a visuospatial transformation mechanism capable of precisely remapping fine motor skills where the observer's and imitator's arms and hands may have quite different orientations and sizes. Accordingly, here we describe a novel neural model to investigate the dynamics between the fronto-parietal MNS and visuospatial processes during observation and imitation of a reaching and grasping action. Our model encompasses i) the inferior frontal gyrus (IFG) and inferior parietal lobule (IPL), regions that are postulated to produce neural drive and sensory predictions, respectively; ii) the middle temporal (MT) and middle superior temporal (MST) regions that are postulated to process visual motion of a particular action; and iii) the superior parietal lobule (SPL) and intra-parietal sulcus (IPS) that are hypothesized to encode the visuospatial transformations enabling action observation/imitation based on different visuospatial viewpoints. The results reveal that when a demonstrator executes an action, an imitator can reproduce it with similar kinematics, independently of differences in anthropometry, distance, and viewpoint. As with prior empirical findings, similar model synaptic activity was observed during both action observation and execution along with the existence of both view-independent and view-dependent neural populations in the frontal MNS. Importantly, this work generates testable behavioral and neurophysiological predictions. Namely, the model predicts that i) during observation/imitation the response time increases linearly as the rotation angle of the observed action increases but remain similar when performing both clockwise and counterclockwise rotation and ii) IPL embeds essentially view-independent neurons while SPL/IPS includes both view-independent and view-dependent neurons. Overall, this work suggests that MT/MST visuomotion processes combined with the SPL/IPS allow the MNS to observe and imitate actions independently of demonstrator-imitator spatial relationships.","Oh H
Braun AR
Reggia JA
Gentili RJ
","(PMID:30219273
)",Fronto-parietal mirror neuron system modeling: Visuospatial transformations support imitation learning independently of imitator perspective.,https://europepmc.org/abstract/MED/30219273%0A
"Cytoskeletal networks of actin filaments and myosin motors drive many dynamic cell processes. A key characteristic of these networks is their contractility. Despite intense experimental and theoretical efforts, it is not clear what mechanism favors network contraction over expansion. Recent work points to a dominant role for the nonlinear mechanical response of actin filaments, which can withstand stretching but buckle upon compression. Here we present an alternative mechanism. We study how interactions between actin and myosin-2 at the single filament level translate into contraction at the network scale by performing time-lapse imaging on reconstituted quasi-2D-networks mimicking the cell cortex. We observe myosin end-dwelling after it runs processively along actin filaments. This leads to transport and clustering of actin filament ends and the formation of transiently stable bipolar structures. Further we show that myosin-driven polarity sorting produces polar actin asters, which act as contractile nodes that drive contraction in crosslinked networks. Computer simulations comparing the roles of the end-dwelling mechanism and a buckling-dependent mechanism show that the relative contribution of end-dwelling contraction increases as the network mesh-size decreases.","Wollrab V
Belmonte JM
Baldauf L
Leptin M
Nédeléc F
Koenderink GH
","(PMID:30404824
)",Polarity sorting drives remodeling of actin-myosin networks.,https://europepmc.org/abstract/MED/30404824%0A
"The development of chronic hypertension is a poorly described process involving many chemical and structural changes to the artery. Typically, mathematical models of this disease focus primarily on the mechanical aspects such as arterial geometry, elasticity, and tissue content, or alternatively on the chemical drivers of vasoactivity such as nitric oxide and reactive oxygen species. This paper presents a model that considers the powerful interaction between mechanical and biochemical drivers of hypertension and arterial remodeling. Based on biological processes thought to be involved in the development of hypertension, we have built a system of algebraic, differential, and integral equations. Endothelial dysfunction, which is known to limit vasodilation, is explicitly considered in the model and plays a vital role in the development of chronic hypertension. Numerical solutions to the system are consistent with available experimental data for normal and spontaneously-hypertensive rats.","Wilstein Z
Alligood DM
McLure VL
Miller AC
","(PMID:29758218
)",Mathematical model of hypertension-induced arterial remodeling: A chemo-mechanical approach.,https://europepmc.org/abstract/MED/29758218%0A
"Busseola fusca is a maize and sorghum pest that can cause significant damage to both crops. Given that maize is one of the main cereals grown in the worldwide, this pest is a major challenge for maize production and therefore for the economies of several countries . In this paper , based on the life cycle of B. fusca, we propose a mathematical model to study the population dynamics of this insect pest . A sensitivity analysis using the eFast method was performed to show the most important parameters of the model. We present the theoretical analysis of the model. More precisely, we derive a threshold parameter [Formula: see text], called basic offspring number and show that the trivial equilibrium is globally asymptotically stable whenever [Formula: see text], while if [Formula: see text], the non trivial equilibrium is globally asymptotically stable. The theoretical results are supported by numerical simulations.","Ntahomvukiye JP
Temgoua A
Bowong S
","(PMID:29948413
)","Study of the Population Dynamics of Busseola fusca, Maize Pest.",https://europepmc.org/abstract/MED/29948413%0A
No abstract provided.,"Wiens J
Fackler J
","(PMID:29985285
)",Striking the Right Balance-Applying Machine Learning to Pediatric Critical Care Data.,https://europepmc.org/abstract/MED/29985285%0A
"This paper proposes a new interferometric near-field 3-D imaging approach based on multi-channel joint sparse reconstruction to solve the problems of conventional methods, i.e., the irrespective correlation of different channels in single-channel independent imaging which may lead to deviated positions of scattering points, and the low accuracy of imaging azimuth angle for real anisotropic targets. Firstly, two full-apertures are divided into several sub-apertures by the same standard; secondly, the joint sparse metric function is constructed based on scattering characteristics of the target in multi-channel status, and the improved Orthogonal Matching Pursuit (OMP) method is used for imaging solving, so as to obtain high-precision 3-D image of each sub-aperture; thirdly, comprehensive sub-aperture processing is performed using all sub-aperture 3-D images to obtain the final 3-D images; finally, validity of the proposed approach is verified by using simulation electromagnetic data and data measured in the anechoic chamber. Experimental results show that, compared with traditional interferometric ISAR imaging approaches, the algorithm proposed in this paper is able to provide a higher accuracy in scattering center reconstruction, and can effectively maintain relative phase information of channels.","Fang Y
Wang B
Sun C
Wang S
Hu J
Song Z
","(PMID:30400251
)",Joint Sparsity Constraint Interferometric ISAR Imaging for 3-D Geometry of Near-Field Targets with Sub-Apertures.,https://europepmc.org/abstract/MED/30400251%0A
"PURPOSE:For extremely close bones, their boundaries are weak and diffused due to strong interaction between adjacent surfaces. These factors prevent the accurate segmentation of bone structure. To alleviate these difficulties, we propose an automatic method for accurate bone segmentation. The method is based on a consideration of the 3D surface normal direction, which is used to detect the bone boundary in 3D CT images. METHODS:Our segmentation method is divided into three main stages. Firstly, we consider a surface tracing corrector combined with Gaussian standard deviation [Formula: see text] to improve the estimation of normal direction. Secondly, we determine an optimal value of [Formula: see text] for each surface point during this normal direction correction. Thirdly, we construct the 1D signal and refining the rough boundary along the corrected normal direction. The value of [Formula: see text] is used in the first directional derivative of the Gaussian to refine the location of the edge point along accurate normal direction. Because the normal direction is corrected and the value of [Formula: see text] is optimized, our method is robust to noise images and narrow joint space caused by joint degeneration. RESULTS:We applied our method to 15 wrists and 50 hip joints for evaluation. In the wrist segmentation, Dice overlap coefficient (DOC) of [Formula: see text]% was obtained by our method. In the hip segmentation, fivefold cross-validations were performed for two state-of-the-art methods. Forty hip joints were used for training in two state-of-the-art methods, 10 hip joints were used for testing and performing comparisons. The DOCs of [Formula: see text], [Formula: see text]%, and [Formula: see text]% were achieved by our method for the pelvis, the left femoral head and the right femoral head, respectively. CONCLUSION:Our method was shown to improve segmentation accuracy for several specific challenging cases. The results demonstrate that our approach achieved a superior accuracy over two state-of-the-art methods.","Guo H
Song S
Wang J
Guo M
Cheng Y
Wang Y
Tamura S
","(PMID:29916062
)",3D surface voxel tracing corrector for accurate bone segmentation.,https://europepmc.org/abstract/MED/29916062%0A
No abstract provided.,"Cho A
","(PMID:12098681
)",Computer science. Collective effort makes the good times roll.,https://europepmc.org/abstract/MED/12098681%0A
"Time-to-digital converters (TDCs) act as the core component in many scientific and engineering systems which are based on high-accuracy time measurement. Traditionally, field programmable gate array (FPGA) based TDCs are constructed by organizing carry chains in the tapped delay line style, though acquiring high resolution, the differential nonlinearity (DNL) error is high in the range of 2 least significant bits (LSBs)-4 LSBs. Additionally, their long used length of the carry chain costs rather high resource, which is not friendly for multi-channel TDCs. This paper proposes a new TDC architecture based on dynamically delay-adjustable looped carry chains, which works in the Vernier mode. The TDC contains two looped carry chains, and their oscillation period difference (resolution) is dynamically adjusted by a personal computer program without manual intervene and re-compilation of the TDC circuit. A prototype TDC implemented on a Stratix III FPGA obtains the resolution of 26 ps and the DNL less than 1 LSB, but it only uses two carry chains of length of 32 each. The proposed TDC architecture opens a new way to exploit the capability of the carry chains on FPGAs for high-performance TDC applications.","Cui K
Li X
Zhu R
","(PMID:30184691
)",A high-linearity time-to-digital converter based on dynamically delay-adjustable looped carry chains on FPGAs.,https://europepmc.org/abstract/MED/30184691%0A
"Developing a cost-effective and robust triclustering algorithm that can identify triclusters of high biological significance in the gene-sample-time (GST) domain is a challenging task. Most existing triclustering algorithms can detect shifting and scaling patterns in isolation, they are not able to handle co-occurring shifting-and-scaling patterns. This paper makes an attempt to address this issue. It introduces a robust triclustering algorithm called THD-Tricluster to identify triclusters over the GST domain. In addition to applying over several benchmark datasets for its validation, the proposed THD-Tricluster algorithm was applied on HIV-1 progression data to identify disease-specific genes. THD-Tricluster could identify 38 most responsible genes for the deadly disease which includes GATA3, EGR1, JUN, ELF1, AGFG1, AGFG2, CX3CR1, CXCL12, CCR5, CCR2, and many others. The results are validated using GeneCard and other established results.","Kakati T
Ahmed HA
Bhattacharyya DK
Kalita JK
","(PMID:29787933
)",THD-Tricluster: A robust triclustering technique and its application in condition specific change analysis in HIV-1 progression data.,https://europepmc.org/abstract/MED/29787933%0A
"Next-generation sequencing (NGS) is routinely applied in life sciences and clinical practice, but interpretation of the massive quantities of genomic data produced has become a critical challenge. The genome-wide mutation analyses enabled by NGS have had a revolutionary impact in revealing the predisposing and driving DNA alterations behind a multitude of disorders. The workflow to identify causative mutations from NGS data, for example in cancer and rare diseases, commonly involves phases such as quality filtering, case-control comparison, genome annotation, and visual validation, which require multiple processing steps and usage of various tools and scripts. To this end, we have introduced an interactive and user-friendly multi-platform-compatible software, BasePlayer, which allows scientists, regardless of bioinformatics training, to carry out variant analysis in disease genetics settings. A genome-wide scan of regulatory regions for mutation clusters can be carried out with a desktop computer in ~10 min with a dataset of 3 million somatic variants in 200 whole-genome-sequenced (WGS) cancers.","Katainen R
Donner I
Cajuso T
Kaasinen E
Palin K
Mäkinen V
Aaltonen LA
Pitkänen E
","(PMID:30323186
)",Discovery of potential causative mutations in human coding and noncoding genome with the interactive software BasePlayer.,https://europepmc.org/abstract/MED/30323186%0A
"Water pollution is the root cause for many diseases in the world. It is necessary to measure water quality using sensors for prevention of water pollution. However, the related works remain the problems of communication, mobility, scalability, and accuracy. In this paper, we propose a new Supervisory Control and Data Acquisition (SCADA) system that integrates with the Internet of Things (IoT) technology for real-time water quality monitoring. It aims to determine the contamination of water, leakage in pipeline, and also automatic measure of parameters (such as temperature sensor, flow sensor, color sensor) in real time using Arduino Atmega 368 using Global System for Mobile Communication (GSM) module. The system is applied in the Tirunelveli Corporation (Metro city of Tamilnadu state, India) for automatic capturing of sensor data (pressure, pH, level, and energy sensors). SCADA system is fine-tuned with additional sensors and reduced cost. The results show that the proposed system outperforms the existing ones and produces better results. SCADA captures the real-time accurate sensor values of flow, temperature, and color and turbidity through the GSM communication.","Saravanan K
Anusuya E
Kumar R
Son LH
","(PMID:30159608
)",Real-time water quality monitoring using Internet of Things in SCADA.,https://europepmc.org/abstract/MED/30159608%0A
"Biomedical implants that incorporate active electronics and offer the ability to operate in a safe, stable fashion for long periods of time must incorporate defect-free layers as barriers to biofluid penetration. This paper reports an engineered material approach to this challenge that combines ultrathin, physically transferred films of silicon dioxide (t-SiO2) thermally grown on silicon wafers, with layers of hafnium oxide (HfO2) formed by atomic layer deposition and coatings of parylene (Parylene C) created by chemical vapor deposition, as a dual-sided encapsulation structure for flexible bioelectronic systems. Accelerated aging tests on passive/active components in platforms that incorporate active, silicon-based transistors suggest that this trilayer construct can serve as a robust, long-lived, defect-free barrier to phosphate-buffered saline (PBS) solution at a physiological pH of 7.4. Reactive diffusion modeling and systematic immersion experiments highlight fundamental aspects of water diffusion and hydrolysis behaviors, with results that suggest lifetimes of many decades at physiological conditions. A combination of ion-diffusion tests under continuous electrical bias, measurements of elemental concentration profiles, and temperature-dependent simulations reveals that this encapsulation strategy can also block transport of ions that would otherwise degrade the performance of the underlying electronics. These findings suggest broad utility of this trilayer assembly as a reliable encapsulation strategy for the most demanding applications in chronic biomedical implants and high-performance flexible bioelectronic systems.","Song E
Li R
Jin X
Du H
Huang Y
Zhang J
Xia Y
Fang H
Lee YK
Yu KJ
Chang JK
Mei Y
Alam MA
Huang Y
Rogers JA
","(PMID:30281278
)",Ultrathin Trilayer Assemblies as Long-Lived Barriers against Water and Ion Penetration in Flexible Bioelectronic Systems.,https://europepmc.org/abstract/MED/30281278%0A
"Science-education literature is replete with studies examining how students learn anatomy most effectively and efficiently. Some researchers have found that students learn best through hands-on learning, whereas other investigators have concluded students rate both computer and hands-on learning as effective and enjoyable. No study to date, however, has examined anatomical learning of preservice music education students on anatomical and physiological knowledge of the larynx. Therefore, the purpose of this investigation was to examine the effectiveness of virtual versus laboratory dissection in learning anatomy of the laryngeal structure for preservice music educators in a vocal pedagogy course. University students (N = 26) were given a pretest on laryngeal physiology and anatomy. Thereafter, the first group (n = 13) attended five 1-hour sessions of laryngeal dissection in a cadaver lab. The second group (n = 13) attended five 1-hour sessions in a computer lab equipped with Physiology and Anatomy Revealed, version 3.0 (McGraw Hill, New York, NY), a computer software program designed to simulate the dissection experience. Two days after finishing the laboratory or virtual dissection experience, each group was given a posttest. Perceptions were also gathered through a short questionnaire following the posttest. Results indicated that student knowledge and perceptions varied widely. All participants showed improved scores from pre- to posttest measures; however, scores were not significantly different between groups. Results are discussed in terms of feasibility of such a learning mode and importance of dissection experiences in understanding human anatomy as well impact on future music educators' teaching practice.","Brunkan MC
Mercado EM
","(PMID:30236536
)",A Comparison of Laboratory and Virtual Laryngeal Dissection Experiences on Preservice Music Educators' Knowledge and Perceptions.,https://europepmc.org/abstract/MED/30236536%0A
The original version of this article was published without funding note. The funding note is given below.,"Ziegle J
Audigier C
Krug J
Ali G
Kim Y
Boctor EM
Friebe M
","(PMID:29971667
)",Correction to: RF-ablation pattern shaping employing switching channels of dual bipolar needle electrodes: ex vivo results.,https://europepmc.org/abstract/MED/29971667%0A
"The phase mode atomic force microscopy (AFM) lithography and monolayer lift-off process are combined to fabricate electronics based on 2D materials (2DMs), which remove the need for pre-fabricating markers and increase the accuracy of the overlay and alignment. The promising phase mode of AFM lithography eliminates the drawbacks of the conventional force mode such as the over-cut, under-cut, debris effect, and severe tip wear. The planar size of MoS2 thin-film transistors is shrunken down to sub-micrometer by the proposed method, and the fabricated devices demonstrate n-type characteristics. It offers a more flexible and easier way to fabricate prototypes of sub-micrometer-sized 2DMs based devices, and gives the opportunity to explore the size effect on the performance of 2DMs devices.","Liu L
Shi J
Li M
Yu P
Yang T
Li G
","(PMID:30239118
)",Fabrication of Sub-Micrometer-Sized MoS2 Thin-Film Transistor by Phase Mode AFM Lithography.,https://europepmc.org/abstract/MED/30239118%0A
"With the development of outsourcing data services, data security has become an urgent problem that needs to be solved. Attribute-based encryption is a valid solution to data security in cloud storage. There is no existing scheme that can guarantee the privacy of access structures and achieve attribute-based encryption with keyword search and attribute revocation. In this article, we propose a new searchable and revocable multi-data owner attribute-based encryption scheme with a hidden policy in cloud storage. In the new scheme, the same access policy is used in both the keyword index and message encryption. The advantage of keyword index with access policy is that as long as a user's attributes satisfy the access policy, the searched ciphertext can be correctly decrypted. This property improves the accuracy of the search results. The hidden policy is used in both the ciphertext and the keyword index to protect users' privacy. The new scheme contains attribute revocation, which is suitable for the actual situation that a user's attributes maybe changed over time. In the general bilinear group model, the security of the scheme is demonstrated, and the efficiency of the scheme is analyzed.","Wang S
Gao T
Zhang Y
","(PMID:30383840
 PMCID:PMC6211670)",Searchable and revocable multi-data owner attribute-based encryption scheme with hidden policy in cloud storage.,https://europepmc.org/abstract/MED/30383840%0A
"Eir version 3 (V3) is an electronic tool for administration of patient-reported outcome measures (Eir-Patient) that immediately presents patient scores on the physician's computer (Eir-Doctor). Perceived usability is an important determinant for successful implementation. The aim of this study was to answer the following research question evaluated at the cancer outpatient clinics, in the patients' home, and at general practitioners' (GPs) offices: What are the number, type, and severity of usability issues evaluated by the patient (Eir-Patient module) and by the physician (Eir-Doctor module)?A usability evaluation using observations, think-aloud sessions, individual interviews and focus group interviews in cancer patients and their physicians was conducted. Identified usability issues were graded on a severity scale from 1 (irritant) to 4 (unusable).Overall, 73 Eir registrations were performed by 37 patients, and used by 17 physicians in clinical consultations. All patients were able to complete the Eir-Patient symptom registration. Seventy-two usability issues were identified. None of them were graded as unusable. For the Eir-Patient module, 62% of the identified usability issues was graded as irritant (grade 1), 18% as moderate (grade 2), and 20% as severe (grade 3). For the Eir-Doctor module, 46% of the identified usability issues were graded as irritant, 36% as moderate and 18% as severe.In the updated Eir version, issues in the severe and moderate categories have been changed, to optimize the usability of using real-time PROMs in clinical practice.","Krogstad H
Sundt-Hansen SM
Hjermstad MJ
Hågensen LÅ
Kaasa S
Loge JH
Raj SX
Steinsbekk A
Sand K
","(PMID:30173402
)",Usability testing of EirV3-a computer-based tool for patient-reported outcome measures in cancer.,https://europepmc.org/abstract/MED/30173402%0A
"Quorum-sensing peptides (QSPs) are the signal molecules that are closely associated with diverse cellular processes, such as cell-cell communication, and gene expression regulation in Gram-positive bacteria. It is therefore of great importance to identify QSPs for better understanding and in-depth revealing of their functional mechanisms in physiological processes. Machine learning algorithms have been developed for this purpose, showing the great potential for the reliable prediction of QSPs. In this study, several sequence-based feature descriptors for peptide representation and machine learning algorithms are comprehensively reviewed, evaluated and compared. To effectively use existing feature descriptors, we used a feature representation learning strategy that automatically learns the most discriminative features from existing feature descriptors in a supervised way. Our results demonstrate that this strategy is capable of effectively capturing the sequence determinants to represent the characteristics of QSPs, thereby contributing to the improved predictive performance. Furthermore, wrapping this feature representation learning strategy, we developed a powerful predictor named QSPred-FL for the detection of QSPs in large-scale proteomic data. Benchmarking results with 10-fold cross validation showed that QSPred-FL is able to achieve better performance as compared to the state-of-the-art predictors. In addition, we have established a user-friendly webserver that implements QSPred-FL, which is currently available at http://server.malab.cn/QSPred-FL. We expect that this tool will be useful for the high-throughput prediction of QSPs and the discovery of important functional mechanisms of QSPs.","Wei L
Hu J
Li F
Song J
Su R
Zou Q
","(PMID:30383239
)",Comparative analysis and prediction of quorum-sensing peptides using feature representation learning and machine learning algorithms.,https://europepmc.org/abstract/MED/30383239%0A
No abstract provided.,"Guo W
Gleditsch K
Wilson A
","(PMID:30323227
)",Retool AI to forecast and limit wars.,https://europepmc.org/abstract/MED/30323227%0A
"The color appearance of a surface depends on the color of its surroundings (inducers). When the perceived color shifts towards that of the surroundings, the effect is called ""color assimilation"" and when it shifts away from the surroundings it is called ""color contrast."" There is also evidence that the phenomenon depends on the spatial configuration of the inducer, e.g., uniform surrounds tend to induce color contrast and striped surrounds tend to induce color assimilation. However, previous work found that striped surrounds under certain conditions do not induce color assimilation but induce color contrast (or do not induce anything at all), suggesting that luminance differences and high spatial frequencies could be key factors in color assimilation. Here we present a new psychophysical study of color assimilation where we assessed the contribution of luminance differences (between the target and its surround) present in striped stimuli. Our results show that luminance differences are key factors in color assimilation for stimuli varying along the s axis of MacLeod-Boynton color space, but not for stimuli varying along the l axis. This asymmetry suggests that koniocellular neural mechanisms responsible for color assimilation only contribute when there is a luminance difference, supporting the idea that mutual-inhibition has a major role in color induction.","Cerda-Company X
Otazu X
Sallent N
Parraga CA
","(PMID:30347096
)",The effect of luminance differences on color assimilation.,https://europepmc.org/abstract/MED/30347096%0A
"The affordability of DNA sequencing has led to the generation of unprecedented volumes of raw sequencing data. These data must be stored, processed and transmitted, which poses significant challenges. To facilitate this effort, we introduce FaStore, a specialized compressor for FASTQ files. FaStore does not use any reference sequences for compression and permits the user to choose from several lossy modes to improve the overall compression ratio, depending on the specific needs.FaStore in the lossless mode achieves a significant improvement in compression ratio with respect to previously proposed algorithms. We perform an analysis on the effect that the different lossy modes have on variant calling, the most widely used application for clinical decision making, especially important in the era of precision medicine. We show that lossy compression can offer significant compression gains, while preserving the essential genomic information and without affecting the variant calling performance.FaStore can be downloaded from https://github.com/refresh-bio/FaStore.Supplementary data are available at Bioinformatics online.","Roguski L
Ochoa I
Hernaez M
Deorowicz S
","(PMID:29617939
)",FaStore: a space-saving solution for raw sequencing data.,https://europepmc.org/abstract/MED/29617939%0A
"Many medical information systems record data about the executed process instances in the form of an event log. In this paper, we present a framework, able to convert actions in the event log into higher level concepts, at different levels of abstraction, on the basis of domain knowledge. Abstracted traces are then provided as an input to trace comparison and semantic process discovery. Our abstraction mechanism is able to manage non trivial situations, such as interleaved actions or delays between two actions that abstract to the same concept. Trace comparison resorts to a similarity metric able to take into account abstraction phase penalties, and to deal with quantitative and qualitative temporal constraints in abstracted traces. As for process discovery, we rely on classical algorithms embedded in the framework ProM, made semantic by the capability of abstracting the actions on the basis of their conceptual meaning. The approach has been tested in stroke care, where we adopted abstraction and trace comparison to cluster event logs of different stroke units, to highlight (in)correct behavior, abstracting from details. We also provide process discovery results, showing how the abstraction mechanism allows to obtain stroke process models more easily interpretable by neurologists.","Leonardi G
Striani M
Quaglini S
Cavallini A
Montani S
","(PMID:29793072
)",Leveraging semantic labels for multi-level abstraction in medical process mining and trace comparison.,https://europepmc.org/abstract/MED/29793072%0A
"Recent years have seen an explosion of interest in both sequence- and structure-based approaches toward in silico-directed evolution. We recently developed a novel computational toolkit, CADEE, which facilitates the computer-aided directed evolution of enzymes. Our initial work (Amrein et al., IUCrJ 4:50-64, 2017) presented a pedagogical example of the application of CADEE to triosephosphate isomerase, to illustrate the CADEE workflow. In this contribution, we describe this workflow in detail, including code input/output snippets, in order to allow users to set up and execute CADEE simulations on any system of interest.","Amrein BA
Runthala A
Kamerlin SCL
","(PMID:30298410
)",In Silico-Directed Evolution Using CADEE.,https://europepmc.org/abstract/MED/30298410%0A
"OBJECTIVE AND BACKGROUND:The exponential growth of the unstructured data available in biomedical literature, and Electronic Health Record (EHR), requires powerful novel technologies and architectures to unlock the information hidden in the unstructured data. The success of smart healthcare applications such as clinical decision support systems, disease diagnosis systems, and healthcare management systems depends on knowledge that is understandable by machines to interpret and infer new knowledge from it. In this regard, ontological data models are expected to play a vital role to organize, integrate, and make informative inferences with the knowledge implicit in that unstructured data and represent the resultant knowledge in a form that machines can understand. However, constructing such models is challenging because they demand intensive labor, domain experts, and ontology engineers. Such requirements impose a limit on the scale or scope of ontological data models. We present a framework that will allow mitigating the time-intensity to build ontologies and achieve machine interoperability. METHODS:Empowered by linked biomedical ontologies, our proposed novel Automated Ontology Generation Framework consists of five major modules: a) Text Processing using compute on demand approach. b) Medical Semantic Annotation using N-Gram, ontology linking and classification algorithms, c) Relation Extraction using graph method and Syntactic Patterns, d), Semantic Enrichment using RDF mining, e) Domain Inference Engine to build the formal ontology. RESULTS:Quantitative evaluations show 84.78% recall, 53.35% precision, and 67.70% F-measure in terms of disease-drug concepts identification; 85.51% recall, 69.61% precision, and F-measure 76.74% with respect to taxonomic relation extraction; and 77.20% recall, 40.10% precision, and F-measure 52.78% with respect to biomedical non-taxonomic relation extraction. CONCLUSION:We present an automated ontology generation framework that is empowered by Linked Biomedical Ontologies. This framework integrates various natural language processing, semantic enrichment, syntactic pattern, and graph algorithm based techniques. Moreover, it shows that using Linked Biomedical Ontologies enables a promising solution to the problem of automating the process of disease-drug ontology generation.","Alobaidi M
Malik KM
Hussain M
","(PMID:30337066
)",Automated ontology generation framework powered by linked biomedical ontologies for disease-drug domain.,https://europepmc.org/abstract/MED/30337066%0A
"Forkhead box O (FOXO) proteins comprise a superfamily of transcription factors that play important roles in controlling various biological processes. Transcriptional control constitutes a crucial component in regulating complex biological processes. The identification of cis-regulatory elements is essential to understand the regulatory mechanism of gene expression. Chromatin immunoprecipitation followed by high-throughput sequencing (ChIP-seq) is widely used to identify the cis-regulatory elements of transcription factors and other DNA-binding proteins on a genome-wide level. It is a powerful tool to analyze the regulatory networks underlying the biological processes. Here, we describe a detailed protocol for preparing ChIP-seq samples that are used for sequencing and subsequent data analyses.","Shin DJ
Joshi P
Shin DG
Wang L
","(PMID:30414155
)",Genome-Wide Analysis for Identifying FOXO Protein-Binding Sites.,https://europepmc.org/abstract/MED/30414155%0A
"As one of the most common user interactive behaviors in many social media services, mention plays a significant role in both user interaction and information cascading. While an increasing line of work has focused on analyzing the mention mechanism for information diffusion, the essential problem of mentionee recommendation from the perspective of common users, i.e., how to find mentionees (mentioned users) who are most likely to be notified by a mentioner (mentioning user) for knowing a post, has been seldom investigated. This paper aims to develop personalized recommendation techniques to automatically generate mentionees when a user intends to mention others in a post. After analyzing real-world social media datasets we observe that users' mention behaviors are influenced by not only the semantic but also the spatial context factors of their mentioning activities, which motivate the needs for spatial context-aware user mention behavior modeling. In light of these, we proposed a joint probabilistic model, named Spatial COntext-aware Mention behavior Model (SCOMM), to simulate the process of generating users' location-tagged mentioning activities. By exploiting the semantic and spatial context factors in a unified way, SCOMM was able to reveal users' preferences behind their mention behaviors and provide a knowledge model for accurate mentionee recommendations. Furthermore, we designed an Item-Attribute Pruning (IAP) algorithm to overcome the curse of dimensionality and facilitate online top-k query performance. Extensive experiments were conducted on two real-world datasets to evaluate the performance of our methods. The experimental results demonstrated the superiority of our approach by making more effective and efficient recommendations compared with other state-of-the-art methods.","Wang K
Meng W
Bian J
Li S
Yang S
","(PMID:30075352
)",Spatial context-aware user mention behavior modeling for mentionee recommendation.,https://europepmc.org/abstract/MED/30075352%0A
"The capacity of 3D cameras to measure many different aspects of behavior (e.g., velocity, pattern, and posture) could contribute to the understanding of behavior. The present article describes a system for the real-time tracking of operant behavior, which is applicable to other domains of behavioral science as well. Methods for real-time 3D tracking of animal behavior are described, along with sample C++ programs. A demonstration using one zebrafish as a subject indicated that the present system successfully tracked the 3D motion of the fish. Moreover, the acquisition of a target response (i.e., approach to a corner of the aquarium) was demonstrated with the arrangement of a reinforcement contingency at the corner in the absence of a traditional, salient operandum. The system offers the capacity to characterize more completely ongoing behavior in learning tasks across a range of species than simply performance of discrete operant responses. The system also is capable of tracking multiple individuals simultaneously so it is possible both to study social interactions and arrange contingencies for engaging in social behavior. Other possible applications of 3D cameras are discussed.","Kuroda T
","(PMID:30230551
)",A system for the real-time tracking of operant behavior as an application of 3D camera.,https://europepmc.org/abstract/MED/30230551%0A
No abstract provided.,"Szalóki N
Krieger JW
Komáromi I
Tóth K
Vámosi G
","(PMID:30012845
 PMCID:PMC6048313)","Erratum for Szalóki et al., ""Evidence for Homodimerization of the c-Fos Transcription Factor in Live Cells Revealed by Fluorescence Microscopy and Computer Modeling"".",https://europepmc.org/abstract/MED/30012845%0A
"Deep learning has been increasingly used to solve a number of problems with state-of-the-art performance in a wide variety of fields. In biology, deep learning can be applied to reduce feature extraction time and achieve high levels of performance. In our present work, we apply deep learning via two-dimensional convolutional neural networks and position-specific scoring matrices to classify Rab protein molecules, which are main regulators in membrane trafficking for transferring proteins and other macromolecules throughout the cell. The functional loss of specific Rab molecular functions has been implicated in a variety of human diseases, e.g., choroideremia, intellectual disabilities, cancer. Therefore, creating a precise model for classifying Rabs is crucial in helping biologists understand the molecular functions of Rabs and design drug targets according to such specific human disease information. We constructed a robust deep neural network for classifying Rabs that achieved an accuracy of 99%, 99.5%, 96.3%, and 97.6% for each of four specific molecular functions. Our approach demonstrates superior performance to traditional artificial neural networks. Therefore, from our proposed study, we provide both an effective tool for classifying Rab proteins and a basis for further research that can improve the performance of biological modeling using deep neural networks.","Le NQ
Ho QT
Ou YY
","(PMID:29908156
)",Classifying the molecular functions of Rab GTPases in membrane trafficking using deep convolutional neural networks.,https://europepmc.org/abstract/MED/29908156%0A
"The surface electromyography (sEMG)-based gesture recognition with deep learning approach plays an increasingly important role in human-computer interaction. Existing deep learning architectures are mainly based on Convolutional Neural Network (CNN) architecture which captures spatial information of electromyogram signal. Motivated by the sequential nature of electromyogram signal, we propose an attention-based hybrid CNN and RNN (CNN-RNN) architecture to better capture temporal properties of electromyogram signal for gesture recognition problem. Moreover, we present a new sEMG image representation method based on a traditional feature vector which enables deep learning architectures to extract implicit correlations between different channels for sparse multi-channel electromyogram signal. Extensive experiments on five sEMG benchmark databases show that the proposed method outperforms all reported state-of-the-art methods on both sparse multi-channel and high-density sEMG databases. To compare with the existing works, we set the window length to 200ms for NinaProDB1 and NinaProDB2, and 150ms for BioPatRec sub-database, CapgMyo sub-database, and csl-hdemg databases. The recognition accuracies of the aforementioned benchmark databases are 87.0%, 82.2%, 94.1%, 99.7% and 94.5%, which are 9.2%, 3.5%, 1.2%, 0.2% and 5.2% higher than the state-of-the-art performance, respectively.","Hu Y
Wong Y
Wei W
Du Y
Kankanhalli M
Geng W
","(PMID:30376567
 PMCID:PMC6207326)",A novel attention-based hybrid CNN-RNN architecture for sEMG-based gesture recognition.,https://europepmc.org/abstract/MED/30376567%0A
"Aiming to address dense small object tracking, we propose an image-to-trajectory framework including tracking and detection, where Track-Oriented Multiple Hypothesis Tracking(TOMHT) is revised for tracking. Unlike common cases of multi-object tracking, merged detections and the greater number of objects make dense small object tracking a more challenging problem. Firstly, we handle frequent merged detections through the aspects of detection and hypothesis selection. To tackle merged detection, we revise Local Contrast Method(LCM) and propose a multi-appearance variant, which exploits tree-like topological information and realizes one threshold for one object. Meanwhile, one-to-many constraint is employed via the proposed extended 0-1 programming, which enables hypothesis selection to handle track exclusions caused by merged detections. Secondly, to alleviate the high complexity caused by dense objects, we consider batch optimization and more rigorous and precise pruning technologies. Specifically, we propose autocorrelation based motion score test and two-stage hypotheses pruning. Experimental results are presented to verify the strength of our methods, which indicates speed and performance advantages of our tracker.","Chen L
Ren M
","(PMID:30379889
 PMCID:PMC6209235)",Multi-appearance segmentation and extended 0-1 programming for dense small object tracking.,https://europepmc.org/abstract/MED/30379889%0A
"Ectodermal dysplasia (ED) is a genetic disorder affecting organs derived from the embryonic ectoderm. Symptoms manifest early in life, and dental anomalies, including partial or complete edentulism, affect most of these patients. Overdentures have been a popular and conservative treatment option for patients with ED with a few natural teeth. Advancements in digital technology have improved and positively influenced dentistry, including removable prosthodontics. This clinical report describes a positive treatment outcome using computer-engineered complete overdentures to rehabilitate a patient with dental manifestations of ectodermal dysplasia.","Punj A
Kattadiyil MT
","(PMID:30139675
)",Management of ectodermal dysplasia with tooth-supported computer-engineered complete overdentures: A clinical report.,https://europepmc.org/abstract/MED/30139675%0A
"In the era of next-generation sequencing and ubiquitous assembly and binning of metagenomes, new putative genome sequences are being produced from isolate and microbiome samples at ever-increasing rates. Genome-scale metabolic models have enormous utility for supporting the analysis and predictive characterization of these genomes based on sequence data. As a result, tools for rapid automated reconstruction of metabolic models are becoming critically important for supporting the analysis of new genome sequences. Many tools and algorithms have now emerged to support rapid model reconstruction and analysis. Here, we are comparing and contrasting the capabilities and output of a variety of these tools, including ModelSEED, Raven Toolbox, PathwayTools, SuBliMinal Toolbox and merlin.","Faria JP
Rocha M
Rocha I
Henry CS
","(PMID:30065105
)",Methods for automated genome-scale metabolic model reconstruction.,https://europepmc.org/abstract/MED/30065105%0A
"While recently emergent driver mutation data sets are available for developing computational methods to predict cancer mutation effects, benchmark sets focusing on passenger mutations are largely missing. Here, we developed a comprehensive literature-based database of Cancer Passenger Mutations (dbCPM), which contains 941 experimentally supported and 978 putative passenger mutations derived from a manual curation of the literature. Using the missense mutation data, the largest group in the dbCPM, we explored patterns of missense passenger mutations by comparing them with the missense driver mutations and assessed the performance of four cancer-focused mutation effect predictors. We found that the missense passenger mutations showed significant differences with drivers at multiple levels, and several appeared in both the passenger and driver categories, showing pleiotropic functions depending on the tumor context. Although all the predictors displayed good true positive rates, their true negative rates were relatively low due to the lack of negative training samples with experimental evidence, which suggests that a suitable negative data set for developing a more robust methodology is needed. We hope that the dbCPM will be a benchmark data set for improving and evaluating prediction algorithms and serve as a valuable resource for the cancer research community. dbCPM is freely available online at http://bioinfo.ahu.edu.cn:8080/dbCPM.","Yue Z
Zhao L
Xia J
","(PMID:30379998
)",dbCPM: a manually curated database for exploring the cancer passenger mutations.,https://europepmc.org/abstract/MED/30379998%0A
"The manifestation of complex traits is influenced by gene-gene and gene-environment interactions, and the identification of multifactor interactions is an important but challenging undertaking for genetic studies. Many complex phenotypes such as disease severity are measured on an ordinal scale with more than two categories. A proportional odds model can improve statistical power for these outcomes, when compared to a logit model either collapsing the categories into two mutually exclusive groups or limiting the analysis to pairs of categories. In this study, we propose a proportional odds model-based generalized multifactor dimensionality reduction (GMDR) method for detection of interactions underlying polytomous ordinal phenotypes. Computer simulations demonstrated that this new GMDR method has a higher power and more accurate predictive ability than the GMDR methods based on a logit model and a multinomial logit model. We applied this new method to the genetic analysis of low-density lipoprotein (LDL) cholesterol, a causal risk factor for coronary artery disease, in the Multi-Ethnic Study of Atherosclerosis, and identified a significant joint action of the CELSR2, SERPINA12, HPGD, and APOB genes. This finding provides new information to advance the limited knowledge about genetic regulation and gene interactions in metabolic pathways of LDL cholesterol. In conclusion, the proportional odds model-based GMDR is a useful tool that can boost statistical power and prediction accuracy in studying multifactor interactions underlying ordinal traits.","Hou TT
Lin F
Bai S
Cleves MA
Xu HM
Lou XY
","(PMID:30387901
)",Generalized multifactor dimensionality reduction approaches to identification of genetic interactions underlying ordinal traits.,https://europepmc.org/abstract/MED/30387901%0A
"Understanding the neurological changes that take place as expertise develops is a central topic in both cognitive psychology and cognitive neuroscience. Here, we argue that video games, despite previous misconceptions, are an excellent model environment from which one can examine the development of neurocognitive expertise. Of particular relevance we argue is the area of esports, which encompass video/computer games played within the medium of cyberspace competitively and increasingly professionally. The massive scale of participation, controlled environments, structured skill ratings, pervasive social nature, and large repositories of data, together make esports potentially a very fruitful area for scientific research to increase our understanding of a new era of cognitive athletes. This chapter reviews the progress and prospects for esports research with a particular focus on the effects of gaming on neurocognition. We also outline some exciting new avenues and techniques from which we hope to further elucidate the benefits of esports on the brain.","Campbell MJ
Toth AJ
Moran AP
Kowal M
Exton C
","(PMID:30390829
)",eSports: A new window on neurocognitive expertise?,https://europepmc.org/abstract/MED/30390829%0A
"Viruses infect their human hosts by a series of interactions between viral and host proteins, indicating that detailed knowledge of such virus-host interaction interfaces are critical for our understanding of viral infection mechanisms, disease etiology and the development of new drugs. In this review, we primarily survey human host-virus interaction data that are available from public databases following the standardized PSI-MS format. Notably, available host-virus protein interaction information is strongly biased toward a small number of virus families including herpesviridae, papillomaviridae, orthomyxoviridae and retroviridae. While we explore the reliability and relevance of these protein interactions we also survey the current knowledge about viruses functional and topological targets. Furthermore, we assess emerging frontiers of host-virus protein interaction research, focusing on protein interaction interfaces of hosts that are infected by different viruses and viruses that infect multiple hosts. Finally, we cover the current status of research that investigates the relationships of virus-targeted host proteins to other comorbidities as well as the influence of host-virus protein interactions on human metabolism.","Goodacre N
Devkota P
Bae E
Wuchty S
Uetz P
","(PMID:30031213
)",Protein-protein interactions of human viruses.,https://europepmc.org/abstract/MED/30031213%0A
"Surprise has been explored as a cognitive-emotional phenomenon that impacts many aspects of mental life from creativity to learning to decision-making. In this paper, we specifically address the role of surprise in learning and memory. Although surprise has been cast as a basic emotion since Darwin's () The Expression of the Emotions in Man and Animals, recently more emphasis has been placed on its cognitive aspects. One such view casts surprise as a process of ""sense making"" or ""explanation finding"": metacognitive explanation-based theory proposes that people's perception of surprise is a metacognitive assessment of the cognitive work done to explain a surprising outcome. Or, to put it more simply, surprise increases with the explanatory work required to resolve it. This theory predicts that some surprises should be more surprising than others because they are harder to explain. In the current paper, this theory is extended to consider the role of surprise in learning as evidenced by memorability. This theory is tested to determine how scenarios with differentially surprising outcomes impact the memorability of those outcomes. The results show that surprising outcomes (less-known outcomes) that are more difficult to explain are recalled more accurately than less-surprising outcomes that require little (known outcomes) or no explanation (normal).","Foster MI
Keane MT
","(PMID:30375159
)",The Role of Surprise in Learning: Different Surprising Outcomes Affect Memorability Differentially.,https://europepmc.org/abstract/MED/30375159%0A
"<label>Motivation</label>Bioinformatics studies often rely on similarity measures between sequence pairs, which often pose a bottleneck in large-scale sequence analysis.<label>Results</label>Here, we present a new convolutional kernel function for protein sequences called the Lempel-Ziv-Welch (LZW)-Kernel. It is based on code words identified with the LZW universal text compressor. The LZW-Kernel is an alignment-free method, it is always symmetric, is positive, always provides 1.0 for self-similarity and it can directly be used with Support Vector Machines (SVMs) in classification problems, contrary to normalized compression distance, which often violates the distance metric properties in practice and requires further techniques to be used with SVMs. The LZW-Kernel is a one-pass algorithm, which makes it particularly plausible for big data applications. Our experimental studies on remote protein homology detection and protein classification tasks reveal that the LZW-Kernel closely approaches the performance of the Local Alignment Kernel (LAK) and the SVM-pairwise method combined with Smith-Waterman (SW) scoring at a fraction of the time. Moreover, the LZW-Kernel outperforms the SVM-pairwise method when combined with Basic Local Alignment Search Tool (BLAST) scores, which indicates that the LZW code words might be a better basis for similarity measures than local alignment approximations found with BLAST. In addition, the LZW-Kernel outperforms n-gram based mismatch kernels, hidden Markov model based SAM and Fisher kernel and protein family based PSI-BLAST, among others. Further advantages include the LZW-Kernel's reliance on a simple idea, its ease of implementation, and its high speed, three times faster than BLAST and several magnitudes faster than SW or LAK in our tests.<label>Availability and implementation</label>LZW-Kernel is implemented as a standalone C code and is a free open-source program distributed under GPLv3 license and can be downloaded from https://github.com/kfattila/LZW-Kernel.<label>Supplementary information</label>Supplementary data are available at Bioinformatics Online.","Filatov G
Bauwens B
Kertész-Farkas A
","(PMID:29741583
)",LZW-Kernel: fast kernel utilizing variable length code blocks from LZW compressors for protein sequence classification.,https://europepmc.org/abstract/MED/29741583%0A
"Einstein's theory of general relativity affords an enormously successful description of gravity. The theory encodes the gravitational interaction in the metric, a tensor field on spacetime that satisfies partial differential equations known as the Einstein equations. This review introduces some of the fundamental concepts of numerical relativity-solving the Einstein equations on the computer-in simple terms. As a primary example, we consider the solution of the general relativistic two-body problem, which features prominently in the new field of gravitational wave astronomy.","Brügmann B
","(PMID:30049876
)",Fundamentals of numerical relativity for gravitational wave sources.,https://europepmc.org/abstract/MED/30049876%0A
"Matrix-assisted laser desorption/ionization time-of-flight mass spectrometry (MALDI-TOF MS) is now widely used to characterize bacterial samples for clinical diagnosis, food safety control, environmental monitoring, and so on. However, existing standard approaches are only applied to analyze single colonies purified by plate culture, which limits the approaches to cultivable bacteria and makes the whole approaches time-consuming. In this work, we propose a new framework to analyze MALDI-TOF spectra of bacterial mixtures and to directly characterize each component without purification procedures. The framework is a combination of a synthetic mixture model based on a non-negative linear combination of candidate reference spectra and a statistical assessment by in silico generated spectra via a jackknife resampling. Ninety-seven model bacterial mixture samples and 8 cocultured blind-coded bacterial mixture samples, containing up to 6 strains in varied ratios in each sample, together with a reference database containing the mass spectra of 1081 strains, were used to validate the framework. High sensitivity (>80%, with error rate <5%) was achieved for balanced binary and ternary mixtures. The sensitivity was >60% for balanced quaternary and pentabasic mixtures, and 48%-71% for asymmetric situation, with error rate <5%. The work can facilitate rapid and reliable characterization of bacterial mixtures without purification procedures, which is of practical value in clinical diagnosis, food safety control, environmental monitoring, and so on. The framework can be further applied to many other spectroscopy-based analytics to interpret spectra from mixed samples.","Yang Y
Lin Y
Qiao L
","(PMID:30091898
)",Direct MALDI-TOF MS Identification of Bacterial Mixtures.,https://europepmc.org/abstract/MED/30091898%0A
"Vitamin D is recognized to play important roles in the onset of immunological diseases as well as the regulation of the amount of Ca in the blood. Since these physiological actions caused by active vitamin D are triggered by the specific interaction between the vitamin D receptor (VDR) and active vitamin D, many types of compounds have been developed as potent ligands against VDR. It was found that the binding affinity between VDR and its ligand depends significantly on the chirality of the ligand. However, the reason for the dependence has, thus far, not been elucidated. In the present study, we investigated the specific interactions between VDR and some ligands with different chirality, using ab initio fragment molecular orbital (FMO) calculations. The FMO results reveal that two histidine residues of VDR contribute significantly to the binding between VDR and ligand and that their protonation states can affect the specific interactions between VDR and ligand. We therefore considered other possible protonation states of these histidine residues and determined their most stable states, using the ab initio FMO calculations. The results illustrate the possibility that the difference in the chirality of a ligand can induce the change in protonation states of the histidine residues of VDR existing near the ligand. This finding provides an important warning that the protonation states of histidine residues existing near the ligand should be considered more precisely in the molecular simulations for investigating the specific interactions between protein and ligand.","Terauchi Y
Suzuki R
Takeda R
Kobayashi I
Kittaka A
Takimoto-Kamimura M
Kurita N
","(PMID:30278216
)",Ligand chirality can affect histidine protonation of vitamin-D receptor: ab initio molecular orbital calculations in water.,https://europepmc.org/abstract/MED/30278216%0A
"Unmanned aerial vehicles (UAVs) have gained significant attention in recent times due to their suitability for a wide variety of civil, military, and societal missions. Development of an unmanned amphibious vehicle integrating the features of a multi-rotor UAV and a hovercraft is the focus of the present study. Components and subsystems of the amphibious vehicle are developed with due consideration for aerodynamic, structural, and environmental aspects. Finite element analysis (FEA) on static thrust conditions and skirt pressure are performed to evaluate the strength of the structure. For diverse wind conditions and angles of attack (AOA), computational fluid dynamic (CFD) analysis is carried out to assess the effect of drag and suitable design modification is suggested. A prototype is built with a 7 kg payload capacity and successfully tested for stable operations in flight and water-borne modes. Internet of things (IoT) based water quality measurement is performed in a typical lake and water quality is measured using pH, dissolved oxygen (DO), turbidity, and electrical conductivity (EC) sensors. The developed vehicle is expected to meet functional requirements of disaster missions catering to the water quality monitoring of large water bodies.","Esakki B
Ganesan S
Mathiyazhagan S
Ramasubramanian K
Gnanasekaran B
Son B
Park SW
Choi JS
","(PMID:30282939
 PMCID:PMC6210420)",Design of Amphibious Vehicle for Unmanned Mission in Water Quality Monitoring Using Internet of Things.,https://europepmc.org/abstract/MED/30282939%0A
"BACKGROUND:GSK2894512 is a topically delivered investigational drug being developed for treatment of atopic dermatitis and psoriasis. OBJECTIVES:To investigate, in a phase I clinical trial, the spatial biodistribution and residency of GSK2894512 within the epidermis and dermis of healthy human participants noninvasively using fluorescence lifetime imaging microscopy (FLIM). METHODS:Two topical drug formulations containing GSK2894512 1% were applied to the right and left forearms of six participants for seven consecutive days, followed by seven days of observation for residency. FLIM images were obtained daily throughout the study, approximately every 24 h. During the treatment phase of the study, images were collected from each participant pretreatment, reflecting the residual dose from the previous day. Three punch biopsies from each participant of one formulation was obtained from the treated region during the post-treatment follow-up period between days 8 and 14 for comparison with FLIM results. RESULTS:Cellular and subcellular features associated with different epidermal and dermal layers were visualized noninvasively, down to a depth of 200 μm. Results yielded three-dimensional maps of GSK2894512 spatial distribution and residency over time. This fluorescence data provided a marker that was used as a monitor for day-to-day variance of drug presence and residency postapplication. CONCLUSIONS:The results suggest FLIM could be a viable alternative to skin biopsies without the usual patient discomfort and limitations, thereby enabling the direct measurement of skin distribution through longitudinal monitoring. These results are the first step in establishing the unique capabilities that multiphoton imaging could provide to patients through noninvasive drug detection.","Alex A
Frey S
Angelene H
Neitzel CD
Li J
Bower AJ
Spillman DR Jr
Marjanovic M
Chaney EJ
Medler JL
Lee W
Vasist Johnson LS
Boppart SA
Arp Z
","(PMID:29989149
)",In situ biodistribution and residency of a topical anti-inflammatory using fluorescence lifetime imaging microscopy.,https://europepmc.org/abstract/MED/29989149%0A
"Empowered by virtualization technology, service requests from cloud users can be honored through creating and running virtual machines. Virtual machines established for different users may be allocated to the same physical server, making the cloud vulnerable to co-residence attacks where a malicious attacker can steal a user's data through co-residing their virtual machines on the same server. For protecting data against the theft, the data partition technique is applied to divide the user's data into multiple blocks with each being handled by a separate virtual machine. Moreover, early warning agents (EWAs) are deployed to possibly detect and prevent co-residence attacks at a nascent stage. This article models and analyzes the attack success probability (complement of data security) in cloud systems subject to competing attack detection process (by EWAs) and data theft process (by co-residence attackers). Based on the suggested probabilistic model, the optimal data partition and protection policy is determined with the objective of minimizing the user's cost subject to providing a desired level of data security. Examples are presented to illustrate effects of different model parameters (attack rate, number of cloud servers, number of data blocks, attack detection time, and data theft time distribution parameters) on the attack success probability and optimization solutions.","Levitin G
Xing L
Huang HZ
","(PMID:30312478
)",Security of Separated Data in Cloud Systems with Competing Attack Detection and Data Theft Processes.,https://europepmc.org/abstract/MED/30312478%0A
"This report presents challenges, opportunities and directions for computational science and engineering (CSE) research and education for the next decade. Over the past two decades the field of CSE has penetrated both basic and applied research in academia, industry, and laboratories to advance discovery, optimize systems, support decision-makers, and educate the scientific and engineering workforce. Informed by centuries of theory and experiment, CSE performs computational experiments to answer questions that neither theory nor experiment alone is equipped to answer. CSE provides scientists and engineers with algorithmic inventions and software systems that transcend disciplines and scales. CSE brings the power of parallelism to bear on troves of data. Mathematics-based advanced computing has become a prevalent means of discovery and innovation in essentially all areas of science, engineering, technology, and society; and the CSE community is at the core of this transformation. However, a combination of disruptive developments-including the architectural complexity of extreme-scale computing, the data revolution and increased attention to data-driven discovery, and the specialization required to follow the applications to new frontiers-is redefining the scope and reach of the CSE endeavor. With these many current and expanding opportunities for the CSE field, there is a growing demand for CSE graduates and a need to expand CSE educational offerings. This need includes CSE programs at both the undergraduate and graduate levels, as well as continuing education and professional development programs, exploiting the synergy between computational science and data science. Yet, as institutions consider new and evolving educational programs, it is essential to consider the broader research challenges and opportunities that provide the context for CSE education and workforce development.","Officers of the SIAM Activity Group on Computational Science and Engineering (SIAG/CSE), 2013-2014
","(PMID:30287973
 PMCID:PMC6168210)",Research and Education in Computational Science and Engineering.,https://europepmc.org/abstract/MED/30287973%0A
"A large amount of multi-species functional genomic data from high-throughput assays are becoming available to help understand the molecular mechanisms for phenotypic diversity across species. However, continuous-trait probabilistic models, which are key to such comparative analysis, remain under-explored. Here we develop a new model, called phylogenetic hidden Markov Gaussian processes (Phylo-HMGP), to simultaneously infer heterogeneous evolutionary states of functional genomic features in a genome-wide manner. Both simulation studies and real data application demonstrate the effectiveness of Phylo-HMGP. Importantly, we applied Phylo-HMGP to analyze a new cross-species DNA replication timing (RT) dataset from the same cell type in five primate species (human, chimpanzee, orangutan, gibbon, and green monkey). We demonstrate that our Phylo-HMGP model enables discovery of genomic regions with distinct evolutionary patterns of RT. Our method provides a generic framework for comparative analysis of multi-species continuous functional genomic signals to help reveal regions with conserved or lineage-specific regulatory roles.","Yang Y
Gu Q
Zhang Y
Sasaki T
Crivello J
O'Neill RJ
Gilbert DM
Ma J
","(PMID:29936186
)",Continuous-Trait Probabilistic Model for Comparing Multi-species Functional Genomic Data.,https://europepmc.org/abstract/MED/29936186%0A
"Here we introduce for the first time a metal-free trianglamine-based supramolecular organic framework, T-SOF-1, with permanent intrinsic porosity and high affinity to CO2. The capability of tuning the pore aperture dimensions is also demonstrated by molecular guest encapsulation to afford excellent CO2/CH4 separation for natural gas upgrading.","Chaix A
Mouchaham G
Shkurenko A
Hoang P
Moosa B
Bhatt PM
Adil K
Salama KN
Eddaoudi M
Khashab NM
","(PMID:30293426
)",Trianglamine-Based Supramolecular Organic Framework with Permanent Intrinsic Porosity and Tunable Selectivity.,https://europepmc.org/abstract/MED/30293426%0A
"Recent advances in machine learning allow faster training, improved performance and increased interpretability of classification techniques. Consequently, their application in neuroscience is rapidly increasing. While classification approaches have proved useful in functional magnetic resonance imaging (fMRI) studies, there are concerns regarding extraction, reproducibility and visualization of brain regions that contribute most significantly to the classification. We addressed these issues using an fMRI classification scheme based on neural networks and compared a set of methods for extraction of category-related voxel importances in three simulated and two empirical datasets. The simulation data revealed that the proposed scheme successfully detects spatially distributed and overlapping activation patterns upon successful classification. Application of the proposed classification scheme to two previously published empirical fMRI datasets revealed robust importance maps that extensively overlap with univariate maps but also provide complementary information. Our results demonstrate increased statistical power of importance maps compared to univariate approaches for both detection of overlapping patterns and patterns with weak univariate information.","Gotsopoulos A
Saarimäki H
Glerean E
Jääskeläinen IP
Sams M
Nummenmaa L
Lampinen J
","(PMID:29964190
)",Reproducibility of importance extraction methods in neural network based fMRI classification.,https://europepmc.org/abstract/MED/29964190%0A
"The human body is the most common object of pictorial representation in western art and its representations trigger a vast range of experiences from pain to pleasure. The goal of this study was to investigate brain activity triggered by paintings of male and female body images exemplifying conditions associated with pleasure or pain. Our findings show participant-general as well as gender specific brain activity for either the pain or the pleasure conditions. Although our participants were fully aware that they were viewing artworks, the inferior parietal lobule - known for its role in the perception of emotional body images - and the somatosensory cortex related to touch were selectively active for female body paintings in all participants in the pleasure conditions. As regards gender we observed that the sight of female bodies activated the subgenual anterior cingulate cortex in males, an area known to subserve autonomic arousal. In contrast, in females the sight of the male body activated reward and control related parts of the dorsal anterior cingulate cortex. This study supports the notion that some basic evolutionary processes operate when we view body images, also when they are cultural heritage paintings far removed from daily experience.","de Gelder B
Watson R
Zhan M
Diano M
Tamietto M
Vaessen MJ
","(PMID:30388438
)",Classical paintings may trigger pain and pleasure in the gendered brain.,https://europepmc.org/abstract/MED/30388438%0A
"The simultaneous administration of multiple drugs increases the probability of interaction among them, as one drug may affect the activities of others. This interaction among drugs may have a positive or negative impact on the therapeutic outcomes. Thus, identification of unknown drug-drug interactions (DDIs) is of significant concern for improving the safety and efficacy of drug consumption. Although multiple DDI resources exist, it is becoming infeasible to maintain these up-to-date manually with the number of biomedical texts growing at a fast pace. Most existing methods model DDI extraction as a classification problem and rely mainly on handcrafted features, and certain features further depend on domain-specific tools. Recently, neural network models using latent features have been demonstrated to yield similar or superior performance compared to existing models. In this study, we present three long short-term memory (LSTM) network models, namely B-LSTM, AB-LSTM, and Joint AB-LSTM. All three models use word and position embedding as latent features; thus, they do not rely on explicit feature engineering. Furthermore, the use of a bidirectional LSTM (Bi-LSTM) network allows for extraction of implicit features from an entire sentence. The two models AB-LSTM and Joint AB-LSTM also apply attentive pooling in the Bi-LSTM layer output in order to assign weights to features. Our experimental results on the SemEval-2013 DDI extraction dataset indicate that the Joint AB-LSTM model produces reasonable performance (F-score: 69.39%) even with the simple architecture.","Sahu SK
Anand A
","(PMID:30142385
)",Drug-drug interaction extraction from biomedical texts using long short-term memory network.,https://europepmc.org/abstract/MED/30142385%0A
"OBJECTIVE:Alzheimers disease (AD) is characterized by gradual neurodegeneration and loss of brain function, especially for memory during early stages. Regression analysis has been widely applied to AD research to relate clinical and biomarker data such as predicting cognitive outcomes from Magnetic Resonance Imaging (MRI) measures. Recently, the multi-task feature learning (MTFL) methods have been widely studied to predict cognitive outcomes and select the discriminative feature subset from MRI features by incorporating inherent correlations among multiple clinical cognitive measures. However, the existing MTFL assumes the correlation among all the tasks is uniform, and the task relatedness is modeled by encouraging a common subset of features with neglecting the inherent structure of tasks and MRI features. METHODS:In this paper, we proposed a generalized fused group lasso (GFGL) regularization to model the underlying structures, involving (1) a graph structure within tasks and (2) a group structure among the image features. Then, we present a multi-task learning framework (called GFGL-MTFL), combining the ℓ2, 1-norm with the GFGL regularization, to model the flexible structures. RESULTS:Through empirical evaluation and comparison with different baseline methods and the state-of-the-art MTL methods on data from Alzheimer's Disease Neuroimaging Initiative (ADNI) database, we illustrate that the proposed GFGL-MTFL method outperforms other methods in terms of both Mean Squared Error (nMSE) and weighted correlation coefficient (wR). Improvements are statistically significant for most scores (tasks). CONCLUSIONS:The experimental results with real and synthetic data demonstrate that incorporating the two prior structures by the generalized fused group lasso norm into the multi task feature learning can improve the prediction performance over several state-of-the-art competing methods, and the estimated correlation of the cognitive functions and the identification of cognition relevant imaging markers are clinically and biologically meaningful.","Cao P
Liu X
Liu H
Yang J
Zhao D
Huang M
Zaiane O
","(PMID:29903486
)",Generalized fused group lasso regularized multi-task feature learning for predicting cognitive outcomes in Alzheimers disease.,https://europepmc.org/abstract/MED/29903486%0A
"Three-dimensional (3D) computer-generated models of plants are urgently needed to support both phenotyping and simulation-based studies such as photosynthesis modeling. However, the construction of accurate 3D plant models is challenging, as plants are complex objects with an intricate leaf structure, often consisting of thin and highly reflective surfaces that vary in shape and size, forming dense, complex, crowded scenes. We address these issues within an image-based method by taking an active vision approach, one that investigates the scene to intelligently capture images, to image acquisition. Rather than use the same camera positions for all plants, our technique is to acquire the images needed to reconstruct the target plant, tuning camera placement to match the plant's individual structure. Our method also combines volumetric- and surface-based reconstruction methods and determines the necessary images based on the analysis of voxel clusters. We describe a fully automatic plant modeling/phenotyping cell (or module) comprising a six-axis robot and a high-precision turntable. By using a standard color camera, we overcome the difficulties associated with laser-based plant reconstruction methods. The 3D models produced are compared with those obtained from fixed cameras and evaluated by comparison with data obtained by x-ray microcomputed tomography across different plant structures. Our results show that our method is successful in improving the accuracy and quality of data obtained from a variety of plant types.","Gibbs JA
Pound M
French AP
Wells DM
Murchie E
Pridmore T
","(PMID:30097468
)",Plant Phenotyping: An Active Vision Cell for Three-Dimensional Plant Shoot Reconstruction.,https://europepmc.org/abstract/MED/30097468%0A
"Fingerprint Recognition System is widely deployed in variety of application domain, ranging from forensic to mobile phones. Its widespread deployment in various applications were person authentication are required, has caused concern that a leaked fingerprint template may be used to reconstruct the original fingerprint and the reconstructed fingerprint can be used to circumvent all the applications the person is enrolled. In this paper, a non-invertible fingerprint template that stores only the relative geometric information about the minutiae points is proposed. The spatial location of the minutiae points in original fingerprint and its orientations are not available in the proposed template which makes it impossible to estimate the orientation of fingerprint from the template. The proposed template is invariant to rotation, translation and distortion and immune to reconstruction algorithm. The proposed system is experimented using standard FVC2000 database and yields better results in terms of EER and FMR as compared with latest techniques.","Trivedi AK
Thounaojam DM
Pal S
","(PMID:29791890
)",A robust and non-invertible fingerprint template for fingerprint matching system.,https://europepmc.org/abstract/MED/29791890%0A
"Recently, snake-like robots are proposed to assist experts during medical procedures on internal organs via natural orifices. Despite their well-spelt advantages, applications in radiosurgery is still hindered by absence of suitable designs required for spatial navigations within clustered and confined parts of human body, and inexistence of precise and fast inverse kinematics (IK) models. In this study, a deeply-learnt damped least squares method is proposed for solving IK of spatial snake-like robot. The robot's model consists of several modules, and each module has a pair of serial-links connected with orthogonal twists. For precise control of the robot's end-effector, damped least-squares approach is used to minimize error magnitude in a function modeled over analytical Jacobian of the robot. This is iteratively done until an apt joint vector needed to converge the robot to desired positions is obtained. For fast control and singularity avoidance, a deep network is built for prediction of unique damping factor required for each target point in the robot's workspace. The deep network consists of 11 x 15 array of neurons at the hidden layer, and deeply-learnt with a huge dataset of 877,500 data points generated from workspace of the snake robot. Implementation results for both simulated and actual prototype of an eight-link model of the robot show the effectiveness of the proposed IK method. With error tolerance of 0.01 mm, the proposed method has a very high reachability measure of 91.59% and faster mean execution time of 9.20 (±16.92) ms for convergence. In addition, the method requires an average of 33.02 (±39.60) iterations to solve the IK problem. Hence, approximately 3.6 iterations can be executed in 1 ms. Evaluation against popularly used IK methods shows that the proposed method has very good performance in terms of accuracy and speed, simultaneously.","Omisore OM
Han S
Ren L
Elazab A
Hui L
Abdelhamid T
Azeez NA
Wang L
","(PMID:30241968
)",Deeply-learnt damped least-squares (DL-DLS) method for inverse kinematics of snake-like robots.,https://europepmc.org/abstract/MED/30241968%0A
A correction to this article has been published and is linked from the HTML and PDF versions of this paper. The error has not been fixed in the paper.,"Tuo S
Zhang J
Yuan X
He Z
Liu Y
Liu Z
","(PMID:29662181
 PMCID:PMC5902605)",Author Correction: Niche harmony search algorithm for detecting complex disease associated high-order SNP combinations.,https://europepmc.org/abstract/MED/29662181%0A
"BACKGROUND:Recent studies have shown that epigenetic alterations, especially the hyper-methylated promoters of tumor suppressor genes (TSGs), contribute to prostate cancer (PCa) progression and metastasis. This paper proposes a novel algorithm to identify epigenetically silenced TSGs (epi-TSGs) for PCa. METHODS:Our method is based on the perception that the promoter CpG island(s) of a typical epi-TSG has a stratified methylation profile over tumor samples. In other words, we assume that the methylation profile resembles the combination of a binary distribution of a driver mutation and a continuous distribution representing measurement noise and intra-tumor heterogeneity. RESULTS:Applying the proposed algorithm and an existing method to the Cancer Genome Atlas (TCGA) PCa data, we identify 57 candidate epi-TSGs. Over one third of these epi-TSGs have been reported to carry potential tumor suppression functions. The negative correlations between the expression levels and methylation levels of these genes are validated on external independent datasets. We further find that the expression profiling of these genes is a robust predictive signature for Gleason scores, with the AUC statistic ranging from 0.75 to 0.79. The identified signature also shows prediction strength for tumor progression stages, biochemical recurrences and metastasis events. CONCLUSIONS:We propose a novel method for pinpointing candidate epi-TSGs in PCa. The expression profiling of the identified epi-TSGs demonstrates significant prediction strength for tumor progression. IMPACT:The proposed epi-TSGs identification method can be adapted to other cancer types beyond PCa. The identified clinically-significant epi-TSGs would shed light on the carcinogenesis of prostate adenocarcinomas.","Zhang W
Flemington EK
Deng HW
Zhang K
","(PMID:30262601
)",Epigenetically silenced candidate tumor suppressor genes in prostate cancer: identified by modelling methylation stratification and applied to progression prediction.,https://europepmc.org/abstract/MED/30262601%0A
"<label>BACKGROUND</label>Despite the general success of total knee arthroplasty (TKA) regarding patient-reported outcome measures, studies investigating gait function have shown diverse functional outcomes. Mobile sensor-based systems have recently been employed for accurate clinical gait assessments, as they allow a better integration of gait analysis into clinical routines as compared to laboratory based systems.<label>RESEARCH QUESTION</label>In this study, we sought to examine whether an accurate assessment of gait function of knee osteoarthritis patients with respect to surgery outcome evaluation after TKA using a mobile sensor-based gait analysis system is possible.<label>METHODS</label>A foot-worn sensor-based system was used to assess spatio-temporal gait parameters of 24 knee osteoarthritis patients one day before and one year after TKA, and in comparison to matched control participants. Patients were clustered into positive and negative responder groups using a heuristic approach regarding improvements in gait function. Machine learning was used to predict surgery outcome based on pre-operative gait parameters.<label>RESULTS</label>Gait function differed significantly between controls and patients. Patient-reported outcome measures improved significantly after surgery, but no significant global gait parameter difference was observed between pre- and post-operative status. However, the responder groups could be correctly predicted with an accuracy of up to 89% using pre-operative gait parameters. Patients exhibiting high pre-operative gait function were more likely to experience a functional decrease after surgery. Important gait parameters for the discrimination were stride time and stride length.<label>SIGNIFICANCE</label>The early identification of post-surgical functional outcomes of patients is of great importance to better inform patients pre-operatively regarding surgery success and to improve post-surgical management.","Kluge F
Hannink J
Pasluosta C
Klucken J
Gaßner H
Gelse K
Eskofier BM
Krinner S
","(PMID:30199778
)",Pre-operative sensor-based gait parameters predict functional outcome after total knee arthroplasty.,https://europepmc.org/abstract/MED/30199778%0A
"This article describes the data for examining the influence of government expenditure and revenue on Nigerian economic growth. Data were extracted from the World Bank database and Central Bank of Nigeria (CBN) Statistical bulletin. The data are available with this article. The data is related to the research article ""Newly proposed estimator for ridge parameter: an application to the Nigerian economy"" (Lukman and Arowolo, 2018) but not discussed in detail. This data article will assist economists in identifying factors that will affect the economy of a country, especially in the African region.","Lukman AF
Adebimpe O
Onate CA
Ogundokun RO
Gbadamosi B
O Oluwayemi M
","(PMID:30263924
 PMCID:PMC6157293)","Data on expenditure, revenue, and economic growth in Nigeria.",https://europepmc.org/abstract/MED/30263924%0A
"The impact of liquid droplets on solid surfaces at conditions inducing cavitation inside their volume has rarely been addressed in the literature. A review is conducted on relevant studies, aiming to highlight the differences from non-cavitating impact cases. Focus is placed on the numerical models suitable for the simulation of droplet impact at such conditions. Further insight is given from the development of a purpose-built compressible two-phase flow solver that incorporates a phase-change model suitable for cavitation formation and collapse; thermodynamic closure is based on a barotropic Equation of State (EoS) representing the density and speed of sound of the co-existing liquid, gas and vapour phases as well as liquid-vapour mixture. To overcome the known problem of spurious oscillations occurring at the phase boundaries due to the rapid change in the acoustic impedance, a new hybrid numerical flux discretization scheme is proposed, based on approximate Riemann solvers; this is found to offer numerical stability and has allowed for simulations of cavitation formation during drop impact to be presented for the first time. Following a thorough justification of the validity of the model assumptions adopted for the cases of interest, numerical simulations are firstly compared against the Riemann problem, for which the exact solution has been derived for two materials with the same velocity and pressure fields. The model is validated against the single experimental data set available in the literature for a 2-D planar drop impact case. The results are found in good agreement against these data that depict the evolution of both the shock wave generated upon impact and the rarefaction waves, which are also captured reasonably well. Moreover, the location of cavitation formation inside the drop and the areas of possible erosion sites that may develop on the solid surface, are also well captured by the model. Following model validation, numerical experiments have examined the effect of impact conditions on the process, utilizing both planar and 2-D axisymmetric simulations. It is found that the absence of air between the drop and the wall at the initial configuration can generate cavitation regimes closer to the wall surface, which significantly increase the pressures induced on the solid wall surface, even for much lower impact velocities. A summary highlighting the open questions still remaining on the subject is given at the end.","Kyriazis N
Koukouvinis P
Gavaises M
","(PMID:30195460
)",Modelling cavitation during drop impact on solid surfaces.,https://europepmc.org/abstract/MED/30195460%0A
"Digital game-based learning (DGBL) is being used increasingly as an alternative learning tool to teach science in further and higher education. A variety of digital game formats currently exist for science learning, alongside diverse methods for their implementation and evaluation. This paper aims to provide a broad summary of the field by discussing the current platforms for DGBL and examples of games played on them. These include gamified simulations and traditional digital games delivered through personal computer and online software; mobile games delivered through downloaded applications for devices such as tablets and mobile phones; and educational modifications of commercial games, known amongst gamers as 'mods'. To conclude the summary, the paper discusses the current challenges and barriers associated with DGBL in further and higher science education, and potential strategies researchers may consider to overcome them.","Brown CL
Comunale MA
Wigdahl B
Urdaneta-Hartmann S
","(PMID:30260380
 PMCID:PMC6203454)",Current climate for digital game-based learning of science in further and higher education.,https://europepmc.org/abstract/MED/30260380%0A
"The Central Asian Kyrgyz highland population provides a unique opportunity to address genetic diversity and understand the genetic mechanisms underlying high-altitude pulmonary hypertension (HAPH). Although a significant fraction of the population is unaffected, there are susceptible individuals who display HAPH in the absence of any lung, cardiac or hematologic disease. We report herein the analysis of the whole-genome sequencing of healthy individuals compared with HAPH patients and other controls (total n = 33). Genome scans reveal selection signals in various regions, encompassing multiple genes from the first whole-genome sequences focusing on HAPH. We show here evidence of three candidate genes MTMR4, TMOD3 and VCAM1 that are functionally associated with well-known molecular and pathophysiological processes and which likely lead to HAPH in this population. These processes are (a) dysfunctional BMP signaling, (b) disrupted tissue repair processes and (c) abnormal endothelial cell function. Whole-genome sequence of well-characterized patients and controls and using multiple statistical tools uncovered novel candidate genes that belong to pathways central to the pathogenesis of HAPH. These studies on high-altitude human populations are pertinent to the understanding of sea level diseases involving hypoxia as a main element of their pathophysiology.","Iranmehr A
Stobdan T
Zhou D
Poulsen O
Strohl KP
Aldashev A
Telenti A
Wong EHM
Kirkness EF
Venter JC
Bafna V
Haddad GG
","(PMID:30254217
)",Novel insight into the genetic basis of high-altitude pulmonary hypertension in Kyrgyz highlanders.,https://europepmc.org/abstract/MED/30254217%0A
"Personalized learning refers to instruction in which the pace of learning and the instructional approach are optimized for the needs of each learner. With the latest advances in information technology and data science, personalized learning is becoming possible for anyone with a personal computer, supported by a data-driven recommendation system that automatically schedules the learning sequence. The engine of such a recommendation system is a recommendation strategy that, based on data from other learners and the performance of the current learner, recommends suitable learning materials to optimize certain learning outcomes. A powerful engine achieves a balance between making the best possible recommendations based on the current knowledge and exploring new learning trajectories that may potentially pay off. Building such an engine is a challenging task. We formulate this problem within the Markov decision framework and propose a reinforcement learning approach to solving the problem.","Tang X
Chen Y
Li X
Liu J
Ying Z
","(PMID:30277574
)",A reinforcement learning approach to personalized learning recommendation systems.,https://europepmc.org/abstract/MED/30277574%0A
"Cardiomyocytes derived from human pluripotent stem cells are a promising tool for disease modeling, drug compound testing, and cardiac toxicity screening. Bio-image segmentation is a prerequisite step in cardiomyocyte image analysis by digital holography (DH) in microscopic configuration and has provided satisfactory results. In this study, we quantified multiple cardiac cells from segmented 3-dimensional DH images at the single-cell level and measured multiple parameters describing the beating profile of each individual cell. The beating profile is extracted by monitoring dry-mass distribution during the mechanical contraction-relaxation activity caused by cardiac action potential. We present a robust two-step segmentation method for cardiomyocyte low-contrast image segmentation based on region and edge information. The segmented single-cell contains mostly the nucleus of the cell since it is the best part of the cardiac cell, which can be perfectly segmented. Clustering accuracy was assessed by a silhouette index evaluation for k-means clustering and the Dice similarity coefficient (DSC) of the final segmented image. 3D representation of single of cardiomyocytes. The cell contains mostly the nucleus section and a small area of cytoplasm.","Moon I
Jaferzadeh K
Ahmadzadeh E
Javidi B
","(PMID:30027630
)",Automated quantitative analysis of multiple cardiomyocytes at the single-cell level with three-dimensional holographic imaging informatics.,https://europepmc.org/abstract/MED/30027630%0A
"Public sector organizations are increasingly interested in using data science and artificial intelligence capabilities to deliver policy and generate efficiencies in high-uncertainty environments. The long-term success of data science and artificial intelligence (AI) in the public sector relies on effectively embedding it into delivery solutions for policy implementation. However, governments cannot do this integration of AI into public service delivery on their own. The UK Government Industrial Strategy is clear that delivering on the AI grand challenge requires collaboration between universities and the public and private sectors. This cross-sectoral collaborative approach is the norm in applied AI centres of excellence around the world. Despite their popularity, cross-sector collaborations entail serious management challenges that hinder their success. In this article we discuss the opportunities for and challenges of AI for the public sector. Finally, we propose a series of strategies to successfully manage these cross-sectoral collaborations.This article is part of a discussion meeting issue 'The growing ubiquity of algorithms in society: implications, impacts and innovations'.","Mikhaylov SJ
Esteve M
Campion A
","(PMID:30082303
)",Artificial intelligence for the public sector: opportunities and challenges of cross-sector collaboration.,https://europepmc.org/abstract/MED/30082303%0A
"Recent studies indicate that the gut microbiome is partially heritable, motivating the need to investigate microbiome-host genome associations via microbial genome-wide association studies (mGWAS). Existing mGWAS demonstrate that microbiome-host genotype associations are typically weak and are spread across multiple variants, similar to associations often observed in genome-wide association studies (GWAS) of complex traits. Here we reconsider mGWAS by viewing them through the lens of GWAS, and demonstrate that there are striking similarities between the challenges and pitfalls faced by the two study designs. We further advocate the mGWAS community to adopt three key lessons learned over the history of GWAS: firstly, adopting uniform data and reporting formats to facilitate replication and meta-analysis efforts; secondly, enforcing stringent statistical criteria to reduce the number of false positive findings; and thirdly, considering the microbiome and the host genome as distinct entities, rather than studying different taxa and single nucleotide polymorphism (SNPs) separately. Finally, we anticipate that mGWAS sample sizes will have to increase by orders of magnitude to reproducibly associate the host genome with the gut microbiome.","Weissbrod O
Rothschild D
Barkan E
Segal E
","(PMID:29909175
)",Host genetics and microbiome associations through the lens of genome wide association studies.,https://europepmc.org/abstract/MED/29909175%0A
"An open-tubular capillary electrochromatography method has been developed for the determination of binding constants between β2 -adrenergic receptor (β2 -AR) and seven drugs. β2 -AR was oriented immobilized onto one part of inner surface of capillary via microwave-assisted technical synthesis. According to the linear relationship between coating length and the apparent mobility of analyte, the binding constant (Kb ) can be obtained by related theories and equations. The order of Kb values between drugs such as adrenaline hydrochloride, norepinephrine bitartrate, and propranolol hydrochloride with β2 -AR is well consistent with that reported in the literature. By the method, Kb values between four extracts of Radix Paeoniae Rubra and β2 -AR were also successfully obtained. Subsequently, computer models were applied to interpret the CEC experiments. And the results proved to be in good agreement with the method. The work, herein, demonstrates the potential of the method in drug-receptor affinity interactions evaluation and screening of lead compounds from natural sources.","Liu C
Zhang X
Jing H
Zhang J
Miao Y
Zhai X
Chen S
","(PMID:30325031
)",Using open-tubular capillary electrochromatography with part-coating column for binding constants determination of β2 -adrenergic receptor with seven drugs.,https://europepmc.org/abstract/MED/30325031%0A
"This paper aims to develop a method for laser speckle image segmentation of tooth surfaces for diagnosis of early stages caries. The method, applied directly to a raw image obtained by digital photography, is based on the difference between the speckle pattern of a carious lesion tooth surface area and that of a sound area. Each image is divided into blocks which are identified in a working matrix by their χ2 distance between block histograms of the analyzed image and the reference histograms previously obtained by K-means from healthy (h_Sound) and lesioned (h_Decay) areas, separately. If the χ2 distance between a block histogram and h_Sound is greater than the distance to h_Decay, this block is marked as decayed. The experiments showed that the method can provide effective segmentation for initial lesions. We used 64 images to test the algorithm and we achieved 100% accuracy in segmentation. Differences between the speckle pattern of a sound tooth surface region and a carious region, even in the early stage, can be evidenced by the χ2 distance between histograms. This method proves to be more effective for segmenting the laser speckle image, which enhances the contrast between sound and lesioned tissues. The results were obtained with low computational cost. The method has the potential for early diagnosis in a clinical environment, through the development of low-cost portable equipment.","Gavinho LG
Araujo SA
Bussadori SK
Silva JVP
Deana AM
","(PMID:29728943
)",Detection of white spot lesions by segmenting laser speckle images using computer vision methods.,https://europepmc.org/abstract/MED/29728943%0A
"Anaphylaxis is a life-threatening allergic reaction that occurs suddenly after contact with an allergen. Epidemiological studies about anaphylaxis are very important in planning and evaluating new strategies that prevent this reaction, but also in providing a guide to the treatment of patients who have just suffered an anaphylactic reaction. Electronic Medical Records (EMR) are one of the most effective and richest sources for the epidemiology of anaphylaxis, because they provide a low-cost way of accessing rich longitudinal data on large populations. However, a negative aspect is that researchers have to manually review a huge amount of information, which is a very costly and highly time consuming task. Therefore, our goal is to explore different machine learning techniques to process Big Data EMR, lessening the needed efforts for performing epidemiological studies about anaphylaxis. In particular, we aim to study the incidence of anaphylaxis by the automatic classification of EMR. To do this, we employ the most widely used and efficient classifiers in text classification and compare different document representations, which range from well-known methods such as Bag Of Words (BoW) to more recent ones based on word embedding models, such as a simple average of word embeddings or a bag of centroids of word embeddings. Because the identification of anaphylaxis cases in EMR is a class-imbalanced problem (less than 1% describe anaphylaxis cases), we employ a novel undersampling technique based on clustering to balance our dataset. In addition to classical machine learning algorithms, we also use a Convolutional Neural Network (CNN) to classify our dataset. In general, experiments show that the most classifiers and representations are effective (F1 above 90%). Logistic Regression, Linear SVM, Multilayer Perceptron and Random Forest achieve an F1 around 95%, however linear methods have considerably lower training times. CNN provides slightly better performance (F1 = 95.6%).","Segura-Bedmar I
Colón-Ruíz C
Tejedor-Alonso MÁ
Moro-Moro M
","(PMID:30266231
)",Predicting of anaphylaxis in big data EMR by exploring machine learning approaches.,https://europepmc.org/abstract/MED/30266231%0A
"Hepatic encephalopathy (HE), as a complication of cirrhosis, is a serious brain disease, which may lead to death. Accurate diagnosis of HE and its intermediate stage, i.e., minimal HE (MHE), is very important for possibly early diagnosis and treatment. Brain connectivity network, as a simple representation of brain interaction, has been widely used for the brain disease (e.g., HE and MHE) analysis. However, those studies mainly focus on finding disease-related abnormal connectivity between brain regions, although a large number of studies have indicated that some brain diseases are usually related to local structure of brain connectivity network (i.e., subnetwork), rather than solely on some single brain regions or connectivities. Also, mining such disease-related subnetwork is a challenging task because of the complexity of brain network. To address this problem, we proposed a novel frequent-subnetwork-based method to mine disease-related subnetworks for MHE classification. Specifically, we first mine frequent subnetworks from both groups, i.e., MHE patients and non-HE (NHE) patients, respectively. Then we used the graph-kernel based method to select the most discriminative subnetworks for subsequent classification. We evaluate our proposed method on a MHE dataset with 77 cirrhosis patients, including 38 MHE patients and 39 NHE patients. The results demonstrate that our proposed method can not only obtain the improved classification performance in comparison with state-of-the-art network-based methods, but also identify disease-related subnetworks which can help us better understand the pathology of the brain diseases.","Zhang D
Tu L
Zhang LJ
Jie B
Lu GM
","(PMID:28717971
)",Subnetwork mining on functional connectivity network for classification of minimal hepatic encephalopathy.,https://europepmc.org/abstract/MED/28717971%0A
"Understanding biological response to stimuli requires identifying mechanisms that coordinate changes across pathways. One of the promises of multi-omics studies is achieving this level of insight by simultaneously identifying different levels of regulation. However, computational approaches to integrate multiple types of data are lacking. An effective systems biology approach would be one that uses statistical methods to detect signatures of relevant network motifs and then builds metabolic circuits from these components to model shifting regulatory dynamics. For example, transcriptome and metabolome data complement one another in terms of their ability to describe shifts in physiology. Here, we extend a previously described linear-modeling based method used to identify single nucleotide polymorphisms (SNPs) associated with metabolic changes. We apply this strategy to link changes in sulfur, amino acid and lipid production under heat stress by relating ratios of compounds to potential precursors and regulators. This approach provides integration of multi-omics data to link previously described, discrete units of regulation into functional pathways and identifies novel biology relevant to the heat stress response, in addition to generating hypotheses.","Hubbard AH
Zhang X
Jastrebski S
Lamont SJ
Singh A
Schmidt CJ
","(PMID:30365526
 PMCID:PMC6203350)",Identifying mechanisms of regulation to model carbon flux during heat stress and generate testable hypotheses.,https://europepmc.org/abstract/MED/30365526%0A
"BACKGROUND AND OBJECTIVE:The detection of optic nerve head (ONH) in retinal fundus images plays a key role in identifying Diabetic Retinopathy (DR) as well as other abnormal conditions in eye examinations. This paper presents a method and its associated software towards the development of an Android smartphone app based on a previously developed ONH detection algorithm. The development of this app and the use of the d-Eye lens which can be snapped onto a smartphone provide a mobile and cost-effective computer-aided diagnosis (CAD) system in ophthalmology. In particular, this CAD system would allow eye examination to be conducted in remote locations with limited access to clinical facilities. METHODS:A pre-processing step is first carried out to enable the ONH detection on the smartphone platform. Then, the optimization steps taken to run the algorithm in a computationally and memory efficient manner on the smartphone platform is discussed. RESULTS:The smartphone code of the ONH detection algorithm was applied to the STARE and DRIVE databases resulting in about 96% and 100% detection rates, respectively, with an average execution time of about 2 s and 1.3 s. In addition, two other databases captured by the d-Eye and iExaminer snap-on lenses for smartphones were considered resulting in about 93% and 91% detection rates, respectively, with an average execution time of about 2.7 s and 2.2 s, respectively.","Elloumi Y
Akil M
Kehtarnavaz N
","(PMID:29903480
)",A mobile computer aided system for optic nerve head detection.,https://europepmc.org/abstract/MED/29903480%0A
No abstract provided.,"Christen P
","(PMID:29767551
)",Moving beyond the genome with computer modeling.,https://europepmc.org/abstract/MED/29767551%0A
"A novel computer-aided detection method based on deep learning framework was proposed to detect small intestinal ulcer and erosion in wireless capsule endoscopy (WCE) images. To the best of our knowledge, this is the first time that deep learning framework has been exploited on automated ulcer and erosion detection in WCE images. Compared with the traditional detection method, deep learning framework can produce image features directly from the data and increase recognition accuracy as well as efficiency, especially for big data. The developed method included image cropping and image compression. The AlexNet convolutional neural network was trained to the database with tens of thousands of WCE images to differentiate lesion and normal tissue. The results of ulcer and erosion detection reached a high accuracy of 95.16% and 95.34%, sensitivity of 96.80% and 93.67%, and specificity of 94.79% and 95.98%, correspondingly. The area under the receiver operating characteristic curve was over 0.98 in both of the networks. The promising results indicate that the proposed method has the potential to work in tandem with doctors to efficiently detect intestinal ulcer and erosion.","Fan S
Xu L
Fan Y
Wei K
Li L
","(PMID:30033931
)",Computer-aided detection of small intestinal ulcer and erosion in wireless capsule endoscopy images.,https://europepmc.org/abstract/MED/30033931%0A
A correction to this article has been published and is linked from the HTML and PDF versions of this paper. The error has been fixed in the paper.,"Amano SI
Ogawa KI
Miyake Y
","(PMID:30127370
 PMCID:PMC6102206)",Author Correction: Node property of weighted networks considering connectability to nodes within two degrees of separation.,https://europepmc.org/abstract/MED/30127370%0A
"Recently, in diffusion magnetic resonance imaging, the reconstruction and three-dimensional rendering of white matter pathways have been introduced to clinical routine protocols. In a number of clinical situations, for example the preoperative analysis of vascular pathologies, the assessment of spatial relations between vascular structures and nearby fiber pathways is of vital interest for treatment planning. In this paper, we present an approach to the integrated vessel and fiber visualization, based on a novel vascular contrast enhancement operator for Magnetic Resonance Angiography (MRA) datasets. We propose a 3D dynamic programming method, allowing contrast enhancement of vascular structures and suppression of partial voluming effects at vessel borders. This makes it easier to visualize vascular structures by realtime volume rendering with surface shading. In contrast to maximum intensity projection, the method provides better depth cues and allows for easier spatial orientation. The integration of tractography-generated fibers as streamlines or streamtubes with correct visibility computation is performed by a combined volume and geometry renderer. In situations where tractography fails to provide reliable results, we use a line integral convolution method to assess white matter structures. In this manner, the spatial relations of vessels to fiber structures can be depicted by three-dimensional visualizations. We evaluate our approach with clinical data from patients with arteriovenous malformations, stenoses, aneurysms, and from healthy volunteers.","Ehricke HH
Hauser TK
Nägele T
Schult T
Klose U
","(PMID:30286332
)",Magnetic resonance angiography contrast enhancement and combined 3D visualization of cerebral vasculature and white matter pathways.,https://europepmc.org/abstract/MED/30286332%0A
"Moonlighting proteins is an emerging concept for considering protein functions, which indicate proteins with two or more independent and distinct functions. An increasing number of moonlighting proteins have been reported in the past years; however, a systematic study of the topic has been hindered because the secondary functions of proteins are usually found serendipitously by experiments. Toward systematic identification and study of moonlighting proteins, computational methods for identifying moonlighting proteins from several different information sources, database entries, literature, and large-scale omics data have been developed. In this study, an overview for finding moonlighting proteins is discussed. Then, the literature-mining method, DextMP, is applied to find new moonlighting proteins in three genomes, Arabidopsis thaliana, Caenorhabditis elegans, and Drosophila melanogaster. Potential moonlighting proteins identified by DextMP are further examined by a two-step manual literature checking procedure, which finally yielded 13 new moonlighting proteins. Identified moonlighting proteins are categorized into two classes based on the clarity of the distinctness of two functions of the proteins. A few cases of the identified moonlighting proteins are described in detail. Further direction for improving the DextMP algorithm is also discussed.","Jain A
Gali H
Kihara D
","(PMID:30260564
)",Identification of Moonlighting Proteins in Genomes Using Text Mining Techniques.,https://europepmc.org/abstract/MED/30260564%0A
"From a therapeutic viewpoint, understanding how drugs bind and regulate the functions of their target proteins to protect against disease is crucial. The identification of drug targets plays a significant role in drug discovery and in studying the mechanisms of diseases. The development of methods to identify drug targets has become a popular issue in this field of research. Originally, scientists used biological experiments to identify drug targets. However, recently, an increasing number of scientists use computational methods to identify drug targets. Although thousands of drug targets are estimated to exist, only hundreds of these potential targets have been verified. Therefore, in this paper, we systematically review the recent work on identifying drug targets.","Hu Y
Zhao T
Zhang N
Zhang Y
Cheng L
","(PMID:30251599
)",A Review of Recent Advances and Research on Drug Target Identification Methods.,https://europepmc.org/abstract/MED/30251599%0A
"Splitting the rouleaux RBCs from single RBCs and its further subdivision is a challenging area in computer-assisted diagnosis of blood. This phenomenon is applied in complete blood count, anemia, leukemia, and malaria tests. Several automated techniques are reported in the state of art for this task but face either under or over splitting problems. The current research presents a novel approach to split Rouleaux red blood cells (chains of RBCs) precisely, which are frequently observed in the thin blood smear images. Accordingly, this research address the rouleaux splitting problem in a realistic, efficient and automated way by considering the distance transform and local maxima of the rouleaux RBCs. Rouleaux RBCs are splitted by taking their local maxima as the centres to draw circles by mid-point circle algorithm. The resulting circles are further mapped with single RBC in Rouleaux to preserve its original shape. The results of the proposed approach on standard data set are presented and analyzed statistically by achieving an average recall of 0.059, an average precision of 0.067 and F-measure 0.063 are achieved through ground truth with visual inspection.","Rehman A
Abbas N
Saba T
Mahmood T
Kolivand H
","(PMID:29637666
)","Rouleaux red blood cells splitting in microscopic thin blood smear images via local maxima, circles drawing, and mapping with original RBCs.",https://europepmc.org/abstract/MED/29637666%0A
"The aim of this review was to summarize major topics in artificial intelligence (AI), including their applications and limitations in surgery. This paper reviews the key capabilities of AI to help surgeons understand and critically evaluate new AI applications and to contribute to new developments.AI is composed of various subfields that each provide potential solutions to clinical problems. Each of the core subfields of AI reviewed in this piece has also been used in other industries such as the autonomous car, social networks, and deep learning computers.A review of AI papers across computer science, statistics, and medical sources was conducted to identify key concepts and techniques within AI that are driving innovation across industries, including surgery. Limitations and challenges of working with AI were also reviewed.Four main subfields of AI were defined: (1) machine learning, (2) artificial neural networks, (3) natural language processing, and (4) computer vision. Their current and future applications to surgical practice were introduced, including big data analytics and clinical decision support systems. The implications of AI for surgeons and the role of surgeons in advancing the technology to optimize clinical effectiveness were discussed.Surgeons are well positioned to help integrate AI into modern practice. Surgeons should partner with data scientists to capture data across phases of care and to provide clinical context, for AI has the potential to revolutionize the way surgery is taught and practiced with the promise of a future optimized for the highest quality patient care.","Hashimoto DA
Rosman G
Rus D
Meireles OR
","(PMID:29389679
)",Artificial Intelligence in Surgery: Promises and Perils.,https://europepmc.org/abstract/MED/29389679%0A
"Learning usually improves the accuracy of beliefs through the accumulation of experience. But are there limits to learning that prevent us from accurately understanding our world? In this article we investigate the concept of a ""learning trap""-the formation of a stable false belief even with extensive experience. Our review highlights how these traps develop through the interaction of learning and decision making in unknown environments. We further document a particularly pernicious learning trap driven by selective attention, a mechanism often assumed to facilitate learning in complex environments. Using computer simulation, we demonstrate the key attributes of the agent and environment that lead to this new type of learning trap. Then, in a series of experiments we present evidence that people robustly fall into this trap, even in the presence of various interventions predicted to meliorate it. These results highlight a fundamental limit to learning and adaptive behavior that impacts individuals, organizations, animals, and machines. (PsycINFO Database Record (c) 2018 APA, all rights reserved).","Rich AS
Gureckis TM
","(PMID:30247058
)","The limits of learning: Exploration, generalization, and the development of learning traps.",https://europepmc.org/abstract/MED/30247058%0A
"Nanoparticles (NPs) grafted with polymer chains prepared via a grafting-from strategy are studied through coarse-grained molecular dynamics simulations combined with our stochastic reaction model. A system involving multiple individual NPs, with grafting-from processes for all the NPs induced simultaneously, is simulated, so that chain growth competition on the same NP, as well as between neighbouring NPs, are both naturally considered. Our results imply that there should be an optimized range of NP sizes, as compared to monomer size, in which initiator sites are most easily induced. Besides, when the initiator density is high, a shielding effect from the sparse long chains on the most short chains or initiators evidently yields an extremely unbiased distribution of chains. We also adopt a representative polymer-tethered NP prepared via a grafting-from strategy to study the potential of mean force between NPs, so that the dispersion and stabilization abilities of such polymer-grafted NPs in a polymer matrix can be generally predicted during the preparation of polymer nanocomposite materials. Our study helps to elucidate the cause of chain dispersity during the grafting-from process and could act as a guide for better design and to improve the performance of polymer nanocomposites.","Li L
Han C
Xu D
Xing JY
Xue YH
Liu H
","(PMID:29946599
)",Polymer-grafted nanoparticles prepared via a grafting-from strategy: a computer simulation study.,https://europepmc.org/abstract/MED/29946599%0A
"OBJECTIVE:To assess the effect of short message service (SMS) communication on facility delivery, exclusive breastfeeding (EBF), and contraceptive use. DESIGN:Mobile WACh was a three-arm unblinded individually randomised controlled trial. SETTING:A public sector maternal child health (MCH) clinic in Nairobi, Kenya. POPULATION:Three hundred women attending antenatal care were randomised, 100 to each arm, and followed for 24 weeks postpartum. Pregnant women, at least 14 years old with access to a mobile phone and able to read SMS were eligible for participation. METHODS:Women were randomised (1:1:1) to receive one-way SMS versus two-way SMS with a nurse versus control. Weekly SMS content was tailored for maternal characteristics and pregnancy or postpartum timing. MAIN OUTCOME MEASURES:Facility delivery, EBF, and contraceptive use were compared separately between each intervention arm and the control arm by Kaplan-Meier analysis and chi-square tests using intent-to-treat analyses. RESULTS:The overall facility delivery rate was high (98%) and did not differ by arm. Compared with controls, probability of EBF was higher in the one-way SMS arm at 10 and 16 weeks, and in the two-way SMS arm at 10, 16, and 24 weeks (P < 0.005 for all). Contraceptive use was significantly higher in both intervention arms by 16 weeks (one-way SMS: 72% and two-way SMS: 73%; P = 0.03 and P = 0.02 versus 57% control, respectively); however, this difference was not significant when correcting for multiple comparisons. CONCLUSION:One-way and two-way SMS improved EBF practices and early contraceptive use. Two-way SMS had an added benefit on sustained EBF, providing evidence that SMS messaging influences uptake of interventions that improve maternal and neonatal health. SOURCE OF FUNDING:Funding was provided by the National Institutes of Health (K12HD001264 to JAU, R01HD080460, K24HD054314 to GJS, and K01AI116298 to ALD), the National Science Foundation (Graduate Research Fellowship to TP and BD), as well as the University of Washington Global Center for Integrated Health of Women Adolescents and Children (Global WACh). TWEETABLE ABSTRACT:The Mobile WACh RCT demonstrates that SMS improved practice of exclusive breastfeeding and early postpartum contraception.","Unger JA
Ronen K
Perrier T
DeRenzi B
Slyker J
Drake AL
Mogaka D
Kinuthia J
John-Stewart G
","(PMID:29924912
)",Short message service communication improves exclusive breastfeeding and early postpartum contraception in a low- to middle-income country setting: a randomised trial.,https://europepmc.org/abstract/MED/29924912%0A
[This corrects the article DOI: 10.1155/2017/6201797.].,"Rola P
Doroszko A
Szahidewicz-Krupska E
Rola P
Dobrowolski P
Skomro R
Szymczyszyn A
Mazur G
Derkacz A
","(PMID:30210651
 PMCID:PMC6120257)","Corrigendum to ""Low-Level Laser Irradiation Exerts Antiaggregative Effect on Human Platelets Independently on the Nitric Oxide Metabolism and Release of Platelet Activation Markers"".",https://europepmc.org/abstract/MED/30210651%0A
"This study describes a dynamic large-scale process fault detection algorithm based on multi-block slow feature analysis by taking advantages of both multi-block algorithms in highlighting the local information and slow feature analysis in extracting the different dynamics of process data. A mutual information-based relevance matrix is first calculated to measure the correlation between any two variables, and then K-means clustering is used to cluster the original variables into several blocks by gathering the variables with similar relevance vectors into the same block. Slow feature analysis is applied in each block. A support vector data description is utilized to give a final decision. The proposed algorithm is tested with a well-known Tennessee Eastman (TE) process. The fault detection results show the efficiency and the superiority of the proposed method as compared to other related methods.","Huang J
Ersoy OK
Yan X
","(PMID:30389247
)",Fault detection in dynamic plant-wide process by multi-block slow feature analysis and support vector data description.,https://europepmc.org/abstract/MED/30389247%0A
"BACKGROUND:Respiratory-induced motion (RIM) causes uncertainties in localizing hepatic lesions, which could lead to inaccurate targeting during interventions. One approach to mitigate the problem is respiratory motion estimation (RME), in which the liver motion is estimated by measuring external signals called surrogates. METHODS:A learning-based approach has been developed and validated to estimate the RIM of hepatic lesions. External markers placed on the human's abdomen were chosen as surrogates. Accordingly, appropriate motion models (multivariate, Ridge and Lasso regression models) were designed to correlate the liver motion with the abdominal motion, and trained to estimate the superior-inferior (SI) motion of the liver. Three subjects volunteered for 6 sessions of such that liver images acquired by magnetic resonance imaging (MRI) were recorded alongside camera-tracked external markers. RESULTS AND CONCLUSIONS:The proposed machine learning approach was validated in MRI on human subjects and the results show that the approach could estimate the respiratory-induced SI motion of the liver with a mean absolute error (MAE) accuracy below 2 mm.","Fahmi S
Simonis FFJ
Abayazid M
","(PMID:30112864
)",Respiratory motion estimation of the liver with abdominal motion as a surrogate.,https://europepmc.org/abstract/MED/30112864%0A
"Probe-based confocal laser endomicroscopy (pCLE) is a subcellular in vivo imaging technique capable of producing images that enable diagnosis of malign structural modifications in epithelial tissue. Images acquired with pCLE are, however, often tainted by significant artifacts that impair diagnosis. This is especially detrimental for automated image analysis, which is why said images are often excluded from recognition pipelines.We present an approach for the automatic detection of motion artifacts in pCLE images and apply this methodology to a data set of 15 thousand images of epithelial tissue acquired in the oral cavity and the vocal folds. The approach is based on transfer learning from intermediate endpoints within a pre-trained Inception v3 network with tailored preprocessing. For detection within the non-rectangular pCLE images, we perform pooling within the activation maps of the network and evaluate this at different network depths.We achieved area under the ROC curve values of 0.92 with the proposed method, compared to 0.80 for the best feature-based machine learning approach. Our overall accuracy with the presented approach is 94.8%.Over traditional machine learning approaches with state-of-the-art features, we achieved significantly improved overall performance.","Aubreville M
Stoeve M
Oetter N
Goncalves M
Knipfer C
Neumann H
Bohr C
Stelzle F
Maier A
","(PMID:30078151
)",Deep learning-based detection of motion artifacts in probe-based confocal laser endomicroscopy images.,https://europepmc.org/abstract/MED/30078151%0A
No abstract provided.,"El Naqa I
Pandey G
Aerts H
Chien JT
Andreassen CN
Niemierko A
Ten Haken RK
","(PMID:30353869
)",Radiation Therapy Outcomes Models in the Era of Radiomics and Radiogenomics: Uncertainties and Validation.,https://europepmc.org/abstract/MED/30353869%0A
"Many US immigrant populations develop metabolic diseases post immigration, but the causes are not well understood. Although the microbiome plays a role in metabolic disease, there have been no studies measuring the effects of US immigration on the gut microbiome. We collected stool, dietary recalls, and anthropometrics from 514 Hmong and Karen individuals living in Thailand and the United States, including first- and second-generation immigrants and 19 Karen individuals sampled before and after immigration, as well as from 36 US-born European American individuals. Using 16S and deep shotgun metagenomic DNA sequencing, we found that migration from a non-Western country to the United States is associated with immediate loss of gut microbiome diversity and function in which US-associated strains and functions displace native strains and functions. These effects increase with duration of US residence and are compounded by obesity and across generations.","Vangay P
Johnson AJ
Ward TL
Al-Ghalith GA
Shields-Cutler RR
Hillmann BM
Lucas SK
Beura LK
Thompson EA
Till LM
Batres R
Paw B
Pergament SL
Saenyakul P
Xiong M
Kim AD
Kim G
Masopust D
Martens EC
Angkurawaranon C
McGready R
Kashyap PC
Culhane-Pera KA
Knights D
","(PMID:30388453
)",US Immigration Westernizes the Human Gut Microbiome.,https://europepmc.org/abstract/MED/30388453%0A
"According to the analysis of investigation, there are many problems in the current clinical skills training for medical education, such as large demand, high difficulty and less opportunity. With the development and application of computer network technology, it has provided new directions for the training in the medical field. Using modern management techniques, it has combined computer technology, biochemical science and microbiology principles with traditional clinical medical education experience, which has promoted the development of advanced clinical medicine concepts and skill levels. The combination of distance education and medical education is a process of integrating theoretical knowledge into practice, which not only improve the medical management capabilities of medical staff, but also improve the overall level of clinical skills.","Yu K
Li X
Wang F
Du Y
","(PMID:30229315
)",Research on the Realization of Remote Clinical Skills Training.,https://europepmc.org/abstract/MED/30229315%0A
"The increase in antibiotic-resistant strains of pathogens has created havoc worldwide. These antibiotic-resistant pathogens require potent drugs for their inhibition. Lipopeptides, which are produced as secondary metabolites by many microorganisms, have the ability to act as potent safe drugs. Lipopeptides are amphiphilic molecules containing a lipid chain bound to the peptide. They exhibit broad-spectrum activities against both bacteria and fungi. Other than their antimicrobial properties, they have displayed anti-cancer properties as well, but their mechanism of action is not understood. In silico drug design uses computer simulation to discover and develop new drugs. This technique reduces the need of expensive and tedious lab work and clinical trials, but this method becomes a challenge due to complex structures of lipopeptides. Specific agonists (ligands) must be identified to initiate a physiological response when combined with a receptor (lipopeptide). In silico drug design and homology modeling talks about the interaction between ligands and the binding sites. This review summarizes the mechanism of selected lipopeptides, their respective ligands, and in silico drug design.","Jujjavarapu SE
Dhagat S
","(PMID:29218506
)",In Silico Discovery of Novel Ligands for Antimicrobial Lipopeptides for Computer-Aided Drug Design.,https://europepmc.org/abstract/MED/29218506%0A
"Human infection by Mycobacterium tuberculosis (Mtb) continues to be a global epidemic. Computer-aided drug design (CADD) methods are used to accelerate traditional drug discovery efforts. One noncovalent interaction that is being increasingly identified in biological systems but is neglected in CADD is the anion-π interaction. The study reported herein supports the conclusion that anion-π interactions play a central role in directing the binding of phenyl-diketo acid (PDKA) inhibitors to malate synthase (GlcB), an enzyme required for Mycobacterium tuberculosis virulence. Using density functional theory methods (M06-2X/6-31+G(d)), a GlcB active site template was developed for a predictive model through a comparative analysis of PDKA-bound GlcB crystal structures. The active site model includes the PDKA molecule and the protein determinants of the electrostatic, hydrogen-bonding, and anion-π interactions involved in binding. The predictive model accurately determines the Asp 633-PDKA structural position upon binding and precisely predicts the relative binding enthalpies of a series of 2-ortho halide-PDKAs to GlcB. A screening model was also developed to efficiently assess the propensity of each PDKA analog to participate in an anion-π interaction; this method is in good agreement with both the predictive model and the experimental binding enthalpies for the 2-ortho halide-PDKAs. With the screening and predictive models in hand, we have developed an efficient method for computationally screening and evaluating the binding enthalpy of variously substituted PDKA molecules. This study serves to illustrate the contribution of this overlooked interaction to binding affinity and demonstrates the importance of integrating anion-π interactions into structure-based CADD.","Ellenbarger JF
Krieger IV
Huang HL
Gómez-Coca S
Ioerger TR
Sacchettini JC
Wheeler SE
Dunbar KR
","(PMID:30137983
)",Anion-π Interactions in Computer-Aided Drug Design: Modeling the Inhibition of Malate Synthase by Phenyl-Diketo Acids.,https://europepmc.org/abstract/MED/30137983%0A
"There are three non-mutually-exclusive key strategies evolved by gene pools to cope with fluctuating food resource availability, including evolutionary adaptation, phenotypic plasticity, and migration. We focus primarily on evolutionary adaptation and behavioral plasticity, which is a type of phenotypic plasticity, resulting in life-history changes as ways of dealing with fluctuations in food resource availability. Using EcoSim, a predator-prey individual-based model, we compare individuals with stable food resources with those in environments where there are fluctuating food resources in terms of adaptation through behavioral plasticity and evolution. The purpose of our study is to determine whether evolution and behavioral plasticity truly play a role in adapting to an environment with fluctuating food resources, as well as to determine whether there are specific gene divergences between gene pools in fluctuating food resource environments versus gene pools where food resources are relatively stable. An important result of our study is that individuals in environments that are unstable with respect to food resource availability exhibited significant differences in behaviors versus those in environments with stable food resources. Although behavioral plasticity facilitates a rapid response to unstable food conditions, our study revealed the evolution of perceptual traits such as vision range in reaction to fluctuating food resources, indicating the importance of evolution in adapting to unstable resource environments in the long run. Moreover, using decision trees, we found that there were significant behavioral gene divergences between individuals in environments with fluctuating food resources as opposed to individuals in environments with stable food resources.","Scott R
MacPherson B
Gras R
","(PMID:30243755
)",A comparison of stable and fluctuating resources with respect to evolutionary adaptation and life-history traits using individual-based modeling and machine learning.,https://europepmc.org/abstract/MED/30243755%0A
"The history of influenza in Taiwan can be traced up to the 1918 H1N1 Spanish flu pandemic, followed by several others including the 1957 H2N2, 1968 H3N2, and the 2009 new H1N1. A couple of avian influenza viruses of H5N1 and H7N9 also posed threats to the general public in Taiwan in the two recent decades. Nevertheless, two seasonal influenza A viruses and two lineages of influenza B viruses continue causing annual endemics one after the other, or appearing simultaneously. Their interplay provided interesting evolutionary trajectories for these viruses, allowing us to computationally model their global migrations together with the data collected elsewhere from different geographical locations. An island-wide laboratory-based surveillance network was also established since 2000 for systematically collecting and managing the disease and molecular epidemiology. Experiences learned from this network helped in encountering and managing newly emerging infectious diseases, including the 2003 SARS and 2009 H1N1 outbreaks.","Gong YN
Kuo RL
Chen GW
Shih SR
","(PMID:30348266
 PMCID:PMC6197989)",Centennial review of influenza in Taiwan.,https://europepmc.org/abstract/MED/30348266%0A
"Diagnosis and Prognosis of brain tumour in children is always a critical case. Medulloblastoma is that subtype of brain tumour which occurs most frequently amongst children. Post-operation, the classification of its subtype is most vital for further clinical management. In this paper a novel approach of pathological subtype classification using biological interpretable and computer-aided textural features is forwarded. The classifier for accurate features prediction is built purely on the feature set obtained by segmentation of the ground truth cells from the original histological tissue images, marked by an experienced pathologist. The work is divided into five stages: marking of ground truth, segmentation of ground truth images, feature extraction, feature reduction and finally classification. Kmeans colour segmentation is used to segment out the ground truth cells from histological images. For feature extraction we used morphological, colour and textural features of the cells followed by feature reduction using Principal Component Analysis. Finally both binary and multiclass classification is done using Support Vector Method (SVM). The classification was compared using six different classifiers and performance was evaluated employing five-fold cross-validation technique. The accuracy achieved for binary and multiclass classification before applying PCA were 95.4 and 62.1% and after applying PCA were 100 and 84.9% respectively. The run-time analysis are also shown. Results reveal that this technique of cell level classification can be successfully adopted as architectural view can be confusing. Moreover it conforms substantially to the pathologist's point of view regarding morphological and colour features, with the addition of computer assisted texture feature.","Das D
Mahanta LB
Ahmed S
Baishya BK
Haque I
","(PMID:29974336
)",Study on Contribution of Biological Interpretable and Computer-Aided Features Towards the Classification of Childhood Medulloblastoma Cells.,https://europepmc.org/abstract/MED/29974336%0A
"fMRI data decomposition techniques have advanced significantly from shallow models such as Independent Component Analysis (ICA) and Sparse Coding and Dictionary Learning (SCDL) to deep learning models such Deep Belief Networks (DBN) and Convolutional Autoencoder (DCAE). However, interpretations of those decomposed networks are still open questions due to the lack of functional brain atlases, no correspondence across decomposed or reconstructed networks across different subjects, and significant individual variabilities. Recent studies showed that deep learning, especially deep convolutional neural networks (CNN), has extraordinary ability of accommodating spatial object patterns, e.g., our recent works using 3D CNN for fMRI-derived network classifications achieved high accuracy with a remarkable tolerance for mistakenly labelled training brain networks. However, the training data preparation is one of the biggest obstacles in these supervised deep learning models for functional brain network map recognitions, since manual labelling requires tedious and time-consuming labours which will sometimes even introduce label mistakes. Especially for mapping functional networks in large scale datasets such as hundreds of thousands of brain networks used in this paper, the manual labelling method will become almost infeasible. In response, in this work, we tackled both the network recognition and training data labelling tasks by proposing a new iteratively optimized deep learning CNN (IO-CNN) framework with an automatic weak label initialization, which enables the functional brain networks recognition task to a fully automatic large-scale classification procedure. Our extensive experiments based on ABIDE-II 1099 brains' fMRI data showed the great promise of our IO-CNN framework.","Zhao Y
Ge F
Liu T
","(PMID:29705574
)",Automatic recognition of holistic functional brain networks using iteratively optimized convolutional neural networks (IO-CNN) with weak label initialization.,https://europepmc.org/abstract/MED/29705574%0A
"BACKGROUND:While RNA is often created from linear splicing during transcription, recent studies have found that non-canonical splicing sometimes occurs. Non-canonical splicing joins 3' and 5' and forms the so-called circular RNA. It is now believed that circular RNA plays important biological roles such as affecting susceptibility of some diseases. During the past several years, multiple experimental methods have been developed to enrich circular RNA while degrade linear RNA. Although several useful software tools for circular RNA detection have been developed as well, these tools are based on reads mapping may miss many circular RNA. Also, existing tools are slow for large data due to their dependence on reads mapping. METHOD:In this paper, we present a new computational approach, named CircMarker, based on k-mers rather than reads mapping for circular RNA detection. CircMarker takes advantage of transcriptome annotation files to create the k-mer table for circular RNA detection. RESULTS:Empirical results show that CircMarker outperforms existing tools in circular RNA detection on accuracy and efficiency in many simulated and real datasets. CONCLUSIONS:We develop a new circular RNA detection method called CircMarker based on k-mer analysis. Our results on both simulation data and real data demonstrate that CircMarker runs much faster and can find more circular RNA with higher consensus-based sensitivity and high accuracy ratio compared with existing tools.","Li X
Chu C
Pei J
Măndoiu I
Wu Y
","(PMID:30367583
)",CircMarker: a fast and accurate algorithm for circular RNA detection.,https://europepmc.org/abstract/MED/30367583%0A
"Novel developments in X-ray sources, optics and detectors have significantly advanced the capability of X-ray microscopy at the nanoscale. Depending on the imaging modality and the photon energy, state-of-the-art X-ray microscopes are routinely operated at a spatial resolution of tens of nanometres for hard X-rays or ∼10 nm for soft X-rays. The improvement in spatial resolution, however, has led to challenges in the tomographic reconstruction due to the fact that the imperfections of the mechanical system become clearly detectable in the projection images. Without proper registration of the projection images, a severe point spread function will be introduced into the tomographic reconstructions, causing the reduction of the three-dimensional (3D) spatial resolution as well as the enhancement of image artifacts. Here the development of a method that iteratively performs registration of the experimentally measured projection images to those that are numerically calculated by reprojecting the 3D matrix in the corresponding viewing angles is shown. Multiple algorithms are implemented to conduct the registration, which corrects the translational and/or the rotational errors. A sequence that offers a superior performance is presented and discussed. Going beyond the visual assessment of the reconstruction results, the morphological quantification of a battery electrode particle that has gone through substantial cycling is investigated. The results show that the presented method has led to a better quality tomographic reconstruction, which, subsequently, promotes the fidelity in the quantification of the sample morphology.","Yu H
Xia S
Wei C
Mao Y
Larsson D
Xiao X
Pianetta P
Yu YS
Liu Y
","(PMID:30407194
 PMCID:PMC6225741)",Automatic projection image registration for nanoscale X-ray tomographic reconstruction.,https://europepmc.org/abstract/MED/30407194%0A
[This corrects the article DOI: 10.1371/journal.pone.0179703.].,"Aqra I
Herawan T
Ghani NA
Akhunzada A
Ali A
Razali RB
Ilahi M
Raymond Choo KK
","(PMID:29715321
 PMCID:PMC5929538)",Correction: A novel association rule mining approach using TID intermediate itemset.,https://europepmc.org/abstract/MED/29715321%0A
"Evaluation of stomach neoplasms by traditional 3-dimensional (3D) computed tomography methods such as volume rendering and maximum-intensity projection plays an important role in lesion detection and characterization, preoperative planning, staging, and follow-up. Recently, a new 3D visualization method has become available known as cinematic rendering (CR). This novel technique makes use of a complex global lighting model to impart photorealistic levels of detail to 3D images. Although this new technique has yet to be systematically studied for the evaluation of stomach neoplasms, its intrinsic ability to create realistic shadowing effects to enhance understanding of the 3D relative locations of anatomic structures and to enhance detail and texture may prove valuable for a variety of applications. In this article, we demonstrate the CR appearance of multiple different gastric neoplasms, describe potential advantages of CR, and suggest future research directions.","Rowe SP
Chu LC
Fishman EK
","(PMID:29787502
)",Evaluation of Stomach Neoplasms With 3-Dimensional Computed Tomography: Focus on the Potential Role of Cinematic Rendering.,https://europepmc.org/abstract/MED/29787502%0A
"Coloured Petri nets are an excellent choice for exploring large biological models, particularly when there are repetitions of components. Such models can be easily adapted by slight modifications of parameter values related to colours. Similarly, multi-scale models could involve multiple spatial scales in addition to multiple time scales. Thus, they require the full interplay between stochastic as well as deterministic processes. In this paper we take these two aspects into account and present a modelling and simulation approach for multi-scale biochemical networks using Coloured Generalised Hybrid Petri Nets (GHPNC). GHPNC are a Petri net class that associates colours to Generalised Hybrid Petri Nets (GHPN), which incorporate discrete and continuous places in addition to stochastic and continuous transitions. Moreover, we present two case studies to illustrate typical applications taking advantage of such a Petri net class.","Herajy M
Liu F
Rohr C
Heiner M
","(PMID:29982167
)",Coloured Hybrid Petri Nets: An adaptable modelling approach for multi-scale biological networks.,https://europepmc.org/abstract/MED/29982167%0A
"RATIONALE:Ion trap mass spectrometers are attractive due to their inherent sensitivity and specificity. Miniaturization increases trap portability for in situ mass analysis by relaxing vacuum and voltage requirements but decreases the trapping volume. To overcome signal/resolution loss from miniaturization, double resonance ejection using phase tracking circuitry was investigated. METHODS:Phase tracking circuitry was developed to induce double resonance ejection in a planar linear ion trap using the β 2/3 hexapole resonance line. RESULTS:Double resonance was observed using phase tracking circuitry. Resolution of 0.5 m/z units and improved signal-to-noise ratio (SNR) compared with AC resonant ejection were achieved. CONCLUSIONS:The phase tracking circuitry proved effective despite deviations from a true phase locked condition. Double resonance ejection is a means to increase signal intensity in a miniaturized planar ion trap.","Decker TK
Zheng Y
McClellan JS
Ruben AJ
Lammert SA
Austin DE
Hawkins AR
","(PMID:30133876
)",Double resonance ejection using novel radiofrequency phase tracking circuitry in a miniaturized planar linear ion trap mass spectrometer.,https://europepmc.org/abstract/MED/30133876%0A
"Fluorodeoxyglucose (FDG) positron emission tomography (PET) is useful to predict Alzheimer's disease (AD) conversion in patients with mild cognitive impairment (MCI). However, few studies have examined the extent to which FDG PET alone can predict AD conversion and compared the efficacy between visual and computer-assisted analysis directly.The current study aimed to evaluate the value of FDG PET in predicting the conversion to AD in patients with MCI and to compare the predictive values of visual reading and computer-assisted analysis.A total of 54 patients with MCI were evaluated with FDG PET and followed-up for 2 years with final diagnostic evaluation. FDG PET images were evaluated by (1) traditional visual rating, (2) composite score of visual rating of the brain cortices, and (3) composite score of computer-assisted analysis. Receiver operating characteristics (ROC) curves were compared to analyze predictive values.Nineteen patients (35.2%) converted to AD from MCI. The area under the curve (AUC) of the ROC curve of the traditional visual rating, composite score of visual rating, and computer-assisted analysis were 0.67, 0.76, and 0.79, respectively. ROC curves of the composite scores of the visual rating and computer-assisted analysis were comparable (Z = 0.463, p = 0.643).Visual rating and computer-assisted analysis of FDG PET scans were analogously accurate in predicting AD conversion in patients with MCI. Therefore, FDG PET may be a useful tool for screening AD conversion in patients with MCI, when using composite score, regardless of the method of interpretation.","Kang JM
Lee JY
Kim YK
Sohn BK
Byun MS
Choi JE
Son SK
Im HJ
Lee JH
Ryu YH
Lee DY
","(PMID:29761365
)",Visual Rating and Computer-Assisted Analysis of FDG PET in the Prediction of Conversion to Alzheimer's Disease in Mild Cognitive Impairment.,https://europepmc.org/abstract/MED/29761365%0A
"The age of the population worldwide is rapidly increasing, bringing social and economic challenges. Persuasive technology can alleviate the burden on traditional healthcare services when used to support healthy behaviors, for instance in the prevention and treatment of chronic diseases. Additionally, healthy behaviors are key factors for active and healthy ageing by delaying or even reversing functional decline. In this manuscript, we present a multi-perspective analysis of technologies that can be used in the support of active and healthy ageing in the daily life. First, we take the perspective of physical and mental health, by focusing on the promotion of physical activity and emotional wellbeing. From a temporal perspective, we look at how technology evolved from past, present and future. The overview of the literature is structured in four main sections: (1) measurement of current behavior (monitoring), (2) analysis of the data gathered to derive meaningful information (analyzing & reasoning), (3) support the individual in the adoption or maintenance of a behavior (coaching), and (4) tools or interfaces that provide the information to the individual to stimulate the desired behavior (applications). Finally, we provide recommendations for the design, development and implementation of future technological innovations to support Active and Healthy Ageing in daily life.","Cabrita M
Op den Akker H
Tabak M
Hermens HJ
Vollenbroek-Hutten MMR
","(PMID:29935348
)","Persuasive technology to support active and healthy ageing: An exploration of past, present, and future.",https://europepmc.org/abstract/MED/29935348%0A
"We developed an interdisciplinary course in computational neuroscience to address the need for students trained in both biological/psychological and quantitative sciences. Increasingly, exposure to advanced math and physics is important to stay on the cutting edge of developments and research in neuroscience. Additionally, the ability to work in multidisciplinary teams will continue to be an asset as the field develops. This course brings together students from biology, psychology, biochemistry, engineering, physics, and mathematics. The course was designed to highlight the importance of math in understanding fundamental neuroscience concepts and to prepare students for professional careers in neuroscience. They learn neurobiology, via a 'biology to model and back again' approach involving wet- and software/modeling-labs, with the latter being the focus of this paper. We presented a subset of the software activities described here at the 2017 Faculty for Undergraduate Neuroscience Workshop.","Latimer B
Bergin D
Guntu V
Schulz D
Nair S
","(PMID:30254531
 PMCID:PMC6153012)",Open Source Software Tools for Teaching Neuroscience.,https://europepmc.org/abstract/MED/30254531%0A
"Antibiotics are drugs that react against, kill, or inhibit the growth of bacteria. The method most often employed to evaluate the effectiveness of an antibiotic to kill bacteria requires at least 16 to 24 h for bacterial incubation. The requirement of long periods of time for the determination of the number of bacteria still alive after antibiotic treatment, may, in many cases, be detrimental to the patient's health. In addition, with increasing of bacterial antibiotic resistance, the need to utilize methods for distinguishing between live and dead bacteria within a short period of time after treatment with antibiotic agents, is becoming more crucial. To that effect, we have utilized a hand-held double monochromator to record in situ and within minutes the synchronous and normal fluorescence spectra of bacteria and other species. The fluorescence spectra of bacterial components such as tryptophan, tyrosine and DNA are clearly displayed. In addition, principal component analysis, PCA, makes it possible to display live and dead bacteria separately and determine the ratio of live:dead bacteria before and after treatment with antibiotics.","Li R
Dhankhar D
Chen J
Cesario TC
Rentzepis PM
","(PMID:30332616
)",Determination of live:dead bacteria as a function of antibiotic treatment.,https://europepmc.org/abstract/MED/30332616%0A
"BACKGROUND:To diagnose pulmonary embolism (PE) in children and adults since evaluating tiny pulmonary vasculature beyond segmental level is a challenging and demanding task with thousands of images. PURPOSE:To evaluate the effect of computer-assisted detection (CAD) on acute PE on CTPA in children and young adults by readers with varying experience levels. MATERIAL AND METHODS:Six radiologists were retrospectively divided into three groups according to experience levels and assessed the CTPA studies on a per-emboli basis. All readers identified independently the PE presence, and ranked diagnostic confidence on a 5-point scale with and without CAD. Reading time, sensitivities, specificities, accuracies, positive predictive values (PPVs), and negative predictive values (NPVs) were calculated for each reading. RESULTS:The sensitivities and NPVs differed significantly in most readers ( P = 0.004, 0.001, 0.010, 0.010, and 0.012 for sensitivities and P = 0.011, 0.003, 0.016, 0.017, and 0.019 for NPVs) except for reader 6 ( P = 0.148 and 0.165, respectively), and the accuracies of all readers differed significantly (all P < 0.05) in peripheral PE (beyond segmental level) detection readings with CAD versus without CAD between two reading methods. The overall time using CAD was longer than those without CAD (76.6 ± 54.4 s vs. 49.4 ± 17.7 s, P = 0.000) for all readers. Significant differences were found for confidence scores in inter-group measurements with CAD ( P = 0.045) and without CAD ( P < 0.001). CONCLUSION:At the expense of longer reading time, the use of the CAD algorithms improves sensitivities, NPVs, and the accuracies of readers in peripheral PE detection, especially for readers with a poor level of interpretation experience.","Tang CX
Zhou CS
Schoepf UJ
Mastrodicasa D
Duguay T
Cline A
Zhao YE
Lu L
Li X
Tao SM
Lu MJ
Lu GM
Zhang LJ
","(PMID:30376717
)",Computer-assisted detection of acute pulmonary embolism at CT pulmonary angiography in children and young adults: a diagnostic performance analysis.,https://europepmc.org/abstract/MED/30376717%0A
"Non-uniform heating is an important obstacle for applying radio frequency (RF) energy in food processing, especially for the material with high moisture content. To further extend wide applications of the RF heating uniformity improvement based on our previous study with cross electromagnetic wave conductor (EWC), a novel and effective method with cylindrical electromagnetic wave conductors and cylindrical containers was introduced in this study to improve the electromagnetic energy distribution inside the sample with mid-high moisture content. The associated computer simulation model with cylindrical EWC and container was also developed and validated based on RF experimental results to evaluate the heating uniformity. The results showed that the parameters of EWC (diameter and height) had a positive effect on the RF heating uniformity index. The sample treated with cylindrical EWC had better heating uniformity but lower temperature than that treated with cross EWC based on the comparison results. The improved target uniformity index (TUI) and the decreased heating time also indicated the positive effects of cylindrical EWC. A simplified structure for cylindrical EWC was developed and evaluated by computer simulation, which may provide potential applications of the cylindrical EWC to achieve the required RF heating uniformity in mid-high moisture food.","Zhu H
Dong Li
Jiwei Ma
Peigang Li
Shaojin Wang
Shujun Li
Zhilong Du
","(AGR:IND605913081
)",Radio frequency heating uniformity evaluation for mid-high moisture food treated with cylindrical electromagnetic wave conductors,https://europepmc.org/abstract/AGR/IND605913081%0A
The objective of this project was to develop a computer vision system (CVS) for objective measurement of pork loin under industry speed requirement. Color images of pork loin samples were acquired using a CVS. Subjective color and marbling scores were determined according to the National Pork Board standards by a trained evaluator. Instrument color measurement and crude fat percentage were used as control measurements. Image features (18 color features; 1 marbling feature; 88 texture features) were extracted from whole pork loin color images. Artificial intelligence prediction model (support vector machine) was established for pork color and marbling quality grades. The results showed that CVS with support vector machine modeling reached the highest prediction accuracy of 92.5% for measured pork color score and 75.0% for measured pork marbling score. This research shows that the proposed artificial intelligence prediction model with CVS can provide an effective tool for predicting color and marbling in the pork industry at online speeds.,"Sun X
David Newman
Jeng-Hung Liu
Jennifer Young
","(AGR:IND605918535
)",Prediction of pork loin quality using online computer vision system and artificial intelligence model,https://europepmc.org/abstract/AGR/IND605918535%0A
"The Multi-Spectral Imaging system is a new diagnostic that captures simultaneous spectrally filtered images from a common line of sight while maintaining a large étendue and high throughput. Imaging several atomic line intensities simultaneously may enable numerous measurement techniques. By making a novel modification of a polychromator layout, the MSI sequentially filters and focuses images onto commercial CMOS cameras while exhibiting minimal vignetting and aberrations. A four-wavelength system was initially installed and tested on Alcator C-Mod and subsequently moved to TCV. The images are absolutely calibrated and spatially registered enabling 2D mappings of atomic line ratios and absolute line intensities. The spectral transmission of the optical system was calibrated using an integrating sphere of known radiance. The images are inverted by cross-referencing points on TCV with a computer-aided design (CAD) model.","Linehan BL
Mumgaard RT
Wensing M
Verhaegh K
Andrebe Y
Harrison JR
Duval BP
Theiler C
TCV Team
","(PMID:30399774
)",The multi-spectral imaging diagnostic.,https://europepmc.org/abstract/MED/30399774%0A
"The transparency of two-dimensional (2D) materials to intermolecular interactions of crystalline materials has been an unresolved topic. Here we report that remote atomic interaction through 2D materials is governed by the binding nature, that is, the polarity of atomic bonds, both in the underlying substrates and in 2D material interlayers. Although the potential field from covalent-bonded materials is screened by a monolayer of graphene, that from ionic-bonded materials is strong enough to penetrate through a few layers of graphene. Such field penetration is substantially attenuated by 2D hexagonal boron nitride, which itself has polarization in its atomic bonds. Based on the control of transparency, modulated by the nature of materials as well as interlayer thickness, various types of single-crystalline materials across the periodic table can be epitaxially grown on 2D material-coated substrates. The epitaxial films can subsequently be released as free-standing membranes, which provides unique opportunities for the heterointegration of arbitrary single-crystalline thin films in functional applications.","Kong W
Li H
Qiao K
Kim Y
Lee K
Nie Y
Lee D
Osadchy T
Molnar RJ
Gaskill DK
Myers-Ward RL
Daniels KM
Zhang Y
Sundram S
Yu Y
Bae SH
Rajan S
Shao-Horn Y
Cho K
Ougazzaden A
Grossman JC
Kim J
","(PMID:30297812
)",Polarity governs atomic interaction through two-dimensional materials.,https://europepmc.org/abstract/MED/30297812%0A
"Directly milling zirconia computer-aided design (CAD)/computer-aided manufacturing (CAM) crowns from fully sintered zirconia blocks using a five-axis laser milling system, compared with three-axis milling and full sintering by heating milled semi-sintered crowns, was investigated. The mechanical characteristics of zirconia specimens were similar across groups. The order of the marginal gap was three-axis>conventional (lingual thickness of 1.5 mm>0.5 mm)>five-axis group (close to zero). The marginal shape was almost perfectly circular in all groups. The internal corner shape and gap were almost perfect for the five-axis milled crown but not for conventional and three-axis crowns. The roundness of the marginal and internal shapes was almost perfect in the five-axis milling group but not for the three-axis and conventional groups. These small distortions result in large marginal gaps. Results of the present study suggest the superiority of the five-axis milling system in creating a zirconia prosthesis.","Ohkuma K
Kameda T
Terada K
","(PMID:30224604
)",Five-axis laser milling system that realizes more accurate zirconia CAD/CAM crowns by direct milling from fully sintered blocks.,https://europepmc.org/abstract/MED/30224604%0A
"Electro-hydraulic shake table (EHST), also known as earthquake simulator, is of considerable significance in civil engineering for evaluating structures or infrastructures subjected to earthquake ground motions. However, reproduction of prescribed accelerations at table for EHST systems remains to be imperfect as the whole systems are confronted with hydraulic nonlinearity, varying dynamics, unexpected disturbance, etc. For enhancing the acceleration tracking performance of EHST systems, an acceleration waveform reproduction strategy using offline designed parametric feedforward compensator (PFC) and online functional link adaptive controller (FLAC) is proposed in this paper. The PFC controller is established on the basis of classical three variable controller (TVC) as an inner compensation loop, in which multi-innovation forgetting gradient (MIFG) algorithm together with zero magnitude error tracking (ZMET) technique are utilized during the design process. The FLAC controller is combined to the PFC controller as an outer loop for further acceleration enhancement purpose, and the controller's nonlinear mapping ability is achieved with trigonometric expansion implementation. Following theoretical analysis of the proposed controller, comparative experiments are performed on an established unidirectional EHST test bench with both random and real-time recorded earthquake input waveforms. The experimental results validate the feasibility and superiority of the proposed acceleration reproduction strategy.","Tang Y
Zhu Z
Shen G
Xia S
Li X
Sa Y
Rui G
","(PMID:30193822
)",Investigation on acceleration performance improvement of electro-hydraulic shake tables using parametric feedforward compensator and functional link adaptive controller.,https://europepmc.org/abstract/MED/30193822%0A
"Flexible photodetectors have been intensely studied for the use of curved image sensors, which are a crucial component in bio-inspired imaging systems, but several challenging points remain, such as a low absorption efficiency due to a thin active layer and low flexibility. We present an advanced method to fabricate a flexible phototransistor array with an improved electrical performance. The outstanding electrical performance is driven by a low dark current owing to deep impurity doping. Stretchable and flexible metal interconnectors simultaneously offer electrical and mechanical stabilities in a highly deformed state. The protocol explicitly describes the fabrication process of the phototransistor using a thin silicon membrane. By measuring I-V characteristics of the completed device in deformed states, we demonstrate that this approach improves the mechanical and electrical stabilities of the phototransistor array. We expect that this approach to a flexible phototransistor can be widely used for the applications of not only next-generation imaging systems/optoelectronics but also wearable devices such as tactile/pressure/temperature sensors and health monitors.","Kim HM
Lee GJ
Kim MS
Song YM
","(PMID:29985334
)",Fabrication of Flexible Image Sensor Based on Lateral NIPIN Phototransistors.,https://europepmc.org/abstract/MED/29985334%0A
No abstract provided.,"Baker J
","(PMID:30214032
)",Forgotten heroes of the Enigma story.,https://europepmc.org/abstract/MED/30214032%0A
"Vastly greater quantities of microbial genome data are being generated where environmental samples mix together the DNA from many different species. Here, we present Opal for metagenomic binning, the task of identifying the origin species of DNA sequencing reads. We introduce 'low-density' locality sensitive hashing to bioinformatics, with the addition of Gallager codes for even coverage, enabling quick and accurate metagenomic binning.On public benchmarks, Opal halves the error on precision/recall (F1-score) as compared to both alignment-based and alignment-free methods for species classification. We demonstrate even more marked improvement at higher taxonomic levels, allowing for the discovery of novel lineages. Furthermore, the innovation of low-density, even-coverage hashing should itself prove an essential methodological advance as it enables the application of machine learning to other bioinformatic challenges.Full source code and data sets are available at http://opal.csail.mit.edu and https://github.com/yunwilliamyu/opal.Supplementary data are available at Bioinformatics online.","Luo Y
Yu YW
Zeng J
Berger B
Peng J
","(PMID:30010790
)",Metagenomic binning through low-density hashing.,https://europepmc.org/abstract/MED/30010790%0A
"We evaluate the impact of denoising and Metal Artefact Reduction (MAR) on 3D object segmentation and classification in low-resolution, cluttered dual-energy Computed Tomography (CT). To this end, we present a novel 3D materials-based segmentation technique based on the Dual-Energy Index (DEI) to automatically generate subvolumes for classification. Subvolume classification is performed using an extension of Extremely Randomised Clustering (ERC) forest codebooks, constructed using dense feature-point sampling and multiscale Density Histogram (DH) descriptors. Within this experimental framework, we evaluate the impact on classification accuracy and computational expense of pre-processing by intensity thresholding, Non-Local Means (NLM) filtering, Linear Interpolation-based MAR (LIMar) and Distance-Driven MAR (DDMar) in the domain of 3D baggage security screening. We demonstrate that basic NLM filtering, although removing fewer artefacts, produces state-of-the-art classification results comparable to the more complex DDMar but at a significant reduction in computational cost - bringing into question the importance (in terms of automated CT analysis) of computationally expensive artefact reduction techniques. Overall, it was found that the use of MAR pre-processing approaches produced only a marginal improvement in classification performance (< 1%) at considerable additional computational cost (> 10×) when compared to NLM pre-processing.","Mouton A
Breckon PT
","(PMID:30347634
)",On the relevance of denoising and artefact reduction in 3d segmentation and classification within complex computed tomography imagery.,https://europepmc.org/abstract/MED/30347634%0A
"The community composition in open advective environments, where individuals are exposed to unidirectional flow, is formed by the complex interplays of hydrological and biological factors. We investigate the coexistence mechanism of species by a reaction-diffusion-advection competition model proposed by Lutscher et al. in [19]. It turns out that the locations of two critical curves, which separate the stable region of the semi-trivial solutions from the unstable one, determines whether coexistence or bistability happens. Furthermore, the analytical and numerical results suggest a tradeoff driven coexistence mechanism. More precisely, there is a tradeoff between the dispersal strategy and growth competence which allows the transition of competition outcomes, including competition exclusion, coexistence and bistability. This shifting may have an effect on the community composition in aquatic habitat.","Lou Y
Nie H
Wang Y
","(PMID:30336145
)",Coexistence and bistability of a competition model in open advective environments.,https://europepmc.org/abstract/MED/30336145%0A
"OBJECTIVE:This in vitro study was conducted to assess the marginal adaptation and fracture resistance of computer aided design/computer aided manufacturer (CAD-CAM) fabricated endocrowns restoring endodontically treated molars using different machinable blocks with thermomechanical loading protocols. MATERIALS AND METHODS:Devitalized mandibular molars were prepared in a standardized way and divided into 4 groups (n = 10) to receive CAD/CAM fabricated endocrowns using four materials (Lithium disilicate ceramics, polymer infiltrated ceramics, zirconia-reinforced lithium silicate ceramics and resin nanoceramics. Marginal gaps (µm) were measured using stereomicroscope before cementation and after cementation. After thermomechanical aging, marginal gap measurements were repeated, and then fracture resistance test was performed. Two-way analysis of variance (ANOVA) and Tukey HSD multiple comparisons were used to assess the effect of material on the marginal gap before, after cementation, and after thermomechanical aging. One Way ANOVA was used to assess the effect of material on the fracture resistance. RESULTS:The difference between marginal gaps values of the tested materials was statistically insignificant but with significant increase after cementation and after thermomechanical aging. Cerasmart endocrowns showed the highest mean fracture load value (1508.5 ± 421.7N) with statistically significant difference than Vita Enamic endocrowns and Celtra Duo. CONCLUSION:The tested materials showed marginal vertical gap readings within the limits of clinically acceptable standards. Resin nanoceramics and lithium disilicate showed the highest values of fracture resistance followed by polymer infiltrated ceramics favoring their use for endocrown restorations. CLINICAL SIGNIFICANCE:The mechanical behavior of ceramic materials varies with the variation of their structure and mechanical properties. Accordingly, further investigation is always needed to explore the biomechanical behavior of recent materials when used as endocrowns before clinical trials.","Taha D
Spintzyk S
Sabet A
Wahsh M
Salah T
","(PMID:30113129
)",Assessment of marginal adaptation and fracture resistance of endocrown restorations utilizing different machinable blocks subjected to thermomechanical aging.,https://europepmc.org/abstract/MED/30113129%0A
"We study the statistics of height and balanced height in the binary search tree problem in computer science. The search tree problem is first mapped to a fragmentation problem that is then further mapped to a modified directed polymer problem on a Cayley tree. We employ the techniques of traveling fronts to solve the polymer problem and translate back to derive exact asymptotic properties in the original search tree problem. The second mapping allows us not only to again derive the already known results for random binary trees but to obtain exact results for search trees where the entries arrive according to an arbitrary distribution, not necessarily randomly. Besides it allows us to derive the asymptotic shape of the full probability distribution of height and not just its moments. Our results are then generalized to m-ary search trees with arbitrary distribution.","Majumdar SN
Krapivsky PL
","(PMID:11909185
)",Extreme value statistics and traveling fronts: application to computer science.,https://europepmc.org/abstract/MED/11909185%0A
"Since identifying relations between chemicals and diseases (CDR) are important for biomedical research and healthcare, the challenge proposed by BioCreative V requires automatically mining causal relationships between chemicals and diseases which may span sentence boundaries. Although most systems explore feature engineering and knowledge bases to recognize document level CDR relations, feature learning automatically is limited only in a sentence. In this work, we proposed an effective model that automatically learns document level semantic representations to extract chemical-induced disease (CID) relations from articles by combining advantages of convolutional neural network and recurrent neural network. First, to purposefully collect contexts, candidate entities existing in multiple sentences of an article were masked to make the model have ability to discern candidate entities and general terms. Next, considering the contiguity and temporality among associated sentences as well as the topic of an article, a hierarchical network architecture was designed at the document level to capture semantic information of different types of text segments in an article. Finally, a softmax classifier performed the CID recognition. Experimental results on the CDR corpus show that the proposed model achieves a good overall performance compared with other state-of-the-art methods. Although only using two types of embedding vectors, our approach can perform well for recognizing not only intra-sentential but also inter-sentential CID relations.","Zheng W
Lin H
Li Z
Liu X
Li Z
Xu B
Zhang Y
Yang Z
Wang J
","(PMID:29746916
)",An effective neural model extracting document level chemical-induced disease relations from biomedical literature.,https://europepmc.org/abstract/MED/29746916%0A
"Advances in technical capabilities for reading complex human microbiomes are leading to an explosion of microbiome research, leading in turn to intense interest among clinicians in applying these techniques to their patients. In this review, we discuss the content of the human microbiome, including intersubject and intrasubject variability, considerations of study design including important confounding factors, and different methods in the laboratory and on the computer to read the microbiome and its resulting gene products and metabolites. We highlight several common pitfalls for clinicians, including the expectation that an individual's microbiome will be stable, that diet can induce rapid changes that are large compared with the differences among subjects, that everyone has essentially the same core stool microbiome, and that different laboratory and computational methods will yield essentially the same results. We also highlight the current limitations and future promise of these techniques, with the expectation that an understanding of these considerations will help accelerate the path toward routine clinical application of these techniques developed in research settings.","Allaband C
McDonald D
Vázquez-Baeza Y
Minich JJ
Tripathi A
Brenner DA
Loomba R
Smarr L
Sandborn WJ
Schnabl B
Dorrestein P
Zarrinpar A
Knight R
","(PMID:30240894
)","Microbiome 101: Studying, Analyzing, and Interpreting Gut Microbiome Data for Clinicians.",https://europepmc.org/abstract/MED/30240894%0A
No abstract provided.,"Extance A
","(PMID:30202054
)",How AI technology can tame the scientific literature.,https://europepmc.org/abstract/MED/30202054%0A
"Multiplexed electrochemical biosensors are intriguing due to their capability to permit high-throughput and low-cost assays. While commercial single-chip potentiostats are one promising approach for rapidly prototyping portable and low-cost electrochemical biosensors, it is still challenging to utilize them to achieve parallel multiplexing due to the limited resources integrated onto the chips. In this paper, we provide a methodology for incorporating multiplexing into commercial single-chip potentiostats by using a sequential architecture. In the sequential architecture, the multiplexed biosensors are interfaced to the single-chip potentiostat via single-pole single-throw switches, and the measurements alternate across the sensors. We build analytical and finite element models to investigate the behavior of the sensors, particularly when they are disconnected from the potentiostat, and find that we can take advantage of the dynamics of the sensors to achieve improved sensitivity over conventional chronoamperometry. We also investigate and compare different strategies to interface the multiplexed sensors to the single-chip potentiostat. Using the proposed multiplexing architecture, we demonstrate the implementation of 16-fold multiplexed amperometry, which is validated using ferricyanide measurement. Finally, the sequential multiplexing methodology is applied to a multiplexed bead-based electronic enzyme-linked immunosorbent assays of human interleukin-6.","Wu D
Rios-Aguirre D
Chounlakone M
Camacho-Leon S
Voldman J
","(PMID:29982123
)",Sequentially multiplexed amperometry for electrochemical biosensors.,https://europepmc.org/abstract/MED/29982123%0A
"To evaluate the status of parvovirus infection in free-range cows in a region of northeast China, nine serum samples were collected and analysed by sequencing and polymerase chain reaction. A new bovine parvovirus-2 (BPV2) was identified and named QQHE16. The genome of the virus is 5759 nucleotides long and retains two ORFs that are typical of the Parvovirinae family. Compared with reference BPV2 strains, BPV2 QQHE16 appeared to have a close relationship with strain BSRI isolated in the USA in 2013. A putative recombination breakpoint located at nucleotide position 2121 and in the interval between the non-structural gene and the VP gene was identified. From our analysis, we propose that strain QQHE16 originates from the natural recombination of strains ujs2665 and BSRI.","Li M
Yang J
Yu TF
","(PMID:29855777
)",Identification of a recombinant isolate of ungulate copiparvovirus.,https://europepmc.org/abstract/MED/29855777%0A
"In this study, we systematically investigate the impact of class imbalance on classification performance of convolutional neural networks (CNNs) and compare frequently used methods to address the issue. Class imbalance is a common problem that has been comprehensively studied in classical machine learning, yet very limited systematic research is available in the context of deep learning. In our study, we use three benchmark datasets of increasing complexity, MNIST, CIFAR-10 and ImageNet, to investigate the effects of imbalance on classification and perform an extensive comparison of several methods to address the issue: oversampling, undersampling, two-phase training, and thresholding that compensates for prior class probabilities. Our main evaluation metric is area under the receiver operating characteristic curve (ROC AUC) adjusted to multi-class tasks since overall accuracy metric is associated with notable difficulties in the context of imbalanced data. Based on results from our experiments we conclude that (i) the effect of class imbalance on classification performance is detrimental; (ii) the method of addressing class imbalance that emerged as dominant in almost all analyzed scenarios was oversampling; (iii) oversampling should be applied to the level that completely eliminates the imbalance, whereas the optimal undersampling ratio depends on the extent of imbalance; (iv) as opposed to some classical machine learning models, oversampling does not cause overfitting of CNNs; (v) thresholding should be applied to compensate for prior class probabilities when overall number of properly classified cases is of interest.","Buda M
Maki A
Mazurowski MA
","(PMID:30092410
)",A systematic study of the class imbalance problem in convolutional neural networks.,https://europepmc.org/abstract/MED/30092410%0A
"Prior research has indicated that as an important biomarker of chronic low-grade inflammation, high-sensitivity C-reactive protein (hs-CRP) can play important roles on the onset of metabolic syndrome and cardiovascular diseases (CVD). We conducted an integrative approach, which combines biological wet-lab experiments, statistical analysis, and semantics-oriented bioinformatics & computational analysis, to investigate the association among hs-CRP, body fat mass (FM) distribution, and other cardiometabolic risk factors in young healthy women. Research outcomes in this study resulted in two novel discoveries. Discovery 1: There are four primary determinants for hs-CRP, i.e., central/abdominal FM (a.k.a. trunk FM) accumulation, leptin, high density lipoprotein cholesterol (HDL-C), and plasminogen activator inhibitior-1 (PAI-1). Discovery 2: Chronic inflammation may involve in adipocyte-cytokine interaction underlying the metabolic derangement in healthy young women.","Wu B
Huang J
Zhang L
Kasukurthi MV
Huang F
Bian J
Fukuo K
Kazumi T
","(PMID:29702223
)","An integrative approach to investigate the association among high-sensitive C-reactive protein, body fat mass distribution, and other cardiometabolic risk factors in young healthy women.",https://europepmc.org/abstract/MED/29702223%0A
"OBJECTIVE:A radial arm maze (RAM) is an essential tool for assessing spatial learning and memory. Although this tool is widely used to study deficits in spatial memory in animal models, it has several restrictions that prevent its adaptation to human research and training. Therefore, we developed a head-mounted-display RAM (HMD-RAM) program for humans and verified its validity by comparing it to the results obtained by previous RAM studies. We also compared the HMD and a flat monitor as experimental devices. METHODS:Forty participants were recruited for the current study (Study 1: 20 participants with the HMD device; Study 2: 20 participants with the flat monitor). They navigated a virtual room as a first-person viewer and used environmental landmarks to remember their spatial position and orientation. The main dependent measures were working memory error, reference memory error, detection time, travel distance, and participant's head movements. To validate the program, participants also conducted neuropsychological assessments and self-reported measures. RESULTS:The results for HMD-RAM tasks were consistent with the results of previous research conducted on animals, and the HMD elicited a higher sense of presence, immersion, and simulator sickness than the flat monitor. According to post-experiment questions on navigation strategy, creating landmarks was important when people were discovering locations in their environment, and an HMD was beneficial for better navigation strategy. CONCLUSION:These results suggest that the HMD-RAM is valuable for estimating spatial learning and memory in humans and may be a useful tool for early diagnosis of deficits in spatial learning and memory, including amnestic mild cognitive impairment and Alzheimer's disease.","Kim H
Park JY
Kim KK
","(PMID:30301309
 PMCID:PMC6212707)",Spatial Learning and Memory Using a Radial Arm Maze with a Head-Mounted Display.,https://europepmc.org/abstract/MED/30301309%0A
"BACKGROUND:Transcriptomic sequencing (RNA-seq) related applications allow for rapid explorations due to their high-throughput and relatively fast experimental capabilities, providing unprecedented progress in gene functional annotation, gene regulation analysis, and environmental factor verification. However, with increasing amounts of sequenced reads and reference model species, the selection of appropriate reference species for gene annotation has become a new challenge. METHODS:We proposed a novel approach for finding the most effective reference model species through taxonomic associations and ultra-conserved orthologous (UCO) gene comparisons among species. An online system for multiple species selection (MSS) for RNA-seq differential expression analysis was developed, and comprehensive genomic annotations from 291 reference model eukaryotic species were retrieved from the RefSeq, KEGG, and UniProt databases. RESULTS:Using the proposed MSS pipeline, gene ontology and biological pathway enrichment analysis can be efficiently achieved, especially in the case of transcriptomic analysis of non-model organisms. The results showed that the proposed method solved problems related to limitations in annotation information and provided a roughly twenty-fold reduction in computational time, resulting in more accurate results than those of traditional approaches of using a single model reference species or the large non-redundant reference database. CONCLUSIONS:Selection of appropriate reference model species helps to reduce missing annotation information, allowing for more comprehensive results than those obtained with a single model reference species. In addition, adequate model species selection reduces the computational time significantly while retaining the same order of accuracy. The proposed system indeed provides superior performance by selecting appropriate multiple species for transcriptomic analysis compared to traditional approaches.","Pai TW
Li KH
Yang CH
Hu CH
Lin HJ
Wang WD
Chen YR
","(PMID:30367568
)",Multiple model species selection for transcriptomics analysis of non-model organisms.,https://europepmc.org/abstract/MED/30367568%0A
"OBJECTIVE:Voice disorders are common and negatively affect various life domains such as occupational functioning and emotional well-being. Perceived present control, a factor that is amenable to change, may reduce the effect of voice disorders on these outcomes. This pilot study aimed to (1) establish the feasibility, usability, and acceptability of a web-based perceived present control intervention for individuals with voice disorders and (2) gather preliminary data on the effectiveness of the intervention. This study is the first to assess whether a web-based psychological intervention would decrease self-reported voice handicap in this population. METHODS:Participants (N = 20) were recruited from an otolaryngology clinic at a large, Midwest university and the surrounding urban community, and completed a 3-week web-based intervention that incorporated psychoeducation and written exercises on increasing perceived present control. RESULTS:Supporting feasibility, the intervention components had high completion rates (75%-95%). Most participants planned to continue the perceived control exercises after study completion and would recommend the intervention to others, demonstrating usability and acceptability. There was a significant decrease in self-reported voice handicap (Voice Handicap Index-10) from pretest (M = 18.38, standard deviation = 4.41) to post-test (M = 15.22, standard deviation = 4.55) with a large effect size (within-group d = -0.86, P < 0.05). CONCLUSIONS:Focusing on perceived present control as a teachable skill may be a useful addition to voice disorder treatment armamentarium. Future studies will incorporate a comparison group and larger sample sizes to assess further the role of perceived present control interventions in voice care.","Nguyen-Feng VN
Frazier PA
Stockness A
Narayanan A
Merians AN
Misono S
","(PMID:30227981
)",Web-Based Perceived Present Control Intervention for Voice Disorders: A Pilot Study.,https://europepmc.org/abstract/MED/30227981%0A
A correction to this article has been published and is linked from the HTML and PDF versions of this paper. The error has been fixed in the paper.,"Kriegman S
Cheney N
Bongard J
","(PMID:30361484
 PMCID:PMC6202404)",Publisher Correction: How morphological development can guide evolution.,https://europepmc.org/abstract/MED/30361484%0A
"This paper proposed a multi-keyword ciphertext search, based on an improved-quality hierarchical clustering (MCS-IQHC) method. MCS-IQHC is a novel technique, which is tailored to work with encrypted data. It has improved search accuracy and can self-adapt when performing multi-keyword ciphertext searches on privacy-protected sensor network cloud platforms. Document vectors are first generated by combining the term frequency-inverse document frequency (TF-IDF) weight factor and the vector space model (VSM). The improved quality hierarchical clustering (IQHC) algorithm then generates document vectors, document indices, and cluster indices, which are encrypted via the k-nearest neighbor algorithm (KNN). MCS-IQHC then returns the top-k search result. A series of experiments proved that the proposed method had better searching efficiency and accuracy in high-privacy sensor cloud network environments, compared to other state-of-the-art methods.","Xie L
Wang Z
Wang Y
Yang H
Zhang J
","(PMID:30213034
 PMCID:PMC6164657)",New Multi-Keyword Ciphertext Search Method for Sensor Network Cloud Platforms.,https://europepmc.org/abstract/MED/30213034%0A
"With the advent of biomedical imaging technology, the number of captured and stored biomedical images is rapidly increasing day by day in hospitals, imaging laboratories and biomedical institutions. Therefore, more robust biomedical image analysis technology is needed to meet the requirement of the diagnosis and classification of various kinds of diseases using biomedical images. However, the current biomedical image classification methods and general non-biomedical image classifiers cannot extract more compact biomedical image features or capture the tiny differences between similar images with different types of diseases from the same category. In this paper, we propose a novel fused convolutional neural network to develop a more accurate and highly efficient classifier for biomedical images, which combines shallow layer features and deep layer features from the proposed deep neural network architecture. In the analysis, it was observed that the shallow layers provided more detailed local features, which could distinguish different diseases in the same category, while the deep layers could convey more high-level semantic information used to classify the diseases among the various categories. A detailed comparison of our approach with traditional classification algorithms and popular deep classifiers across several public biomedical image datasets showed the superior performance of our proposed method for biomedical image classification. In addition, we also evaluated the performance of our method in modality classification of medical images using the ImageCLEFmed dataset. Graphical abstract The graphical abstract shows the fused, deep convolutional neural network architecture proposed for biomedical image classification. In the architecture, we can clearly see the feature-fusing process going from shallow layers and the deep layers.","Pang S
Du A
Orgun MA
Yu Z
","(PMID:30003400
)",A novel fused convolutional neural network for biomedical image classification.,https://europepmc.org/abstract/MED/30003400%0A
"In the past two decades, significant advances have been made on automated electroencephalogram (EEG)-based diagnosis of epilepsy and seizure detection. A number of innovative algorithms have been introduced that can aid in epilepsy diagnosis with a high degree of accuracy. In recent years, the frontiers of computational epilepsy research have moved to seizure prediction, a more challenging problem. While antiepileptic medication can result in complete seizure freedom in many patients with epilepsy, up to one-third of patients living with epilepsy will have medically intractable epilepsy, where medications reduce seizure frequency but do not completely control seizures. If a seizure can be predicted prior to its clinical manifestation, then there is potential for abortive treatment to be given, either self-administered or via an implanted device administering medication or electrical stimulation. This will have a far-reaching impact on the treatment of epilepsy and patient's quality of life. This paper presents a state-of-the-art review of recent efforts and journal articles on seizure prediction. The technologies developed for epilepsy diagnosis and seizure detection are being adapted and extended for seizure prediction. The paper ends with some novel ideas for seizure prediction using the increasingly ubiquitous machine learning technology, particularly deep neural network machine learning.","Acharya UR
Hagiwara Y
Adeli H
","(PMID:30317059
)",Automated seizure prediction.,https://europepmc.org/abstract/MED/30317059%0A
"Biological neural networks are systems of extraordinary computational capabilities shaped by evolution, development, and lifelong learning. The interplay of these elements leads to the emergence of biological intelligence. Inspired by such intricate natural phenomena, Evolved Plastic Artificial Neural Networks (EPANNs) employ simulated evolution in-silico to breed plastic neural networks with the aim to autonomously design and create learning systems. EPANN experiments evolve networks that include both innate properties and the ability to change and learn in response to experiences in different environments and problem domains. EPANNs' aims include autonomously creating learning systems, bootstrapping learning from scratch, recovering performance in unseen conditions, testing the computational advantages of particular neural components, and deriving hypotheses on the emergence of biological learning. Thus, EPANNs may include a large variety of different neuron types and dynamics, network architectures, plasticity rules, and other factors. While EPANNs have seen considerable progress over the last two decades, current scientific and technological advances in artificial neural networks are setting the conditions for radically new approaches and results. Exploiting the increased availability of computational resources and of simulation environments, the often challenging task of hand-designing learning neural networks could be replaced by more autonomous and creative processes. This paper brings together a variety of inspiring ideas that define the field of EPANNs. The main methods and results are reviewed. Finally, new opportunities and possible developments are presented.","Soltoggio A
Stanley KO
Risi S
","(PMID:30142505
)","Born to learn: The inspiration, progress, and future of evolved plastic artificial neural networks.",https://europepmc.org/abstract/MED/30142505%0A
"This study provides current evidence about cross-section production processes in the theoretical and experimental results of neutron induced reaction of uranium isotope on projectile energy range of 1-100 MeV in order to improve the reliability of nuclear stimulation. In such fission reactions of 235U within nuclear reactors, much amount of energy would be released as a product that able to satisfy the needs of energy to the world wide without polluting processes as compared to other sources. The main objective of this work is to transform a related knowledge in the neutron-induced fission reactions on 235U through describing, analyzing and interpreting the theoretical results of the cross sections obtained from computer code COMPLET by comparing with the experimental data obtained from EXFOR. The cross section value of 235U(n,2n)234U, 235U(n,3n)233U, 235U(n,γ)236U, 235U(n,f) are obtained using computer code COMPLET and the corresponding experimental values were browsed by EXFOR, IAEA. The theoretical results are compared with the experimental data taken from EXFOR Data Bank. Computer code COMPLET has been used for the analysis with the same set of input parameters and the graphs were plotted by the help of spreadsheet & Origin-8 software. The quantification of uncertainties stemming from both experimental data and computer code calculation plays a significant role in the final evaluated results. The calculated results for total cross sections were compared with the experimental data taken from EXFOR in the literature, and good agreement was found between the experimental and theoretical data. This comparison of the calculated data was analyzed and interpreted with tabulation and graphical descriptions, and the results were briefly discussed within the text of this research work.","Asres YH
Mathuthu M
Birhane MD
","(PMID:29729485
)",Analysis of reaction cross-section production in neutron induced fission reactions on uranium isotope using computer code COMPLET.,https://europepmc.org/abstract/MED/29729485%0A
"Insights at the microscopic level of the process of radiocesium adsorption and interaction with clay mineral particles have improved substantially over the past several years, triggered by pressing social issues such as management of huge amounts of waste soil accumulated after the Fukushima Dai-ichi nuclear power plant accident. In particular, computer-based molecular modeling supported by advanced hardware and algorithms has proven to be a powerful approach. Its application can now generally encompass the full complexity of clay particle adsorption sites from basal surfaces to interlayers with inserted water molecules, to edges including fresh and weathered frayed ones. On the other hand, its methodological schemes are now varied from traditional force-field molecular dynamics on large-scale realizations composed of many thousands of atoms including water molecules to first-principles methods on smaller models in rather exacting fashion. In this article, we overview new understanding enabled by simulations across methodological variations, focusing on recent insights that connect with experimental observations, namely: 1) the energy scale for cesium adsorption on the basal surface, 2) progress in understanding the structure of clay edges, which is difficult to probe experimentally, 3) cesium adsorption properties at hydrated interlayer sites, 4) the importance of the size relationship between the ionic radius of cesium and the interlayer distance at frayed edge sites, 5) the migration of cesium into deep interlayer sites, and 6) the effects of nuclear decay of radiocesium. Key experimental observations that motivate these simulation advances are also summarized. Furthermore, some directions toward future solutions of waste soil management are discussed based on the obtained microscopic insights.","Okumura M
Kerisit S
Bourg IC
Lammers LN
Ikeda T
Sassi M
Rosso KM
Machida M
","(PMID:30340873
)",Radiocesium interaction with clay minerals: Theory and simulation advances Post-Fukushima.,https://europepmc.org/abstract/MED/30340873%0A
"BACKGROUND:The large amount of clinical signals in intensive care units can easily overwhelm health-care personnel and can lead to treatment delays, suboptimal care, or clinical errors. The aim of this study was to apply deep machine learning methods to predict severe complications during critical care in real time after cardiothoracic surgery. METHODS:We used deep learning methods (recurrent neural networks) to predict several severe complications (mortality, renal failure with a need for renal replacement therapy, and postoperative bleeding leading to operative revision) in post cardiosurgical care in real time. Adult patients who underwent major open heart surgery from Jan 1, 2000, to Dec 31, 2016, in a German tertiary care centre for cardiovascular diseases formed the main derivation dataset. We measured the accuracy and timeliness of the deep learning model's forecasts and compared predictive quality to that of established standard-of-care clinical reference tools (clinical rule for postoperative bleeding, Simplified Acute Physiology Score II for mortality, and the Kidney Disease: Improving Global Outcomes staging criteria for acute renal failure) using positive predictive value (PPV), negative predictive value, sensitivity, specificity, area under the curve (AUC), and the F1 measure (which computes a harmonic mean of sensitivity and PPV). Results were externally retrospectively validated with 5898 cases from the published MIMIC-III dataset. FINDINGS:Of 47 559 intensive care admissions (corresponding to 42 007 patients), we included 11 492 (corresponding to 9269 patients). The deep learning models yielded accurate predictions with the following PPV and sensitivity scores: PPV 0·90 and sensitivity 0·85 for mortality, 0·87 and 0·94 for renal failure, and 0·84 and 0·74 for bleeding. The predictions significantly outperformed the standard clinical reference tools, improving the absolute complication prediction AUC by 0·29 (95% CI 0·23-0·35) for bleeding, by 0·24 (0·19-0·29) for mortality, and by 0·24 (0·13-0·35) for renal failure (p<0·0001 for all three analyses). The deep learning methods showed accurate predictions immediately after patient admission to the intensive care unit. We also observed an increase in performance in our validation cohort when the machine learning approach was tested against clinical reference tools, with absolute improvements in AUC of 0·09 (95% CI 0·03-0·15; p=0·0026) for bleeding, of 0·18 (0·07-0·29; p=0·0013) for mortality, and of 0·25 (0·18-0·32; p<0·0001) for renal failure. INTERPRETATION:The observed improvements in prediction for all three investigated clinical outcomes have the potential to improve critical care. These findings are noteworthy in that they use routinely collected clinical data exclusively, without the need for any manual processing. The deep machine learning method showed AUC scores that significantly surpass those of clinical reference tools, especially soon after admission. Taken together, these properties are encouraging for prospective deployment in critical care settings to direct the staff's attention towards patients who are most at risk. FUNDING:No specific funding.","Meyer A
Zverinski D
Pfahringer B
Kempfert J
Kuehne T
Sündermann SH
Stamm C
Hofmann T
Falk V
Eickhoff C
","(PMID:30274956
)",Machine learning for real-time prediction of complications in critical care: a retrospective study.,https://europepmc.org/abstract/MED/30274956%0A
"Over the last few years, Internet of Things (IoT) has opened the doors to innovations that facilitate interactions among things and humans. Focusing on healthcare domain, IoT devices such as medical sensors, visual sensors, cameras, and wireless sensor network are leading this evolutionary trend. In this direction, the paper proposes a novel, IoT-aware student-centric stress monitoring framework to predict student stress index at a particular context. Bayesian Belief Network (BBN) is used to classify the stress event as normal or abnormal using physiological readings collected from medical sensors at fog layer. Abnormal temporal structural data which is time-enriched dataset sequence is analyzed for various stress-related parameters at cloud layer. To compute the student stress index, a two-stage Temporal Dynamic Bayesian Network (TDBN) model is formed. This model computes stress based on four parameters, namely, leaf node evidences, workload, context, and student health trait. After computing the stress index of the student, decisions are taken in the form of alert generation mechanism with the deliverance of time-sensitive information to caretaker or responder. Experiments are conducted both at fog and cloud layer which hold evidence for the utility and accuracy of the BBN classifier and TDBN predictive model in our proposed system. Graphical Abstract Student stress monitoring in IoT-Fog Environment.","Verma P
Sood SK
","(PMID:30083806
)",A comprehensive framework for student stress monitoring in fog-cloud IoT environment: m-health perspective.,https://europepmc.org/abstract/MED/30083806%0A
"Algorithms that learn through environmental interaction and delayed rewards, or reinforcement learning (RL), increasingly face the challenge of scaling to dynamic, high-dimensional, and partially observable environments. Significant attention is being paid to frameworks from deep learning, which scale to high-dimensional data by decomposing the task through multilayered neural networks. While effective, the representation is complex and computationally demanding. In this work, we propose a framework based on genetic programming which adaptively complexifies policies through interaction with the task. We make a direct comparison with several deep reinforcement learning frameworks in the challenging Atari video game environment as well as more traditional reinforcement learning frameworks based on a priori engineered features. Results indicate that the proposed approach matches the quality of deep learning while being a minimum of three orders of magnitude simpler with respect to model complexity. This results in real-time operation of the champion RL agent without recourse to specialized hardware support. Moreover, the approach is capable of evolving solutions to multiple game titles simultaneously with no additional computational cost. In this case, agent behaviours for an individual game as well as single agents capable of playing all games emerge from the same evolutionary run.","Kelly S
Heywood MI
","(PMID:29932363
)",Emergent Solutions to High-Dimensional Multitask Reinforcement Learning.,https://europepmc.org/abstract/MED/29932363%0A
"Effective communication requires knowing the ""right"" amount of information to provide; what is necessary for a naïve learner to arrive at a target hypothesis may be superfluous and inefficient for a knowledgeable learner. The current study examines 4- to 7-year-olds' developing sensitivity to overinformative communication and their ability to decide how much information is appropriate depending on the learner's prior knowledge. In Experiment 1 (N = 184, age = 4.09-7.98 years), 5- to 7-year-old children preferred teachers who gave costly, exhaustive demonstrations when learners were naïve, but preferred teachers who gave efficient, selective demonstrations when learners were already knowledgeable given their prior experience (i.e., common ground). However, 4-year-olds did not show a clear preference. In Experiment 2 (N = 80, age = 4.05-6.99 years), we asked whether children flexibly modulated their own teaching based on learners' knowledge. Five and 6-year-olds, but not 4-year-olds, were more likely to provide exhaustive demonstrations to naïve learners than to knowledgeable learners. These results suggest that by 5 years of age, children are sensitive to overinformativeness and understand the trade-off between informativeness and efficiency; they reason about what others know based on the presence or absence of common ground and flexibly decide how much information is appropriate both as learners and as teachers. (PsycINFO Database Record (c) 2018 APA, all rights reserved).","Gweon H
Shafto P
Schulz L
","(PMID:30265027
)",Development of children's sensitivity to overinformativeness in learning and teaching.,https://europepmc.org/abstract/MED/30265027%0A
"With the popularization of IoT (Internet of Things) devices and the continuous development of machine learning algorithms, learning-based IoT malicious traffic detection technologies have gradually matured. However, learning-based IoT traffic detection models are usually very vulnerable to adversarial samples. There is a great need for an automated testing framework to help security analysts to detect errors in learning-based IoT traffic detection systems. At present, most methods for generating adversarial samples require training parameters of known models and are only applicable to image data. To address the challenge, we propose a testing framework for learning-based IoT traffic detection systems, TLTD. By introducing genetic algorithms and some technical improvements, TLTD can generate adversarial samples for IoT traffic detection systems and can perform a black-box test on the systems.","Liu X
Zhang X
Guizani N
Lu J
Zhu Q
Du X
","(PMID:30103460
 PMCID:PMC6111594)",TLTD: A Testing Framework for Learning-Based IoT Traffic Detection Systems.,https://europepmc.org/abstract/MED/30103460%0A
"Magnetic skyrmions are topologically protected whirling spin texture. Their nanoscale dimensions, topologically protected stability and solitonic nature, together are promising for future spintronics applications. To translate these compelling features into practical spintronic devices, a key challenge lies in achieving effective control of skyrmion properties, such as size, density and thermodynamic stability. Here, we report the discovery of ferroelectrically tunable skyrmions in ultrathin BaTiO3/SrRuO3 bilayer heterostructures. The ferroelectric proximity effect at the BaTiO3/SrRuO3 heterointerface triggers a sizeable Dzyaloshinskii-Moriya interaction, thus stabilizing robust skyrmions with diameters less than a hundred nanometres. Moreover, by manipulating the ferroelectric polarization of the BaTiO3 layer, we achieve local, switchable and nonvolatile control of both skyrmion density and thermodynamic stability. This ferroelectrically tunable skyrmion system can simultaneously enhance the integratability and addressability of skyrmion-based functional devices.","Wang L
Feng Q
Kim Y
Kim R
Lee KH
Pollard SD
Shin YJ
Zhou H
Peng W
Lee D
Meng W
Yang H
Han JH
Kim M
Lu Q
Noh TW
","(PMID:30397313
)",Ferroelectrically tunable magnetic skyrmions in ultrathin oxide heterostructures.,https://europepmc.org/abstract/MED/30397313%0A
"Quantifying dynamic strain fields from time-resolved volumetric medical imaging and microscopy stacks is a pressing need for radiology and mechanobiology. A critical limitation of all existing techniques is regularization: because these volumetric images are inherently noisy, the current strain mapping techniques must impose either displacement regularization and smoothing that sacrifices spatial resolution, or material property assumptions that presuppose a material model, as in hyperelastic warping. Here, we present, validate, and apply the first three-dimensional (3D) method for estimating mechanical strain directly from raw 3D image stacks without either regularization or assumptions about material behavior. We apply the method to high-frequency ultrasound images of mouse hearts to diagnose myocardial infarction. We also apply the method to present the first ever in vivo quantification of elevated strain fields in the heart wall associated with the insertion of the chordae tendinae. The method shows promise for broad application to dynamic medical imaging modalities, including high-frequency ultrasound, tagged magnetic resonance imaging, and confocal fluorescence microscopy.","Boyle JJ
Soepriatna A
Damen F
Rowe RA
Pless RB
Kovacs A
Goergen CJ
Thomopoulos S
Genin GM
","(PMID:30267039
)","Regularization-Free Strain Mapping in Three Dimensions, With Application to Cardiac Ultrasound.",https://europepmc.org/abstract/MED/30267039%0A
"RATIONALE:Chronic alcohol misuse can escalate into alcohol use disorder (AUD). The causal mechanisms through which recreational social drinking develops into compulsive uncontrolled alcohol misuse are multifaceted. For example, stress is an important risk factor that influences alcohol craving in both healthy and addicted individuals. In addition, those that are high in impulsivity/risk taking drink more and are at greater risk of developing addiction. At present, however, it is not possible accurately to predict those at risk of escalation in alcohol use, or of developing AUD. OBJECTIVES:The aim of this study was to investigate how underlying physiological and personality traits affect stress-induced craving for, and consumption of, alcohol, in a sample of social drinkers. The primary hypothesis was that impulsivity/risk-taking would modulate stress-induced alcohol craving and consumption. METHODS:Thirty-nine participants (22 male and 17 female; mean age = 23.92 years [SD = 4.90]) were randomly allocated to 'stress' and 'no-stress' groups; in the stress group, participants took part in the Trier Social Stress Test (TSST). Participants completed several questionnaires and computer tasks in order to assess prior alcohol use, impulsivity/risk-taking, stress-reactivity, craving and physiological biomarkers of stress. Finally, participants completed a voluntary drinking task, in which increasing numbers of presses on a computer keyboard were reinforced with 5-ml shots of 37% ABV vodka (plus mixer). RESULTS:Participants exposed to the TSST showed an increase in craving following the stressor. Several factors predicted voluntary drinking, including risky decision making, slow HR recovery from stress, poor vagal tone during recovery from stress and greater stress reactivity. Surprisingly, we found no correlation between craving and consumption. CONCLUSIONS:Our data suggest that variation in physiological stress parameters and poor decision-making abilities increase risk of stress-induced alcohol consumption. This may provide a useful translational framework through which we can further study early predictive markers for the shift between controlled recreational drinking to uncontrolled alcohol misuse, including AUD.","Clay JM
Parker MO
","(PMID:30209533
 PMCID:PMC6208948)","The role of stress-reactivity, stress-recovery and risky decision-making in psychosocial stress-induced alcohol consumption in social drinkers.",https://europepmc.org/abstract/MED/30209533%0A
No abstract provided.,"Zwicker M
","(PMID:29903964
)",Understanding spatial environments from images.,https://europepmc.org/abstract/MED/29903964%0A
"Investigating functional brain networks and patterns using sparse representation of fMRI data has received significant interests in the neuroimaging community. It has been reported that sparse representation is effective in reconstructing concurrent and interactive functional brain networks. To date, most of data-driven network reconstruction approaches rarely take consideration of anatomical structures, which are the substrate of brain function. Furthermore, it has been rarely explored whether structured sparse representation with anatomical guidance could facilitate functional networks reconstruction. To address this problem, in this paper, we propose to reconstruct brain networks utilizing the structure guided group sparse regression (S2GSR) in which 116 anatomical regions from the AAL template, as prior knowledge, are employed to guide the network reconstruction when performing sparse representation of whole-brain fMRI data. Specifically, we extract fMRI signals from standard space aligned with the AAL template. Then by learning a global over-complete dictionary, with the learned dictionary as a set of features (regressors), the group structured regression employs anatomical structures as group information to regress whole brain signals. Finally, the decomposition coefficients matrix is mapped back to the brain volume to represent functional brain networks and patterns. We use the publicly available Human Connectome Project (HCP) Q1 dataset as the test bed, and the experimental results indicate that the proposed anatomically guided structure sparse representation is effective in reconstructing concurrent functional brain networks.","Zhao Q
Li WXY
Jiang X
Lv J
Lu J
Liu T
","(PMID:28600738
)",Functional brain networks reconstruction using group sparsity-regularized learning.,https://europepmc.org/abstract/MED/28600738%0A
"Predicting how a point mutation alters a protein's stability can guide pharmaceutical drug design initiatives which aim to counter the effects of serious diseases. Conducting mutagenesis studies in physical proteins can give insights about the effects of amino acid substitutions, but such wet-lab work is prohibitive due to the time as well as financial resources needed to assess the effect of even a single amino acid substitution. Computational methods for predicting the effects of a mutation on a protein structure can complement wet-lab work, and varying approaches are available with promising accuracy rates. In this work we compare and assess the utility of several machine learning methods and their ability to predict the effects of single and double mutations. We in silico generate mutant protein structures, and compute several rigidity metrics for each of them. We use these as features for our Support Vector Regression (SVR), Random Forest (RF), and Deep Neural Network (DNN) methods. We validate the predictions of our in silico mutations against experimental Δ Δ G stability data, and attain Pearson Correlation values upwards of 0.71 for single mutations, and 0.81 for double mutations. We perform ablation studies to assess which features contribute most to a model's success, and also introduce a voting scheme to synthesize a single prediction from the individual predictions of the three models.","Dehghanpoor R
Ricks E
Hursh K
Gunderson S
Farhoodi R
Haspel N
Hutchinson B
Jagodzinski F
","(PMID:29382060
 PMCID:PMC6017198)",Predicting the Effect of Single and Multiple Mutations on Protein Structural Stability.,https://europepmc.org/abstract/MED/29382060%0A
"Long non-coding RNAmaternally expressed gene 3 (lncRNAMEG3) plays an important role in mammalian muscle development. Our previous transcriptome study showed that lncRNAMEG3 is differentially expressed during postnatal skeletal muscle development in pigs. The objective of the present study was to analyse the role of lncRNAMEG3 in prenatal and postnatal skeletal muscle development and investigate the association of MEG3 with meat production traits in pigs. We investigated the sequence conservation and temporal-spatial expression of lncRNAMEG3 and identified its core promoter and single nucleotide polymorphisms (SNPs). Our results show that MEG3 is conserved among pig, human and mouse and is expressed in a tissue-specific manner with high expression levels in kidney and leg and dorsal muscles. In addition, MEG3 is more abundant in prenatal muscle compared to postnatal muscle, and its expression peaks at gestational day 60. Notably, we observed almost no expression 40 days after birth. The core promoter of MEG3 is located upstream of the transcription initiation site between -447 and -40 bp. In our SNP linkage disequilibrium and association analyses, four of the 10 potential polymorphism sites were found to be associated with corrected back fat thickness and age to reach 100 kg (rs325797437, rs344501106, rs81286029 and rs318656749). In addition, three haplotypes were found to be associated with differences in corrected age to reach 100 kg (AAAT, AAAT/GGGC, GAAT/GGGC). Our results indicate that MEG3 regulates skeletal muscle development and is a candidate gene for improving meat production traits in pigs.","Yu X
Wang Z
Sun H
Yang Y
Li K
Tang Z
","(PMID:30294799
)",Long non-coding MEG3 is a marker for skeletal muscle development and meat production traits in pigs.,https://europepmc.org/abstract/MED/30294799%0A
[This corrects the article DOI: 10.2196/publichealth.7009.].,"Tatara N
Hammer HL
Andreassen HK
Mirkovic J
Kjøllesdal MKR
","(PMID:30168798
 PMCID:PMC6118225)","Correction: The Association Between Commonly Investigated User Factors and Various Types of eHealth Use for Self-Care of Type 2 Diabetes: Case of First-Generation Immigrants From Pakistan in the Oslo Area, Norway.",https://europepmc.org/abstract/MED/30168798%0A
"A computational semi-empirical model based on electronic radiation damage to medium has been presented to simulate the radial dose distribution. An analytical approach was used to calculate the deposited energy in water per unit mass within a cylindrical shell of unit length around the ion path at a radial distance between r and r + dr, the so-called radial dose distribution, RDD. Detail steps were given and the final radial dose integration over the electron range between Rmin and Rmax was solved numerically using the Mid-Point Method. A validation for the present model was presented by integrating the RDD over all possible radial distances, r to yield the tabulated LET of the ion. The validation was presented for a range of proton ions of different energies. The RDD for heavy charged particles of proton, alpha, Carbon and Oxygen ions of different energies in liquid water were obtained. Good agreement between the present model and experimental, theoretical, and Monte Carlo (Geant4-DNA) data were obtained for all ions under investigations.","Awad EM
El Masady I
Rammah YS
Abu-Shady M
","(PMID:30292957
)",Simulating the radial dose distribution for charged particles in water medium by a semi-empirical model: An analytical approach.,https://europepmc.org/abstract/MED/30292957%0A
"Searching for information is critical in many situations. In medicine, for instance, careful choice of a diagnostic test can help narrow down the range of plausible diseases that the patient might have. In a probabilistic framework, test selection is often modeled by assuming that people's goal is to reduce uncertainty about possible states of the world. In cognitive science, psychology, and medical decision making, Shannon entropy is the most prominent and most widely used model to formalize probabilistic uncertainty and the reduction thereof. However, a variety of alternative entropy metrics (Hartley, Quadratic, Tsallis, Rényi, and more) are popular in the social and the natural sciences, computer science, and philosophy of science. Particular entropy measures have been predominant in particular research areas, and it is often an open issue whether these divergences emerge from different theoretical and practical goals or are merely due to historical accident. Cutting across disciplinary boundaries, we show that several entropy and entropy reduction measures arise as special cases in a unified formalism, the Sharma-Mittal framework. Using mathematical results, computer simulations, and analyses of published behavioral data, we discuss four key questions: How do various entropy models relate to each other? What insights can be obtained by considering diverse entropy models within a unified framework? What is the psychological plausibility of different entropy models? What new questions and insights for research on human information acquisition follow? Our work provides several new pathways for theoretical and empirical research, reconciling apparently conflicting approaches and empirical findings within a comprehensive and unified information-theoretic formalism.","Crupi V
Nelson JD
Meder B
Cevolani G
Tentori K
","(PMID:29911318
)",Generalized Information Theory Meets Human Cognition: Introducing a Unified Framework to Model Uncertainty and Information Search.,https://europepmc.org/abstract/MED/29911318%0A
"Recent studies have built encoding models in the early visual cortex, and reliable mappings have been made between the low-level visual features of stimuli and brain activities. However, these mappings are irreversible, so that the features cannot be directly decoded. To solve this problem, we designed a sparse framework-based encoding model that predicted brain activities from a complete feature representation. Moreover, according to the distribution and activation rules of neurons in the primary visual cortex (V1), three key transformations were introduced into the basic feature to improve the model performance. In this setting, the mapping was simple enough that it could be inverted using a closed-form formula. Using this mapping, we designed a hybrid identification method based on the support vector machine (SVM), and tested it on a published functional magnetic resonance imaging (fMRI) dataset. The experiments confirmed the rationality of our encoding model, and the identification accuracies for 2 subjects increased from 92% and 72% to 98% and 92% with the chance level only 0.8%.","Li C
Xu J
Liu B
","(PMID:29870930
)",Decoding natural images from evoked brain activities using encoding models with invertible mapping.,https://europepmc.org/abstract/MED/29870930%0A
"Key-based substructural fingerprints are an important element of computer-aided drug design techniques. The usefulness of the fingerprints in filtering compound databases is invaluable, as they allow for the quick rejection of molecules with a low probability of being active. However, this method is flawed, as it does not consider the connections between substructures. After changing the connections between particular chemical moieties, the fingerprint representation of the compound remains the same, which leads to difficulties in distinguishing between active and inactive compounds. In this study, we present a new method of compound representation-substructural connectivity fingerprints (SCFP), providing information not only about the presence of particular substructures in the molecule but also additional data on substructure connections. Such representation was analyzed by the recently developed methodology-extreme entropy machines (EEM). The SCFP can be a valuable addition to virtual screening tools, as it represents compound structure with greater detail and more specificity, allowing for more accurate classification.","Rataj K
Czarnecki W
Podlewska S
Pocha A
Bojarski AJ
","(PMID:29789513
 PMCID:PMC6100401)",Substructural Connectivity Fingerprint and Extreme Entropy Machines-A New Method of Compound Representation and Analysis.,https://europepmc.org/abstract/MED/29789513%0A
"Text categorization has been used extensively in recent years to classify plain-text clinical reports. This study employs text categorization techniques for the classification of open narrative forensic autopsy reports. One of the key steps in text classification is document representation. In document representation, a clinical report is transformed into a format that is suitable for classification. The traditional document representation technique for text categorization is the bag-of-words (BoW) technique. In this study, the traditional BoW technique is ineffective in classifying forensic autopsy reports because it merely extracts frequent but discriminative features from clinical reports. Moreover, this technique fails to capture word inversion, as well as word-level synonymy and polysemy, when classifying autopsy reports. Hence, the BoW technique suffers from low accuracy and low robustness unless it is improved with contextual and application-specific information. To overcome the aforementioned limitations of the BoW technique, this research aims to develop an effective conceptual graph-based document representation (CGDR) technique to classify 1500 forensic autopsy reports from four (4) manners of death (MoD) and sixteen (16) causes of death (CoD). Term-based and Systematized Nomenclature of Medicine-Clinical Terms (SNOMED CT) based conceptual features were extracted and represented through graphs. These features were then used to train a two-level text classifier. The first level classifier was responsible for predicting MoD. In addition, the second level classifier was responsible for predicting CoD using the proposed conceptual graph-based document representation technique. To demonstrate the significance of the proposed technique, its results were compared with those of six (6) state-of-the-art document representation techniques. Lastly, this study compared the effects of one-level classification and two-level classification on the experimental results. The experimental results indicated that the CGDR technique achieved 12% to 15% improvement in accuracy compared with fully automated document representation baseline techniques. Moreover, two-level classification obtained better results compared with one-level classification. The promising results of the proposed conceptual graph-based document representation technique suggest that pathologists can adopt the proposed system as their basis for second opinion, thereby supporting them in effectively determining CoD.","Mujtaba G
Shuib L
Raj RG
Rajandram R
Shaikh K
Al-Garadi MA
","(PMID:29738820
)",Classification of forensic autopsy reports through conceptual graph-based document representation model.,https://europepmc.org/abstract/MED/29738820%0A
"In this paper, we propose a novel technique termed as optimized swarm search-based feature selection (OS-FS), which is a swarm-type of searching function that selects an ideal subset of features for enhanced classification accuracy. In terms of gaining insights from unstructured medical based texts, sentiment prediction is becoming an increasingly crucial machine learning technique. In fact, due to its robustness and accuracy, it recently gained popularity in the medical industries. Medical text mining is well known as a fundamental data analytic for sentiment prediction. To form a high-dimensional sparse matrix, a popular preprocessing step in text mining is employed to transform medical text strings to word vectors. However, such a sparse matrix poses problems to the induction of accurate sentiment prediction model. The swarm search in our proposed OS-FS can be optimized by a new feature evaluation technique called clustering-by-coefficient-of-variation. In order to find a subset of features from all the original features from the sparse matrix, this type of feature selection has been a commonly utilized dimensionality reduction technique, and has the capability to improve accuracy of the prediction model. We implement this method based on a case scenario where 279 medical articles related to 'meaningful use functionalities on health care quality, safety, and efficiency' from a systematic review of previous medical IT literature. For this medical text mining, a multi-class of sentiments, positive, mixed-positive, neutral and negative is recognized from the document contents. Our experimental results demonstrate the superiority of OS-FS over traditional feature selection methods in literature.","Zeng D
Peng J
Fong S
Qiu Y
Wong R
","(PMID:30206813
)",Medical data mining in sentiment analysis based on optimized swarm search feature selection.,https://europepmc.org/abstract/MED/30206813%0A
No abstract provided.,"Mohammadnejad A
Brasch-Andersen C
Li W
Haagerup A
Baumbach J
Tan Q
","(PMID:29981864
)",A case-only genome-wide association study on gene-sex interaction in allergic rhinitis.,https://europepmc.org/abstract/MED/29981864%0A
"Ultraviolet (UV) mutagenesis is a widely used technique to increase bacterial mutation rates in laboratory experiments. UV mutagenesis requires fine regulation of UV dose, because the number of dead cells increases exponentially as the dose increases. Ignoring this hazard can cause extinction of UV-exposed populations. Therefore, an automated system that cooperatively conducts both growth measurement and UV irradiation is needed for efficient UV mutagenesis experiments. To address this task, we constructed an automated UV irradiation device for microbial cell culture. This device can measure cell density and irradiate the bacterial cells with UV light automatically according to the state of cell growth. We demonstrated that this growth feedback control avoided extinction and enabled accumulation of mutations in bacterial genomes at a rapid rate for a long period. Whole-genome sequencing revealed the high accumulation rate, neutrality, and spectrum of UV-induced mutations. These characteristics were all consistent with those obtained by manual UV irradiation. These results indicate that our automated device is useful in accelerating mutation accumulation over a long duration.","Shibai A
Tsuru S
Yomo T
","(PMID:30199651
)",Development of an Automated UV Irradiation Device for Microbial Cell Culture.,https://europepmc.org/abstract/MED/30199651%0A
"Nucleation-elongation is known to give satisfactory descriptions of many supramolecular polymerization systems in thermal equilibrium. Its key feature is the necessity to form a ""nucleus"" consisting of a certain number of monomer units before being able to grow into a longer polymer chain. The size of the nucleus has significant implications for the understanding of the supramolecular polymerization mechanism. Here we investigate how experiments can give information on the nucleus size by regression analysis of various types of measurements. The measurements of free monomer concentrations, diffusion coefficients, and calorimetric response as functions of concentration or temperature are considered. The nucleation-elongation model with a general value for the nucleus size is used to provide mathematical expressions for these experimental observables. Numerical experiments are performed where experimental errors are simulated by computer-generated random numbers, and it is investigated whether least-squares fitting analyses can give the correct values of the nucleus size in the presence of experimental errors. It is recommended that the calorimetric measurements such as differential scanning calorimetry (DSC) or isothermal titration calorimetry (ITC) be performed under various conditions to correctly determine the nucleus size experimentally.","Kawai S
Kuni M
Sugiyasu K
","(PMID:30216068
)",Regression Analysis for Nucleation-Elongation Model of Supramolecular Assembly: How To Determine Nucleus Size.,https://europepmc.org/abstract/MED/30216068%0A
"Respiratory gating reduces motion blurring in cardiac SPECT. Here we aim to evaluate the performance of three respiratory gating strategies using a population of digital phantoms with known truth and clinical data.We analytically simulated 60 projections for 10 XCAT phantoms with 99mTc-sestamibi distributions using three gating schemes: equal amplitude gating (AG), equal count gating (CG), and equal time gating (TG). Clinical list-mode data for 10 patients who underwent 99mTc-sestamibi scans were also processed using the 3 gating schemes. Reconstructed images in each gate were registered to a reference gate, averaged and reoriented to generate the polar plots. For simulations, image noise, relative difference (RD) of averaged count for each of the 17 segment, and relative defect size difference (RSD) were analyzed. For clinical data, image intensity profile and FWHM were measured across the left ventricle wall.For simulations, AG and CG methods showed significantly lower RD and RSD compared to TG, while noise variation was more non-uniform through different gates for AG. In the clinical study, AG and CG had smaller FWHM than TG.AG and CG methods show better performance for motion reduction and are recommended for clinical respiratory gating SPECT implementation.","Zhang D
Pretorius PH
Ghaly M
Zhang Q
King MA
Mok GSP
","(PMID:30088195
)",Evaluation of different respiratory gating schemes for cardiac SPECT.,https://europepmc.org/abstract/MED/30088195%0A
"Metasurfaces provide a versatile platform for manipulating the wavefront of light using planar nanostructured surfaces. Transmissive metasurfaces, with full 2π phase control, are a particularly attractive platform for replacing conventional optical elements due to their small footprint and broad functionality. However, the operational bandwidth of metasurfaces has been a critical limitation and is directly connected to either their resonant response or the diffractive dispersion of their lattice. While multiwavelength and continuous band operation have been demonstrated, the elements suffer from either low efficiency, reduced imaging quality, or limited element size. Here, we propose a platform that provides for multiwavelength operation by employing tightly spaced multilayer dielectric metasurfaces. As a proof of concept, we demonstrate a multiwavelength metalens doublet (NA = 0.42) with focusing efficiencies of 38% and 52% at wavelengths of 1180 and 1680 nm, respectively. We further show how this approach can be extended to three-wavelength metalenses as well as a spectral splitter. This approach could find applications in fluorescent microscopy, digital imaging, and color routing.","Zhou Y
Kravchenko II
Wang H
Nolen JR
Gu G
Valentine J
","(PMID:30394751
)",Multilayer Noninteracting Dielectric Metasurfaces for Multiwavelength Metaoptics.,https://europepmc.org/abstract/MED/30394751%0A
"The flexibility of biological macromolecules is an important structural determinant of function. Unfortunately, the correlations between different motional modes are poorly captured by discrete ensemble representations. Here, we present new ways to both represent and visualize correlated interdomain motions. Interdomain motions are determined directly from residual dipolar couplings, represented as a continuous conformational distribution, and visualized using the disk-on-sphere representation. Using the disk-on-sphere representation, features of interdomain motions, including correlations, are intuitively visualized. The representation works especially well for multidomain systems with broad conformational distributions.This analysis also can be extended to multiple probability density modes, using a Bingham mixture model. We use this new paradigm to study the interdomain motions of staphylococcal protein A, which is a key virulence factor contributing to the pathogenicity of Staphylococcus aureus. We capture the smooth transitions between important states and demonstrate the utility of continuous distribution functions for computing the reorientational components of binding thermodynamics. Such insights allow for the dissection of the dynamic structural components of functionally important intermolecular interactions.","Qi Y
Martin JW
Barb AW
Thélot F
Yan AK
Donald BR
Oas TG
","(PMID:29924964
)",Continuous Interdomain Orientation Distributions Reveal Components of Binding Thermodynamics.,https://europepmc.org/abstract/MED/29924964%0A
"The International Society of Computational Biology and Bioinformatics (ISCB) brings together scientists from a wide range of disciplines, including biology, medicine, computer science, mathematics and statistics. Practitioners in these fields are constantly dealing with information in visual form: from microscope images and photographs of gels to scatter plots, network graphs and phylogenetic trees, structural formulae and protein models to flow diagrams, visual aids for problem-solving are omnipresent. The ISCB Art in Science Competition2017 at the ISCB/ECCB 2017 conference in Prague offered a way to show the beauty of science in art form. Past artworks in this annual exhibition at ISMB combined outstanding beauty and aesthetics with deep insight that perfectly validated the exhibit's approach or went beyond the problem's solution. Others were surprising and inspiring through the transition from science to art, opening eyes and minds to reflect on the work being undertaken.","Welch L
Gaeta B
Kovats DE
Frenkel Morgenstern M
","(PMID:29623191
 PMCID:PMC5861520)",Art in Science Competition invites artworks to the annual exhibition on ISMB 2018 in Chicago.,https://europepmc.org/abstract/MED/29623191%0A
"Arrhythmias are one of the most common symptoms of cardiac failure. They are usually diagnosed using ECG recordings, particularly long ambulatory recordings (AECG). These recordings are tedious to interpret by humans due to their extent (up to 48 h) and the relative scarcity of arrhythmia events. This makes automated systems for detecting various AECG anomalies indispensable. In this work we present a novel procedure based on topological principles (Morse theory) for detecting arrhythmic beats in AECG. It works in nearly real-time (delayed by a 14 s window), and can be applied to raw (unprocessed) ECG signals.The procedure is based on a subject-specific adaptation of the one-dimensional discrete Morse theory (ADMT), which represents the signal as a sequence of its most important extrema. The ADMT algorithm is applied twice; for low-amplitude, high-frequency noise removal, and for detection of the characteristic waves of individual ECG beats. The waves are annotated using the ADMT algorithm and template matching. The annotated beats are then compared to the adjacent beats with two measures of similarity: the distance between two beats, and the difference in shape between them. The two measures of similarity are used as inputs to a decision tree algorithm that classifies the beats as normal or abnormal. The classification performance is evaluated with the leave-one-record-out cross-validation method.Our approach was tested on the MIT-BIH database, where it exhibited a classification accuracy of 92.73%, a sensitivity of 73.35%, a specificity of 96.70%, a positive predictive value of 88.01%, and a negative predictive value of 95.73%.Compared to related studies, our algorithm requires less preprocessing while retaining the capability to detect and classify beats in almost real-time. The algorithm exhibits a high degree of accuracy in beats detection and classification that are at least comparable to state-of-the-art methods.","Faganeli Pucer J
Kukar M
","(PMID:30195424
)",A topological approach to delineation and arrhythmic beats detection in unprocessed long-term ECG signals.,https://europepmc.org/abstract/MED/30195424%0A
"Since the advent of transformation optics and scattering cancelling technology, a plethora of unprecedented metamaterials, especially invisibility cloaks, have been successfully demonstrated in various communities, e.g., optics, acoustics, elastic mechanics, dc electric field, dc magnetic field, and thermotics. A long-held captivation is that transformation-optic metamaterials of anisotropic or noncentrosymmetric geometry (e.g., ellipsoids) commonly come along with parameter approximation/simplification or directional functions. Here, a synthetic paradigm with strictly full parameters and omnidirectionality is reported simultaneously to address this long-held issue for molding heat flow and experimentally demonstrate a series of noncentrosymmetric thermal metadevices. It changes the usual perception that transformation thermotic/dc/acoustic metamaterials are just a direct and simplified derivatives of the transformation-optic counterpart. Instead, the proposed methodology solves an intriguingly important and challenging problem that is not possibly achievable for transformation-optic metamaterials. The approach is rigorous, exact, robust, and yet elegantly facile, which may open a new avenue to manipulating the Laplacian and wave-dynamic fields in ways previously inconceivable.","Han T
Yang P
Li Y
Lei D
Li B
Hippalgaonkar K
Qiu CW
","(PMID:30311275
)",Full-Parameter Omnidirectional Thermal Metadevices of Anisotropic Geometry.,https://europepmc.org/abstract/MED/30311275%0A
"The hierarchy of social organization is a ubiquitous property of animal and human groups, linked to resource allocation, collective decisions, individual health, and even to social instability. Experimental evidence shows that both the intrinsic abilities of individuals and social reinforcement processes impact hierarchies; existing mathematical models, however, focus on the latter. Here, we develop a rigorous model that incorporates both features and explore their synergistic effect on stability and the structure of hierarchy. For pairwise interactions, we show that there is a trade-off between relationship stability and having the most talented individuals in the highest ranks. Extending this to open societies, where individuals enter and leave the population, we show that important societal effects arise from the interaction between talent and social processes: (i) Despite a positive global correlation between talent and rank, paradoxically, local correlation is negative, and (ii) the removal of an individual can induce a series of rank reversals. We show that the mechanism underlying the latter is the removal of an older individual of limited talent, who nonetheless was able to suppress the rise of younger, more talented individuals.","Pósfai M
D'Souza RM
","(PMID:30253624
)",Talent and experience shape competitive social hierarchies.,https://europepmc.org/abstract/MED/30253624%0A
"This paper presents our efforts to detect Concept Drifts (changes in data generation processes), using the Cross-Recurrence Quantification Analysis, on time series produced by social network systems. Experiments were performed on the TSViz project (http://www.tsviz.com.br), which collects online tweets associated with predefined hashtags and processes them to generate different time series: one to measure the amount of information contained in textual short messages and another to quantify the positiveness and negativeness of users' sentiments, etc. In that context, this work proposed and evaluated a Concept Drift approach to point out when generating processes change along time, indicating the detection of relevant textual changes in terms of the amount of information and sentiments. As a main contribution, results show that our approach indicates when the most important social events happen, which were confirmed by official news.","de Mello RF
Rios RA
Pagliosa PA
Lopes CS
","(PMID:30180606
)",Concept drift detection on social network data using cross-recurrence quantification analysis.,https://europepmc.org/abstract/MED/30180606%0A
"Aging invokes physiological changes, such as immunosenescence and inflammation, that could increase host susceptibility to oral microbiome shifts that enable periodontitis progression in later life. At present, there is a dearth of studies specifically evaluating the oral microbiome and periodontitis in older adults. We used high-throughput untargeted sequencing methods and functional metagenomic analyses to assess and compare the subgingival biofilm of postmenopausal women (mean age 71 years) according to periodontitis status. Subgingival plaque samples were obtained from 15 postmenopausal women with no periodontitis, and from 15 women with severe periodontitis, determined by probing measures. The 16S rRNA gene (V1⁻V3 region) was sequenced on the 454 FLX platform. The PICRUSt technique was used to provide information on what the potential functional characteristics of microbiota might be in healthy, compared with diseased, periodontium. The subgingival microbiome associated with periodontitis showed clear differences to that associated with health. Of the 464 species identified, 22.8% had elevated abundance in disease, while only 6.3% had elevated abundance in health. Among the 12 most prevalent organisms in periodontitis, one-half have previously been recognized as periodontal pathogens by other investigators. The subgingival microbiome in periodontitis contained genes that could code for specific activities, including microbial mobility, synthesis of endotoxin, and proteolytic degradation. The healthy microbiome included genes that could code for sustaining microbial life, including encoding for transporters, glycolysis, gluconeogenesis, the Krebs cycle, and protein kinases. In the present study on postmenopausal women, aged 60 and older, the subgingival microbiome differed in composition and potential function between those with and without periodontitis. Studies of functional gene expression, such as transcriptomics, are needed to definitively identify the molecules carrying out functions associated with pathogenic subgingival complexes. This, in turn, could lead to identification of targets for enhanced management of periodontitis and, possibly, other diseases, in later life.","LaMonte MJ
Genco RJ
Zheng W
McSkimming DI
Andrews CA
Hovey KM
Li L
Sun Y
Buck MJ
Millen AE
Falkner KL
Wactawski-Wende J
","(PMID:30347640
)",Substantial Differences in the Subgingival Microbiome Measured by 16S Metagenomics According to Periodontitis Status in Older Women.,https://europepmc.org/abstract/MED/30347640%0A
"Structural connectivity plays a dominant role in brain function and arguably lies at the core of understanding the structure-function relationship in the cerebral cortex. Connectivity-based cortex parcellation (CCP), a framework to process structural connectivity information gained from diffusion MRI and diffusion tractography, identifies cortical subunits that furnish functional inference. The underlying pipeline of algorithms interprets similarity in structural connectivity as a segregation criterion. Validation of the CCP-pipeline is critical to gain scientific reliability of the algorithmic processing steps from dMRI data to voxel grouping. In this paper we provide a proof of concept based upon a novel model validation principle that characterizes the trade-off between informativeness and robustness to assess the validity of the CCP pipeline, including diffusion tractography and clustering. We ultimately identify a pipeline of algorithms and parameter settings that tolerate more noise and extract more information from the data than their alternatives.","Gorbach NS
Tittgemeyer M
Buhmann JM
","(PMID:29981484
)",Pipeline validation for connectivity-based cortex parcellation.,https://europepmc.org/abstract/MED/29981484%0A
"BACKGROUND:Unreliable neuronavigation owing to inaccurate patient-to-image registration and brain shift is a major problem in conventional magnetic resonance imaging-guided neurosurgery. We performed a prospective intraoperative validation of a system for fully automatic correction of this inaccuracy based on intraoperative three-dimensional ultrasound and magnetic resonance imaging-to-ultrasound registration. METHODS:The system was tested intraoperatively in 13 tumor resection cases, and performance was evaluated intraoperatively and postoperatively. RESULTS:Intraoperatively, the system was accurate enough for tumor resection guidance in 9 of 13 cases. Manually placed anatomic landmarks showed improvement of alignment from 5.12 mm to 2.72 mm (median) after intraoperative correction. Postoperatively, the limitations of the current system were identified and modified for the system to be sufficiently accurate in all cases. CONCLUSIONS:Automatic and accurate correction of spatially unreliable neuronavigation is feasible within the constraints of surgery. The current limitations of the system were also identified and addressed.","Iversen DH
Wein W
Lindseth F
Unsgård G
Reinertsen I
","(PMID:30213682
)",Automatic Intraoperative Correction of Brain Shift for Accurate Neuronavigation.,https://europepmc.org/abstract/MED/30213682%0A
"Landmark-based goal-searching tasks that were similar to those for pigeons (Ushitani & Jitsumori, 2011) were provided to human participants to investigate whether they could learn and use multiple sources of spatial information that redundantly indicate the position of a hidden target in both an open field (Experiment 1) and on a computer screen (Experiments 2 and 3). During the training in each experiment, participants learned to locate a target in 1 of 25 objects arranged in a 5 × 5 grid, using two differently colored, arrow-shaped (Experiments 1 and 2) or asymmetrically shaped (Experiment 3) landmarks placed adjacent to the goal and pointing to the goal location. The absolute location and directions of the landmarks varied across trials, but the constant configuration of the goal and the landmarks enabled participants to find the goal using both global configural information and local vector information (pointing to the goal by each individual landmark). On subsequent test trials, the direction was changed for one of the landmarks to conflict with the global configural information. Results of Experiment 1 indicated that participants used vector information from a single landmark but not configural information. Further examinations revealed that the use of global (metric) information was enhanced remarkably by goal searching with nonarrow-shaped landmarks on the computer monitor (Experiment 3) but much less so with arrow-shaped landmarks (Experiment 2). The General Discussion focuses on a comparison between humans in the current study and pigeons in the previous study. (PsycINFO Database Record","Sekiguchi K
Ushitani T
Sawa K
","(PMID:29517247
)",Use of redundant sets of landmark information by humans (Homo sapiens) in a goal-searching task in an open field and on a computer screen.,https://europepmc.org/abstract/MED/29517247%0A
No abstract provided.,"Fogg CN
Kovats DE
Shamir R
","(PMID:29879101
 PMCID:PMC5991638)",2018 ISCB Innovator Award recognizes M. Madan Babu.,https://europepmc.org/abstract/MED/29879101%0A
"We construct and analyze piecewise approximations of functional data on arbitrary 2D bounded domains using generalized barycentric finite elements, and particularly quadratic serendipity elements for planar polygons. We compare approximation qualities (precision/convergence) of these partition-of-unity finite elements through numerical experiments, using Wachspress coordinates, natural neighbor coordinates, Poisson coordinates, mean value coordinates, and quadratic serendipity bases over polygonal meshes on the domain. For a convex n-sided polygon, the quadratic serendipity elements have 2n basis functions, associated in a Lagrange-like fashion to each vertex and each edge midpoint, rather than the usual n(n + 1)/2 basis functions to achieve quadratic convergence. Two greedy algorithms are proposed to generate Voronoi meshes for adaptive functional/scattered data approximations. Experimental results show space/accuracy advantages for these quadratic serendipity finite elements on polygonal domains versus traditional finite elements over simplicial meshes. Polygonal meshes and parameter coefficients of the quadratic serendipity finite elements obtained by our greedy algorithms can be further refined using an L2-optimization to improve the piecewise functional approximation. We conduct several experiments to demonstrate the efficacy of our algorithm for modeling features/discontinuities in functional data/image approximation.","Cao J
Xiao Y
Chen Z
Wang W
Bajaj C
","(PMID:29892139
)",Functional Data Approximation on Bounded Domains using Polygonal Finite Elements.,https://europepmc.org/abstract/MED/29892139%0A
"Photo-anthropometry is a metric-based facial image comparison technique where measurements of the face are taken from an image using predetermined facial landmarks. In particular, dimensions and proportionality indices (DPIs) are compared to DPIs from another facial image. Different studies concluded that photo-anthropometric facial comparison, as it is currently practiced, is unsuitable for elimination purposes. The major limitation is the need for images acquired under very restrictive, controlled conditions. To overcome this latter issue, we propose a novel methodology to estimate 3D DPIs from 2D ones. It uses computer graphic techniques to simulate thousands of facial photographs under known camera conditions and regression to derive the mathematical relationship between 2D and 3D DPIs automatically. Additionally, we present a methodology that makes use of the estimated 3D DPIs for reducing the number of potential matches of a given unknown facial photograph within a set of known candidates. The error in the estimation of the 3D DPIs can be as large as 35%, but both I and III quartiles are consistently inside the ±5% range. The methodology for filtering cases has demonstrated to be useful in the task of narrowing down the list of possible candidates for a given photograph. It is able to remove on average (validated using cross-validation technique) 57% and 24% of the negative cases, depending on the amounts of DPIs available. Limitations of the work developed together with open research lines are included within the Discussion section.","Martos R
Valsecchi A
Ibáñez O
Alemán I
","(PMID:29665481
)",Estimation of 2D to 3D dimensions and proportionality indices for facial examination.,https://europepmc.org/abstract/MED/29665481%0A
"Natural life is encoded by evolvable, DNA-based memory. Recent advances in dynamic genome-engineering technologies, which we collectively refer to as in vivo DNA writing, have opened new avenues for investigating and engineering biology. This Review surveys these technological advances, outlines their prospects and emerging applications, and discusses the features and current limitations of these technologies for building various genetic circuits for processing and recording information in living cells.","Farzadfard F
Lu TK
","(PMID:30166483
)",Emerging applications for DNA writers and molecular recorders.,https://europepmc.org/abstract/MED/30166483%0A
"Recent genome-wide association studies have identified various dyslipidemia-related genetic variants. However, most studies were conducted in a cross-sectional manner. We thus performed longitudinal exome-wide association studies of dyslipidemia in a Japanese population. We used ~244,000 genetic variants and clinical data of 6022 Japanese individuals who had undergone annual health checkups for several years. After quality control, the association of dyslipidemia-related phenotypes with 24,691 single nucleotide polymorphisms (SNPs) was tested using the generalized estimating equation model. In total, 82 SNPs were significantly (P < 2.03 × 10-6) associated with dyslipidemia phenotypes. Of these SNPs, four (rs74416240 of TCHP, rs925368 of GIT2, rs7969300 of ATXN2, and rs12231744 of NAA25) and two (rs34902660 of SLC17A3 and rs1042127 of CDSN) were identified as novel genetic determinants of hypo-HDL- and hyper-LDL-cholesterolemia, respectively. A replication study using the cross-sectional data of 8310 Japanese individuals showed the association of the six identified SNPs with dyslipidemia-related traits.","Yasukochi Y
Sakuma J
Takeuchi I
Kato K
Oguri M
Fujimaki T
Horibe H
Yamada Y
","(PMID:29879492
)",Identification of six novel susceptibility loci for dyslipidemia using longitudinal exome-wide association studies in a Japanese population.,https://europepmc.org/abstract/MED/29879492%0A
"Gram-negative bacteria are one of the most common microorganisms in the environment. Their differential detection and recognition from Gram-positive bacteria has been attracting much attention over the years. Using Escherichia coli (E. coli) as a model, we demonstrated on-site detection of Gram-negative bacteria by an AC electrokinetics-based capacitive sensing method using commercial microelectrodes functionalized with an aptamer specific to lipopolysaccharides. Dielectrophoresis effect was utilized to enrich viable bacteria to the microelectrodes rapidly, achieving a detection limit of 102 cells/mL within a 30 s' response time. The sensor showed a negligible response to Staphylococcus aureus (S. aureus), a Gram-positive species. The developed sensor showed significant advantages in sensitivity, selectivity, cost, operation simplicity, and response time. Therefore, this sensing method has shown great application potential for environmental monitoring, food safety, and real-time diagnosis.","Zhang J
Oueslati R
Cheng C
Zhao L
Chen J
Almeida R
Wu J
","(PMID:29698808
)","Rapid, highly sensitive detection of Gram-negative bacteria with lipopolysaccharide based disposable aptasensor.",https://europepmc.org/abstract/MED/29698808%0A
"Antimicrobial resistant pathogens are a growing worldwide threat to human health. This study describes a novel method for rapid and sensitive detection of antimicrobial resistance (AMR) genes, specifically blaCTX-M-15 which encodes for the enzyme that offers resistance to extended spectrum β-lactam antibiotics. The method combines isothermal DNA amplification by recombinase polymerase amplification (RPA), with microbead dielectrophoresis (DEP)-based DNA detection. The RPA amplicon is captured onto dielectric microbeads, and the amount of amplicon determined by dielectrophoretic impedance measurement (DEPIM) of the microbeads. Amplicon-labeled microbeads were prepared by either a two-step or one-step method. A purified recombinant plasmid containing blaCTX-M-15 and genomic DNA (with plasmid) extracted from an AMR bacteria (Escherichia coli NCTC 13441) were used as target samples. A one-step method in which RPA and DNA immobilization on the microbeads is carried out simultaneously, has a detection limit of 2 copies/reaction for pure plasmid and 50 copies/reaction for genomic DNA. The assays are quantitative with a dynamic range up to 105 copies/reaction, with a total detection time of 26 min. Both methods are easy, rapid, and unlike lateral flow detection are quantitative.","Nakano M
Kalsi S
Morgan H
","(PMID:30005377
)",Fast and sensitive isothermal DNA assay using microbead﻿ dielectrophoresis for detection of anti-microbial resistance genes.,https://europepmc.org/abstract/MED/30005377%0A
"To examine whether there were any associations between high-resolution cervical auscultation (HRCA) acoustic signals recorded by a contact microphone and swallowing kinematic events during pharyngeal swallow as assessed by a videofluoroscopic (VF) examination.Prospective pilot study.University teaching hospital, university research laboratories.Patients (N=35) with stroke who have suspected dysphagia (26 men + 9 women; age = 65.8±11.2).VF recordings of 100 liquid swallows from 35 stroke patients were analyzed, and a variety of HRCA signal features to characterize each swallow were calculated.Percent of signal feature maxima (peak) occurring within 0.1 seconds of swallow kinematic event identified from VF recording.Maxima of HRCA signal features, such as standard deviation, skewness, kurtosis, centroid frequency, bandwidth, and wave entropy, were associated with hyoid elevation, laryngeal vestibule closure, and upper esophageal sphincter opening, and the contact of the base of the tongue and posterior pharyngeal wall.Although the kinematic source of HRCA acoustic signals has yet to be fully elucidated, these results indicate a strong relationship between these HRCA signals and several swallow kinematic events. There is a potential for HRCA to be developed for diagnostic and rehabilitative clinical management of dysphagia.","Kurosu A
Coyle JL
Dudik JM
Sejdic E
","(PMID:30071198
)",Detection of Swallow Kinematic Events From Acoustic High-Resolution Cervical Auscultation Signals in Patients With Stroke.,https://europepmc.org/abstract/MED/30071198%0A
No abstract provided.,"Koprowski R
Nowińska A
Wilczynski S
Lanza M
Molebny V
Ambrosio R Jr
","(PMID:29887981
 PMCID:PMC5985124)",Image Processing in Ophthalmology.,https://europepmc.org/abstract/MED/29887981%0A
"PURPOSE:Automated segmentation of torso organs from positron emission tomography/computed tomography (PET/CT) images is a prerequisite step for nuclear medicine image analysis. However, accurate organ segmentation from clinical PET/CT is challenging due to the poor soft tissue contrast in the low-dose CT image and the low spatial resolution of the PET image. To overcome these challenges, we developed a multi-atlas segmentation (MAS) framework for torso organ segmentation from 2-deoxy-2-[18F]fluoro-D-glucose PET/CT images. METHOD:Our key idea is to use PET information to compensate for the imperfect CT contrast and use surface-based atlas fusion to overcome the low PET resolution. First, all the organs are segmented from CT using a conventional MAS method, and then the abdomen region of the PET image is automatically cropped. Focusing on the cropped PET image, a refined MAS segmentation of the abdominal organs is performed, using a surface-based atlas fusion approach to reach subvoxel accuracy. RESULTS:This method was validated based on 69 PET/CT images. The Dice coefficients of the target organs were between 0.80 and 0.96, and the average surface distances were between 1.58 and 2.44 mm. Compared to the CT-based segmentation, the PET-based segmentation gained a Dice increase of 0.06 and an ASD decrease of 0.38 mm. The surface-based atlas fusion leads to significant accuracy improvement for the liver and kidneys and saved ~ 10 min computation time compared to volumetric atlas fusion. CONCLUSIONS:The presented method achieves better segmentation accuracy than conventional MAS method within acceptable computation time for clinical applications.","Wang H
Zhang N
Huo L
Zhang B
","(PMID:30390179
)",Dual-modality multi-atlas segmentation of torso organs from [18F]FDG-PET/CT images.,https://europepmc.org/abstract/MED/30390179%0A
"Sigma promoter sequences in bacterial genomes are important due to their role in transcription initiation. Sigma 70 is one of the most important and crucial sigma factors. In this paper, we address the problem of identification of σ70 promoter sequences in bacterial genome. We propose iPromoter-FSEn, a novel predictor for identification of σ70 promoter sequences. Our proposed method is based on a feature subspace based ensemble classifier. A large set of of features extracted from the sequence of nucleotides are divided into subsets and each subset is given to individual single classifiers to learn. Based on the decisions of the ensemble an aggregate decision is made by the ensemble voting classifier. We tested our method on a standard benchmark dataset extracted from experimentally validated results. Experimental results shows that iPromoter-FSEn significantly improves over the state-of-the art σ70 promoter sequence predictors. The accuracy and area under receiver operating characteristic curve of iPromoter-FSEn are 86.32% and 0.9319 respectively. We have also made our method readily available for use as an web application from: http://ipromoterfsen.pythonanywhere.com/server.","Rahman MS
Aktar U
Jani MR
Shatabda S
","(PMID:30059731
)",iPromoter-FSEn: Identification of bacterial σ70 promoter sequences using feature subspace based ensemble classifier.,https://europepmc.org/abstract/MED/30059731%0A
"Glaucoma is a neurodegenerative illness and is considered as a standout amongst the most widely recognized reasons for visual impairment. Nerve's degeneration is an irretrievable procedure, so the diagnosis of the illness at an early stage is an absolute requirement to stay away from lasting loss of vision. Glaucoma effected mainly because of increased intraocular pressure, if it is not distinguished and looked early, it can result in visual impairment. There are not generally evident side effects of glaucoma; thus, patients attempt to get treatment just when the seriousness of malady is advanced altogether. Determination of glaucoma often comprises of review of the basic crumbling of the nerve in conjunction with the examination of visual function capacity. This article shows the persistent illustration of glaucoma, its side effects, and the potential people inclined to this malady. The essence of this article is on different classification methods being utilized and proposed by various scientists for the identification of glaucoma. This article audits a few division and segmentation methodologies that are exceptionally useful for recognizable proof, identification, and diagnosis of glaucoma. The research related to the findings and the treatment is likewise evaluated in this article.","Saba T
Bokhari STF
Sharif M
Yasmin M
Raza M
","(PMID:30281861
)",Fundus image classification methods for the detection of glaucoma: A review.,https://europepmc.org/abstract/MED/30281861%0A
"High-throughput technology has generated large-scale protein interaction data, which is crucial in our understanding of biological organisms. Many complex identification algorithms have been developed to determine protein complexes. However, these methods are only suitable for dense protein interaction networks, because their capabilities decrease rapidly when applied to sparse protein⁻protein interaction (PPI) networks. In this study, based on penalized matrix decomposition (PMD), a novel method of penalized matrix decomposition for the identification of protein complexes (i.e., PMDpc) was developed to detect protein complexes in the human protein interaction network. This method mainly consists of three steps. First, the adjacent matrix of the protein interaction network is normalized. Second, the normalized matrix is decomposed into three factor matrices. The PMDpc method can detect protein complexes in sparse PPI networks by imposing appropriate constraints on factor matrices. Finally, the results of our method are compared with those of other methods in human PPI network. Experimental results show that our method can not only outperform classical algorithms, such as CFinder, ClusterONE, RRW, HC-PIN, and PCE-FR, but can also achieve an ideal overall performance in terms of a composite score consisting of F-measure, accuracy (ACC), and the maximum matching ratio (MMR).","Cao B
Deng S
Qin H
Ding P
Chen S
Li G
","(PMID:29914123
 PMCID:PMC6100434)",Detection of Protein Complexes Based on Penalized Matrix Decomposition in a Sparse Protein⁻Protein Interaction Network.,https://europepmc.org/abstract/MED/29914123%0A
No abstract provided.,"Solari F
Chessa M
Chinellato E
Bresciani JP
","(PMID:30073022
 PMCID:PMC6057347)","Advances in Human-Computer Interactions: Methods, Algorithms, and Applications.",https://europepmc.org/abstract/MED/30073022%0A
"Development of Mitsucal. Recent advances in DNA sequencing technology have facilitated whole-genome sequencing of mutants and variants. However, the analyses of large sequence datasets using a computer remain more difficult than operating a sequencer. Forward genetic approach is powerful even in sexual reproduction to identify key genes. Therefore, we developed the Mitsucal computer system for identifying causal genes of mutants, using whole-genome sequence data. Mitsucal includes a user-friendly web interface to configure analysis variables, such as background and crossed strains. Other than configuration, users are only required to upload short reads. All results are presented through a web interface where users can easily obtain a short list of candidate mutations. In the present study, we present three examples of Arabidopsis mutants defective in sexual reproduction in which Mitsucal is used to identify causal mutation. One mutant was screened from seeds of a transgenic line with a reporter gene to elucidate the mechanisms involved in the regulation of seed oil storage. The identified gene codes for a protein may be involved in mRNA splicing. Other two mutants had defects in the surface walls on pollen termed exine. Both causal genes were identified, and mutants were found to be allele of known mutants. These results show that Mitsucal could facilitate identification of causal genes.","Suzuki T
Kawai T
Takemura S
Nishiwaki M
Suzuki T
Nakamura K
Ishiguro S
Higashiyama T
","(PMID:29497825
)",Development of the Mitsucal computer system to identify causal mutation with a high-throughput sequencer.,https://europepmc.org/abstract/MED/29497825%0A
"The main objective of our research was to analyze the structure of the Se-containing polysaccharides and to examine how the selenium is bound to the polysaccharide molecule. During investigation of the biosynthesis of new immunomodulators, we isolated a selenium (Se)-containing polysaccharide-protein fraction containing proteoglycans of molecular weights of 3.9 × 106 Da and 2.6 × 105 Da, composed of glucose or mannose, nearly 8% of protein and 190 μg Se/g dry weight. X-ray absorption spectroscopy (XAS) data analysis in the near edge region (XANES) confirmed that selenium in the Se-polysaccharides structure is present at the -II oxidation state and that Se is organically bound. The simulation analysis in the EXAFS (extended X-ray absorption fine structure) region suggested that selenium is most likely bound by a glycosidic-link in a β-1,3 or α-1,4-glycosidic bond or substituted for oxygen in a pyranosidic ring. Calculations performed with Gaussian 03 software predicted deformations in the polysaccharide structure caused by the incorporation of the selenium atom including change in bond lengths and torsion angles and, as a result, disappearance of hydrogen bonds in the vicinity of the selenium atoms.","Malinowska E
Klimaszewska M
Strączek T
Schneider K
Kapusta C
Podsadni P
Łapienis G
Dawidowski M
Kleps J
Górska S
Pisklak DM
Turło J
","(PMID:30093016
)",Selenized polysaccharides - Biosynthesis and structural analysis.,https://europepmc.org/abstract/MED/30093016%0A
"In this article we study a nonlinear age-structured consumer population model with density-dependent death and fertility rates, and time delays that model incubation/gestation period. Density dependence we consider combines both positive effects at low population numbers (i.e., the Allee effect) and negative effects at high population numbers due to intra-specific competition of consumers. The positive density-dependence is either due to an increase in the birth rate, or due to a decrease in the mortality rate at low population numbers. We prove that similarly to unstructured models, the Allee effect leads to model multi-stability where, besides the locally stable extinction equilibrium, there are up to two positive equilibria. Calculating derivatives of the basic reproduction number at the equilibria we prove that the upper of the two non-trivial equilibria (when it exists) is locally asymptotically stable independently of the time delay. The smaller of the two equilibria is always unstable. Using numerical simulations we analyze topologically nonequivalent phase portraits of the model.","Akimenko V
Křivan V
","(PMID:30292874
)",Asymptotic stability of delayed consumer age-structured population models with an Allee effect.,https://europepmc.org/abstract/MED/30292874%0A
"INTRODUCTION:Combination antiretroviral therapy (ART) reduces viral load to under the limit of detection, successfully decreasing HIV-related morbidity and mortality. Due to viral mutations, complex drug combinations and different patient response, there is an increasing demand for individualized treatment options for patients. Areas covered: This review first summarizes the pharmacokinetic and pharmacodynamic profile of clinical first-line drugs, which serves as guidance for antiretroviral precision medicine. Factors which have influential effects on drug efficacy and thus precision medicine are discussed: patients' pharmacogenetic information, virus mutations, comorbidities, and immune recovery. Furthermore, strategies to improve the application of precision medicine are discussed. Expert opinion: Precision medicine for ART requires comprehensive information on the drug, virus, and clinical data from the patients. The clinically available genetic tests are a good starting point. To better apply precision medicine, deeper knowledge of drug concentrations, HIV reservoirs, and efficacy associated genes, such as polymorphisms of drug transporters and metabolizing enzymes, are required. With advanced computer-based prediction systems which integrate more comprehensive information on pharmacokinetics, pharmacodynamics, pharmacogenomics, and the clinically relevant information of the patients, precision medicine will lead to better treatment choices and improved disease outcomes.","Mu Y
Kodidela S
Wang Y
Kumar S
Cory TJ
","(PMID:30234392
)",The dawn of precision medicine in HIV: state of the art of pharmacotherapy.,https://europepmc.org/abstract/MED/30234392%0A
"As one of the most important fundamental problems in protein sequence analysis, protein remote homology detection is critical for both theoretical research (protein structure and function studies) and real world applications (drug design). Although several computational predictors have been proposed, their detection performance is still limited. In this study, we treat protein remote homology detection as a document retrieval task, where the proteins are considered as documents and its aim is to find the highly related documents with the query documents in a database. A protein similarity network was constructed based on the true labels of proteins in the database, and the query proteins were then connected into the network based on the similarity scores calculated by three ranking methods, including PSI-BLAST, Hmmer and HHblits. The PageRank algorithm and Hyperlink-Induced Topic Search (HITS) algorithm were respectively performed on this network to move the homologous proteins of query proteins to the neighbors of the query proteins in the network. Finally, PageRank and HITS algorithms were combined, and a predictor called HITS-PR-HHblits was proposed to further improve the predictive performance. Tested on the SCOP and SCOPe benchmark datasets, the experimental results showed that the proposed protocols outperformed other state-of-the-art methods. For the convenience of the most experimental scientists, a web server for HITS-PR-HHblits was established at http://bioinformatics.hitsz.edu.cn/HITS-PR-HHblits, by which the users can easily get the results without the need to go through the mathematical details. The HITS-PR-HHblits predictor is a protocol for protein remote homology detection using different sets of programs, which will become a very useful computational tool for proteome analysis.","Liu B
Jiang S
Zou Q
","(PMID:30403770
)",HITS-PR-HHblits: protein remote homology detection by combining PageRank and Hyperlink-Induced Topic Search.,https://europepmc.org/abstract/MED/30403770%0A
"Wireless body area network (WBAN) provides a medium through which physiological information could be harvested and transmitted to application provider (AP) in real time. Integrating WBAN in a heterogeneous Internet of Things (IoT) ecosystem would enable an AP to monitor patients from anywhere and at anytime. However, the IoT roadmap of interconnected 'Things' is still faced with many challenges. One of the challenges in healthcare is security and privacy of streamed medical data from heterogeneously networked devices. In this paper, we first propose a heterogeneous signcryption scheme where a sender is in a certificateless cryptographic (CLC) environment while a receiver is in identity-based cryptographic (IBC) environment. We then use this scheme to design a heterogeneous access control protocol. Formal security proof for indistinguishability against adaptive chosen ciphertext attack and unforgeability against adaptive chosen message attack in random oracle model is presented. In comparison with some of the existing access control schemes, our scheme has lower computation and communication cost.","Omala AA
Mbandu AS
Mutiria KD
Jin C
Li F
","(PMID:29705947
)",Provably Secure Heterogeneous Access Control Scheme for Wireless Body Area Network.,https://europepmc.org/abstract/MED/29705947%0A
"The dynamics of haematopoietic stem cell differentiation and the hierarchy of oligopotent stem cells in the bone marrow remain controversial. Here we dissect haematopoietic progenitor populations at single cell resolution, deriving an unbiased reference model of transcriptional states in normal and perturbed murine bone marrow. We define the signature of the naive haematopoietic stem cell and find a continuum of core progenitor states. Core cell populations mix transcription of pre-myeloid and pre-lymphoid programs, but do not mix erythroid or megakaryocyte programs with other fates. CRISP-seq perturbation analysis confirms our models and reveals that Cebpa regulates entry into all myeloid fates, while Irf8 and PU.1 deficiency block later differentiation towards monocyte or granulocyte fates. Our transcriptional map defines a reference network model for blood progenitors and their differentiation trajectories during normal and perturbed haematopoiesis.","Giladi A
Paul F
Herzog Y
Lubling Y
Weiner A
Yofe I
Jaitin D
Cabezas-Wallscheid N
Dress R
Ginhoux F
Trumpp A
Tanay A
Amit I
","(PMID:29915358
)",Single-cell characterization of haematopoietic progenitors and their trajectories in homeostasis and perturbed haematopoiesis.,https://europepmc.org/abstract/MED/29915358%0A
No abstract provided.,"Redfern J
Cobo MJ
Herrera-Viedma E
","(PMID:29635342
)",Editorial: Mapping microbiology with scientometrics - help provide a clearer vision of microbiology research around the globe.,https://europepmc.org/abstract/MED/29635342%0A
No abstract provided.,"Cui J
Zempleni J
","(PMID:30184225
)",Reply to B Fromm et al.,https://europepmc.org/abstract/MED/30184225%0A
A correction to this article has been published and is linked from the HTML and PDF versions of this paper. The error has been fixed in the paper.,"Zhang W
Ye B
Liang W
Ren Y
","(PMID:29934596
 PMCID:PMC6015057)",Author Correction: Preoperative prognostic nutritional index is a powerful predictor of prognosis in patients with stage III ovarian cancer.,https://europepmc.org/abstract/MED/29934596%0A
"This paper is concerned with the remote state estimator design problem for a class of discrete neural networks under communication bandwidth constraints. Due to the limited bandwidth of the transmission channel, only partial components of the measurement outputs can be transmitted to the remote estimator at each time step. A UKF-based state estimator is developed to cope with the nonlinear activation functions in the neural networks subject to the communication constraints. Moreover, the stability of the proposed estimator is analyzed. Sufficient conditions are established under which the error dynamics of the state estimation is exponentially bounded in mean square. A numerical example is provided to demonstrate the effectiveness of the proposed method.","Liu Y
Wang Z
Zhou D
","(PMID:30268060
)",UKF-based remote state estimation for discrete artificial neural networks with communication bandwidth constraints.,https://europepmc.org/abstract/MED/30268060%0A
"The prevalent view that evaporating black holes should simply be smaller black holes has been challenged by the firewall paradox. In particular, this paradox suggests that something different occurs once a black hole has evaporated to one-half its original surface area. Here, we derive variations of the firewall paradox by tracking the thermodynamic entropy within a black hole across its entire lifetime and extend it even to anti-de Sitter space-times. Our approach sweeps away many unnecessary assumptions, allowing us to demonstrate a paradox exists even after its initial onset (when conventional assumptions render earlier analyses invalid). The most natural resolution may be to accept firewalls as a real phenomenon. Further, the vast entropy accumulated implies a deep firewall that goes 'all the way down' in contrast with earlier work describing only a structure at the horizon.This article is part of a discussion meeting issue 'Foundations of quantum mechanics and their impact on contemporary society'.","Braunstein SL
Pirandola S
","(PMID:29807901
)",Quantum information versus black hole physics: deep firewalls from narrow assumptions.,https://europepmc.org/abstract/MED/29807901%0A
"The reduction of trichloroethylene (TCE) in gas phase by different types of granular zero-valent iron (Fe0) was examined in anaerobic batch vapor systems performed at room temperature. Concentrations of TCE and byproducts were determined at discrete time intervals by analysis of the headspace vapors. Depending on the type of iron used, reductions of TCE gas concentration from 35% up to 99% were observed for treatments of 6 weeks. In line with other experimental studies performed with aqueous solutions, the particle size was found to play a key role in the reactivity of the iron. Namely an increase of the TCE removal up to almost 3 times was observed using iron powders with particle size lower than 425 μm compared to iron powders with particle size lower than 850 μm. The manufacturing process of the iron powder was instead found to play only a limited role. Namely, no significant differences were observed in the TCE reduction by Fe0 obtained using an iron powder attained by water atomization and sieving compared to the removal achieved using an iron powder subjected to a further annealing processes to reduce the content of oxides. Conversely, the pretreatment of the iron powder with HCl was found to enhance the reactivity of the iron. In particular, by washing the iron powder of 425 μm with HCl acid 0.1 M the reduction of TCE after 6 weeks of treatment increase from approximately 80% for the as received material to >99% for the pretreated iron powder. We also performed tests at different humidity of the iron observing that not statistical differences were obtained using a water content of 10% or 50% by weight. In all the experiments, the only detectable byproducts of the reactions were C4-C6 alkenes and alkanes that can be attributed to a hydrogenation of the CCl bond.","Zingaretti D
Verginelli I
Baciocchi R
","(PMID:30092524
)",Dehalogenation of trichloroethylene vapors by partially saturated zero-valent iron.,https://europepmc.org/abstract/MED/30092524%0A
"Neural engineering research is actively engaged in optimizing the robustness of sensorimotor rhythms (SMR)-brain-computer interface (BCI) to boost its potential real-world use. OBJECTIVE:This paper investigates two vital factors in efficient and robust SMR-BCI design-algorithms that address subject-variability of optimal features and neurophysiological factors that correlate with BCI performance. Existing SMR-BCI research using electroencephalogram (EEG) to classify bilateral motor imagery (MI) focus on identifying subject-specific frequency bands with most discriminative motor patterns localized to sensorimotor region. APPROACH:A novel strategy to further optimize BCI performance by taking into account the variability of discriminative spectral regions across various EEG channels is proposed in this paper. MAIN RESULTS:The proposed technique results in a significant ([Formula: see text]) increase in average ([Formula: see text]) classification accuracy by [Formula: see text] accompanied by a considerable reduction in number of channels and bands. The session-to-session transfer variation in spectro-spatial patterns using proposed algorithm is investigated offline and classification performance of the optimized BCI model is successfully evaluated in an online SMR-BCI. Further, the effective prediction of SMR-BCI performance with physiological indicators derived from multi-channel resting-state EEG is demonstrated. The results indicate that the resting state activation patterns such as entropy and gamma power from pre-motor (fronto-central) and posterior (parietal and centro-parietal) areas, and beta power from posterior (centro-parietal) areas estimate BCI performance with minimum error. These patterns, strongly related to BCI performance, may represent certain cognitive states during rest. SIGNIFICANCE:Findings reported in this paper imply the need for subject-specific modelling of BCI and the prediction of BCI performance using multi-channel rest-state parameters, to ensure enhanced BCI performance.","Robinson N
Thomas KP
Vinod AP
","(PMID:30277219
)",Neurophysiological predictors and spectro-spatial discriminative features for enhancing SMR-BCI.,https://europepmc.org/abstract/MED/30277219%0A
"Genetics experiments have identified six mutations located in the subdomain IA (A17V, R23H, G32D, G32S, R34K, V372I) of Ssa1 that influence propagation of the yeast [PSI+] prion. However, the underlining molecular mechanisms of these mutations are still unclear. The six mutation sites are present in the IA subdomain of the nucleotide-binding domain (NBD). The ATPase subdomain IA is a critical mediator of inter-domain allostery in Hsp70 molecular chaperones, so the mutation and changes in this subdomain may influence the function of the substrate-binding domain. In addition, ADP release is a rate-limiting step of the ATPase cycle and dysregulation of the ATPase cycle influences the propagation of the yeast [PSI+] prion. In this work, steered molecular dynamics (SMD) simulations were performed to explore the interaction between ADP and NBD. Results suggest that during the SMD simulations, hydrophobic interactions are predominant and variations in the binding state of ADP within the mutants is a potential reason for in vivo effects on yeast [PSI+] prion propagation. Additionally, we identify the primary residues in the ATPase domain that directly constitute the main hydrophobic interaction network and directly influence the ADP interaction state with the NBD of Ssa1. Furthermore, this in silico analysis reaffirms the importance of previously experimentally-determined residues in the Hsp70 ATPase domain involved in ADP binding and also identifies new residues potentially involved in this process.","Xue YL
Zhang Q
Sun Y
Zhou X
Hurley IP
Jones GW
Song Y
","(PMID:30392073
)",Using steered molecular dynamics to study the interaction between ADP and the nucleotide-binding domain of yeast Hsp70 protein Ssa1.,https://europepmc.org/abstract/MED/30392073%0A
No abstract provided.,"Jones N
","(PMID:30209383
)",How to stop data centres from gobbling up the world's electricity.,https://europepmc.org/abstract/MED/30209383%0A
"The integration of the latest breakthroughs in bioinformatics technology from one side and artificial intelligence from another side, enables remarkable advances in the fields of intelligent security guard computational biology, healthcare, and so on. Among them, biometrics based automatic human identification is one of the most fundamental and significant research topic. Human gait, which is a biometric features with the unique capability, has gained significant attentions as the remarkable characteristics of remote accessed, robust and security in the biometrics based human identification. However, the existed methods cannot well handle the indistinctive inter-class differences and large intra-class variations of human gait in real-world situation. In this paper, we have developed an efficient spatial-temporal gait features with deep learning for human identification. First of all, we proposed a gait energy image (GEI) based Siamese neural network to automatically extract robust and discriminative spatial gait features for human identification. Furthermore, we exploit the deep 3-dimensional convolutional networks to learn the human gait convolutional 3D (C3D) as the temporal gait features. Finally, the GEI and C3D gait features are embedded into the null space by the Null Foley-Sammon Transform (NFST). In the new space, the spatial-temporal features are sufficiently combined with distance metric learning to drive the similarity metric to be small for pairs of gait from the same person, and large for pairs from different persons. Consequently, the experiments on the world's largest gait database show our framework impressively outperforms state-of-the-art methods.","Liu W
Zhang C
Ma H
Li S
","(PMID:29404933
)",Learning Efficient Spatial-Temporal Gait Features with Deep Learning for Human Identification.,https://europepmc.org/abstract/MED/29404933%0A
"Automating conversation analysis in the natural clinical setting is essential to scale serious illness communication research to samples that are large enough for traditional epidemiological studies. Our objective is to automate the identification of pauses in conversations because these are important linguistic targets for evaluating dynamics of speaker involvement and turn-taking, listening and human connection, or distraction and disengagement.We used 354 audio recordings of serious illness conversations from the multisite Palliative Care Communication Research Initiative cohort study.Hospitalized people with advanced cancer seen by the palliative care team.We developed a Random Forest machine learning (ML) algorithm to detect Conversational Pauses of two seconds or longer. We triple-coded 261 minutes of audio with human coders to establish a gold standard for evaluating ML performance characteristics.ML automatically identified Conversational Pauses with a sensitivity of 90.5 and a specificity of 94.5.ML is a valid method for automatically identifying Conversational Pauses in the natural acoustic setting of inpatient serious illness conversations.","Manukyan V
Durieux BN
Gramling CJ
Clarfeld LA
Rizzo DM
Eppstein MJ
Gramling R
","(PMID:30183468
)",Automated Detection of Conversational Pauses from Audio Recordings of Serious Illness Conversations in Natural Hospital Settings.,https://europepmc.org/abstract/MED/30183468%0A
"Locomotion studies, biomechanics, and particularly vertebrate paleontology have had a deep influence on the development of motion pictures, animation, and computer generated visual effects. Biologically straightforward concepts such as morphological correlates of diet, sexual dimorphism, and ontogenetic change are powerful tools for animators and visual effects artists. Despite this deep debt to the ever-increasing role of science and technology in film making, scientists often forget to mine the communication strategies of their science-savvy entertainment industry kin. Further, many of the tools of the film industry are making a direct impact on basic research or have the potential to do so. It is becoming increasingly clear as part of the overall outreach for science, technology, engineering, and mathematics (""STEM""), scientists must inform and engage with the public. Significantly, many of the concepts and stories we offer as useful to film makers are compelling stories to offer to our own students. And these can be as compelling to the public as the entertainment they often facilitate. Whereas STEM is critically important, adding ""A"" - art - as in the artistic strategies from the fields of animation and visual effects to produce ""STEAM"" helps to build a potentially unstoppable tool for science communication and the public good.","Sumida SS
Jefcoat B
","(PMID:30137369
)","Anatomy, Animation and Visual Effects: the Reciprocal Tools of Biology and Film-Making.",https://europepmc.org/abstract/MED/30137369%0A
"Integral photography (IP) is one of the most promising 3D displays that can achieve a full parallax 3D display without glasses. There is a great need to render a correct, high-precision 3D image from an IP display. To achieve a correct 3D display, calibration is needed to correct optical misalignment and optical aberrations, while it is challenging to achieve correct mapping between a microlens array and matrix display. We propose an IP calibration method for a 3D autostereoscopic integral photography display based on a sparse camera array. Our method distinguishes itself from previous methods by estimating parameters for a dense correspondence map of an IP display with a relatively flexible setup and high precision in a reasonable time cost. We also propose a workflow to enable our method to handle both a visible and invisible microlens array and obtain a great outcome. One prototype is fabricated to evaluate the feasibility of the proposed method. Moreover, we evaluate our proposed method in geometry accuracy and image quality.","Chen G
Wang H
Liu M
Liao H
","(PMID:30183012
)",Hybrid camera array based calibration for computer-generated integral photography display.,https://europepmc.org/abstract/MED/30183012%0A
"We propose a novel linear model of pedestrian safety in urban areas with respect to road traffic crashes that considers a single independent variable of pedestrian path safety. This variable is estimated for a given urban area by sampling pedestrian paths from the population of such paths in that area and in turn estimating the mean safety of these paths. We argue that this independent variable directly models the factors contributing to pedestrian safety. This contrasts previous approaches, which, by considering multiple independent variables describing the environment, traffic and pedestrians themselves, indirectly model these factors. Using data about 15 UK cities, we demonstrate that the proposed model accurately estimates numbers of pedestrian casualties.","Hannah C
Spasić I
Corcoran P
","(PMID:29961544
)",A computational model of pedestrian road safety: The long way round is the safe way home.,https://europepmc.org/abstract/MED/29961544%0A
"A huge surge of research is being conducted on combination therapy with anticancer compounds formulated in the form of nanoparticles (NPs). Numerous advantages like dose minimalization and synergism, reversal of multi drug resistance (MDRs), enhanced efficacy have emerged with nanoencapsulation of chemotherapeutic agents with chemo-sensitizing agent like curcumin. Within last couple of years various nano-sized formulations have been designed and tested both in vitro with cell lines for different types of cancers and in vivo with cancer types and drug resistance models. Despite the combinatorial models being advanced, translation to human trials has not been as smooth as one would have hoped, with as few as twenty ongoing clinical trials with curcumin combination, with less than 1/10th being nano-particulate formulations. Mass production of nano-formulation based on their physico-chemical and pharmacokinetics deficits poses as major hurdle up the ladder. Combination of these nano-sized dosage with poorly bioavailable drugs, unspecific target binding ability and naturally unstable curcumin further complicates the formulation aspects. Emphasis is now therefore being laid on altering natural forms of curcumin and usage of formulations like prodrug or coating of curcumin to overcome stability issues and focus more on enhancing the pharmaceutical and therapeutic ability of the nano-composites. Current studies and futuristic outlook in this direction are discussed in the review, which can serve as the basis for upcoming research which could boost commercial translational of improved nano-sized curcumin combination chemotherapy.","Batra H
Pawar S
Bahl D
","(PMID:30408575
)",Curcumin in Combination with Anti-Cancer Drugs: A Nanomedicine Review.,https://europepmc.org/abstract/MED/30408575%0A
"Navigation support in interventional magnetic resonance imaging (MRI) is separated from the operating field, which makes it difficult to interpret positions and orientations and to coordinate the necessary hand movements.We developed a projector-based augmented reality system to enable visual navigation of tracked instruments on pre-planned paths and visualization of risk structures directly on the patient inside the MRI bore. To assess the accuracy of the system, a user study was carried out with clinicians in a needle navigation test scenario.The targets were reached with an error of 1.7 ± 0.5 mm and the entry points with an error of 1.7 ± 0.8 mm.The accuracy results are similar to those reached by live image-guided interventions and related work and confirm that this projective augmented reality prototype for the interventional MRI can serve as a platform for current and future research in augmented reality visualization and dynamic registration.","Mewes A
Heinrich F
Kägebein U
Hensen B
Wacker F
Hansen C
","(PMID:30168639
)",Projector-based augmented reality system for interventional visualization inside MRI scanners.,https://europepmc.org/abstract/MED/30168639%0A
"To identify potential stars in social networks, the idea of combining member promotion with skyline operator attracts people's attention. Some algorithms have been proposed to deal with this problem so far, such as skyline boundary algorithms in unequal-weighted social networks.We propose an improved member promotion algorithm by presenting ReputationRank based on eigenvectors as well as Influence and Activeness and introduce the concept of skyline distance. Furthermore, we perform skyline operator over non-skyline set and choose the infra-skyline as our candidate set. The added ReputationRank helps a lot to describe the importance of a member while the skyline distance assists us to obtain the necessary condition for not being dominated so that some meaningless plans can be pruned.Experiments on the DBLP and WikiVote datasets verify the effectiveness and efficiency of our proposed algorithm.Treating the infra-skyline set as candidate set reduces the number of candidates. The pruning strategies based on dominance and promotion cost decrease the searching space.","Zheng J
Zhang S
","(PMID:30221125
 PMCID:PMC6132376)",Adding ReputationRank to member promotion using skyline operator in social networks.,https://europepmc.org/abstract/MED/30221125%0A
"The growth in the availability of personal genomic data to nonexperts poses multiple challenges to human-computer interaction research; data are highly sensitive, complex, and have health implications for individuals and families. However, there has been little research on how nonexpert users explore their genomic data.We focus on how to support nonexperts in exploring and comparing their own personal genomic report with those of other people. We designed and evaluated CrossGenomics, a novel tool for comparing personal genetic reports, which enables exploration of shared and unshared genetic variants. Focusing on communicating comparative impact, rarity, and certainty, we evaluated alternative novel interactive prototypes.We conducted 3 user studies. The first focuses on assessing the usability and understandability of a prototype that facilitates the comparison of reports from 2 family members. Following a design iteration, we studied how various prototypes support the comparison of genetic reports of a 4-person family. Finally, we evaluated the needs of early adopters-people who share their genetic reports publicly for comparing their genetic reports with that of others.In the first study, sunburst- and Venn-based comparisons of two genomes led to significantly higher domain comprehension, compared with the linear comparison and with the commonly used tabular format. However, results show gaps between objective and subjective comprehension, as sunburst users reported significantly lower perceived understanding and higher levels of confusion than the users of the tabular report. In the second study, users who were allowed to switch between the different comparison views presented higher comprehension levels, as well as more complex reasoning than users who were limited to a single comparison view. In the third study, 35% (17/49) reported learning something new from comparing their own data with another person's data. Users indicated that filtering and toggling between comparison views were the most useful features.Our findings (1) highlight features and visualizations that show strengths in facilitating user comprehension of genomic data, (2) demonstrate the value of affording users the flexibility to examine the same report using multiple views, and (3) emphasize users' needs in comparison of genomic data. We conclude with design implications for engaging nonexperts with complex multidimensional genomic data.","Westendorf L
Shaer O
Pollalis C
Verish C
Nov O
Ball MP
","(PMID:30249582
)",Exploring Genetic Data Across Individuals: Design and Evaluation of a Novel Comparative Report Tool.,https://europepmc.org/abstract/MED/30249582%0A
"Electronic medical records (EMRs) contain medical knowledge that can be used for clinical decision support (CDS). Our objective is to develop a general system that can extract and represent knowledge contained in EMRs to support three CDS tasks-test recommendation, initial diagnosis, and treatment plan recommendation-given the condition of a patient.We extracted four kinds of medical entities from records and constructed an EMR-based medical knowledge network (EMKN), in which nodes are entities and edges reflect their co-occurrence in a record. Three bipartite subgraphs (bigraphs) were extracted from the EMKN, one to support each task. One part of the bigraph was the given condition (e.g., symptoms), and the other was the condition to be inferred (e.g., diseases). Each bigraph was regarded as a Markov random field (MRF) to support the inference. We proposed three graph-based energy functions and three likelihood-based energy functions. Two of these functions are based on knowledge representation learning and can provide distributed representations of medical entities. Two EMR datasets and three metrics were utilized to evaluate the performance.As a whole, the evaluation results indicate that the proposed system outperformed the baseline methods. The distributed representation of medical entities does reflect similarity relationships with respect to knowledge level.Combining EMKN and MRF is an effective approach for general medical knowledge representation and inference. Different tasks, however, require individually designed energy functions.","Zhao C
Jiang J
Guan Y
Guo X
He B
","(PMID:29691122
)",EMR-based medical knowledge representation and inference via Markov random fields and distributed representation learning.,https://europepmc.org/abstract/MED/29691122%0A
"Hyperspectral imaging (HSI) has become a sophisticated technique in modern applications such as food analyses, recycling technology, medicine, pharmacy and forensic science. It allows one to analyse both spatial and spectral information from an object. But hyperspectral cameras are still expensive due to their extended wavelength range. The development of new light-emitting diodes (LED) in the recent past enables another approach to HSI using a monochrome camera in combination with a LED-based illumination. However, such a system has a lower spectral resolution. Additionally, the growing supply of LED on the market complicates the selection of LED. In this paper, we propose a new time efficient selection method for the design process of an illumination. It chooses an optimised LED combination from an existing database to match a predefined spectral power distribution. Therefore, an algorithm is used to evaluate various LED combinations. Furthermore, the method considers the spectral behaviour of each LED in dependence of forward current and temperature of the solder point. Our method has already shown promise during the selection process for even spectral distributions which is demonstrated in the study. Additionally, we will show its potential for HSI illuminations.","Heimpold T
Reifegerste F
Drechsel S
Lienig J
","(PMID:30244231
)",LED for hyperspectral imaging - a new selection method.,https://europepmc.org/abstract/MED/30244231%0A
"Notch signaling is involved in both differentiation of hepatocyte progenitors and hepatocellular carcinoma (HCC). The mechanism whereby Notch signaling regulates cellular transformation in hepatocytes is still controversial. This study investigated the impact of overexpressing truncated intracellular Notch1 (NICD1) on transcriptomic profiles of immortalized human hepatocytes. RNA sequencing and gene ontology enrichment analysis revealed that extracellular matrix organization and hyaluronan biosynthesis process gene sets are among those affected by Notch hyperactivation. The relationship between Notch signaling and periostin, an extracellular matrix protein highly expressed in HCC, were further studied. Modulating Notch signaling through NICD1 overexpression or treatment with a gamma secretase inhibitor resulted in increased or decreased periostin expression, respectively, in HCC and liver bile duct carcinoma cell lines. Based on The Cancer Genome Atlas database, mRNA levels of NOTCH1 and POSTN are positively correlated in tumor tissues but not in nontumor tissues. Two consensus RBPJ binding motifs were identified in the -3932/-3921 and + 2522/+2533 bp of POSTN regulatory regions, and NOTCH1 is associated with these binding sites in a liver bile duct carcinoma cell line. Taken together, these results indicate that Notch signaling directly regulates transcription of POSTN in hepatocytes and liver cancer cell lines and may be a candidate for drug targeting in liver cancer.","Kongkavitoon P
Butta P
Sanpavat A
Bhattarakosol P
Tangtanatakul P
Wongprom B
Tangkijvanich P
Hirankarn N
Palaga T
","(PMID:30384995
)",Regulation of periostin expression by Notch signaling in hepatocytes and liver cancer cell lines.,https://europepmc.org/abstract/MED/30384995%0A
"Cancer was initially considered a genetic disease. However, recent studies have revealed the connection between bacterial infections and growth of different types of cancer. The enteroinvasive strain of Mycoplasma hominis alters the normal behavior of host cells that may result in the growth of prostate cancer. The role of M. hominis in the growth and development of prostate cancer still remains unclear. The infection may regulate several factors that influence prostate cancer growth in susceptible individuals. The aim of this study was to predict M. hominis proteins targeted into the endoplasmic reticulum (ER) of the host cell, and their potential role in the induction of prostate cancer. From the whole proteome of M. hominis, 19 proteins were predicted to be targeted into the ER of host cells. The results of our study predict that several proteins of M. hominis may be targeted to the host cell ER, and possibly alter the normal pattern of protein folding. These predicted proteins can modify the normal function of the host cell. Thus, the intercellular infection of M. hominis in host cells may serve as a potential factor in prostate cancer etiology.","Zakariah M
Khan S
Chaudhary AA
Rolfo C
Ben Ismail MM
Alotaibi YA
","(PMID:29695086
 PMCID:PMC6099661)",To Decipher the Mycoplasma hominis Proteins Targeting into the Endoplasmic Reticulum and Their Implications in Prostate Cancer Etiology Using Next-Generation Sequencing Data.,https://europepmc.org/abstract/MED/29695086%0A
"We investigate the mechanism underlying the self-assembly of gear-shaped amphiphilic molecules into a highly ordered nanocubic capsule (""nanocube"") in aqueous methanol. Simulation results show that the solvent molecules play a significant role in the assembly process by directing the primitive intermediates to orthogonal/rectangular shapes, thus creating appropriate building blocks for cubic assembly while avoiding off-pathway stacked aggregates. Free-energy analyses reveal that the interplay of the direct intermonomer interaction and the solvent-mediated repulsion between large aromatic cores (via preferential solvation of methanol on hydrophobic surfaces) leads to the strong trend for perpendicular binding of monomers and hence the solvent-guided formation of rectangular blocks. Furthermore, we report the self-assembly simulation of the nanocube using replica exchange with solute tempering and demonstrate that the simulation can predict a highly ordered nanocapsule structure, assembly intermediates, and encapsulated molecules, which helps promote computer-aided design of functional molecular self-assemblies in explicit solvent.","Yamamoto T
Arefi H
Shanker S
Sato H
Hiraoka S
","(PMID:30274518
)",Self-Assembly of Nanocubic Molecular Capsules via Solvent-Guided Formation of Rectangular Blocks.,https://europepmc.org/abstract/MED/30274518%0A
"Studies regarding knowledge organization and acquisition are of great importance to understand areas related to science and technology. A common way to model the relationship between different concepts is through complex networks. In such representations, networks' nodes store knowledge and edges represent their relationships. Several studies that considered this type of structure and knowledge acquisition dynamics employed one or more agents to discover node concepts by walking on the network. In this study, we investigate a different type of dynamics adopting a single node as the ""network brain."" Such a brain represents a range of real systems such as the information about the environment that is acquired by a person and is stored in the brain. To store the discovered information in a specific node, the agents walk on the network and return to the brain. We propose three different dynamics and test them on several network models and on a real system, which is formed by journal articles and their respective citations. The results revealed that, according to the adopted walking models, the efficiency of self-knowledge acquisition has only a weak dependency on topology and search strategy.","Lima TS
de Arruda HF
Silva FN
Comin CH
Amancio DR
Costa LDF
","(PMID:30180654
)",The dynamics of knowledge acquisition via self-learning in complex networks.,https://europepmc.org/abstract/MED/30180654%0A
"Gene regulatory network (GRN) inference can understand the growth and development of animals and plants, and reveal the mystery of biology. Many computational approaches have been proposed to infer GRN. However, these inference approaches have hardly met the need of modeling, and the reducing redundancy methods based on individual information theory method have bad universality and stability. To overcome the limitations and shortcomings, this thesis proposes a novel algorithm, named HSCVFNT, to infer gene regulatory network with time-delayed regulations by utilizing a hybrid scoring method and complex-valued flexible neural network (CVFNT). The regulations of each target gene can be obtained by iteratively performing HSCVFNT. For each target gene, the HSCVFNT algorithm utilizes a novel scoring method based on time-delayed mutual information (TDMI), time-delayed maximum information coefficient (TDMIC) and time-delayed correlation coefficient (TDCC), to reduce the redundancy of regulatory relationships and obtain the candidate regulatory factor set. Then, the TDCC method is utilized to create time-delayed gene expression time-series matrix. Finally, a complex-valued flexible neural tree model is proposed to infer the time-delayed regulations of each target gene with the time-delayed time-series matrix. Three real time-series expression datasets from (Save Our Soul) SOS DNA repair system in E. coli and Saccharomyces cerevisiae are utilized to evaluate the performance of the HSCVFNT algorithm. As a result, HSCVFNT obtains outstanding F-scores of 0.923, 0.8 and 0.625 for SOS network and (In vivo Reverse-Engineering and Modeling Assessment) IRMA network inference, respectively, which are 5.5%, 14.3% and 72.2% higher than the best performance of other state-of-the-art GRN inference methods and time-delayed methods.","Yang B
Chen Y
Zhang W
Lv J
Bao W
Huang DS
","(PMID:30326663
 PMCID:PMC6214043)",HSCVFNT: Inference of Time-Delayed Gene Regulatory Network Based on Complex-Valued Flexible Neural Tree Model.,https://europepmc.org/abstract/MED/30326663%0A
"Change history: In Fig. 3b of this Letter, the labels for the outer (11.8 nm) and inner (7.4 nm) diameters of the structure were inadvertently omitted. Fig. 3 has been corrected online.","Ma K
Gong Y
Aubert T
Turker MZ
Kao T
Doerschuk PC
Wiesner U
","(PMID:29991798
)","Publisher Correction: Self-assembly of highly symmetrical, ultrasmall inorganic cages directed by surfactant micelles.",https://europepmc.org/abstract/MED/29991798%0A
"VERDICT (vascular, extracellular and restricted diffusion for cytometry in tumours) estimates and maps microstructural features of cancerous tissue non-invasively using diffusion MRI. The main purpose of this study is to address the high computational time of microstructural model fitting for prostate diagnosis, while retaining utility in terms of tumour conspicuity and repeatability. In this work, we adapt the accelerated microstructure imaging via convex optimization (AMICO) framework to linearize the estimation of VERDICT parameters for the prostate gland. We compare the original non-linear fitting of VERDICT with the linear fitting, quantifying accuracy with synthetic data, and computational time and reliability (performance and precision) in eight patients. We also assess the repeatability (scan-rescan) of the parameters. Comparison of the original VERDICT fitting versus VERDICT-AMICO showed that the linearized fitting (1) is more accurate in simulation for a signal-to-noise ratio of 20 dB; (2) reduces the processing time by three orders of magnitude, from 6.55 seconds/voxel to 1.78 milliseconds/voxel; (3) estimates parameters more precisely; (4) produces similar parametric maps and (5) produces similar estimated parameters with a high Pearson correlation between implementations, r2  > 0.7. The VERDICT-AMICO estimates also show high levels of repeatability. Finally, we demonstrate that VERDICT-AMICO can estimate an extra diffusivity parameter without losing tumour conspicuity and retains the fitting advantages. VERDICT-AMICO provides microstructural maps for prostate cancer characterization in seconds.","Bonet-Carne E
Johnston E
Daducci A
Jacobs JG
Freeman A
Atkinson D
Hawkes DJ
Punwani S
Alexander DC
Panagiotaki E
","(PMID:30378195
)",VERDICT-AMICO: Ultrafast fitting algorithm for non-invasive prostate microstructure characterization.,https://europepmc.org/abstract/MED/30378195%0A
"The precuneus has connectivity with brain systems implicated in depression.We performed the first fully voxel-level resting-state functional connectivity (FC) neuroimaging analysis of depression of the precuneus, with 282 patients with major depressive disorder and 254 control subjects.In 125 unmedicated patients, voxels in the precuneus had significantly increased FC with the lateral orbitofrontal cortex, a region implicated in nonreward that is thereby implicated in depression. FC was also increased in depression between the precuneus and the dorsolateral prefrontal cortex, temporal cortex, and angular and supramarginal areas. In patients receiving medication, the FC between the lateral orbitofrontal cortex and precuneus was decreased back toward that in the control subjects. In the 254 control subjects, parcellation revealed superior anterior, superior posterior, and inferior subdivisions, with the inferior subdivision having high connectivity with the posterior cingulate cortex, parahippocampal gyrus, angular gyrus, and prefrontal cortex. It was the ventral subdivision of the precuneus that had increased connectivity in depression with the lateral orbitofrontal cortex and adjoining inferior frontal gyrus.The findings support the theory that the system in the lateral orbitofrontal cortex implicated in the response to nonreceipt of expected rewards has increased effects on areas in which the self is represented, such as the precuneus. This may result in low self-esteem in depression. The increased connectivity of the precuneus with the prefrontal cortex short-term memory system may contribute to the rumination about low self-esteem in depression. These findings provide evidence that a target to ameliorate depression is the lateral orbitofrontal cortex.","Cheng W
Rolls ET
Qiu J
Yang D
Ruan H
Wei D
Zhao L
Meng J
Xie P
Feng J
","(PMID:30243643
)",Functional Connectivity of the Precuneus in Unmedicated Patients With Depression.,https://europepmc.org/abstract/MED/30243643%0A
No abstract provided.,"Birbaumer N
Hochberg LR
","(PMID:29950438
)",A useful communication in brain-computer interfaces.,https://europepmc.org/abstract/MED/29950438%0A
"Emerging evidence indicates that adipose stromal cells (ASC) are recruited to enhance cancer development. In this study, we examined the role these adipocyte progenitors play relating to intercellular communication in obesity-associated endometrial cancer. This is particularly relevant given that gap junctions have been implicated in tumor suppression. Examining the effects of ASCs on the transcriptome of endometrial epithelial cells (EEC) in an in vitro co-culture system revealed transcriptional repression of GJA1 (encoding the gap junction protein Cx43) and other genes related to intercellular communication. This repression was recapitulated in an obesity mouse model of endometrial cancer. Furthermore, inhibition of plasminogen activator inhibitor 1 (PAI-1), which was the most abundant ASC adipokine, led to reversal of cellular distribution associated with the GJA1 repression profile, suggesting that PAI-1 may mediate actions of ASC on transcriptional regulation in EEC. In an endometrial cancer cohort (n=141), DNA hypermethylation of GJA1 and related loci TJP2 and PRKCA was observed in primary endometrial endometrioid tumors and was associated with obesity. Pharmacologic reversal of DNA methylation enhanced gap junction intercellular communication and cell-cell interactions in vitro. Restoring Cx43 expression in endometrial cancer cells reduced cellular migration; conversely, depletion of Cx43 increased cell migration in immortalized normal EEC. Our data suggest that persistent repression by ASC adipokines leads to promoter hypermethylation of GJA1 and related genes in the endometrium, triggering long-term silencing of these loci in endometrial tumors of obese patients.","Polusani SR
Huang YW
Huang G
Chen CW
Wang CM
Lin LL
Osmulski P
Lucio ND
Liu L
Hsu YT
Zhou Y
Lin CL
Aguilera-Barrantes I
Valente PT
Kost ER
Chen CL
Shim EY
Lee SE
Ruan J
Gaczynska ME
Yan P
Goodfellow PJ
Mutch DG
Jin VX
Nicholson BJ
Huang TH
Kirma NB
","(PMID:30389702
)",Adipokines Deregulate Cellular Communication via Epigenetic Repression of Gap Junction Loci in Obese Endometrial Cancer.,https://europepmc.org/abstract/MED/30389702%0A
"In recent years, serious concerns have arisen about reproducibility in science. Estimates of the cost of irreproducible preclinical studies range from 28 billion USD per year in the USA alone (Freedman et al. in PLoS Biol 13(6):e1002165, 2015) to over 200 billion USD per year worldwide (Chalmers and Glasziou in Lancet 374:86-89, 2009). The situation in the social sciences is not very different: Reproducibility in psychological research, for example, has been estimated to be below 50% as well (Open Science Collaboration in Science 349:6251, 2015). Less well studied is the issue of reproducibility of simulation research. A few replication studies of agent-based models, however, suggest the problem for computational modeling may be more severe than for laboratory experiments (Willensky and Rand in JASSS 10(4):2, 2007; Donkin et al. in Environ Model Softw 92:142-151, 2017; Bajracharya and Duboz in: Proceedings of the symposium on theory of modeling and simulation-DEVS integrative M&S symposium, pp 6-11, 2013). In this perspective, we discuss problems of reproducibility in agent-based simulations of life and social science problems, drawing on best practices research in computer science and in wet-lab experiment design and execution to suggest some ways to improve simulation research practice.","Fitzpatrick BG
","(PMID:30191471
)",Issues in Reproducible Simulation Research.,https://europepmc.org/abstract/MED/30191471%0A
No abstract provided.,"Lin MC
Iqbal U
Li YC
","(PMID:30195435
)",AI in Medicine: Big Data Remains a Challenge.,https://europepmc.org/abstract/MED/30195435%0A
"STATEMENT OF PROBLEM:The marginal and internal adaptations of porcelain laminate veneers (PLVs) are key elements in their long-term success. However, the marginal and internal fit obtained with a pressable material compared with computer-aided design and computer-aided manufacturing (CAD-CAM) needs further investigation as does the choice of cement used. PURPOSE:The purpose of this in vitro study was to evaluate the marginal and internal fit of PLVs fabricated using pressing and CAD-CAM milling and cemented using 2 types of composite resin cement. MATERIAL AND METHODS:Twenty PLVs were fabricated from VITA PM9 pressable material, and 20 veneers were milled using VITA Blocs Mark II. Veneers were cemented to composite resin dies using either RelyX Veneer cement or Variolink-N cement. Specimens were embedded in clear resin and sectioned incisogingivally and mesiodistally. Marginal discrepancy at the incisal and cervical positions and the internal gap at 6 different locations were evaluated by using a scanning electron microscope. Two-way ANOVA followed by Tukey multiple comparisons were used to examine difference among groups (α=.05). RESULTS:The cement and fabrication methods did not show any significant effect for absolute marginal gap (AMG) at the incisal edge, AMG at the cervical margin or marginal gap at the incisal edge. However, both had a significant effect on marginal gap at the cervical margin (P=.038 for the fabrication method and P=.050 for the cement used). Also, both cement and fabrication methods had a significant effect on internal gap average (P<.001). The lowest gap values were reported for veneers fabricated from VITA PM9 by using the press technique and cemented with RelyX Veneer cement. When the position of gap measurements was taken into consideration, it was the only significant factor (P<.001 for the effect of position on AMG and P<.001 for the effect of position on marginal gap). Gaps at the cervical position were significantly lower than gaps at the incisal position. CONCLUSIONS:Smaller marginal and internal discrepancies were recorded for PLVs fabricated by using the pressing technique and cemented using RelyX Veneer cement compared with milled veneers and Variolink-N cement. Larger discrepancies were present incisally than cervically.","Al-Dwairi ZN
Alkhatatbeh RM
Baba NZ
Goodacre CJ
","(PMID:30391059
)",A comparison of the marginal and internal fit of porcelain laminate veneers fabricated by pressing and CAD-CAM milling and cemented with 2 different resin cements.,https://europepmc.org/abstract/MED/30391059%0A
"This Special Issue is focused on breakthrough developments in the field of biosensors and current scientific progress in biomedical signal processing. The papers address innovative solutions in assistance robotics based on bioelectrical signals, including: Affordable biosensor technology, affordable assistive-robotics devices, new techniques in myoelectric control and advances in brain⁻machine interfacing.","Torres F
Puente ST
Úbeda A
","(PMID:30336595
 PMCID:PMC6211006)",Assistance Robotics and Biosensors.,https://europepmc.org/abstract/MED/30336595%0A
"Ideal cardiovascular health (CVH) was defined as meeting ideal levels of 4 health behaviours (smoking, body mass index, physical activity, and diet) and 3 biological factors (blood pressure, total cholesterol, and glucose) and is inversely related to cardiovascular disease and mortality. However, the prevalence of ideal CVH in patients with severe mental illness and the possible independent associations of sedentary behaviour and fitness with CVH score are unexplored.This study included 142 (34 women) outpatients with severe mental illness (primarily schizophrenia, n = 92). CVH was evaluated according to the American Heart Association guidelines. Sedentary behaviour, cardiorespiratory fitness, and muscular strength were measured by an activity-monitor, the 6-min walk test, and handgrip dynamometry. Cardiorespiratory fitness and strength values were combined in a composite fitness score. The prevalence of ideal CVH was: non-smoking (47.9%), body mass index (16.9), physical activity (83.1%), diet (10.4%), blood pressure (40.4%), total cholesterol (62.9%), and plasma glucose (66.7%). Low levels of sedentary behaviour and high cardiorespiratory, strength, and composite fitness score were associated with meeting the ideal threshold in most CVH metrics and having higher global CVH score; however, only cardiorespiratory and composite fitness score remained significantly related to global CVH score independent of sedentary behaviour and multiple confounders.Patients with severe mental illness generally have low prevalence of ideal CVH metrics, especially diet and body mass index. Additionally, our findings suggest the need or considering cardiorespiratory fitness, regardless of sedentary behaviour, to promote ideal CVH in this population.","Bueno-Antequera J
Oviedo-Caro MÁ
Munguía-Izquierdo D
","(PMID:29898823
)",Ideal cardiovascular health and its association with sedentary behaviour and fitness in psychiatric patients. The PsychiActive project.,https://europepmc.org/abstract/MED/29898823%0A
"In this paper, we propose two four-base related 2D curves of DNA primary sequences (termed as F-B curves) and their corresponding single-base related 2D curves (termed as A-related, G-related, T-related and C-related curves). The constructions of these graphical curves are based on the assignments of individual base to four different sinusoidal (or tangent) functions; then by connecting all these points on these four sinusoidal (tangent) functions, we can get the F-B curves; similarly, by connecting the points on each of the four sinusoidal (tangent) functions, we get the single-base related 2D curves. The proposed 2D curves are all strictly non degenerate. Then, a 8-component characteristic vector is constructed to compare similarity among DNA sequences from different species based on a normalized geometrical centers of the proposed curves. As examples, we examine similarity among the coding sequences of the first exon of beta-globin gene from eleven species, similarity of cDNA sequences of beta-globin gene from eight species, and similarity of the whole mitochondrial genomes of 18 eutherian mammals. The experimental results well demonstrate the effectiveness of the proposed method.","Xie GS
Jin XB
Yang C
Pu J
Mo Z
","(PMID:29675730
)",Graphical Representation and Similarity Analysis of DNA Sequences Based on Trigonometric Functions.,https://europepmc.org/abstract/MED/29675730%0A
"Optical analog signal processing has been gaining significant attention as a way to overcome the speed and energy limitations of digital techniques. Metasurfaces offer a promising avenue towards this goal due to their efficient manipulation of optical signals over deeply subwavelength volumes. To date, metasurfaces have been proposed to transform signals in the spatial domain, e.g., for beam steering, focusing, or holography, for which angular-dependent responses, or nonlocality, are unwanted features that must be avoided or mitigated. Here, we show that the metasurface nonlocality can be engineered to enable signal manipulation in the momentum domain over an ultrathin platform. We explore nonlocal metasurfaces performing basic mathematical operations, paving the way towards fast and power-efficient ultrathin devices for edge detection and optical image processing.","Kwon H
Sounas D
Cordaro A
Polman A
Alù A
","(PMID:30411907
)",Nonlocal Metasurfaces for Optical Signal Processing.,https://europepmc.org/abstract/MED/30411907%0A
"Agronomic experiments are often complex and difficult to interpret, and the proper use of appropriate statistical methodology is essential for an efficient and reliable analysis. In this paper, the basics of the statistical analysis of designed experiments are discussed using real examples from agricultural field trials. Factorial designs allow for the study of two or more treatment factors in the same experiment, and here we discuss the analysis of factorial designs for both qualitative and quantitative level treatment factors. Where treatment factors have quantitative levels, models of treatment effects are essential for efficient analysis and in this paper we discuss the use of polynomials for empirical quantitative modelling of treatment effects. The example analyses cover experiments with a single quantitative level factor, experiments with mixtures of quantitative and qualitative level factors, polynomial regression designs with two quantitative level factors, split‐plot designs with quantitative level factors and repeated‐measures designs with correlated data and a quantitative treatment response over time. Modern mixed model computer software for routine analysis of experimental data is now readily available, and we demonstrate the use of two alternative software packages, the SAS package and the R language. The main purpose of the paper is to exemplify standard statistical methodology for routine analysis of designed experiments in agricultural research, but in our discussion we also provide some references for the study of more advanced methodology.","Piepho HP
R. N. Edmondson
","(AGR:IND606117336
)",A tutorial on the statistical analysis of factorial experiments with qualitative and quantitative treatment factor levels,https://europepmc.org/abstract/AGR/IND606117336%0A
"Laser-induced fluorescence (LIF) using a pulsed laser is successfully applied in an argon plasma. The laser system consists of a pumping pulse laser fixed at 532 nm and a tunable dye laser. Using a homemade Fabry-Perot interferometer, the large linewidth of the original output is reduced by one order from 4 GHz to 340 MHz. The measured ion temperature is 0.15 eV with a velocity resolution about 200 m/s. It provides great possibility for the combination of LIF and planar LIF using the same pulsed laser system.","Zhang Q
Xie J
Luo M
Sun X
Fan F
Lu Q
Ding W
Zhu Y
","(PMID:30399798
)",Laser-induced fluorescence diagnostic via pulsed lasers in an argon plasma.,https://europepmc.org/abstract/MED/30399798%0A
"3D structures with complex geometric features at the microscale, such as microparticles and microfibers, have promising applications in biomedical engineering, self-assembly, and photonics. Fabrication of complex 3D microshapes at scale poses a unique challenge; high-resolution methods such as two-photon-polymerization have print speeds too low for high-throughput production, while top-down approaches for bulk processing using microfabricated template molds have limited control of microstructure geometries over multiple axes. Here, a method for microshape fabrication is presented that combines a thermally drawn transparent fiber template with a masked UV-photopolymerization approach to enable biaxial control of microshape fabrication. Using this approach, high-resolution production of complex microshapes not producible using alternative methods is demonstrated, such as octahedrons, dreidels, and axially asymmetric fibers, at throughputs as high as 825 structures/minute. Finally, the fiber template is functionalized with conductive electrodes to enable hierarchical subparticle localization using dielectrophoretic forces.","Yuan R
Nagarajan MB
Lee J
Voldman J
Doyle PS
Fink Y
","(PMID:30369043
)",Designable 3D Microshapes Fabricated at the Intersection of Structured Flow and Optical Fields.,https://europepmc.org/abstract/MED/30369043%0A
"The human body's immune response to bacterial challenge, even when successful in controlling the infection, can result in negative consequences for the host, including reduced functionality of associated tissues. We present and analyze a low-dimensional mathematical model of this immune response to pathogen invasion, incorporating the coordinated actions of active immune cells, and both pro- and anti-inflammatory cytokines. The model simulates both the positive (pathogen reduction) and negative (local tissue dysfunction) effects of the immune response and includes the important role of immunologic memory in the process of a return to stasis. This differential equation-based model is sufficiently general to be applicable to a wide range of human tissues and organs.","Caudill L
Lynch F
","(PMID:29951890
)",A Mathematical Model of the Inflammatory Response to Pathogen Challenge.,https://europepmc.org/abstract/MED/29951890%0A
"Creative thinking plays a vital role in almost all aspects of human life. However, little is known about the neural and genetic mechanisms underlying creative thinking. Based on a cross-validation based predictive framework, we searched from the whole-brain connectome (34,716 functional connectivities) and whole genome data (309,996 SNPs) in two datasets (all collected by Southwest University, Chongqing) consisting of altogether 236 subjects, for a better understanding of the brain and genetic underpinning of creativity. Using the Torrance Tests of Creative Thinking score, we found that high figural creativity is mainly related to high functional connectivity between the executive control, attention, and memory retrieval networks (strong top-down effects); and to low functional connectivity between the default mode network, the ventral attention network, and the subcortical and primary sensory networks (weak bottom-up processing) in the first dataset (consisting of 138 subjects). High creativity also correlates significantly with mutations of genes coding for both excitatory and inhibitory neurotransmitters. Combining the brain connectome and the genomic data we can predict individuals' creativity scores with an accuracy of 78.4%, which is significantly better than prediction using single modality data (gene or functional connectivity), indicating the importance of combining multi-modality data. Our neuroimaging prediction model built upon the first dataset was cross-validated by a completely new dataset of 98 subjects (r = 0.267, p = 0.0078) with an accuracy of 64.6%. In addition, the creativity-related functional connectivity network we identified in the first dataset was still significantly correlated with the creativity score in the new dataset (p<10-3). In summary, our research demonstrates that strong top-down control versus weak bottom-up processes underlie creativity, which is modulated by competition between the glutamate and GABA neurotransmitter systems. Our work provides the first insights into both the neural and the genetic bases of creativity.","Liu Z
Zhang J
Xie X
Rolls ET
Sun J
Zhang K
Jiao Z
Chen Q
Zhang J
Qiu J
Feng J
","(PMID:29518564
)",Neural and genetic determinants of creativity.,https://europepmc.org/abstract/MED/29518564%0A
"A novel compact single-ridge waveguide (SRW) to coaxial line ultra-wideband transition is proposed in this paper. The transition using shorter matching networks between the coaxial port and the SRW port achieves maximum matching bandwidth; meanwhile, a wideband short circuit is also introduced to further broaden bandwidth performance. The whole structure is very simple and can be readily fabricated with a conventional computer numerical control machine. The prototype transitions were designed, manufactured, and measured. The measured results are reasonably consistent with the simulated results. Measurements show that the return loss and insertion loss of the back-to-back transition are better than 18 dB and 0.2 dB, respectively, from 6 to 18 GHz, with 100% fractional bandwidth. Besides, the measured return loss of the single transition is higher than 23 dB in the entire bandwidth. Compared with some other reported SRW transitions, the proposed SRW transition exhibits extreme compactness, lower insertion loss, and more excellent bandwidth performance. The dimensions of the transition structure are only 0.75λ * 0.7λ * 0.35λ (λ is the wavelength at the center frequency) for the central frequency of 12 GHz. The design's transition is completely scalable to other needed frequency band.","Deng J
Wang Q
Zhao P
","(PMID:30399821
)",A compact ultra-wideband ridge waveguide to coaxial line transition.,https://europepmc.org/abstract/MED/30399821%0A
"We present a new class of tunable light-driven oscillators based on mm-scale objects adsorbed at fluid interfaces. A fixed light source induces photothermal surface tension gradients (Marangoni stresses) that drive nanocomposite hydrogel discs away from a stable apex position atop a drop of water. The capillary forces on the disc increase with surface curvature; thus, they act to restore the disc to its original position. As the disc reenters the light source it again experiences Marangoni propulsion, leading to sustained oscillation for appropriate conditions. Propulsive forces can be modulated with incident light intensity, while the restoring force can be tuned via surface curvature-i.e., drop volume-providing highly tunable oscillatory behaviors. To our knowledge, this is the first example where Marangoni and capillary forces combine to incite sustained motion. As such, a model was developed that describes this behavior and provides key insights into the underlying control parameters. We expect that this simple approach will enable the study of more complex and coupled oscillatory systems.","Hauser AW
Sundaram S
Hayward RC
","(PMID:30362782
)",Photothermocapillary Oscillators.,https://europepmc.org/abstract/MED/30362782%0A
"Recent advances in DNA synthesis and computer science have enabled the de novo design of biosynthetic pathways. Numerous computational tools are currently available for searching biosynthetic pathways and ranking them on the basis of multiple criteria for installation into microbial chassis strains. This new framework allows the design of artificial biosynthetic pathways without expert knowledge of the specific biochemical reactions involved. Moreover, genetic apparatuses with quantitative and predictable properties enable rational construction of gene circuits. Thus, our ability to construct microbial cells specialized for bio-production is accelerating. However, many synthetic biology tools have not yet been fully applied to metabolic engineering owing to the lack of interdisciplinary collaboration between metabolic engineers and synthetic biologists. Therefore, we have focused on discussing how synthetic biology tools can be applied to de novo design of biosynthetic pathways.","Okano K
Honda K
Taniguchi H
Kondo A
","(PMID:30169822
)",De novo design of biosynthetic pathways for bacterial production of bulk chemicals and biofuels.,https://europepmc.org/abstract/MED/30169822%0A
"The incidence of benign and malignant testicular disorders is on the rise. Three literature reviews and one qualitative study found that men's awareness of testicular disorders was lacking, and their intentions to seek help for symptoms of testicular disease were low.The aim of the study was to enhance men's awareness of testicular disorders, help-seeking intentions for testicular symptoms, and intention and behavior to feel their testes.Men aged 18-50 years were recruited from a university and asked to engage in a three-level, educational, virtual reality experience. The Medical Research Council framework guided the development and pilot testing of the intervention. Knowledge, awareness, perceived risk, implementation intentions, help-seeking intentions, and behaviors were measured at pretest (T0), immediately posttest (T1), and 1 month posttest (T2).Data were available from 49 participants. In comparison to T0, a significant increase in knowledge (mean difference [MD] = 3.5, 95% CI [2.8, 4.26]); testicular awareness (MD = 0.2, 95% CI [0.01, 0.41]); implementation intentions (MD = 0.6, 95% CI [0.33, 0.90]); and help-seeking intentions for testicular swelling (MD = 0.3, 95% CI [0.12, 0.51]), lumpiness (MD = 0.3, 95% CI [0.08, 0.46]), and pain (MD = 0.6, 95% CI [0.25, 1.01]) was noted at T1. This increase was maintained at T2. Participants who expressed an intention to feel their testes at T0 were more likely to report performing this behavior at T2.The intervention succeeded in promoting knowledge, testicular awareness, implementation intentions, help-seeking intentions, and behaviors. A randomized controlled trial of the Enhancing Men's Awareness of Testicular Disorders intervention with a larger sample size is warranted.","Saab MM
Landers M
Cooke E
Murphy D
Davoren M
Hegarty J
","(PMID:30059354
)",Enhancing Men's Awareness of Testicular Disorders Using a Virtual Reality Intervention: A Pre-Post Pilot Study.,https://europepmc.org/abstract/MED/30059354%0A
"The objective of this study was to investigate the ability of computer vision system to predict pork intramuscular fat percentage (IMF%). Center-cut loin samples (n = 85) were trimmed of subcutaneous fat and connective tissue. Images were acquired and pixels were segregated to estimate image IMF% and 18 image color features for each image. Subjective IMF% was determined by a trained grader. Ether extract IMF% was calculated using ether extract method. Image color features and image IMF% were used as predictors for stepwise regression and support vector machine models. Results showed that subjective IMF% had a correlation of 0.81 with ether extract IMF% while the image IMF% had a 0.66 correlation with ether extract IMF%. Accuracy rates for regression models were 0.63 for stepwise and 0.75 for support vector machine. Although subjective IMF% has shown to have better prediction, results from computer vision system demonstrates the potential of being used as a tool in predicting pork IMF% in the future.","Liu JH
Sun X
Young JM
Bachmeier LA
Newman DJ
","(PMID:29684840
)",Predicting pork loin intramuscular fat using computer vision system.,https://europepmc.org/abstract/MED/29684840%0A
"BACKGROUND:To provide feedback to surgeons in robotic surgery training, many surgical skill evaluation methods have been developed. However, they hardly focus on the performance of the surgical motion segments. This paper proposes a method of specifying a trainee's skill weakness in the surgical training. METHODS:This paper proposed an automatic skill evaluation framework by comparing the trainees' operations with the template operation in each surgical motion segment, which is mainly based on dynamic time warping (DTW) and continuous hidden Markov model (CHMM). RESULTS:The feasibility of this proposed framework has been preliminarily verified. For specifying the skill weakness in instrument handling and efficiency, the result of this proposed framework was significantly correlated with that of manual scoring. CONCLUSION:The automatic skill evaluation framework has shown its superiority in efficiency, objectivity, and being targeted, which can be used in robotic surgery training.","Peng W
Xing Y
Liu R
Li J
Zhang Z
","(PMID:30281892
)",An automatic skill evaluation framework for robotic surgery training.,https://europepmc.org/abstract/MED/30281892%0A
"Studying the neural correlates of craving to smoke is of great importance to improve treatment outcomes in smoking addiction. According to previous studies, the critical roles of striatum and frontal brain regions had been revealed in addiction. However, few studies focused on the hub of brain regions in the 12 h abstinence induced craving in young smokers. Thirty-one young male smokers were enrolled in the present study. A within-subject experiment design was carried out to compare functional connectivity density between 12-h smoking abstinence and smoking satiety conditions during resting state in young adult smokers by using functional connectivity density mapping (FCDM). Then, the functional connectivity density changes during smoking abstinence versus satiety were further used to examine correlations with abstinence-induced changes in subjective craving. We found young adult smokers in abstinence state (vs satiety) had higher local functional connectivity density (lFCD) and global functional connectivity density (gFCD) in brain regions including striatal subregions (i.e., bilateral caudate and putamen), frontal regions (i.e., anterior cingulate cortex (ACC) and orbital frontal cortex (OFC)) and bilateral insula. We also found higher lFCD during smoking abstinence (vs satiety) in bilateral thalamus. Additionally, the lFCD changes of the left ACC, bilateral caudate and right OFC were positively correlated with the changes in craving induced by abstinence (i.e., abstinence minus satiety) in young adult smokers. The present findings improve the understanding of the effects of acute smoking abstinence on the hubs of brain gray matter in the abstinence-induces craving and may contribute new insights into the neural mechanism of abstinence-induced craving in young smokers in smoking addiction.","Zhao S
Li Y
Li M
Wang R
Bi Y
Zhang Y
Lu X
Yu D
Yang L
Yuan K
","(PMID:29926324
)",12-h abstinence-induced functional connectivity density changes and craving in young smokers: a resting-state study.,https://europepmc.org/abstract/MED/29926324%0A
"Studies of different cultures have reported that expectant fathers experience physiological and psychological changes during their partner's pregnancy. These symptoms are classed as Couvade Syndrome (sympathetic pregnancy) symptoms. The main aim of this study was to determine the prevalence of Couvade Syndrome among Jordanian expectant fathers. A descriptive quantitative research design that utilized the Men's Health During Partners' Pregnancy (MHDPP) questionnaire was employed to collect data from three Maternal and Child Health Care Centers in public hospitals. A total of 449 participants completed the questionnaire. Descriptive statistics were used to describe the characteristics of the sample and the main variables. Chi-square tests were conducted to find the relationship between the pregnancy trimester and the specific Couvade Syndrome symptom. Jordanian expectant fathers experienced high rates of Couvade Syndrome (59.1%). The prevalence of Couvade Syndrome among the participants is considered to be the highest reported rate when compared to the results of previous studies. This rate may be due to the tendency among men in Jordan to have a strong desire for children soon after marriage and to have a strong commitment to family life. With a better understanding of the expectant father's response to pregnancy, health-care providers would be better able to provide them with the necessary support and education. This could contribute to the health and well-being of expectant fathers and their families.","Mrayan L
Abujilban S
Abuidhail J
Bani Yassein M
Al-Modallal H
","(PMID:30387694
)",Couvade Syndrome Among Jordanian Expectant Fathers.,https://europepmc.org/abstract/MED/30387694%0A
"Unveiling the impact of a single parameter on the catalytic descriptor is fundamental to guide rational design principles for high-activity catalysts. Facets with distinct surface coordination that exhibit a central role in the kinetics modulation (reactivity) of surface electrochemistry, have remained elusive in oxygen evolution reactions (OERs). Here, the relationship between the predominant facets and catalytic reactivity is revealed, and it is recognized that facets decisively govern the oxygen evolution activity descriptor in hematite nanocrystals. Specifically, the hematite shows facet-dependent activity that follows the computed binding energy of surface-oxygenated intermediates. Moreover, a lower kinetics energy barrier is observed on a highly coordinated surface, both experimentally and computationally, in the light of molecular orbital principles. Consequently, a record-low overpotential and Tafel slope in iron oxides toward OER are manifested, competing against the benchmark binary transition metal oxide electrocatalysts and expelling the stereotype of the passive oxygen evolution activity of iron oxides. Significantly, the identification of facet-governing reactivity, construction of favorable facets, and strategic regulation of surface covalency enlighten design strategies for highly active catalysts.","Wu H
Yang T
Du Y
Shen L
Ho GW
","(PMID:30387194
)",Identification of Facet-Governing Reactivity in Hematite for Oxygen Evolution.,https://europepmc.org/abstract/MED/30387194%0A
"Objective: Standard antimicrobial susceptibility testing (AST) approaches lead to delays in the selection of optimal antimicrobial therapy. We sought to determine the accuracy of antimicrobial resistance (AMR) determinants identified by Nanopore whole genome sequencing in predicting AST results.Methods: Using a cohort of 40 clinical isolates (21 carbapenemase-producing carbapenem-resistant Klebsiella pneumoniae, 10 non-carbapenemase-producing carbapenem resistant K. pneumoniae, and 9 carbapenem-susceptible K. pneumoniae), three separate sequencing and analysis pipelines were performed: (1) a real-time Nanopore analysis approach identifying acquired AMR genes, (2) an assembly-based Nanopore approach identifying acquired AMR genes and chromosomal mutations, and (3) an approach using short read correction of Nanopore assemblies. The short read correction of Nanopore assemblies served as the reference standard to determine the accuracy of Nanopore sequencing results.Results: With the real-time analysis approach, full annotation of acquired AMR genes occurred within 8 hours of subcultured isolates. Assemblies sufficient for full resistance gene and single nucleotide polymorphism annotation were available within 14 hours from subcultured isolates. The overall agreement of genotypic results and anticipated AST results for the 40 K. pneumoniae isolates was 77% (range 30-100%) and 92% (range 80-100%) for the real-time approach and the assembly approach, respectively. Evaluating the patients contributing the 40 isolates, the real-time approach and assembly approach could shorten the median time to effective antibiotic therapy by 20 hours and 26 hours, respectively, compared to standard AST.Conclusions: Nanopore sequencing offers a rapid approach to both accurately identify resistance mechanisms as well as predict AST results for K. pneumoniae isolates. Bioinformatics improvements enabling real-time alignment coupled with rapid extraction and library preparation will further enhance the accuracy and workflow of the Nanopore real-time approach.","Tamma PD
Fan Y
Bergman Y
Pertea G
Kazmi A
Lewis S
Carroll KC
Schatz MC
Timp W
Simner PJ
","(PMID:30373801
)",Applying Rapid Whole Genome Sequencing to Predict Phenotypic Antimicrobial Susceptibility Testing Results Among Carbapenem-Resistant Klebsiella pneumoniae Clinical Isolates.,https://europepmc.org/abstract/MED/30373801%0A
"Hepatocellular carcinoma (HCC) remains a deadly cancer, underscoring the need for relevant preclinical models. Male C3HeB/FeJ mice model spontaneous HCC with some hepatocarcinogenesis susceptibility loci corresponding to syntenic regions of human chromosomes altered in HCC. We tested other properties of C3HeB/FeJ tumors for similarity to human HCC. C3HeB/FeJ tumors were grossly visible at 4 months of age, with prevalence and size increasing until about 11 months of age. Histologic features shared with human HCC include hepatosteatosis, tumor progression from dysplasia to poorly differentiated, vascular invasion, and trabecular, oncocytic, vacuolar, and clear cell variants. More tumor cells displayed cytoplasmic APE1 staining versus normal liver. Ultrasound effectively detected and monitored tumors, with 85.7% sensitivity. Over 5000 genes were differentially expressed based on the GSE62232 and GSE63898 human HCC datasets. Of these, 158 and 198 genes, respectively, were also differentially expressed in C3HeB/FeJ. Common cancer pathways, cell cycle, p53 signaling and other molecular aspects, were shared between human and mouse differentially expressed genes. We established eigengenes that distinguish HCC from normal liver in the C3HeB/FeJ model and a subset of human HCC. These features extend the relevance and improve the utility of the C3HeB/FeJ line for HCC studies.","Zavadil JA
Herzig MCS
Hildreth K
Foroushani A
Boswell W
Walter R
Reddick R
White H
Zare H
Walter CA
","(PMID:30365185
)",C3HeB/FeJ Mice mimic many aspects of gene expression and pathobiological features of human hepatocellular carcinoma.,https://europepmc.org/abstract/MED/30365185%0A
"BACKGROUND AND OBJECTIVE:In pulmonary nodule detection, the first stage, candidate detection, aims to detect suspicious pulmonary nodules. However, detected candidates include many false positives and thus in the following stage, false positive reduction, such false positives are reliably reduced. Note that this task is challenging due to 1) the imbalance between the numbers of nodules and non-nodules and 2) the intra-class diversity of non-nodules. Although techniques using 3D convolutional neural networks (CNNs) have shown promising performance, they suffer from high computational complexity which hinders constructing deep networks. To efficiently address these problems, we propose a novel framework using the ensemble of 2D CNNs using single views, which outperforms existing 3D CNN-based methods. METHODS:Our ensemble of 2D CNNs utilizes single-view 2D patches to improve both computational and memory efficiency compared to previous techniques exploiting 3D CNNs. We first categorize non-nodules on the basis of features encoded by an autoencoder. Then, all 2D CNNs are trained by using the same nodule samples, but with different types of non-nodules. By extending the learning capability, this training scheme resolves difficulties of extracting representative features from non-nodules with large appearance variations. Note that, instead of manual categorization requiring the heavy workload of radiologists, we propose to automatically categorize non-nodules based on the autoencoder and k-means clustering. RESULTS:We performed extensive experiments to validate the effectiveness of our framework based on the database of the lung nodule analysis 2016 challenge. The superiority of our framework is demonstrated through comparing the performance of five frameworks trained with differently constructed training sets. Our proposed framework achieved state-of-the-art performance (0.922 of the competition performance metric score) with low computational demands (789K of parameters and 1024M of floating point operations per second). CONCLUSION:We presented a novel false positive reduction framework, the ensemble of single-view 2D CNNs with fully automatic non-nodule categorization, for pulmonary nodule detection. Unlike previous 3D CNN-based frameworks, we utilized 2D CNNs using 2D single views to improve computational efficiency. Also, our training scheme using categorized non-nodules, extends the learning capability of representative features of different non-nodules. Our framework achieved state-of-the-art performance with low computational complexity.","Eun H
Kim D
Jung C
Kim C
","(PMID:30337076
)",Single-view 2D CNNs with fully automatic non-nodule categorization for false positive reduction in pulmonary nodule detection.,https://europepmc.org/abstract/MED/30337076%0A
"The discovery of new materials can bring enormous societal and technological progress. In this context, exploring completely the large space of potential materials is computationally intractable. Here, we review methods for achieving inverse design, which aims to discover tailored materials from the starting point of a particular desired functionality. Recent advances from the rapidly growing field of artificial intelligence, mostly from the subfield of machine learning, have resulted in a fertile exchange of ideas, where approaches to inverse molecular design are being proposed and employed at a rapid pace. Among these, deep generative models have been applied to numerous classes of materials: rational design of prospective drugs, synthetic routes to organic compounds, and optimization of photovoltaics and redox flow batteries, as well as a variety of other solid-state materials.","Sanchez-Lengeling B
Aspuru-Guzik A
","(PMID:30049875
)",Inverse molecular design using machine learning: Generative models for matter engineering.,https://europepmc.org/abstract/MED/30049875%0A
"Hydroponic uptake studies were conducted to evaluate the uptake and translocation of Tc, Cs (stable analog for Cs), Np, and U into established and seedling Andropogon virginicus specimens under controlled laboratory conditions. Plant specimens were grown in analyte-spiked Hoagland nutrient solution for 24 h, 3 d, and 5 d. Translocation to shoots was greatest for Tc and Cs, likely due to their analogous nature to plant nutrients, while U (and Np to a lesser extent) predominantly partitioned to root tissue with less extensive translocation to the shoots. Plant age contributed significantly to differences in concentration ratios for all nuclides in shoot tissues (p ≤ 0.024), with higher concentration ratios for seedling specimens. Additionally, duration of exposure was associated with significant differences in concentration ratios of Cs and Tc for seedlings (p = 0.007 and p = 0.030, respectively) while plant part (root or shoot) was associated with significant differences in concentration ratios of established plants (p < 0.001 for both nuclides). Statistically significant increases in radionuclide uptake in seedling specimens relative to established plants under controlled conditions suggests that, in addition to geochemical factors, plant life stage of wild grasses may also be an important factor influencing radionuclide transport in the natural environment.","Montgomery DA
Edayilam N
Tharayil N
Powell BA
Martinez NE
","(PMID:29878916
)","The Uptake and Translocation of 99Tc, 133Cs, 237Np, and 238U Into Andropogon Virginicus With Consideration of Plant Life Stage.",https://europepmc.org/abstract/MED/29878916%0A
"Haloarcula strains, which are halophilic archaea, harbour two to three copies of 16S rRNA genes (rrsA, rrsB and rrsC) in their genomes. While rrsB and rrsC (rrsBC) show almost identical sequences, rrsA shows 4-6% sequence difference and 1-3% guanine-plus-cytosine content (PGC) difference compared to rrsBC. Based on the strong correlation between the PGC of 16S rRNA genes and the growth temperatures of the prokaryotes, we hypothesised that high-PGC rrsA and low-PGC rrsBC are expressed at high and low temperatures, respectively. To verify the hypothesis, we performed sequence analyses and expression surveys of each 16S rRNA gene in eight Haloarcula strains. The secondary structure prediction of the 16S rRNA via computer simulation showed that the structural stability of 16S rRNAs transcribed from rrsA was higher than that of 16S rRNAs transcribed from rrsBC. We measured expression levels of rrsA and rrsBC under various temperature conditions by reverse-transcriptase quantitative PCR. The expression ratio of high-PGC rrsA to low-PGC rrsBC increased with cultivation temperatures in seven of eight Haloarcula strains. Our results suggest that the transcription of high-PGC rrsA and low-PGC rrsBC may be regulated in response to environmental temperature, and that 16S rRNAs transcribed from high-PGC rrsA function under high temperature conditions close to the maximum growth temperature.","Sato Y
Kimura H
","(PMID:30128892
)",Temperature-dependent expression of different guanine-plus-cytosine content 16S rRNA genes in Haloarcula strains of the class Halobacteria.,https://europepmc.org/abstract/MED/30128892%0A
"While structural data on viruses are more and more common, information on their dynamics is much harder to obtain as those viruses form very large molecular complexes. In this paper, we propose a new method for computing the coarse-grained normal modes of such supra-molecules, NormalGo. A new formalism is developed to represent the Hessian of a quadratic potential using tensor products. This formalism is applied to the Tirion elastic potential, as well as to a Gō like potential. When combined with a fast method for computing a select set of eigenpairs of the Hessian, this new formalism enables the computation of thousands of normal modes of a full viral shell with more than one hundred thousand atoms in less than 2 h on a standard desktop computer. We then compare the two coarse-grained potentials. We show that, despite significant differences in their formulations, the Tirion and the Gō like potentials capture very similar dynamics characteristics of the molecule under study. However, we find that the Gō like potential should be preferred as it leads to less local deformations in the structure of the molecule during normal mode dynamics. Finally, we use NormalGo to characterize the structural transitions that occur when FAB fragments bind to the icosahedral outer shell of serotype 3 of the Dengue virus. We have identified residues at the surface of the outer shell that are important for the transition between the FAB-free and FAB-bound conformations, and therefore potentially useful for the design of antibodies to Dengue viruses.","Koehl P
Delarue M
","(PMID:30273615
)",Coarse-grained dynamics of supramolecules: Conformational changes in outer shells of Dengue viruses.,https://europepmc.org/abstract/MED/30273615%0A
"There are several computer applications (apps) that can be installed on smartphones to assist patients with diabetes in treating their disease. Not only does the range of use of such apps vary greatly, their quality does as well. As part of the DiaDigital initiative of the German Working Group for Diabetes Technology (AGDT), apps are evaluated using a set of criteria and a seal of distinction is then awarded ( www.diadigital.de ). The information collected in this review process is made public on this website to ensure both the necessary transparency as well as to be able to rapidly adapt voting on further app development. Until now, no such approach on evaluating the quality of diabetes apps has existed in Germany. The hope is that this will also help improve the quality of apps.","Kaltheuner M
Drossel D
Heinemann L
","(PMID:30264585
)",DiaDigital Apps: Evaluation of Smartphone Apps Using a Quality Rating Methodology for Use by Patients and Diabetologists in Germany.,https://europepmc.org/abstract/MED/30264585%0A
"Motivation:Identification of enhancers and their strength is important because they play a critical role in controlling gene expression. Although some bioinformatics tools were developed, they are limited in discriminating enhancers from non-enhancers only. Recently, a two-layer predictor called 'iEnhancer-2L' was developed that can be used to predict the enhancer's strength as well. However, its prediction quality needs further improvement to enhance the practical application value. Results:A new predictor called 'iEnhancer-EL' was proposed that contains two layer predictors: the first one (for identifying enhancers) is formed by fusing an array of six key individual classifiers, and the second one (for their strength) formed by fusing an array of ten key individual classifiers. All these key classifiers were selected from 171 elementary classifiers formed by SVM (Support Vector Machine) based on kmer, subsequence profile and PseKNC (Pseudo K-tuple Nucleotide Composition), respectively. Rigorous cross-validations have indicated that the proposed predictor is remarkably superior to the existing state-of-the-art one in this area. Availability and implementation:A web server for the iEnhancer-EL has been established at http://bioinformatics.hitsz.edu.cn/iEnhancer-EL/, by which users can easily get their desired results without the need to go through the mathematical details. Supplementary information:Supplementary data are available at Bioinformatics online.","Liu B
Li K
Huang DS
Chou KC
","(PMID:29878118
)",iEnhancer-EL: identifying enhancers and their strength with ensemble learning approach.,https://europepmc.org/abstract/MED/29878118%0A
"OBJECTIVE:As for stroke rehabilitation, brain-computer interfaces could potentially be used for inducing neural plasticity in patients with cerebral palsy by pairing movement intentions with relevant somatosensory feedback. Therefore, the aim of this study was to investigate if movement intentions from children with cerebral palsy can be detected from single-trial EEG. Moreover, different feature types and electrode setups were evaluated. APPROACH:Eight adolescents with cerebral palsy performed self-paced dorsiflexions of the ankle while nine channels of EEG were recorded. The EEG was divided into movement intention epochs and idle epochs. The data were pre-processed and temporal, spectral and template matching features were extracted and classified using a random forest classifier. The classification accuracy of the 2-class problem was used as an estimation of the detection performance. This analysis was repeated using a single EEG channel, a large Laplacian filtered channel and nine channels. MAIN RESULTS:A classification accuracy of ~70% was obtained using only a single channel. This increased to ~80% for the Laplacian filtered data, while ~75% of the data were correctly classified when using nine channels. In general, the highest accuracies were obtained using temporal features or using all of them combined. SIGNIFICANCE:The results indicate that it is possible to detect movement intentions in patients with cerebral palsy; this may be used in the development of a brain-computer interface for motor rehabilitation of patients with cerebral palsy.","Jochumsen M
Shafique M
Hassan A
Niazi IK
","(PMID:30260322
)",Movement intention detection in adolescents with cerebral palsy from single-trial EEG.,https://europepmc.org/abstract/MED/30260322%0A
"This study examined whether trained variability would generalize across dimensions of the target response. Two experiments used a computerized rectangle drawing task that required participants to click and drag a mouse cursor to create rectangles on a computer screen. In Experiment 1, one group received points when successive rectangles varied in their size, shape and location (VAR), another group were yoked to the VAR group and received points that were allocated to them using a yoking procedure (YOKE), regardless of the variability in the size, shape or location of the rectangle drawn. Variability was higher for a dimension when variability on that dimension was directly reinforced. In Experiment 2, three groups of participants received points when rectangles varied on two dimensions; each group differed in the two dimensions that required variation. Variability was again higher for the reinforced dimensions for two of the three groups. Comparison with the YOKE group showed that the variability on those dimensions where variability was not directly reinforced was affected by reinforcement for variability on the other dimensions. Specifically, the variability in Shape and Location was significantly higher when these two dimensions occurred with other dimensions where variability was reinforced (as in Experiment 2) compared to when they were not required to vary (as in the YOKE group). This suggests that, for these two groups, the reinforced variability on the other two dimensions generalized to the third dimension. Implications of this finding to our understanding of factors that promote behavioral variability are discussed.","Kong X
McEwan JS
Bizo LA
Foster MT
","(PMID:30391657
)",Generalization of learned variability across multiple dimensions in humans.,https://europepmc.org/abstract/MED/30391657%0A
No abstract provided.,"Ferguson AL
","(PMID:30159387
 PMCID:PMC6107860)",ACS Central Science Virtual Issue on Machine Learning.,https://europepmc.org/abstract/MED/30159387%0A
"The paper discusses the possibility of using a mixture of two growth limiting substrates to induce or eliminate self-sustained oscillations in a continuous culture process. The proportion of both substrates in the mixture is treated as a new control variable. The presented approach is based on the assumption that the oscillatory behaviour occurs for selected substrates in some range of dilution rates. Because a double-substrate limitation may occur, the analysis is performed for two fundamental substrate utilization patterns: simultaneous consumption and diauxic growth. By using model simulations and bifurcation analysis, we show that an appropriate proportion of two substrates in the mixture allows for the control of the oscillatory behaviour.","Skupin P
Metzger M
","(PMID:30058476
)",Oscillatory behaviour control in a continuous culture under double-substrate limitation.,https://europepmc.org/abstract/MED/30058476%0A
"The paper presents the application of Grade Correspondence Analysis (GCA) and Grade Correspondence Cluster Analysis (GCCA) for ordering and grouping -omics datasets, using transcriptomic data as an example. Based on gene expression data describing 256 patients with Multiple Myeloma it was shown that the GCA method could be used to find regularities in the analyzed collections and to create characteristic gene expression profiles for individual groups of patients. GCA iteratively permutes rows and columns to maximize the tau-Kendall or rho-Spearman coefficients, which makes it possible to arrange rows and columns in such a way that the most similar ones remain in each other's neighbourhood. In this way, the GCA algorithm highlights regularities in the data matrix. The ranked data can then be grouped using the GCCA method, and after that aggregated in clusters, providing a representation that is easier to analyze-especially in the case of large sets of gene expression profiles. Regularization of transcriptomic data, which is presented in this manuscript, has enabled division of the data set into column clusters (representing genes) and row clusters (representing patients). Subsequently, rows were aggregated (based on medians) to visualise the gene expression profiles for patients with Multiple Myeloma in each collection. The presented analysis became the starting point for characterisation of differentiated genes and biochemical processes in which they are involved. GCA analysis may provide an alternative analytical method to support differentiation and analysis of gene expression profiles characterising individual groups of patients.","Piwowar M
Kocemba-Pilarczyk KA
Piwowar P
","(PMID:30383819
 PMCID:PMC6211732)",Regularization and grouping -omics data by GCA method: A transcriptomic case.,https://europepmc.org/abstract/MED/30383819%0A
"The fundamental light-matter interactions in monolayer transition metal dichalcogenides might be significantly engineered by hybridization with their organic counterparts, enabling intriguing optoelectronic applications. Here, atomically thin organic-inorganic (O-I) heterostructures, comprising monolayer MoSe2 and mono-/few-layer single-crystal pentacene samples, are fabricated. These heterostructures show type-I band alignments, allowing efficient and layer-dependent exciton pumping across the O-I interfaces. The interfacial exciton pumping has much higher efficiency (>86 times) than the photoexcitation process in MoSe2 , although the pentacene layer has much lower optical absorption than MoSe2 . This highly enhanced pumping efficiency is attributed to the high quantum yield in pentacene and the ultrafast energy transfer between the O-I interface. Furthermore, those organic counterparts significantly modulate the bindings of charged excitons in monolayer MoSe2 via their precise dielectric environment engineering. The results open new avenues for exploring fundamental phenomena and novel optoelectronic applications using atomically thin O-I heterostructures.","Zhang L
Sharma A
Zhu Y
Zhang Y
Wang B
Dong M
Nguyen HT
Wang Z
Wen B
Cao Y
Liu B
Sun X
Yang J
Li Z
Kar A
Shi Y
Macdonald D
Yu Z
Wang X
Lu Y
","(PMID:30159929
)",Efficient and Layer-Dependent Exciton Pumping across Atomically Thin Organic-Inorganic Type-I Heterostructures.,https://europepmc.org/abstract/MED/30159929%0A
"Due to the difficulty of collecting labeled images for hundreds of thousands of visual categories, zero-shot learning, where unseen categories do not have any labeled images in training stage, has attracted more attention. In the past, many studies focused on transferring knowledge from seen to unseen categories by projecting all category labels into a semantic space. However, the label embeddings could not adequately express the semantics of categories. Furthermore, the common semantics of seen and unseen instances cannot be captured accurately because the distribution of these instances may be quite different. For these issues, we propose a novel deep semisupervised method by jointly considering the heterogeneity gap between different modalities and the correlation among unimodal instances. This method replaces the original labels with the corresponding textual descriptions to better capture the category semantics. This method also overcomes the problem of distribution difference by minimizing the maximum mean discrepancy between seen and unseen instance distributions. Extensive experimental results on two benchmark data sets, CU200-Birds and Oxford Flowers-102, indicate that our method achieves significant improvements over previous methods.","Zhang L
Liu J
Luo M
Chang X
Zheng Q
","(PMID:29566352
)",Deep Semisupervised Zero-Shot Learning with Maximum Mean Discrepancy.,https://europepmc.org/abstract/MED/29566352%0A
No abstract provided.,"Qi C
Yun S
Yang Y
Han Y
Renqi W
","(PMID:30318488
)",Chromatographic Retention Assisted Deconvolution of Liquid Chromatography-Mass Spectrometry Chromatogram of Natural Products.,https://europepmc.org/abstract/MED/30318488%0A
"CRISPR-Cas systems not only play key roles in prokaryotic acquired immunity, but can also be adapted as powerful genome editing tools. Understanding the native role of CRISPR-Cas systems in providing adaptive immunity can lead to new CRISPR-based technologies. Here, we develop CRISPRminer, a knowledge base and web server to comprehensively collect and investigate the knowledge of CRISPR-Cas systems and generate instructive annotations, including CRISPR arrays and Cas protein annotation, CRISPR-Cas system classification, self-targeting events detection, microbe-phage interaction inference, and anti-CRISPR annotation. CRISPRminer is user-friendly and freely available at http://www.microbiome-bigdata.com/CRISPRminer.","Zhang F
Zhao S
Ren C
Zhu Y
Zhou H
Lai Y
Zhou F
Jia Y
Zheng K
Huang Z
","(PMID:30393777
 PMCID:PMC6208339)",CRISPRminer is a knowledge base for exploring CRISPR-Cas systems in microbe and phage interactions.,https://europepmc.org/abstract/MED/30393777%0A
"Poly(3,4-ethylenenedioxythiophene) or PEDOT is a promising candidate for next-generation neuronal electrode materials but its weak adhesion to underlying metallic conductors impedes its potential. An effective method of mechanically anchoring the PEDOT within an Au nanorod (Au-nr) structure is reported and it is demonstrated that it provides enhanced adhesion and overall PEDOT layer stability. Cyclic voltammetry (CV) stress is used to investigate adhesion and stability of spin-cast and electrodeposited PEDOT. The Au-nr adhesion layer permits 10 000 CV cycles of coated PEDOT film in phosphate buffered saline solution without delamination nor significant change of the electrochemical impedance, whereas PEDOT coating film on planar Au electrodes delaminates at or below 1000 cycles. Under CV stress, spin-cast PEDOT on planar Au delaminates, whereas electroplated PEDOT on planar Au encounters surface leaching/decomposition. After 5 weeks of accelerated aging tests at 60 °C, the electrodeposited PEDOT/Au-nr microelectrodes demonstrate a 92% channel survival compared to only 25% survival for spin-cast PEDOT on planar films. Furthermore, after a 10 week chronic implantation onto mouse barrel cortex, PEDOT/Au-nr microelectrodes do not exhibit delamination nor morphological changes, whereas the conventional PEDOT microelectrodes either partially or fully delaminate. Immunohistochemical evaluation demonstrates no or minimal response to the PEDOT implant.","Ganji M
Hossain L
Tanaka A
Thunemann M
Halgren E
Gilja V
Devor A
Dayeh SA
","(PMID:30369088
)",Monolithic and Scalable Au Nanorod Substrates Improve PEDOT-Metal Adhesion and Stability in Neural Electrodes.,https://europepmc.org/abstract/MED/30369088%0A
"This work is concerned with the numerical modeling of susceptible-latent-breakingout-quarantine-susceptible (SLBQRS) computer virus dynamics. The SLBQRS epidemic system is solved with three finite difference methods, one is proposed nonstandard finite difference (NSFD) method and the other two are well known forward Euler finite difference (FD) method and Runge-Kutta finite difference method of order 4 (RK-4). The proposed NSFD method preserves all the essential conditions of the continuous system while RK-4 method and forward Euler method fail to preserve some of its essential conditions like positivity, convergence to the true steady states of the continuous system. The convergence analysis of the proposed NSFD method is also performed. Bifurcation value of infection coefficient for the system is also find out.","Fatima U
Ali M
Ahmed N
Rafiq M
","(PMID:29872764
 PMCID:PMC5986544)",Numerical modeling of susceptible latent breaking-out quarantine computer virus epidemic dynamics.,https://europepmc.org/abstract/MED/29872764%0A
"In nature, repeated base units produce handed structures that selectively bond to make rigid or compliant materials. Auxetic tilings are scale-independent frameworks made from repeated unit cells that expand under tension. We discovered how to produce handedness in auxetic unit cells that shear as they expand by changing the symmetries and alignments of auxetic tilings. Using the symmetry and alignment rules that we developed, we made handed shearing auxetics that tile planes, cylinders, and spheres. By compositing the handed shearing auxetics in a manner inspired by keratin and collagen, we produce both compliant structures that expand while twisting and deployable structures that can rigidly lock. This work opens up new possibilities in designing chemical frameworks, medical devices like stents, robotic systems, and deployable engineering structures.","Lipton JI
MacCurdy R
Manchester Z
Chin L
Cellucci D
Rus D
","(PMID:29748279
)",Handedness in shearing auxetics creates rigid and compliant structures.,https://europepmc.org/abstract/MED/29748279%0A
"Systematic experimental approaches have led to construction of comprehensive genetic and protein-protein interaction networks for the budding yeast, Saccharomyces cerevisiae. Genetic interactions capture functional relationships between genes using phenotypic readouts, while protein-protein interactions identify physical connections between gene products. These complementary, and largely non-overlapping, networks provide a global view of the functional architecture of a cell, revealing general organizing principles, many of which appear to be evolutionarily conserved. Here, we focus on insights derived from the integration of large-scale genetic and protein-protein interaction networks, highlighting principles that apply to both unicellular and more complex systems, including human cells. Network integration reveals fundamental connections involving key functional modules of eukaryotic cells, defining a core network of cellular function, which could be elaborated to explore cell-type specificity in metazoans.","VanderSluis B
Costanzo M
Billmann M
Ward HN
Myers CL
Andrews BJ
Boone C
","(PMID:30059827
)",Integrating genetic and protein-protein interaction networks maps a functional wiring diagram of a cell.,https://europepmc.org/abstract/MED/30059827%0A
"The authors combined virtual reality technology and social robotics to develop a tutoring system that resembled a small-group arrangement. This tutoring system featured a virtual teacher instructing sight words, and included a humanoid robot emulating a peer. The authors used a multiple-probe design across word sets to evaluate the effects of the instructional package on the explicit acquisition and vicarious learning of sight words instructed to three children with autism spectrum disorder (ASD) and the robot peer. Results indicated that participants acquired, maintained, and generalized 100% of the words explicitly instructed to them, made fewer errors while learning the words common between them and the robot peer, and vicariously learned 94% of the words solely instructed to the robot.","Saadatzi MN
Pennington RC
Welch KC
Graham JH
","(PMID:29926295
)",Small-Group Technology-Assisted Instruction: Virtual Teacher and Robot Peer for Individuals with Autism Spectrum Disorder.,https://europepmc.org/abstract/MED/29926295%0A
"Early diagnoses of esophageal cancer can greatly improve the survival rate of patients. At present, the lesion annotation of early esophageal cancers (EEC) in gastroscopic images is generally performed by medical personnel in a clinic. To reduce the effect of subjectivity and fatigue in manual annotation, computer-aided annotation is required. However, automated annotation of EEC lesions using images is a challenging task owing to the fine-grained variability in the appearance of EEC lesions. This study modifies the traditional EEC annotation framework and utilizes visual salient information to develop a two saliency levels-based lesion annotation (TSL-BLA) for EEC annotations on gastroscopic images. Unlike existing methods, the proposed framework has a strong ability of constraining false positive outputs. What is more, TSL-BLA is also placed an additional emphasis on the annotation of small EEC lesions. A total of 871 gastroscopic images from 231 patients were used to validate TSL-BLA. 365 of those images contain 434 EEC lesions and 506 images do not contain any lesions. 101 small lesion regions are extracted from the 434 lesions to further validate the performance of TSL-BLA. The experimental results show that the mean detection rate and Dice similarity coefficients of TSL-BLA were 97.24 and 75.15%, respectively. Compared with other state-of-the-art methods, TSL-BLA shows better performance. Moreover, it shows strong superiority when annotating small EEC lesions. It also produces fewer false positive outputs and has a fast running speed. Therefore, The proposed method has good application prospects in aiding clinical EEC diagnoses.","Liu D
Rao N
Mei X
Jiang H
Li Q
Luo C
Li Q
Zeng C
Zeng B
Gan T
","(PMID:30327890
)",Annotating Early Esophageal Cancers Based on Two Saliency Levels of Gastroscopic Images.,https://europepmc.org/abstract/MED/30327890%0A
"With an increase in the number of traffic accidents and enhanced attention to the rule of law, technical appraisement to reconstruct traffic accidents is attracting increasing attention. Accident videos are important aspects in identification; however, we cannot reconstruct an accident scene onsite using video for many reasons. In this paper, we introduce a computer-based virtual reality method that can digitally reconstruct a traffic accident. This method employs accident videos to perform a three-dimensional (3D) reconstruction of accident scenes. Using video screenshots, it constructs a model of humans and vehicles in 3D space to achieve the goal of dynamic restoration. The results indicate that this method has relatively high accuracy, requires little time and is easy to use. In this paper, we analyse the sources of errors for this method and summarize the application conditions.","Jiao P
Miao Q
Zhang M
Zhao W
","(PMID:30321743
)",A virtual reality method for digitally reconstructing traffic accidents from videos or still images.,https://europepmc.org/abstract/MED/30321743%0A
"Motor learning is an essential task, but little is known about how it might be facilitated via instructional presentation, particularly with respect to recent technological advancements. We examined the effects of spatial orientation (0° vs. 180°) and immersion (immersive virtual reality vs. nonimmersive video) on the ability to reproduce complex, dynamic movement sequences. We also evaluated whether these effects were modulated by experience. Experienced dancers and novices practiced dances by imitating a virtual instructor and then, following a delay, had to perform them from memory. In line with theoretical models of motor learning, video-coded accuracy scores increased with successive trials in accordance with the power law of practice. Participants were more accurate after viewing the instructor in a 0° orientation. However, their performance was not improved by immersive virtual reality instruction. Experienced dancers were more accurate than novices, but experience did not interact with orientation or immersion. These results suggest that, when observing complex, dynamic movement sequences, individuals across experience levels can perform and learn these actions better via a 0° orientation, and that virtual instruction does not require immersion to be effective. (PsycINFO Database Record (c) 2018 APA, all rights reserved).","LaFortune J
Macuga KL
","(PMID:30265051
)","Learning movements from a virtual instructor: Effects of spatial orientation, immersion, and expertise.",https://europepmc.org/abstract/MED/30265051%0A
"BACKGROUND & AIMS:The benefit of colonoscopy for colorectal cancer prevention depends on the adenoma detection rate (ADR). The ADR should reflect the adenoma prevalence rate, which is estimated to be higher than 50% in the screening-age population. However, the ADR by colonoscopists varies from 7% to 53%. It is estimated that every 1% increase in ADR lowers the risk of interval colorectal cancers by 3%-6%. New strategies are needed to increase the ADR during colonoscopy. We tested the ability of computer-assisted image analysis using convolutional neural networks (CNNs; a deep learning model for image analysis) to improve polyp detection, a surrogate of ADR. METHODS:We designed and trained deep CNNs to detect polyps using a diverse and representative set of 8,641 hand-labeled images from screening colonoscopies collected from more than 2000 patients. We tested the models on 20 colonoscopy videos with a total duration of 5 hours. Expert colonoscopists were asked to identify all polyps in 9 de-identified colonoscopy videos, which were selected from archived video studies, with or without benefit of the CNN overlay. Their findings were compared with those of the CNN using CNN-assisted expert review as the reference. RESULTS:When tested on manually labeled images, the CNN identified polyps with an area under the receiver operating characteristic curve of 0.991 and an accuracy of 96.4%. In the analysis of colonoscopy videos in which 28 polyps were removed, 4 expert reviewers identified 8 additional polyps without CNN assistance that had not been removed and identified an additional 17 polyps with CNN assistance (45 in total). All polyps removed and identified by expert review were detected by the CNN. The CNN had a false-positive rate of 7%. CONCLUSION:In a set of 8,641 colonoscopy images containing 4,088 unique polyps, the CNN identified polyps with a cross-validation accuracy of 96.4% and an area under the receiver operating characteristic curve of 0.991. The CNN system detected and localized polyps well within real-time constraints using an ordinary desktop machine with a contemporary graphics processing unit. This system could increase the ADR and decrease interval colorectal cancers but requires validation in large multicenter trials.","Urban G
Tripathi P
Alkayali T
Mittal M
Jalali F
Karnes W
Baldi P
","(PMID:29928897
)",Deep Learning Localizes and Identifies Polyps in Real Time With 96% Accuracy in Screening Colonoscopy.,https://europepmc.org/abstract/MED/29928897%0A
"For most of the cells, water permeability and plasma membrane properties play a vital role in the optimal protocol for successful cryopreservation. Measuring the water permeability of cells during subzero temperature is essential. So far, there is no perfect segmentation technique to be used for the image processing task on subzero temperature accurately. The ice formation and variable background during freezing posed a significant challenge for most of the conventional segmentation algorithms. Thus, a robust and accurate segmentation approach that can accurately extract cells from extracellular ice that surrounding the cell boundary is needed. Therefore, we propose a convolutional neural network (CNN) architecture similar to U-Net but differs from those conventionally used in computer vision to extract all the cell boundaries as they shrank in the engulfing ice. The images used was obtained from the cryo-stage microscope, and the data was validated using the Hausdorff distance, means ± standard deviation for different methods of segmentation result using the CNN model. The experimental results prove that the typical CNN model extracts cell borders contour from the background in its subzero state more coherent and effective as compared to other traditional segmentation approaches.","Mbogba MK
Haider Z
Hossain SMC
Huang D
Memon K
Panhwar F
Lei Z
Zhao G
","(PMID:30219374
)",The application of convolution neural network based cell segmentation during cryopreservation.,https://europepmc.org/abstract/MED/30219374%0A
"The importance of transient dynamics in ecological systems and in the models that describe them has become increasingly recognized. However, previous work has typically treated each instance of these dynamics separately. We review both empirical examples and model systems, and outline a classification of transient dynamics based on ideas and concepts from dynamical systems theory. This classification provides ways to understand the likelihood of transients for particular systems, and to guide investigations to determine the timing of sudden switches in dynamics and other characteristics of transients. Implications for both management and underlying ecological theories emerge.","Hastings A
Abbott KC
Cuddington K
Francis T
Gellner G
Lai YC
Morozov A
Petrovskii S
Scranton K
Zeeman ML
","(PMID:30190378
)",Transient phenomena in ecology.,https://europepmc.org/abstract/MED/30190378%0A
"The de Bruijn graph is fundamental to the analysis of next generation sequencing data and so, as datasets of DNA reads grow rapidly, it becomes more important to represent de Bruijn graphs compactly while still supporting fast assembly. Previous implementations of compact de Bruijn graphs have not supported node or edge deletion, however, which is important for pruning spurious elements from the graph.Belazzougui et al. (2016b) recently proposed a compact and fully dynamic representation, which supports exact membership queries and insertions and deletions of both nodes and edges. In this paper, we give a practical implementation of their data structure, supporting exact membership queries and fully dynamic edge operations, as well as limited support for dynamic node operations. We demonstrate experimentally that its performance is comparable to that of state-of-the-art implementations based on Bloom filters.Our source-code is publicly available at https://github.com/csirac/dynamicDBG under an open-source license.","Crawford V
Kuhnle A
Boucher C
Chikhi R
Gagie T
","(PMID:29939217
)",Practical Dynamic de Bruijn Graphs.,https://europepmc.org/abstract/MED/29939217%0A
"Comparative neuroanatomy studies improve understanding of brain structure and function and provide insight regarding brain development, evolution, and also what features of the brain are uniquely human. With modern methods such as diffusion MRI (dMRI) and quantitative MRI (qMRI), we are able to measure structural features of the brain with the same methods across human and non-human primates. In this review article, we discuss how recent dMRI measurements of vertical occipital connections in humans and macaques can be compared with previous findings from invasive anatomical studies that examined connectivity, including relatively forgotten classic strychnine neuronography studies. We then review recent progress in understanding the neuroanatomy of vertical connections within the occipitotemporal cortex by combining modern quantitative MRI and classical histological measurements in human and macaque. Finally, we a) discuss current limitations of dMRI and tractography and b) consider potential paths for future investigations using dMRI and tractography for comparative neuroanatomical studies of white matter tracts between species. While we focus on vertical association connections in visual cortex in the present paper, this same approach can be applied to other white matter tracts. Similar efforts are likely to continue to advance our understanding of the neuroanatomical features of the brain that are shared across species, as well as to distinguish the features that are uniquely human.","Takemura H
Pestilli F
Weiner KS
","(PMID:30389574
)",Comparative neuroanatomy: Integrating classic and modern methods to understand association fibers connecting dorsal and ventral visual cortex.,https://europepmc.org/abstract/MED/30389574%0A
"The tumor-stroma ratio (TSR) reflected on hematoxylin and eosin (H&E)-stained histological images is a potential prognostic factor for survival. Automatic image processing techniques that allow for high-throughput and precise discrimination of tumor epithelium and stroma are required to elevate the prognostic significance of the TSR. As a variant of deep learning techniques, transfer learning leverages nature-images features learned by deep convolutional neural networks (CNNs) to relieve the requirement of deep CNNs for immense sample size when handling biomedical classification problems. Herein we studied different transfer learning strategies for accurately distinguishing epithelial and stromal regions of H&E-stained histological images acquired from either breast or ovarian cancer tissue. We compared the performance of important deep CNNs as either a feature extractor or as an architecture for fine-tuning with target images. Moreover, we addressed the current contradictory issue about whether the higher-level features would generalize worse than lower-level ones because they are more specific to the source-image domain. Under our experimental setting, the transfer learning approach achieved an accuracy of 90.2 (vs. 91.1 for fine tuning) with GoogLeNet, suggesting the feasibility of using it in assisting pathology-based binary classification problems. Our results also show that the superiority of the lower-level or the higher-level features over the other ones was determined by the architecture of deep CNNs.","Du Y
Zhang R
Zargari A
Thai TC
Gunderson CC
Moxley KM
Liu H
Zheng B
Qiu Y
","(PMID:30051247
)",Classification of Tumor Epithelium and Stroma by Exploiting Image Features Learned by Deep Convolutional Neural Networks.,https://europepmc.org/abstract/MED/30051247%0A
"This paper summarizes the current state-of-the-art in geomorphometry and describes the innovations that are close at hand and will be required to push digital terrain modeling forward in the future. These innovations will draw on concepts and methods from computer science and the spatial sciences and require greater collaboration to produce “actionable” knowledge and outcomes. The key innovations include rediscovering and using what we already know, developing new digital terrain modeling methods, clarifying and strengthening the role of theory, developing high-fidelity DEMs, developing and embracing new visualization methods, adopting new computational approaches, and making better use of provenance, credibility, and application-content knowledge.","Wilson JP
","(PPR:PPR55630
)",Geomorphometry: Today and Tomorrow,https://europepmc.org/abstract/PPR/PPR55630%0A
"Objects play vital roles in scene categorization. Although a number of studies have researched on the neural responses during object and object-based scene recognition, few studies have investigated the neural mechanism underlying object-masked scene categorization. Here, we used functional magnetic resonance imaging (fMRI) to measure the changes in brain activations and functional connectivity (FC) while subjects performed a visual scene-categorization task with different numbers of 'signature objects' masked. The object-selective region in the lateral occipital complex (LOC) showed a decrease in activations and changes in FC with the default mode network (DMN), indicating changes in object attention after the masking of signature objects. Changes in top-down modulation effect were revealed in the FC from the dorsolateral prefrontal cortex (DLPFC) to LOC and the extrastriate visual cortex, possibly participating in conscious object recognition. The whole-brain analyses showed the participation of fronto-parietal network (FPN) in scene categorization judgment, and right DLPFC served as the core hub in this network. Another core hub was found in left middle temporal gyrus (MTG) and its connection with middle cingulate cortex (MCC), supramarginal gyrus (SMG) and insula might serve in the processing of motor response and the semantic relations between objects and scenes. Brain-behavior correlation analysis substantiated the contributions of the FC to the different processes in the object-masked scene-categorization tasks. Altogether, the results suggest that masking of objects significantly affected the object attention, cognitive demand, top-down modulation effect, and semantic judgment.","Miao Q
Zhang G
Yan W
Liu B
","(PMID:30056114
)",Investigating the Brain Neural Mechanism when Signature Objects were Masked during a Scene Categorization Task using Functional MRI.,https://europepmc.org/abstract/MED/30056114%0A
"AIM:Cefepime, a fourth-generation cephalosporin, acts as a GABAA receptor antagonist. Cefepime-induced encephalopathy (CIE) is frequently overlooked. We aimed to clarify the clinical features, characteristic EEGs, and mechanisms of CIE to aid in its early recognition. METHODS:CIE cases documented by a single-center consultation-liaison team between April 2015 and March 2017 were retrospectively reviewed. For further investigation, neural mass modeling was performed in silico. RESULTS:Three patients with CIE refused medication/examination and showed overt pain, palilalia, and much greater deterioration of eye and verbal response than the motor response, which was possibly related to GABAergic dysfunction. Triphasic wave-like generalized periodic discharges with a high negative component (Tri-HNC) were identified on the EEG of all three cases. The simulation reproduced the characteristic feature of 2-3 Hz Tri-HNC and recovery course on EEG, and a possible involvement of individual differences in pharmacological intervention. It also suggested that auto-inhibition (synaptic inputs from interneuron to interneuron) dysregulation contributed to generating Tri-HNC in CIE. CONCLUSIONS:Since CIE is iatrogenic and continues unless cefepime is stopped, early recognition is crucial. Physicians should be vigilant about altered mental status, pain, and verbal changes in patients taking cefepime. Tri-HNC on EEG can expedite the diagnosis of CIE, and the association between Tri-HNC and CIE suggested that an excitatory and inhibitory (E/I) imbalance due to the dysfunction of GABAergic interneurons was the underlying mechanism. This modeling may offer a new method of investigating disorders related to GABAergic dysfunction. This article is protected by copyright. All rights reserved.","Tamune H
Hamamoto Y
Aso N
Yamamoto N
","(PMID:30375126
)",Cefepime-induced encephalopathy (CIE): Neural mass modeling of triphasic wave-like generalized periodic discharges with a high negative component (Tri-HNC).,https://europepmc.org/abstract/MED/30375126%0A
"We describe a robotic material that tightly integrates sensing, actuation, computation, and communication to perform autonomous shape change. The composite consists of multiple cells, each with the ability to control their local stiffness (by Joule heating of a thermoplastic) and communicate with their local neighbors. We also present a distributed algorithm for calculating the inverse kinematic solution of the resulting N-body system by iteratively solving a series of problems with reduced kinematics. We describe material design choices, mechanism design, algorithm, and manufacturing, emphasizing the interdisciplinary codesign problem that robotic materials pose, and demonstrate the results from a series of shape-changing experiments.","McEvoy MA
Correll N
","(PMID:30312147
)",Shape-Changing Materials Using Variable Stiffness and Distributed Control.,https://europepmc.org/abstract/MED/30312147%0A
"Objective: To evaluate the accuracy and feasibility of a custom robot system guided by navigation for lateral skull base tumor biopsy. Methods: Two cadaver heads were used, with iopamidol injected into different areas in the skull base and infratemporal region to imitate the tumor. Cone beam CT (CBCT) scanning was performed before operation. With image data transferred to the graphical user interface of the computer workstation, the ""tumor"" was segmented as the target. The needle trajectory was determined by selecting the skin entry point and the target point on the surgical planning software. Following point-based registration, the data was sent to the robot control unit. The needle was automatically inserted into the intended target by the robot guided by optical navigation. After the procedure was performed, the instantaneous data of needle tip position acquired by navigation system was sent back to the computer workstation for accuracy verification. Subsequently, after the needle was released, CBCT scanning was performed again, and the pre-and post-operative skull were superimposed. The position data of needle tip was acquired on the postoperative image and the accuracy was re-verified. The paired t-test was used to compare the differences in the accuracy calculated by intraoperative navigation and postoperative image fusion. The independent samples t-test was used to compare the accuracy between the cadavers. The Pearson correlation coefficients (r) was used to analyze correlation between the needle intervention accuracy and insertion depth. Results: All 20 interventions were successfully performed. The mean deviation of the needle tip was (0.67±0.28) mm (measured by the navigation system) and (3.19±0.39) mm (measured by image fusion) respectively (t=-23.238, P<0.001). The comparison of accuracy test showed no significant difference between the cadavers (t=-1.116, P=0.279). Pearson correlation coefficients (r=0.714, P<0.001) showed the close correlation between the needle intervention accuracy and insertion depth. The mean insertion depth was (5.14±0.21) cm. Conclusions: The experimental results show that the robot system is efficient and reliable. The navigation accuracy and the needle deflection are the most significant factors affecting robotic puncture procedures.","Zhu JH
Wang J
Liu XJ
Guo CB
","(PMID:30078263
)",[Accuracy analysis of robotic assistant needle placement for lateral skull base biopsy].,https://europepmc.org/abstract/MED/30078263%0A
"Developing drugs with anticancer activity and low toxic side-effects at low costs is a challenging issue for cancer chemotherapy. In this work, we propose to use molecular pathways as the therapeutic targets and develop a novel computational approach for drug repositioning for cancer treatment. We analyzed chemically induced gene expression data of 1112 drugs on 66 human cell lines and searched for drugs that inactivate pathways involved in the growth of cancer cells (cell cycle) and activate pathways that contribute to the death of cancer cells (e.g., apoptosis and p53 signaling). Finally, we performed a large-scale prediction of potential anticancer effects for all the drugs and experimentally validated the prediction results via three in vitro cellular assays that evaluate cell viability, cytotoxicity, and apoptosis induction. Using this strategy, we successfully identified several potential anticancer drugs. The proposed pathway-based method has great potential to improve drug repositioning research for cancer treatment.","Iwata M
Hirose L
Kohara H
Liao J
Sawada R
Akiyoshi S
Tani K
Yamanishi Y
","(PMID:30371064
)",Pathway-Based Drug Repositioning for Cancers: Computational Prediction and Experimental Validation.,https://europepmc.org/abstract/MED/30371064%0A
"Information security is of great importance for the approaching Internet of things (IoT) era. Physically unclonable functions (PUFs) have been intensively studied for information security. However, silicon PUFs are vulnerable to hazards such as modeling and side-channel attacks. Here we demonstrate a magnetic analogue PUF based on perpendicularly magnetized Ta/CoFeB/MgO heterostructures. The perpendicular magnetic anisotropy originates from the CoFeB/MgO interface, which is sensitive to the subnanometer variation of MgO thickness within a certain range (0.6-1.3 nm). When the MgO layer is thinned, a thickness variation resulting from ion milling nonuniformity induces unclonable random distributions of eas y-axis magnetization orientations in heterostructures. The analogue PUF can provide a much larger key size than a conventional binary-bit counterpart. Moreover, after the thinning process, the unique eas y-axis magnetization orientation in each single device was formed, which can avoid setting random states to realize low power consumption and high-density integration. This magnetic PUF is a promising innovative primitive for secret key generation and storage with high security in the IoT era.","Chen H
Song M
Guo Z
Li R
Zou Q
Luo S
Zhang S
Luo Q
Hong J
You L
","(PMID:30365330
)",Highly Secure Physically Unclonable Cryptographic Primitives Based on Interfacial Magnetic Anisotropy.,https://europepmc.org/abstract/MED/30365330%0A
"Magnesium (Mg) alloys as a new group of biodegradable metal implants are being extensively investigated as a promising selection for biomaterials applications due to their apt mechanical and biological performance. However, as a foremost drawback of Mg alloys, the high degradation in body fluid prevents its clinical applications. In this work, a bioceramic composite coating is developed composed of diopside, bredigite, and fluoridated hydroxyapatite on the AZ91 Mg alloy in order to moderate the degradation rate, while improving its bioactivity, cell compatibility, and mechanical integrity. Microstructural studies were performed using a transmission electron microscope (TEM), scanning electron microscope (SEM), X-ray diffraction (XRD) analysis, and energy dispersive spectroscopy (EDS). The degradation properties of samples were carried out under two steps, including electrochemical corrosion test and immersion test in simulated body fluid (SBF). Additionally, compression test was performed to evaluate the mechanical integrity of the specimens. L-929 fibroblast cells were cultured on the samples to determine the cell compatibility of the samples, including the cell viability and attachment. The degradation results suggest that the composite coating decreases the degradation and improves the bioactivity of AZ91 Mg alloy substrate. No considerable deterioration in the compression strength was observed for the coated samples compared to the uncoated sample after 4 weeks immersion. Cytotoxicity test indicated that the coatings improve the cell compatibility of AZ91 alloy for L-929 cells.","Razavi M
Fathi M
Savabi O
Tayebi L
Vashaee D
","(PMID:30350229
)",Improvement of in vitro behavior of an Mg alloy using a nanostructured composite bioceramic coating.,https://europepmc.org/abstract/MED/30350229%0A
"The optical properties of blood play crucial roles in medical diagnostics and treatment, and in the design of new medical devices. Haemoglobin is a vital constituent of the blood whose optical properties affect all of the optical properties of human blood. The refractive index of haemoglobin has been reported to strongly depend on its concentration which is a function of the physiology of biological cells. This makes the refractive index of haemoglobin an essential non-invasive bio-marker of diseases. Unfortunately, the complexity of blood tissue makes it challenging to experimentally measure the refractive index of haemoglobin. While a few studies have reported on the refractive index of haemoglobin, there is no solid consensus with the data obtained due to different measuring instruments and the conditions of the experiments. Moreover, obtaining the refractive index via an experimental approach is quite laborious. In this work, an accurate, fast and relatively convenient strategy to estimate the refractive index of haemoglobin is reported. Thus, the GA-SVR model is presented for the prediction of the refractive index of haemoglobin using wavelength, temperature, and the concentration of haemoglobin as descriptors. The model developed is characterised by an excellent accuracy and very low error estimates. The correlation coefficients obtained in these studies are 99.94% and 99.91% for the training and testing results, respectively. In addition, the result shows an almost perfect match with the experimental data and also demonstrates significant improvement over a recent mathematical model available in the literature. The GA-SVR model predictions also give insights into the influence of concentration, wavelength, and temperature on the RI measurement values. The model outcome can be used not only to accurately estimate the refractive index of haemoglobin but also could provide a reliable common ground to benchmark the experimental refractive index results.","Oyehan TA
Alade IO
Bagudu A
Sulaiman KO
Olatunji SO
Saleh TA
","(PMID:29777986
)",Predicting of the refractive index of haemoglobin using the Hybrid GA-SVR approach.,https://europepmc.org/abstract/MED/29777986%0A
"Most proteins perform their functions after a series of post translational modifications (PTMs). Post-translational modifications play crucial roles in various cell functions and biological process. Identifying the PTMs sites in proteins is very important to basic research and drug design. Computational identification of PTMs is a complementary way with its convenience. This review gave the process for prediction of post-translational modification sites including feature construction, algorithms, evaluation measurement, and online web-server. There are two types of post translational modification in proteins. In the prediction of single PTM sites, we transformed it into binary classification learning. While in the prediction of crosstalk PTM sites, we transformed it into multi-label learning. This review summarized the steps on the two issues.","Xu Y
Yang Y
Wang Z
Li C
Shao Y
","(PMID:30255739
)","A systematic review on posttranslational modification in proteins: feature construction, algorithm and webserver.",https://europepmc.org/abstract/MED/30255739%0A
"N6- methyladenosine (m6A) is a vital post-transcriptional modification, which adds another layer of epigenetic regulation at RNA level. It chemically modifies mRNA that effects protein expression. RNA sequence contains many genetic code motifs (GAC). Among these codes, identification of methylated or not methylated GAC motif is highly indispensable. However, with a large number of RNA sequences generated in post-genomic era, it becomes a challenging task how to accurately and speedily characterize these sequences. In view of this, the concept of an intelligent is incorporated with a computational model that truly and fast reflects the motif of the desired classes. An intelligent computational model ""iMethyl-STTNC"" model is proposed for identification of methyladenosine sites in RNA. In the proposed study, four feature extraction techniques, such as; Pseudo-dinucleotide-composition, Pseudo-trinucleotide-composition, split-trinucleotide-composition, and split-tetra-nucleotides-composition (STTNC) are utilized for genuine numerical descriptors. Three different classification algorithms including probabilistic neural network, Support vector machine (SVM), and K-nearest neighbor are adopted for prediction. After examining the outcomes of prediction model on each feature spaces, SVM using STTNC feature space reported the highest accuracy of 69.84%, 91.84% on dataset1 and dataset2, respectively. The reported results show that our proposed predictor has achieved encouraging results compared to the present approaches, so far in the research. It is finally reckoned that our developed model might be beneficial for in-depth analysis of genomes and drug development.","Akbar S
Hayat M
","(PMID:30031793
)",iMethyl-STTNC: Identification of N6-methyladenosine sites by extending the idea of SAAC into Chou's PseAAC to formulate RNA sequences.,https://europepmc.org/abstract/MED/30031793%0A
"Recently, implantable artificial subretinal chips using electronic components have replaced photoreceptors to serve as the most feasible treatment for retinal diseases. As such a chip that is meant to be implanted and used for very long periods, growing retinal cells on it to improve the electrical stimulation efficiency and attraction of neuronal elements remains a challenge. Here, an inkjet printing technology is employed to create graphene oxide (GO) micropatterns onto microelectrodes of a photovoltaic-powered implantable retinal chip. These GO micropatterns allow human retinal pigment epithelium (RPE) cells to specially attach and grow in each microelectrode. In addition, the cell proliferation, viability, and tight junction of RPE cells are improved during culturing. The development of a simple surface-coating technology would pave the way for the development of the first fully integrated and encapsulated retinal prostheses with biocompatible on-chip microelectrodes for long-term implantation, which could be effectively applied in retina tissue engineering and therapy.","Yang JW
Tseng ML
Fu YM
Kang CH
Cheng YT
Kuo PH
Tzeng CK
Chiou SH
Wu CY
Chen GY
","(PMID:30051620
)",Printable Graphene Oxide Micropatterns for a Bio-Subretinal Chip.,https://europepmc.org/abstract/MED/30051620%0A
"A phase of matter is a familiar notion for inanimate physical matter. The nature of a phase of matter transcends the microscopic material properties. For example, materials in the liquid phase have certain common properties independent of the chemistry of the constituents: liquids take the shape of the container; they flow; and they can be poured-alcohol, oil, and water as well as a Lennard-Jones computer model exhibit similar behavior when poised in the liquid phase. Here, we identify a hitherto unstudied ""phase"" of matter, the elixir phase, in a simple model of a polymeric chain whose backbone has the correct local cylindrical symmetry induced by the tangent to the chain. The elixir phase appears on breaking the cylindrical symmetry by adding side spheres along the negative normal direction, as in proteins. This phase, nestled between other phases, has multiple ground states made up of building blocks of helices and almost planar sheets akin to protein native folds. We discuss the similarities of this ""phase"" of a finite size system to the liquid crystal and spin glass phases. Our findings are relevant for understanding proteins; the creation of novel bioinspired nanomachines; and also may have implications for life elsewhere in the cosmos.","Škrbić T
Hoang TX
Maritan A
Banavar JR
Giacometti A
","(PMID:30371948
)",The elixir phase of chain molecules.,https://europepmc.org/abstract/MED/30371948%0A
"Genome-wide association studies (GWAS) have successfully discovered a number of disease-associated genetic variants in the past decade, providing an unprecedented opportunity for deciphering genetic basis of human inherited diseases. However, it is still a challenging task to extract biological knowledge from the GWAS data, due to such issues as missing heritability and weak interpretability. Indeed, the fact that the majority of discovered loci fall into noncoding regions without clear links to genes has been preventing the characterization of their functions and appealing for a sophisticated approach to bridge genetic and genomic studies. Towards this problem, network-based prioritization of candidate genes, which performs integrated analysis of gene networks with GWAS data, has emerged as a promising direction and attracted much attention. However, most existing methods overlook the sparse and noisy properties of gene networks and thus may lead to suboptimal performance. Motivated by this understanding, we proposed a novel method called REGENT for integrating multiple gene networks with GWAS data to prioritize candidate genes for complex diseases. We leveraged a technique called the network representation learning to embed a gene network into a compact and robust feature space, and then designed a hierarchical statistical model to integrate features of multiple gene networks with GWAS data for the effective inference of genes associated with a disease of interest. We applied our method to six complex diseases and demonstrated the superior performance of REGENT over existing approaches in recovering known disease-associated genes. We further conducted a pathway analysis and showed that the ability of REGENT to discover disease-associated pathways. We expect to see applications of our method to a broad spectrum of diseases for post-GWAS analysis. REGENT is freely available at https://github.com/wmmthu/REGENT.","Wu M
Zeng W
Liu W
Lv H
Chen T
Jiang R
","(PMID:29874547
)",Leveraging multiple gene networks to prioritize GWAS candidate genes via network representation learning.,https://europepmc.org/abstract/MED/29874547%0A
No abstract provided.,"Kwok R
","(PMID:30206146
 PMCID:PMC6140515)",Science and Culture: Raw data videos offer a glimpse into laboratory research.,https://europepmc.org/abstract/MED/30206146%0A
"Least squares regression (LSR) is a fundamental statistical analysis technique that has been widely applied to feature learning. However, limited by its simplicity, the local structure of data is easy to neglect, and many methods have considered using orthogonal constraint for preserving more local information. Another major drawback of LSR is that the loss function between soft regression results and hard target values cannot precisely reflect the classification ability; thus, the idea of the large margin constraint is put forward. As a consequence, we pay attention to the concepts of large margin and orthogonal constraint to propose a novel algorithm, orthogonal least squares regression with large margin (OLSLM), for multiclass classification in this letter. The core task of this algorithm is to learn regression targets from data and an orthogonal transformation matrix simultaneously such that the proposed model not only ensures every data point can be correctly classified with a large margin than conventional least squares regression, but also can preserve more local data structure information in the subspace. Our efficient optimization method for solving the large margin constraint and orthogonal constraint iteratively proved to be convergent in both theory and practice. We also apply the large margin constraint in the process of generating a sparse learning model for feature selection via joint [Formula: see text]-norm minimization on both loss function and regularization terms. Experimental results validate that our method performs better than state-of-the-art methods on various real-world data sets.","Zhao H
Wang S
Wang Z
","(PMID:30021086
)",Multiclass Classification and Feature Selection Based on Least Squares Regression with Large Margin.,https://europepmc.org/abstract/MED/30021086%0A
"Growth rate of the protein sequence universe dramatically exceeds the speed of expansion for the protein structure universe, generating an immense dark proteome that includes proteins with unknown structure. A whole-proteome scale analysis of 5.4 million proteins from 987 proteomes in the three domains of life and viruses to systematically dissect an interplay between structural coverage, degree of putative intrinsic disorder, and predicted propensity for structure determination is performed. It has been found that Archaean and Bacterial proteomes have relatively high structural coverage and low amounts of disorder, whereas Eukaryotic and Viral proteomes are characterized by a broad spread of structural coverage and higher disorder levels. The analysis reveals that dark proteomes (i.e., proteomes containing high fractions of proteins with unknown structure) have significantly elevated amounts of intrinsic disorder and are predicted to be difficult to solve structurally. Although the majority of dark proteomes are of viral origin, many dark viral proteomes have at least modest crystallization propensity and only a handful of them are enriched in the intrinsic disorder. The disorder, structural coverage, and propensity are mapped for structural determination onto a novel proteome-level sequence similarity network to analyze the interplay of these characteristics in the taxonomic landscape.","Hu G
Wang K
Song J
Uversky VN
Kurgan L
","(PMID:30198635
)","Taxonomic Landscape of the Dark Proteomes: Whole-Proteome Scale Interplay Between Structural Darkness, Intrinsic Disorder, and Crystallization Propensity.",https://europepmc.org/abstract/MED/30198635%0A
No abstract provided.,"Cinelli C
Pearl J
","(PMID:30096057
)",On the utility of causal diagrams in modeling attrition: a practical example.,https://europepmc.org/abstract/MED/30096057%0A
"MOTIVATION:Modern analytical techniques such as LC-MS, GC-MS and NMR are increasingly being used to study the underlying dynamics of biological systems by tracking changes in metabolite levels over time. Such techniques are capable of providing information on large numbers of metabolites simultaneously, a feature that is exploited in non-targeted studies. However, since the dynamics of specific metabolites are unlikely to be known a priori this presents an initial subjective challenge as to where the focus of the investigation should be. Whilst a number of feed-forward software tools are available for manipulation of metabolomic data, no tool centralizes on clustering and focus is typically directed by a workflow that is chosen in advance. RESULTS:We present an interactive approach to time-course analyses and a complementary implementation in a software package, MetaboClust. This is presented through the analysis of two LC-MS time-course case studies on plants (Medicago truncatula and Alopecurus myosuroides). We demonstrate a dynamic, user-centric workflow to clustering with intrinsic visual feedback at all stages of analysis. The software is used to apply data correction, generate the time-profiles, perform exploratory statistical analysis and assign tentative metabolite identifications. Clustering is used to group metabolites in an unbiased manner, allowing pathway analysis to score metabolic pathways, based on their overlap with clusters showing interesting trends.","Rusilowicz MJ
Dickinson M
Charlton AJ
O'Keefe S
Wilson J
","(PMID:30372459
 PMCID:PMC6205582)",MetaboClust: Using interactive time-series cluster analysis to relate metabolomic data with perturbed pathways.,https://europepmc.org/abstract/MED/30372459%0A
No abstract provided.,"Uda K
Morioka I
","(PMID:29877206
)",[Effect of an application program for managing hours of working with visual display terminals (VDT) on computer-related subjective symptoms].,https://europepmc.org/abstract/MED/29877206%0A
"PURPOSE:Segmentations produced manually by experts or by algorithms are subject to variability, as they depend on many factors, e.g., the structure of interest, the resolution, contrast and quality of the images, and the expert experience or the algorithmic method. To properly assess the quality of these segmentations, it is thus essential to quantify their variability. However, obtaining reference variability ground truth requires several observers to manually delineate structures, which is time-consuming and impractical. METHODS:We describe a new comprehensive formal framework for segmentation evaluation and variability estimation without ground truth and a generic method for automatic segmentation variability estimation based on segmentation priors and multivariate sensitivity analysis. The method inputs the image scan and a user-validated segmentation of the structure of interest and uses predefined segmentation priors to compute a variability estimation around the given segmentation. The segmentation priors are combined with an integrator function whose sensitivity around the given segmentation is the segmentation variability. RESULTS:We validate our methods with two studies. The first study establishes the reference manual delineation variability. Eleven radiologists with varying levels of expertise manually delineated the contours of liver tumors, lung tumors, kidneys, and brain hematomas on 2,835 delineations from 18 CT scans. The relative delineation volume variability ranges are 51 [-24,+27]% for liver tumors, 56 [-25,+31]% for lung tumors, 25 [-12,+13]% for kidney contours, and 53 [-24,+29]% brain hematomas. The second study compares the estimated segmentation variability results to this reference data. The mean volume variability difference of the delineation is <6%, with a Dice similarity coefficient of >70% with respect to the mean manual delineation variability data. CONCLUSIONS:Reliable segmentation variability estimation with no ground truth enables the establishment of a proper observer variability reference. The segmentation variability should be taken into account when setting reference standards for clinical decisions based on volumetric measurements and when evaluating segmentation algorithms.","Joskowicz L
Cohen D
Caplan N
Sosna J
","(PMID:30208356
)",Automatic segmentation variability estimation with segmentation priors.,https://europepmc.org/abstract/MED/30208356%0A
"There are many different methods of meniscal allograft measurements, which depend on individual tissue bank procedures. Due to the lack of a standardised method of dimensioning, measurement results may vary between individual cases. Consequently, allograft may be mismatched to the patient's knee anatomy. The purpose of this study was to measure four meniscal dimensions - two standard and two specific - and then compare them between sexes.Fourteen cadaveric lateral menisci (seven male and seven female) were scanned using a microtomography scanner. The obtained three-dimensional (3-D) models of each meniscus were analysed, taking into account four dimensions: circumference, width, central meniscal concavity, and total meniscal volume. The computer researcher was not informed of the original data of the meniscal samples until the calculations were completed.No statistical between-sex differences were found in the standard dimensions. The specific dimensions, in turn, presented statistically significant between-sex differences (P>0.05). The mean difference between male and female total volume of the meniscus was equal to 36.59%, and the mean difference between male and female central meniscal concavity surface was equal to 31.22%.This study found that sex should be taken into account as an important factor during a matching procedure performed by tissue bank staff.","Mickiewicz P
Walczak M
Łaszczyca M
Kusz D
Wróbel Z
","(PMID:29352626
)",Differences between sexes in the standard and advanced dimensioning of lateral meniscal allografts.,https://europepmc.org/abstract/MED/29352626%0A
"BACKGROUND AND OBJECTIVE:Automatic classification of healthy tissues and organs based on histology images is an open problem, mainly due to the lack of automated tools. Solutions in this regard have potential in educational medicine and medical practices. Some preliminary advances have been made using image processing techniques and classical supervised learning. Due to the breakthrough performance of deep learning in various areas, we present an approach to recognise and classify, automatically, fundamental tissues and organs using Convolutional Neural Networks (CNN). METHODS:We adapt four popular CNNs architectures - ResNet, VGG19, VGG16 and Inception - to this problem through transfer learning. The resulting models are evaluated at three stages. Firstly, all the transferred networks are compared to each other. Secondly, the best resulting fine-tuned model is compared to an ad-hoc 2D multi-path model to outline the importance of transfer learning. Thirdly, the same model is evaluated against the state-of-the-art method, a cascade SVM using LBP-based descriptors, to contrast a traditional machine learning approach and a representation learning one. The evaluation task consists of separating six classes accurately: smooth muscle of the elastic artery, smooth muscle of the large vein, smooth muscle of the muscular artery, cardiac muscle, loose connective tissue, and light regions. The different networks are tuned on 6000 blocks of 100 × 100 pixels and tested on 7500. RESULTS:Our proposal yields F-score values between 0.717 and 0.928. The highest and lowest performances are for cardiac muscle and smooth muscle of the large vein, respectively. The main issue leading to limited classification scores for the latter class is its similarity with the elastic artery. However, this confusion is evidenced during manual annotation as well. Our algorithm reached improvements in F-score between 0.080 and 0.220 compared to the state-of-the-art machine learning approach. CONCLUSIONS:We conclude that it is possible to classify healthy cardiovascular tissues and organs automatically using CNNs and that deep learning holds great promise to improve tissue and organs classification. We left our training and test sets, models and source code publicly available to the research community.","Mazo C
Bernal J
Trujillo M
Alegre E
","(PMID:30337082
)",Transfer learning for classification of cardiovascular tissues in histological images.,https://europepmc.org/abstract/MED/30337082%0A
"With the increasing demand for novel bone repair solutions that overcome the drawbacks of current grafting techniques, the design of artificial bone scaffolds is a central focus in bone regeneration research. Calcium phosphate scaffolds are interesting given their compositional similarity with bone mineral. The majority of studies focus on bone growth in the macropores (>100 µm) of implanted calcium phosphate scaffolds where bone structures such as osteons and trabeculae can form. However, a growing body of research shows that micropores (<50 µm) play an important role not only in improving bone growth in the macropores, but also in providing additional space for bone growth. Bone growth in the micropores of calcium phosphate scaffolds offers major mechanical advantages as it improves the mechanical properties of the otherwise brittle materials, further stabilizes the implant, improves load transfer, and generally enhances osteointegration. In this paper, we review evidence in the literature of bone growth into micropores, emphasizing on identification techniques and conditions under which bone components are observed in the micropores. We also review theories on mineralization and propose mechanisms, mediated by cells or not, by which mineralization may occur in the confined micropore space of calcium phosphate scaffolds. Understanding and validating these mechanisms will allow to better control and enhance mineralization in micropores to improve the design and efficiency of bone implants. STATEMENT OF SIGNIFICANCE: The design of synthetic bone scaffolds remains a major focus for engineering solutions to repair damaged and diseased bone. Most studies focus on the design of and growth in macropores (>100 µm), however research increasingly shows the importance of microporosity (<50 µm). Micropores provide an additional space for bone growth, which provides multiple mechanical advantages to the scaffold/bone composite. Here, we review evidence of bone growth into micropores in calcium phosphate scaffolds and conditions under which growth occurs in micropores, and we propose mechanisms that enable or facilitate growth in these pores. Understanding these mechanisms will allow researchers to exploit them and improve the design and efficiency of bone implants.","Rustom LE
Poellmann MJ
Wagoner Johnson AJ
","(PMID:30408560
)",Mineralization in micropores of calcium phosphate scaffolds.,https://europepmc.org/abstract/MED/30408560%0A
"Computer-aided design (CAD) and additive manufacturing (AM) have shown promise in facilitating the fabrication of custom trays. Due to the clinical requirements, custom tray materials should achieve good bonding to the impression/adhesive systems. This study evaluated the retention of three fused deposition modeling (FDM) custom tray materials to a silicone impression/adhesive system before and after gritblasting (GB) by peel-off test. CAD-designed experimental test blocks were printed by FDM using acrylonitrile butadiene styrene (ABS), polyethylene terephthalate glycol copolyester (PETG), and high impact polystyrene (HIPS), and the reference test blocks were made of a conventional light-curing resin (n = 11). Before and after GB, the surface topography of all tray materials was analysed, and the maximum strength of the test block peeled off from a silicone impression/adhesive system was measured. After GB, the arithmetic mean height (Sa) and the valley fluid retention index (Svi) of the four material groups declined (p < 0.05). The peel-off strength of each of the four material groups significantly decreased by GB (p < 0.05), but no statistical difference could be found among them before or after GB. In all peel-off tests, adhesive failure occurred at the adhesive-impression material interface. The results indicated ABS, HIPS, and PETG could provide sufficient adhesion to the adhesive as the conventional light-curing resin, and GB could reduce the roughness generated by FDM and weaken the bonding between the adhesive and the silicone impression.","Xu Y
Unkovskiy A
Klaue F
Rupp F
Geis-Gerstorfer J
Spintzyk S
","(PMID:30301282
 PMCID:PMC6213137)",Compatibility of a Silicone Impression/Adhesive System to FDM-Printed Tray Materials-A Laboratory Peel-off Study.,https://europepmc.org/abstract/MED/30301282%0A
"Logic circuit device and molecular computer are idealized binary tools that implement manifold signal transformation and operation and is a basic component of integrated circuits and is widely used in computer, computerized numerical control, and communication fields. By combining the advantages of synthetic feasibility and enantioselective luminescent recognition, a logic device based on the lanthanide functional membrane has been constructed to effectively recognize the enantiomer and judge the enantiomer excess of the chair drug mixture. In addition, it would be interesting if such a logic circuit could be assembled into a loop circuit to realize intelligent control of the electronic component. Read-only memory arrays built by the logic circuit are also actualized, which can be converted and stored in binary strings. This work provides an active and universal approach to modulate a luminescent device and logic circuit based on a chemical sensor, with promising application for intelligent control, information processing, and human-machine interaction.","Lian X
Yan B
","(PMID:30091583
)",Luminescent Hybrid Membrane-Based Logic Device: From Enantioselective Discrimination to Read-Only Memory for Information Processing.,https://europepmc.org/abstract/MED/30091583%0A
"Recently, L1-norm distance measure based Linear Discriminant Analysis (LDA) techniques have been shown to be robust against outliers. However, these methods have no guarantee of obtaining a satisfactory-enough performance due to the insufficient robustness of L1-norm measure. To mitigate this problem, inspired by recent works on Lp-norm based learning, this paper proposes a new discriminant method, called Lp- and Ls-Norm Distance Based Robust Linear Discriminant Analysis (FLDA-Lsp). The proposed method achieves robustness by replacing the L2-norm within- and between-class distances in conventional LDA with Lp- and Ls-norm ones. By specifying the values of p and s, many of previous efforts can be naturally expressed by our objective. The requirement of simultaneously maximizing and minimizing a number of Lp- and Ls-norm terms results in a difficulty to the optimization of the formulated objective. As one of the important contributions of this paper, we design an efficient iterative algorithm to address this problem, and also conduct some insightful analysis on the existence of local minimum and the convergence of the proposed algorithm. Theoretical insights of our method are further supported by promising experimental results on several images databases.","Ye Q
Fu L
Zhang Z
Zhao H
Naiem M
","(PMID:29940488
)",Lp- and Ls-Norm Distance Based Robust Linear Discriminant Analysis.,https://europepmc.org/abstract/MED/29940488%0A
"A mathematical model for Vibrio Cholerae (V. Cholerae) in a closed environment is considered, with the aim of investigating the impact of climatic factors which exerts a direct influence on the bacterial metabolism and on the bacterial reservoir capacity. We first propose a V. Cholerae mathematical model in a closed environment. A sensitivity analysis using the eFast method was performed to show the most important parameters of the model. After, we extend this V. cholerae model by taking account climatic factors that influence the bacterial reservoir capacity. We present the theoretical analysis of the model. More precisely, we compute equilibria and study their stabilities. The stability of equilibria was investigated using the theory of periodic cooperative systems with a concave nonlinearity. Theoretical results are supported by numerical simulations which further suggest the necessity to implement sanitation campaigns of aquatic environments by using suitable products against the bacteria during the periods of growth of aquatic reservoirs.","Kolaye G
Damakoa I
Bowong S
Houe R
Békollè D
","(PMID:29728954
)",Theoretical Assessment of the Impact of Climatic Factors in a Vibrio Cholerae Model.,https://europepmc.org/abstract/MED/29728954%0A
"The patient's expression of pain using digital-body maps expands analytic opportunities for exploring the spatial variation of bodily pain. A common knee pain condition in adolescents and adults is patellofemoral pain (PFP) and recently PFP was shown to be characterized by a heterogeneous distribution of pain. Whether there are important patterns in these distributions remains unclear. This pioneering study assesses the spatial variation of pain using principal component analysis and a clustering approach. Detailed digital-body maps of knee pain were drawn by 299 PFP patients of mixed sex, age, and pain severity. Three pain distribution patterns emerged resembling an Anchor, Hook, and an Ovate shape on and around the patella. The variations in pain distribution were independent of sex, age, and pain intensity. Bilateral pain associated with a longer duration of pain and the majority characterized by the Hook and Ovate pain distributions. Bilateral and/or symmetrical pain between the left and right knees may represent symptoms associated with longstanding PFP. The distinct patterns of pain location and area suggest specific underlying structures cannot be ruled out as important drivers, although central neuronal mechanisms possibly exemplified by the symmetrical representation of pain may play a role in individuals with longstanding symptoms.","Boudreau SA
Royo AC
Matthews M
Graven-Nielsen T
Kamavuako EN
Slabaugh G
Thorborg K
Vicenzino B
Rathleff MS
","(PMID:30410031
 PMCID:PMC6224396)",Distinct patterns of variation in the distribution of knee pain.,https://europepmc.org/abstract/MED/30410031%0A
"Ophthalmic medical images, such as optical coherence tomography (OCT) images and color photo of fundus, provide valuable information for clinical diagnosis and treatment of ophthalmic diseases. In this paper, we introduce a software system specially oriented to ophthalmic images processing, analysis, and visualization (OIPAV) to assist users. OIPAV is a cross-platform system built on a set of powerful and widely used toolkit libraries. Based on the plugin mechanism, the system has an extensible framework. It provides rich functionalities including data I/O, image processing, interaction, ophthalmic diseases detection, data analysis, and visualization. By using OIPAV, users can easily access to the ophthalmic image data manufactured from different imaging devices, facilitate workflows of processing ophthalmic images, and improve quantitative evaluations. With a satisfying function scalability and expandability, the software is applicable for both ophthalmic researchers and clinicians.","Zhang L
Xiang D
Jin C
Shi F
Yu K
Chen X
","(PMID:30187316
)","OIPAV: an Integrated Software System for Ophthalmic Image Processing, Analysis, and Visualization.",https://europepmc.org/abstract/MED/30187316%0A
"One of the most interesting fields of research in cancer diagnosis is tracing the relation between extracellular media and cancer progression. Detecting the secreting contents of the cells and translating these molecular identifications into label-free recognizable patterns would open new opportunities in cancer research. Electrochemical responses are in the range of most attractive sensing mechanisms especially in biochemical approaches. Perturbed ionic exchanges as a known biochemical function of cancer cells presented a strong correlation with the pH of the tumor microenvironment. Different ionic activities detected by an electrochemical bio-sensing system in the malignant and normal cells in the presence of acidic ambient were our main results presented in this research. Herein, silicon Nano-roughened substrate as a well-known electrochemical interface was applied in the construction of the biosensor. Viability rate as well as apoptotic factors involving in cancer progression were assessed by biochemical assays in normal (MCF10A) and cancer (MCF7 and MDA-MB468) breast cells. Our findings demonstrated that pH-based electrochemical responses were matched with the results obtained from the biological analyses of both normal and malignant cells. Induction of acidosis in the cells followed by monitoring their electrochemical responses would be a new trend in microenvironment based cancer investigation.","Alikhani A
Gharooni M
Moghtaderi H
Farokhmanesh F
Abiri H
Salimi M
Attari F
Abdolahad M
","(PMID:30219672
)",An electrochemical biosensor to distinguish between normal and cancer cells based on monitoring their acidosis using gold-coated silicon Nano-roughened electrode.,https://europepmc.org/abstract/MED/30219672%0A
No abstract provided.,"Adam GC
","(PMID:29872204
)",Two artificial synapses are better than one.,https://europepmc.org/abstract/MED/29872204%0A
"Deep learning involves a difficult nonconvex optimization problem with a large number of weights between any two adjacent layers of a deep structure. To handle large data sets or complicated networks, distributed training is needed, but the calculation of function, gradient, and Hessian is expensive. In particular, the communication and the synchronization cost may become a bottleneck. In this letter, we focus on situations where the model is distributedly stored and propose a novel distributed Newton method for training deep neural networks. By variable and feature-wise data partitions and some careful designs, we are able to explicitly use the Jacobian matrix for matrix-vector products in the Newton method. Some techniques are incorporated to reduce the running time as well as memory consumption. First, to reduce the communication cost, we propose a diagonalization method such that an approximate Newton direction can be obtained without communication between machines. Second, we consider subsampled Gauss-Newton matrices for reducing the running time as well as the communication cost. Third, to reduce the synchronization cost, we terminate the process of finding an approximate Newton direction even though some nodes have not finished their tasks. Details of some implementation issues in distributed environments are thoroughly investigated. Experiments demonstrate that the proposed method is effective for the distributed training of deep neural networks. Compared with stochastic gradient methods, it is more robust and may give better test accuracy.","Wang CC
Tan KL
Chen CT
Lin YH
Keerthi SS
Mahajan D
Sundararajan S
Lin CJ
","(PMID:29652589
)",Distributed Newton Methods for Deep Neural Networks.,https://europepmc.org/abstract/MED/29652589%0A
"PURPOSE:With the advent of robot-assisted surgery, the role of data-driven approaches to integrate statistics and machine learning is growing rapidly with prominent interests in objective surgical skill assessment. However, most existing work requires translating robot motion kinematics into intermediate features or gesture segments that are expensive to extract, lack efficiency, and require significant domain-specific knowledge. METHODS:We propose an analytical deep learning framework for skill assessment in surgical training. A deep convolutional neural network is implemented to map multivariate time series data of the motion kinematics to individual skill levels. RESULTS:We perform experiments on the public minimally invasive surgical robotic dataset, JHU-ISI Gesture and Skill Assessment Working Set (JIGSAWS). Our proposed learning model achieved competitive accuracies of 92.5%, 95.4%, and 91.3%, in the standard training tasks: Suturing, Needle-passing, and Knot-tying, respectively. Without the need of engineered features or carefully tuned gesture segmentation, our model can successfully decode skill information from raw motion profiles via end-to-end learning. Meanwhile, the proposed model is able to reliably interpret skills within a 1-3 second window, without needing an observation of entire training trial. CONCLUSION:This study highlights the potential of deep architectures for efficient online skill assessment in modern surgical training.","Wang Z
Majewicz Fey A
","(PMID:30255463
)",Deep learning with convolutional neural network for objective skill evaluation in robot-assisted surgery.,https://europepmc.org/abstract/MED/30255463%0A
"Gesture recognition based on surface electromyogram (sEMG) signals has drawn significant attention and obtained satisfactory achievement in the field of human-computer interaction. However, the same gesture performed with different arm positions tends not to generate the same sEMG signals. Traditional solutions can be divided into two types. One type treats the same gesture with different arm positions as the same type, leading to a relatively low classification rate. The other type adopts a gesture classifier followed by the position classifier, which will achieve a satisfactory classification accuracy but at the expenses of high training burdens. To address these issues, we propose a novel framework to explore the intrinsic position independent (PI) characteristics of sEMG signals generated from the same gesture with different arm positions by canonical correlation analysis (CCA), termed as PICCA. In this framework, with the bridge link of the predefined expert set, both the training set and the testing set can be mapped into a unified-style with CCA, and hence, the classification accuracy can be improved in both user-dependent and user-independent manners. Experimental results on 13 gestures with 3 arm positions indicate that the proposed PICCA can achieve higher classification rates than those without CCA (with 28.52% and 44.19% promotions during user-dependent and user-independent manners respectively) while maintaining acceptable training burdens. These improvements will facilitate the practical implementation of myoelectric interfaces.","Cheng J
Wei F
Li C
Liu Y
Liu A
Chen X
","(PMID:30340212
)",Position-independent gesture recognition using sEMG signals via canonical correlation analysis.,https://europepmc.org/abstract/MED/30340212%0A
"microRNAs (miRNAs) functioning in gene silencing have been associated with cancer progression. However, common abnormal miRNA expression patterns and their potential roles in cancer have not yet been evaluated. To account for individual differences between patients, we retrieved miRNA sequencing data for 575 patients with both tumor and adjacent non-tumorous tissues from 14 cancer types from The Cancer Genome Atlas (TCGA). We then performed differential expression analysis using DESeq2 and edgeR. Results showed that cancer types can be grouped based on the distribution of miRNAs with different expression patterns between tumor and non-tumor samples. We found 81 significantly differentially expressed miRNAs (SDEmiRNAs) in a single cancer. We also found 21 key SDEmiRNAs (nine over-expressed and 12 under-expressed) associated with at least eight cancers each and enriched in more than 60% of patients per cancer, including four newly identified SDEmiRNAs (hsa-mir-4746, hsa-mir-3648, hsa-mir-3687, and hsa-mir-1269a). The downstream effects of these 21 SDEmiRNAs on cellular function were evaluated through enrichment and pathway analysis of 7186 protein-coding gene targets mined from literature reports of differential expression of miRNAs in cancer. This analysis enables identification of SDEmiRNA functional similarity in cell proliferation control across a wide range of cancers, and assembly of common regulatory networks over cancer-related pathways. These findings were validated by construction of a regulatory network in the PI3K pathway. This study provides evidence for the value of further analysis of SDEmiRNAs as potential biomarkers and therapeutic targets for cancer diagnosis and treatment.","Hu Y
Dingerdissen H
Gupta S
Kahsay R
Shanker V
Wan Q
Yan C
Mazumder R
","(PMID:30384176
)",Identification of key differentially expressed MicroRNAs in cancer patients through pan-cancer analysis.,https://europepmc.org/abstract/MED/30384176%0A
A correction to this article has been published and is linked from the HTML version of this paper. The error has not been fixed in the paper.,"Yang Y
Luo T
Li Z
Zhang X
Yu PS
","(PMID:29520091
 PMCID:PMC5843598)",Author Correction: A Robust Method for Inferring Network Structures.,https://europepmc.org/abstract/MED/29520091%0A
"OBJECTIVE:To determine the association between ruptured saccular aneurysms and aspirin use/aspirin dose. METHODS:Four thousand seven hundred one patients who were diagnosed at the Massachusetts General Hospital and Brigham and Women's Hospital between 1990 and 2016 with 6,411 unruptured and ruptured saccular intracranial aneurysms were evaluated. Univariable and multivariable logistic regression analyses were performed to determine the association between aneurysmal subarachnoid hemorrhage and aspirin use, including aspirin dose. Inverse probability weighting using propensity scores was used to adjust for potential differences in baseline characteristics between cases and controls. Additional analyses were performed to examine the association of aspirin use and rerupture before treatment. RESULTS:In multivariate analysis with propensity score weighting, aspirin use (odds ratio [OR] 0.60, 95% confidence interval [CI] 0.45-0.80) was significantly associated with decreased risk of ruptured intracranial aneurysms. There was a significant inverse dose-response relationship between aspirin dose and aneurysmal subarachnoid hemorrhage (OR 0.65, 95% CI 0.53-0.81). In contrast, there was a significant association between aspirin use and increased risk of rerupture before treatment (OR 8.15, 95% CI 2.22-30.0). CONCLUSIONS:In this large case-control study, aspirin therapy at diagnosis was associated with a significantly decreased risk of subarachnoid hemorrhage, with an inverse dose-response relationship among aspirin users. However, once rupture has occurred, aspirin is associated with an increased risk of rerupture before treatment.","Can A
Rudy RF
Castro VM
Yu S
Dligach D
Finan S
Gainer V
Shadick NA
Savova G
Murphy S
Cai T
Weiss ST
Du R
",(PMID:30135253),Association between aspirin dose and subarachnoid hemorrhage from saccular aneurysms: A case-control study.,https://europepmc.org/abstract/MED/30135253
